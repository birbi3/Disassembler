
[]

[<td>37</td>, <td>AAA</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>ASCII adjust AL after addition.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If in 64-bit mode.</td>]

[<td>D5 0A</td>, <td>AAD</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>ASCII adjust AX before division.</td>, <td>D5 <em>ib</em></td>, <td>AAD imm8</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Adjust AX before division to number base <em>imm8.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If in 64-bit mode.</td>]

[<td>D4 0A</td>, <td>AAM</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>ASCII adjust AX after multiply.</td>, <td>D4 <em>ib</em></td>, <td>AAM imm8</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Adjust AX after multiply to number base <em>imm8.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#DE</td>, <td>If an immediate value of 0 is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If in 64-bit mode.</td>]

[<td>3F</td>, <td>AAS</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>ASCII adjust AL after subtraction.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If in 64-bit mode.</td>]

[<td>14 <em>ib</em></td>, <td>ADC AL, <em>imm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Add with carry <em>imm8</em> to AL.</td>, <td>15 <em>iw</em></td>, <td>ADC AX, <em>imm16</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Add with carry <em>imm16</em> to AX.</td>, <td>15 <em>id</em></td>, <td>ADC EAX, <em>imm32</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Add with carry <em>imm32</em> to EAX.</td>, <td>REX.W + 15 <em>id</em></td>, <td>ADC RAX, <em>imm32</em></td>, <td>I</td>, <td>Valid</td>, <td>N.E.</td>, <td>Add with carry <em>imm32 sign extended to 64-bits</em> to RAX.</td>, <td>80 /2 <em>ib</em></td>, <td>ADC <em>r/m8</em>, <em>imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Add with carry <em>imm8</em> to <em>r/m8.</em></td>, <td>REX + 80 /2 <em>ib</em></td>, <td>ADC <em>r/m8</em><sup>*</sup>, <em>imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Add with carry <em>imm8</em> to <em>r/m8.</em></td>, <td>81 /2 <em>iw</em></td>, <td>ADC <em>r/m16, imm16</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Add with carry <em>imm16</em> to <em>r/m16.</em></td>, <td>81 /2 <em>id</em></td>, <td>ADC <em>r/m32, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Add with CF <em>imm32</em> to <em>r/m32.</em></td>, <td>REX.W + 81 /2 <em>id</em></td>, <td>ADC <em>r/m64, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Add with CF <em>imm32</em> sign extended to 64-bits to <em>r/m64.</em></td>, <td>83 /2 <em>ib</em></td>, <td>ADC <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Add with CF sign-extended <em>imm8</em> to <em>r/m16.</em></td>, <td>83 /2 <em>ib</em></td>, <td>ADC <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Add with CF sign-extended <em>imm8</em> into <em>r/m32.</em></td>, <td>REX.W + 83 /2 <em>ib</em></td>, <td>ADC <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Add with CF sign-extended <em>imm8</em> into <em>r/m64.</em></td>, <td>10 /<em>r</em></td>, <td>ADC <em>r/m8, r8</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Add with carry byte register to <em>r/m8.</em></td>, <td>REX + 10 /<em>r</em></td>, <td>ADC <em>r/m8</em><sup>*</sup><em>, r8</em><sup>*</sup></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Add with carry byte register to <em>r/m64.</em></td>, <td>11 /<em>r</em></td>, <td>ADC <em>r/m16, r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Add with carry <em>r16</em> to <em>r/m16.</em></td>, <td>11 /<em>r</em></td>, <td>ADC <em>r/m32, r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Add with CF <em>r32</em> to <em>r/m32.</em></td>, <td>REX.W + 11 /<em>r</em></td>, <td>ADC <em>r/m64, r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Add with CF <em>r64</em> to <em>r/m64.</em></td>, <td>12 /<em>r</em></td>, <td>ADC <em>r8, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Add with carry <em>r/m8</em> to byte register.</td>, <td>REX + 12 /<em>r</em></td>, <td>ADC <em>r8</em><sup>*</sup><em>, r/m8</em><sup>*</sup></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Add with carry <em>r/m64</em> to byte register.</td>, <td>13 /<em>r</em></td>, <td>ADC <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Add with carry <em>r/m16</em> to <em>r16.</em></td>, <td>13 /<em>r</em></td>, <td>ADC <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Add with CF <em>r/m32</em> to <em>r32.</em></td>, <td>REX.W + 13 /<em>r</em></td>, <td>ADC <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Add with CF <em>r/m64</em> to <em>r64.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>MR</td>, <td>ModRM:r/m (r, w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td>I</td>, <td>AL/AX/EAX/RAX</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>66 0F 38 F6 /r ADCX r32, r/m32</td>, <td>RM</td>, <td>V/V</td>, <td>ADX</td>, <td>Unsigned addition of r32 with CF, r/m32 to r32, writes CF.</td>, <td>66 REX.w 0F 38 F6 /r ADCX r64, r/m64</td>, <td>RM</td>, <td>V/NE</td>, <td>ADX</td>, <td>Unsigned addition of r64 with CF, r/m64 to r64, writes CF.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.ADX[bit 19] = 0.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td rowspan="2">#GP(0)</td>, <td>For an illegal memory operand effective address in the CS, DS, ES, FS or GS segments.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a null segment selector.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.ADX[bit 19] = 0.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#GP(0)</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.ADX[bit 19] = 0.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#GP(0)</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.ADX[bit 19] = 0.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>]

[<td>04 <em>ib</em></td>, <td>ADD AL, <em>imm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>imm8</em> to AL.</td>, <td>05 <em>iw</em></td>, <td>ADD AX, <em>imm16</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>imm16</em> to AX.</td>, <td>05 <em>id</em></td>, <td>ADD EAX, <em>imm32</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>imm32</em> to EAX.</td>, <td>REX.W + 05 <em>id</em></td>, <td>ADD RAX, <em>imm32</em></td>, <td>I</td>, <td>Valid</td>, <td>N.E.</td>, <td>Add <em>imm32 sign-extended to 64-bits</em> to RAX.</td>, <td>80 /0 <em>ib</em></td>, <td>ADD <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>imm8</em> to <em>r/m8.</em></td>, <td>REX + 80 /0 <em>ib</em></td>, <td>ADD <em>r/m8</em><sup>*</sup><em>, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Add <em>sign</em>-extended <em>imm8</em> to <em>r/m8.</em></td>, <td>81 /0 <em>iw</em></td>, <td>ADD <em>r/m16, imm16</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>imm16</em> to <em>r/m16.</em></td>, <td>81 /0 <em>id</em></td>, <td>ADD <em>r/m32, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>imm32</em> to <em>r/m32</em>.</td>, <td>REX.W + 81 /0 <em>id</em></td>, <td>ADD <em>r/m64, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Add <em>imm32 sign-extended to 64-bits</em> to <em>r/m64</em>.</td>, <td>83 /0 <em>ib</em></td>, <td>ADD <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>sign</em>-extended <em>imm8</em> to <em>r/m16.</em></td>, <td>83 /0 <em>ib</em></td>, <td>ADD <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>sign</em>-extended <em>imm8</em> to <em>r/m32.</em></td>, <td>REX.W + 83 /0 <em>ib</em></td>, <td>ADD <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Add <em>sign</em>-extended <em>imm8</em> to <em>r/m64.</em></td>, <td>00 /<em>r</em></td>, <td>ADD <em>r/m8, r8</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>r8</em> to <em>r/m8.</em></td>, <td>REX + 00 /<em>r</em></td>, <td>ADD <em>r/m8</em><sup>*</sup><em>, r8</em><sup>*</sup></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Add <em>r8</em> to <em>r/m8.</em></td>, <td>01 /<em>r</em></td>, <td>ADD <em>r/m16, r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>r16</em> to <em>r/m16.</em></td>, <td>01 /<em>r</em></td>, <td>ADD <em>r/m32, r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Add r32 to <em>r/m32.</em></td>, <td>REX.W + 01 /<em>r</em></td>, <td>ADD <em>r/m64, r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Add r64 to <em>r/m64.</em></td>, <td>02 /<em>r</em></td>, <td>ADD <em>r8, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>r/m8</em> to <em>r8.</em></td>, <td>REX + 02 /<em>r</em></td>, <td>ADD <em>r8</em><sup>*</sup><em>, r/m8</em><sup>*</sup></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Add <em>r/m8</em> to <em>r8.</em></td>, <td>03 /<em>r</em></td>, <td>ADD <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>r/m16</em> to <em>r16.</em></td>, <td>03 /<em>r</em></td>, <td>ADD <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>r/m32</em> to <em>r32.</em></td>, <td>REX.W + 03 /<em>r</em></td>, <td>ADD <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Add <em>r/m64</em> to <em>r64.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>MR</td>, <td>ModRM:r/m (r, w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td>I</td>, <td>AL/AX/EAX/RAX</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>66 0F 58 /r ADDPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed double-precision floating-point values from xmm2/mem to xmm1 and store result in xmm1.</td>, <td>VEX.128.66.0F.WIG 58 /r VADDPD xmm1,xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed double-precision floating-point values from xmm3/mem to xmm2 and store result in xmm1.</td>, <td>VEX.256.66.0F.WIG 58 /r VADDPD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed double-precision floating-point values from ymm3/mem to ymm2 and store result in ymm1.</td>, <td>EVEX.128.66.0F.W1 58 /r VADDPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed double-precision floating-point values from xmm3/m128/m64bcst to xmm2 and store result in xmm1 with writemask k1.</td>, <td>EVEX.256.66.0F.W1 58 /r VADDPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed double-precision floating-point values from ymm3/m256/m64bcst to ymm2 and store result in ymm1 with writemask k1.</td>, <td>EVEX.512.66.0F.W1 58 /r VADDPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Add packed double-precision floating-point values from zmm3/m512/m64bcst to zmm2 and store result in zmm1 with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 58 /r ADDPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Add packed single-precision floating-point values from xmm2/m128 to xmm1 and store result in xmm1.</td>, <td>VEX.128.0F.WIG 58 /r VADDPS xmm1,xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed single-precision floating-point values from xmm3/m128 to xmm2 and store result in xmm1.</td>, <td>VEX.256.0F.WIG 58 /r VADDPS ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed single-precision floating-point values from ymm3/m256 to ymm2 and store result in ymm1.</td>, <td>EVEX.128.0F.W0 58 /r VADDPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed single-precision floating-point values from xmm3/m128/m32bcst to xmm2 and store result in xmm1 with writemask k1.</td>, <td>EVEX.256.0F.W0 58 /r VADDPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed single-precision floating-point values from ymm3/m256/m32bcst to ymm2 and store result in ymm1 with writemask k1.</td>, <td>EVEX.512.0F.W0 58 /r VADDPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst {er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Add packed single-precision floating-point values from zmm3/m512/m32bcst to zmm2 and store result in zmm1 with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F2 0F 58 /r ADDSD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add the low double-precision floating-point value from xmm2/mem to xmm1 and store the result in xmm1.</td>, <td>VEX.LIG.F2.0F.WIG 58 /r VADDSD xmm1, xmm2, xmm3/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add the low double-precision floating-point value from xmm3/mem to xmm2 and store the result in xmm1.</td>, <td>EVEX.LIG.F2.0F.W1 58 /r VADDSD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Add the low double-precision floating-point value from xmm3/m64 to xmm2 and store the result in xmm1 with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F3 0F 58 /r ADDSS xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Add the low single-precision floating-point value from xmm2/mem to xmm1 and store the result in xmm1.</td>, <td>VEX.LIG.F3.0F.WIG 58 /r VADDSS xmm1,xmm2, xmm3/m32</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add the low single-precision floating-point value from xmm3/mem to xmm2 and store the result in xmm1.</td>, <td>EVEX.LIG.F3.0F.W0 58 /r VADDSS xmm1{k1}{z}, xmm2, xmm3/m32{er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Add the low single-precision floating-point value from xmm3/m32 to xmm2 and store the result in xmm1with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F D0 /r ADDSUBPD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE3</td>, <td>Add/subtract double-precision floating-point values from <em>xmm2/m128</em> to <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG D0 /r VADDSUBPD xmm1, xmm2, xmm3/m128</td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Add/subtract packed double-precision floating-point values from xmm3/mem to xmm2 and stores result in xmm1.</td>, <td>VEX.256.66.0F.WIG D0 /r VADDSUBPD ymm1, ymm2, ymm3/m256</td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Add / subtract packed double-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F2 0F D0 /r ADDSUBPS <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE3</td>, <td>Add/subtract single-precision floating-point values from <em>xmm2/m128</em> to <em>xmm1</em>.</td>, <td>VEX.128.F2.0F.WIG D0 /r VADDSUBPS xmm1, xmm2, xmm3/m128</td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Add/subtract single-precision floating-point values from xmm3/mem to xmm2 and stores result in xmm1.</td>, <td>VEX.256.F2.0F.WIG D0 /r VADDSUBPS ymm1, ymm2, ymm3/m256</td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Add / subtract single-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F3 0F 38 F6 /r ADOX r32, r/m32</td>, <td>RM</td>, <td>V/V</td>, <td>ADX</td>, <td>Unsigned addition of r32 with OF, r/m32 to r32, writes OF.</td>, <td>F3 REX.w 0F 38 F6 /r ADOX r64, r/m64</td>, <td>RM</td>, <td>V/NE</td>, <td>ADX</td>, <td>Unsigned addition of r64 with OF, r/m64 to r64, writes OF.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.ADX[bit 19] = 0.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td rowspan="2">#GP(0)</td>, <td>For an illegal memory operand effective address in the CS, DS, ES, FS or GS segments.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a null segment selector.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.ADX[bit 19] = 0.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#GP(0)</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.ADX[bit 19] = 0.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#GP(0)</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.ADX[bit 19] = 0.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>]

[<td>66 0F 38 DE /r AESDEC xmm1, xmm2/m128</td>, <td>RM</td>, <td>V/V</td>, <td>AES</td>, <td>Perform one round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128.</td>, <td>VEX.128.66.0F38.WIG DE /r VAESDEC xmm1, xmm2, xmm3/m128</td>, <td>RVM</td>, <td>V/V</td>, <td>Both AES and AVX flags</td>, <td>Perform one round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm2 with a 128-bit round key from xmm3/m128; store the result in xmm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand2</td>, <td>Operand3</td>, <td>Operand4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 38 DF /r AESDECLAST xmm1, xmm2/m128</td>, <td>RM</td>, <td>V/V</td>, <td>AES</td>, <td>Perform the last round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128.</td>, <td>VEX.128.66.0F38.WIG DF /r VAESDECLAST xmm1, xmm2, xmm3/m128</td>, <td>RVM</td>, <td>V/V</td>, <td>Both AES and AVX flags</td>, <td>Perform the last round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm2 with a 128-bit round key from xmm3/m128; store the result in xmm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand2</td>, <td>Operand3</td>, <td>Operand4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 38 DC /r AESENC xmm1, xmm2/m128</td>, <td>RM</td>, <td>V/V</td>, <td>AES</td>, <td>Perform one round of an AES encryption flow, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128.</td>, <td>VEX.128.66.0F38.WIG DC /r VAESENC xmm1, xmm2, xmm3/m128</td>, <td>RVM</td>, <td>V/V</td>, <td>Both AES and AVX flags</td>, <td>Perform one round of an AES encryption flow, operating on a 128-bit data (state) from xmm2 with a 128-bit round key from the xmm3/m128; store the result in xmm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand2</td>, <td>Operand3</td>, <td>Operand4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 38 DD /r AESENCLAST xmm1, xmm2/m128</td>, <td>RM</td>, <td>V/V</td>, <td>AES</td>, <td>Perform the last round of an AES encryption flow, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128.</td>, <td>VEX.128.66.0F38.WIG DD /r VAESENCLAST xmm1, xmm2, xmm3/m128</td>, <td>RVM</td>, <td>V/V</td>, <td>Both AES and AVX flags</td>, <td>Perform the last round of an AES encryption flow, operating on a 128-bit data (state) from xmm2 with a 128 bit round key from xmm3/m128; store the result in xmm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand2</td>, <td>Operand3</td>, <td>Operand4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 38 DB /r AESIMC xmm1, xmm2/m128</td>, <td>RM</td>, <td>V/V</td>, <td>AES</td>, <td>Perform the InvMixColumn transformation on a 128-bit round key from xmm2/m128 and store the result in xmm1.</td>, <td>VEX.128.66.0F38.WIG DB /r VAESIMC xmm1, xmm2/m128</td>, <td>RM</td>, <td>V/V</td>, <td>Both AES and AVX flags</td>, <td>Perform the InvMixColumn transformation on a 128-bit round key from xmm2/m128 and store the result in xmm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand2</td>, <td>Operand3</td>, <td>Operand4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>66 0F 3A DF /r ib AESKEYGENASSIST xmm1, xmm2/m128, imm8</td>, <td>RMI</td>, <td>V/V</td>, <td>AES</td>, <td>Assist in AES round key generation using an 8 bits Round Constant (RCON) specified in the immediate byte, operating on 128 bits of data specified in xmm2/m128 and stores the result in xmm1.</td>, <td>VEX.128.66.0F3A.WIG DF /r ib VAESKEYGENASSIST xmm1, xmm2/m128, imm8</td>, <td>RMI</td>, <td>V/V</td>, <td>Both AES and AVX flags</td>, <td>Assist in AES round key generation using 8 bits Round Constant (RCON) specified in the immediate byte, operating on 128 bits of data specified in xmm2/m128 and stores the result in xmm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand2</td>, <td>Operand3</td>, <td>Operand4</td>, <td>RMI</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>24 <em>ib</em></td>, <td>AND AL, <em>imm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>AL AND <em>imm8.</em></td>, <td>25 <em>iw</em></td>, <td>AND AX, <em>imm16</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>AX AND i<em>mm16.</em></td>, <td>25 <em>id</em></td>, <td>AND EAX, <em>imm32</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>EAX AND <em>imm32.</em></td>, <td>REX.W + 25 <em>id</em></td>, <td>AND RAX, <em>imm32</em></td>, <td>I</td>, <td>Valid</td>, <td>N.E.</td>, <td>RAX AND <em>imm32 sign-extended to 64-bits.</em></td>, <td>80 /4 <em>ib</em></td>, <td>AND <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m8</em> AND <em>imm8.</em></td>, <td>REX + 80 /4 <em>ib</em></td>, <td>AND <em>r/m8</em><sup>*</sup><em>, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r/m8</em> AND <em>imm8.</em></td>, <td>81 /4 <em>iw</em></td>, <td>AND <em>r/m16, imm16</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m16</em> AND <em>imm16.</em></td>, <td>81 /4 <em>id</em></td>, <td>AND <em>r/m32, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m32</em> AND <em>imm32.</em></td>, <td>REX.W + 81 /4 <em>id</em></td>, <td>AND <em>r/m64, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r/m64</em> AND <em>imm32 sign extended to 64-bits.</em></td>, <td>83 /4 <em>ib</em></td>, <td>AND <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m16</em> AND <em>imm8 (sign-extended).</em></td>, <td>83 /4 <em>ib</em></td>, <td>AND <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m32</em> AND <em>imm8 (sign-extended).</em></td>, <td>REX.W + 83 /4 <em>ib</em></td>, <td>AND <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r/m64</em> AND <em>imm8 (sign-extended).</em></td>, <td>20 <em>/r</em></td>, <td>AND <em>r/m8, r8</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m8</em> AND <em>r8.</em></td>, <td>REX + 20 <em>/r</em></td>, <td>AND <em>r/m8</em><sup>*</sup><em>, r8</em><sup>*</sup></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r/m64</em> AND <em>r8 (sign-extended).</em></td>, <td>21 /<em>r</em></td>, <td>AND <em>r/m16, r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m16</em> AND <em>r16.</em></td>, <td>21 /<em>r</em></td>, <td>AND <em>r/m32, r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m32</em> AND <em>r32.</em></td>, <td>REX.W + 21 /<em>r</em></td>, <td>AND <em>r/m64, r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r/m64</em> AND <em>r32.</em></td>, <td>22 /<em>r</em></td>, <td>AND <em>r8, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r8</em> AND <em>r/m8.</em></td>, <td>REX + 22 /<em>r</em></td>, <td>AND <em>r8</em><sup>*</sup><em>, r/m8</em><sup>*</sup></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r/m64</em> AND <em>r8 (sign-extended).</em></td>, <td>23 /<em>r</em></td>, <td>AND <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r16</em> AND <em>r/m16.</em></td>, <td>23 /<em>r</em></td>, <td>AND <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r32</em> AND <em>r/m32.</em></td>, <td>REX.W + 23 /<em>r</em></td>, <td>AND <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r64</em> AND <em>r/m64.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>MR</td>, <td>ModRM:r/m (r, w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td>I</td>, <td>AL/AX/EAX/RAX</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination operand points to a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>VEX.LZ.0F38.W0 F2 /r ANDN r32a, r32b, r/m32</td>, <td>RVM</td>, <td>V/V</td>, <td>BMI1</td>, <td>Bitwise AND of inverted r32b with r/m32, store result in r32a.</td>, <td>VEX.LZ. 0F38.W1 F2 /r ANDN r64a, r64b, r/m64</td>, <td>RVM</td>, <td>V/NE</td>, <td>BMI1</td>, <td>Bitwise AND of inverted r64b with r/m64, store result in r64a.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 55 /r ANDNPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Return the bitwise logical AND NOT of packed double-precision floating-point values in xmm1 and xmm2/mem.</td>, <td>VEX.128.66.0F 55 /r VANDNPD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the bitwise logical AND NOT of packed double-precision floating-point values in xmm2 and xmm3/mem.</td>, <td>VEX.256.66.0F 55/r VANDNPD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the bitwise logical AND NOT of packed double-precision floating-point values in ymm2 and ymm3/mem.</td>, <td>EVEX.128.66.0F.W1 55 /r VANDNPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Return the bitwise logical AND NOT of packed double-precision floating-point values in xmm2 and xmm3/m128/m64bcst subject to writemask k1.</td>, <td>EVEX.256.66.0F.W1 55 /r VANDNPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Return the bitwise logical AND NOT of packed double-precision floating-point values in ymm2 and ymm3/m256/m64bcst subject to writemask k1.</td>, <td>EVEX.512.66.0F.W1 55 /r VANDNPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Return the bitwise logical AND NOT of packed double-precision floating-point values in zmm2 and zmm3/m512/m64bcst subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 55 /r ANDNPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Return the bitwise logical AND NOT of packed single-precision floating-point values in xmm1 and xmm2/mem.</td>, <td>VEX.128.0F 55 /r VANDNPS xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the bitwise logical AND NOT of packed single-precision floating-point values in xmm2 and xmm3/mem.</td>, <td>VEX.256.0F 55 /r VANDNPS ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the bitwise logical AND NOT of packed single-precision floating-point values in ymm2 and ymm3/mem.</td>, <td>EVEX.128.0F.W0 55 /r VANDNPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Return the bitwise logical AND of packed single-precision floating-point values in xmm2 and xmm3/m128/m32bcst subject to writemask k1.</td>, <td>EVEX.256.0F.W0 55 /r VANDNPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Return the bitwise logical AND of packed single-precision floating-point values in ymm2 and ymm3/m256/m32bcst subject to writemask k1.</td>, <td>EVEX.512.0F.W0 55 /r VANDNPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Return the bitwise logical AND of packed single-precision floating-point values in zmm2 and zmm3/m512/m32bcst subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 54 /r ANDPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Return the bitwise logical AND of packed double-precision floating-point values in xmm1 and xmm2/mem.</td>, <td>VEX.128.66.0F 54 /r VANDPD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the bitwise logical AND of packed double-precision floating-point values in xmm2 and xmm3/mem.</td>, <td>VEX.256.66.0F 54 /r VANDPD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the bitwise logical AND of packed double-precision floating-point values in ymm2 and ymm3/mem.</td>, <td>EVEX.128.66.0F.W1 54 /r VANDPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Return the bitwise logical AND of packed double-precision floating-point values in xmm2 and xmm3/m128/m64bcst subject to writemask k1.</td>, <td>EVEX.256.66.0F.W1 54 /r VANDPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Return the bitwise logical AND of packed double-precision floating-point values in ymm2 and ymm3/m256/m64bcst subject to writemask k1.</td>, <td>EVEX.512.66.0F.W1 54 /r VANDPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Return the bitwise logical AND of packed double-precision floating-point values in zmm2 and zmm3/m512/m64bcst subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 54 /r ANDPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Return the bitwise logical AND of packed single-precision floating-point values in xmm1 and xmm2/mem.</td>, <td>VEX.128.0F 54 /r VANDPS xmm1,xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the bitwise logical AND of packed single-precision floating-point values in xmm2 and xmm3/mem.</td>, <td>VEX.256.0F 54 /r VANDPS ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the bitwise logical AND of packed single-precision floating-point values in ymm2 and ymm3/mem.</td>, <td>EVEX.128.0F.W0 54 /r VANDPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Return the bitwise logical AND of packed single-precision floating-point values in xmm2 and xmm3/m128/m32bcst subject to writemask k1.</td>, <td>EVEX.256.0F.W0 54 /r VANDPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Return the bitwise logical AND of packed single-precision floating-point values in ymm2 and ymm3/m256/m32bcst subject to writemask k1.</td>, <td>EVEX.512.0F.W0 54 /r VANDPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Return the bitwise logical AND of packed single-precision floating-point values in zmm2 and zmm3/m512/m32bcst subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>63 /<em>r</em></td>, <td>ARPL <em>r/m16, r16</em></td>, <td>MR</td>, <td>N. E.</td>, <td>Valid</td>, <td>Adjust RPL of <em>r/m16</em> to not less than RPL of <em>r16.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>MR</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#UD</td>, <td>The ARPL instruction is not recognized in real-address mode.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#UD</td>, <td>The ARPL instruction is not recognized in virtual-8086 mode.</td>, <td>If the LOCK prefix is used.</td>]

[<td>VEX.LZ.0F38.W0 F7 /r BEXTR r32a, r/m32, r32b</td>, <td>RMV</td>, <td>V/V</td>, <td>BMI1</td>, <td>Contiguous bitwise extract from r/m32 using r32b as control; store result in r32a.</td>, <td>VEX.LZ.0F38.W1 F7 /r BEXTR r64a, r/m64, r64b</td>, <td>RMV</td>, <td>V/N.E.</td>, <td>BMI1</td>, <td>Contiguous bitwise extract from r/m64 using r64b as control; store result in r64a</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMV</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>VEX.vvvv (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.W = 1.</td>]

[<td>66 0F 3A 0D /r ib BLENDPD <em>xmm1</em>, <em>xmm2/m128, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Select packed DP-FP values from <em>xmm1</em> and <em>xmm2/m128</em> from mask specified in imm8 and store the values into <em>xmm1</em>.</td>, <td>VEX.128.66.0F3A.WIG 0D /r ib VBLENDPD xmm1, xmm2, xmm3/m128, imm8</td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Select packed double-precision floating-point Values from xmm2 and xmm3/m128 from mask in imm8 and store the values in xmm1.</td>, <td>VEX.256.66.0F3A.WIG 0D /r ib VBLENDPD ymm1, ymm2, ymm3/m256, imm8</td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Select packed double-precision floating-point Values from ymm2 and ymm3/m256 from mask in imm8 and store the values in ymm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMI</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>RVMI</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8[3:0]</td>]

[<td>66 0F 3A 0C /r ib BLENDPS xmm1, xmm2/m128, imm8</td>, <td>RMI</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Select packed single precision floating-point values from <em>xmm1</em> and <em>xmm2/m128</em> from mask specified in <em>imm8</em> and store the values into <em>xmm1.</em></td>, <td>VEX.128.66.0F3A.WIG 0C /r ib VBLENDPS xmm1, xmm2, xmm3/m128, imm8</td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Select packed single-precision floating-point values from xmm2 and xmm3/m128 from mask in imm8 and store the values in xmm1.</td>, <td>VEX.256.66.0F3A.WIG 0C /r ib VBLENDPS ymm1, ymm2, ymm3/m256, imm8</td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Select packed single-precision floating-point values from ymm2 and ymm3/m256 from mask in imm8 and store the values in ymm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMI</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>RVMI</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>]

[<td>66 0F 38 15 /r BLENDVPD xmm1, xmm2/m128 , &lt;XMM0&gt;</td>, <td>RM0</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Select packed DP FP values from <em>xmm1</em> and <em>xmm2</em> from mask specified in <em>XMM0</em> and store the values in <em>xmm1</em>.</td>, <td>VEX.128.66.0F3A.W0 4B /r /is4 VBLENDVPD xmm1, xmm2, xmm3/m128, xmm4</td>, <td>RVMR</td>, <td>V/V</td>, <td>AVX</td>, <td>Conditionally copy double-precision floating-point values from xmm2 or xmm3/m128 to xmm1, based on mask bits in the mask operand, xmm4.</td>, <td>VEX.256.66.0F3A.W0 4B /r /is4 VBLENDVPD ymm1, ymm2, ymm3/m256, ymm4</td>, <td>RVMR</td>, <td>V/V</td>, <td>AVX</td>, <td>Conditionally copy double-precision floating-point values from ymm2 or ymm3/m256 to ymm1, based on mask bits in the mask operand, ymm4.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM0</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>implicit XMM0</td>, <td>NA</td>, <td>RVMR</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8[7:4]</td>, <td>#UD</td>, <td>If VEX.W = 1.</td>]

[<td>66 0F 38 14 /r BLENDVPS <em>xmm1, xmm2/m128, &lt;XMM0&gt;</em></td>, <td>RM0</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Select packed single precision floating-point values from <em>xmm1</em> and <em>xmm2/m128</em> from mask specified in <em>XMM0</em> and store the values into <em>xmm1</em>.</td>, <td>VEX.128.66.0F3A.W0 4A /r /is4 VBLENDVPS xmm1, xmm2, xmm3/m128, xmm4</td>, <td>RVMR</td>, <td>V/V</td>, <td>AVX</td>, <td>Conditionally copy single-precision floating-point values from xmm2 or xmm3/m128 to xmm1, based on mask bits in the specified mask operand, xmm4.</td>, <td>VEX.256.66.0F3A.W0 4A /r /is4 VBLENDVPS ymm1, ymm2, ymm3/m256, ymm4</td>, <td>RVMR</td>, <td>V/V</td>, <td>AVX</td>, <td>Conditionally copy single-precision floating-point values from ymm2 or ymm3/m256 to ymm1, based on mask bits in the specified mask register, ymm4.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM0</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>implicit XMM0</td>, <td>NA</td>, <td>RVMR</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8[7:4]</td>, <td>#UD</td>, <td>If VEX.W = 1.</td>]

[<td>VEX.LZ.0F38.W0 F3 /3 BLSI r32, r/m32</td>, <td>VM</td>, <td>V/V</td>, <td>BMI1</td>, <td>Extract lowest set bit from r/m32 and set that bit in r32.</td>, <td>VEX.LZ.0F38.W1 F3 /3 BLSI r64, r/m64</td>, <td>VM</td>, <td>V/N.E.</td>, <td>BMI1</td>, <td>Extract lowest set bit from r/m64, and set that bit in r64.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>VM</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>VEX.LZ.0F38.W0 F3 /2 BLSMSK r32, r/m32</td>, <td>VM</td>, <td>V/V</td>, <td>BMI1</td>, <td>Set all lower bits in r32 to “1” starting from bit 0 to lowest set bit in r/m32.</td>, <td>VEX.LZ.0F38.W1 F3 /2 BLSMSK r64, r/m64</td>, <td>VM</td>, <td>V/N.E.</td>, <td>BMI1</td>, <td>Set all lower bits in r64 to “1” starting from bit 0 to lowest set bit in r/m64.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>VM</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>VEX.LZ.0F38.W0 F3 /1 BLSR r32, r/m32</td>, <td>VM</td>, <td>V/V</td>, <td>BMI1</td>, <td>Reset lowest set bit of r/m32, keep all other bits of r/m32 and write result to r32.</td>, <td>VEX.LZ.0F38.W1 F3 /1 BLSR r64, r/m64</td>, <td>VM</td>, <td>V/N.E.</td>, <td>BMI1</td>, <td>Reset lowest set bit of r/m64, keep all other bits of r/m64 and write result to r64.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>VM</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>F3 0F 1A /r BNDCL bnd, r/m32</td>, <td>RM</td>, <td>NE/V</td>, <td>MPX</td>, <td>Generate a #BR if the address in r/m32 is lower than the lower bound in bnd.LB.</td>, <td>F3 0F 1A /r BNDCL bnd, r/m64</td>, <td>RM</td>, <td>V/NE</td>, <td>MPX</td>, <td>Generate a #BR if the address in r/m64 is lower than the lower bound in bnd.LB.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#BR</td>, <td>If lower bound check fails.</td>, <td rowspan="4">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 67H prefix is not used and CS.D=0.</td>, <td>If 67H prefix is used and CS.D=1.</td>, <td>#BR</td>, <td>If lower bound check fails.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 16-bit addressing is used.</td>, <td>#BR</td>, <td>If lower bound check fails.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 16-bit addressing is used.</td>, <td>#UD</td>, <td>If ModRM.r/m and REX encodes BND4-BND15 when Intel MPX is enabled.</td>]

[<td>F2 0F 1A /r BNDCU bnd, r/m32</td>, <td>RM</td>, <td>NE/V</td>, <td>MPX</td>, <td>Generate a #BR if the address in r/m32 is higher than the upper bound in bnd.UB (bnb.UB in 1's complement form).</td>, <td>F2 0F 1A /r BNDCU bnd, r/m64</td>, <td>RM</td>, <td>V/NE</td>, <td>MPX</td>, <td>Generate a #BR if the address in r/m64 is higher than the upper bound in bnd.UB (bnb.UB in 1's complement form).</td>, <td>F2 0F 1B /r BNDCN bnd, r/m32</td>, <td>RM</td>, <td>NE/V</td>, <td>MPX</td>, <td>Generate a #BR if the address in r/m32 is higher than the upper bound in bnd.UB (bnb.UB not in 1's complement form).</td>, <td>F2 0F 1B /r BNDCN bnd, r/m64</td>, <td>RM</td>, <td>V/NE</td>, <td>MPX</td>, <td>Generate a #BR if the address in r/m64 is higher than the upper bound in bnd.UB (bnb.UB not in 1's complement form).</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#BR</td>, <td>If upper bound check fails.</td>, <td rowspan="4">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 67H prefix is not used and CS.D=0.</td>, <td>If 67H prefix is used and CS.D=1.</td>, <td>#BR</td>, <td>If upper bound check fails.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 16-bit addressing is used.</td>, <td>#BR</td>, <td>If upper bound check fails.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 16-bit addressing is used.</td>, <td>#UD</td>, <td>If ModRM.r/m and REX encodes BND4-BND15 when Intel MPX is enabled.</td>]

[<td>F2 0F 1A /r BNDCU bnd, r/m32</td>, <td>RM</td>, <td>NE/V</td>, <td>MPX</td>, <td>Generate a #BR if the address in r/m32 is higher than the upper bound in bnd.UB (bnb.UB in 1's complement form).</td>, <td>F2 0F 1A /r BNDCU bnd, r/m64</td>, <td>RM</td>, <td>V/NE</td>, <td>MPX</td>, <td>Generate a #BR if the address in r/m64 is higher than the upper bound in bnd.UB (bnb.UB in 1's complement form).</td>, <td>F2 0F 1B /r BNDCN bnd, r/m32</td>, <td>RM</td>, <td>NE/V</td>, <td>MPX</td>, <td>Generate a #BR if the address in r/m32 is higher than the upper bound in bnd.UB (bnb.UB not in 1's complement form).</td>, <td>F2 0F 1B /r BNDCN bnd, r/m64</td>, <td>RM</td>, <td>V/NE</td>, <td>MPX</td>, <td>Generate a #BR if the address in r/m64 is higher than the upper bound in bnd.UB (bnb.UB not in 1's complement form).</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#BR</td>, <td>If upper bound check fails.</td>, <td rowspan="4">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 67H prefix is not used and CS.D=0.</td>, <td>If 67H prefix is used and CS.D=1.</td>, <td>#BR</td>, <td>If upper bound check fails.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 16-bit addressing is used.</td>, <td>#BR</td>, <td>If upper bound check fails.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 16-bit addressing is used.</td>, <td>#UD</td>, <td>If ModRM.r/m and REX encodes BND4-BND15 when Intel MPX is enabled.</td>]

[<td>NP 0F 1A /r BNDLDX bnd, mib</td>, <td>RM</td>, <td>V/V</td>, <td>MPX</td>, <td>Load the bounds stored in a bound table entry (BTE) into bnd with address translation using the base of mib and conditional on the index of mib matching the pointer value in the BTE.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>SIB.base (r): Address of pointer SIB.index(r)</td>, <td>NA</td>, <td>#BR</td>, <td>If the bound directory entry is invalid.</td>, <td rowspan="4">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 67H prefix is not used and CS.D=0.</td>, <td>If 67H prefix is used and CS.D=1.</td>, <td rowspan="2">#GP(0)</td>, <td>If a destination effective address of the Bound Table entry is outside the DS segment limit.</td>, <td>If DS register contains a NULL segment selector.</td>, <td>#PF(fault</td>, <td>code) If a page fault occurs.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 16-bit addressing is used.</td>, <td>#GP(0)</td>, <td>If a destination effective address of the Bound Table entry is outside the DS segment limit.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 16-bit addressing is used.</td>, <td>#GP(0)</td>, <td>If a destination effective address of the Bound Table entry is outside the DS segment limit.</td>, <td>#PF(fault</td>, <td>code) If a page fault occurs.</td>, <td>#BR</td>, <td>If the bound directory entry is invalid.</td>, <td rowspan="3">#UD</td>, <td>If ModRM is RIP relative.</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m and REX encodes BND4-BND15 when Intel MPX is enabled.</td>, <td>#GP(0)</td>, <td>If the memory address (A_BDE or A_BTE) is in a non-canonical form.</td>, <td>#PF(fault</td>, <td>code) If a page fault occurs.</td>]

[<td>F3 0F 1B /r BNDMK bnd, m32</td>, <td>RM</td>, <td>NE/V</td>, <td>MPX</td>, <td>Make lower and upper bounds from m32 and store them in bnd.</td>, <td>F3 0F 1B /r BNDMK bnd, m64</td>, <td>RM</td>, <td>V/NE</td>, <td>MPX</td>, <td>Make lower and upper bounds from m64 and store them in bnd.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td rowspan="4">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 67H prefix is not used and CS.D=0.</td>, <td>If 67H prefix is used and CS.D=1.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 16-bit addressing is used.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 16-bit addressing is used.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m and REX encodes BND4-BND15 when Intel MPX is enabled.</td>, <td>If RIP-relative addressing is used.</td>, <td>#SS(0)</td>, <td>If the memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>]

[<td>66 0F 1A /r BNDMOV bnd1, bnd2/m64</td>, <td>RM</td>, <td>NE/V</td>, <td>MPX</td>, <td>Move lower and upper bound from bnd2/m64 to bound register bnd1.</td>, <td>66 0F 1A /r BNDMOV bnd1, bnd2/m128</td>, <td>RM</td>, <td>V/NE</td>, <td>MPX</td>, <td>Move lower and upper bound from bnd2/m128 to bound register bnd1.</td>, <td>66 0F 1B /r BNDMOV bnd1/m64, bnd2</td>, <td>MR</td>, <td>NE/V</td>, <td>MPX</td>, <td>Move lower and upper bound from bnd2 to bnd1/m64.</td>, <td>66 0F 1B /r BNDMOV bnd1/m128, bnd2</td>, <td>MR</td>, <td>V/NE</td>, <td>MPX</td>, <td>Move lower and upper bound from bnd2 to bound register bnd1/m128.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>MR</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td rowspan="4">#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 67H prefix is not used and CS.D=0.</td>, <td>If 67H prefix is used and CS.D=1.</td>, <td>#SS(0)</td>, <td>If the memory operand effective address is outside the SS segment limit.</td>, <td rowspan="3">#GP(0)</td>, <td>If the memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the destination operand points to a non-writable segment</td>, <td>If the DS, ES, FS, or GS segment register contains a NULL segment selector.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while CPL is 3.</td>, <td>#PF(fault</td>, <td>code) If a page fault occurs.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 16-bit addressing is used.</td>, <td>#GP(0)</td>, <td>If the memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If the memory operand effective address is outside the SS segment limit.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 16-bit addressing is used.</td>, <td>#GP(0)</td>, <td>If the memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If the memory operand effective address is outside the SS segment limit.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while CPL is 3.</td>, <td>#PF(fault</td>, <td>code) If a page fault occurs.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>If ModRM.r/m and REX encodes BND4-BND15 when Intel MPX is enabled.</td>, <td>#SS(0)</td>, <td>If the memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while CPL is 3.</td>, <td>#PF(fault</td>, <td>code) If a page fault occurs.</td>]

[<td>NP 0F 1B /r BNDSTX mib, bnd</td>, <td>MR</td>, <td>V/V</td>, <td>MPX</td>, <td>Store the bounds in bnd and the pointer value in the index register of mib to a bound table entry (BTE) with address translation using the base of mib.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>MR</td>, <td>SIB.base (r): Address of pointer SIB.index(r)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>#BR</td>, <td>If the bound directory entry is invalid.</td>, <td rowspan="4">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 67H prefix is not used and CS.D=0.</td>, <td>If 67H prefix is used and CS.D=1.</td>, <td rowspan="3">#GP(0)</td>, <td>If a destination effective address of the Bound Table entry is outside the DS segment limit.</td>, <td>If DS register contains a NULL segment selector.</td>, <td>If the destination operand points to a non-writable segment</td>, <td>#PF(fault</td>, <td>code) If a page fault occurs.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 16-bit addressing is used.</td>, <td>#GP(0)</td>, <td>If a destination effective address of the Bound Table entry is outside the DS segment limit.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m encodes BND4-BND7 when Intel MPX is enabled.</td>, <td>If 16-bit addressing is used.</td>, <td>#GP(0)</td>, <td>If a destination effective address of the Bound Table entry is outside the DS segment limit.</td>, <td>#PF(fault</td>, <td>code) If a page fault occurs.</td>, <td>#BR</td>, <td>If the bound directory entry is invalid.</td>, <td rowspan="3">#UD</td>, <td>If ModRM is RIP relative.</td>, <td>If the LOCK prefix is used.</td>, <td>If ModRM.r/m and REX encodes BND4-BND15 when Intel MPX is enabled.</td>, <td rowspan="2">#GP(0)</td>, <td>If the memory address (A_BDE or A_BTE) is in a non-canonical form.</td>, <td>If the destination operand points to a non-writable segment</td>, <td>#PF(fault</td>, <td>code) If a page fault occurs.</td>]

[<td>62 /r</td>, <td>BOUND <em>r16, m16&amp;16</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Check if <em>r16</em> (array index) is within bounds specified by <em>m16&amp;16.</em></td>, <td>62 /r</td>, <td>BOUND <em>r32, m32&amp;32</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Check if <em>r32</em> (array index) is within bounds specified by <em>m32&amp;32.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#BR</td>, <td>If the bounds test fails.</td>, <td rowspan="2">#UD</td>, <td>If second operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#BR</td>, <td>If the bounds test fails.</td>, <td rowspan="2">#UD</td>, <td>If second operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#BR</td>, <td>If the bounds test fails.</td>, <td rowspan="2">#UD</td>, <td>If second operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If in 64-bit mode.</td>]

[<td>0F BC /r</td>, <td>BSF <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Bit scan forward on <em>r/m16.</em></td>, <td>0F BC /r</td>, <td>BSF <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Bit scan forward on <em>r/m32.</em></td>, <td>REX.W + 0F BC /r</td>, <td>BSF <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Bit scan forward on <em>r/m64.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F BD /r</td>, <td>BSR <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Bit scan reverse on <em>r/m16.</em></td>, <td>0F BD /r</td>, <td>BSR <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Bit scan reverse on <em>r/m32.</em></td>, <td>REX.W + 0F BD /r</td>, <td>BSR <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Bit scan reverse on <em>r/m64.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F C8+<em>rd</em></td>, <td>BSWAP <em>r32</em></td>, <td>O</td>, <td>Valid*</td>, <td>Valid</td>, <td>Reverses the byte order of a 32-bit register.</td>, <td>REX.W + 0F C8+<em>rd</em></td>, <td>BSWAP <em>r64</em></td>, <td>O</td>, <td>Valid</td>, <td>N.E.</td>, <td>Reverses the byte order of a 64-bit register.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>O</td>, <td>opcode + rd (r, w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>0F A3 /r</td>, <td>BT <em>r/m16, r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Store selected bit in CF flag.</td>, <td>0F A3 /r</td>, <td>BT <em>r/m32, r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Store selected bit in CF flag.</td>, <td>REX.W + 0F A3 /r</td>, <td>BT <em>r/m64, r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store selected bit in CF flag.</td>, <td>0F BA /4 <em>ib</em></td>, <td>BT <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Store selected bit in CF flag.</td>, <td>0F BA /4 <em>ib</em></td>, <td>BT <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Store selected bit in CF flag.</td>, <td>REX.W + 0F BA /4 <em>ib</em></td>, <td>BT <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store selected bit in CF flag.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>MR</td>, <td>ModRM:r/m (r)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F BB /r</td>, <td>BTC <em>r/m16, r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Store selected bit in CF flag and complement.</td>, <td>0F BB /r</td>, <td>BTC <em>r/m32, r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Store selected bit in CF flag and complement.</td>, <td>REX.W + 0F BB /r</td>, <td>BTC <em>r/m64, r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store selected bit in CF flag and complement.</td>, <td>0F BA /7 <em>ib</em></td>, <td>BTC <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Store selected bit in CF flag and complement.</td>, <td>0F BA /7 <em>ib</em></td>, <td>BTC <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Store selected bit in CF flag and complement.</td>, <td>REX.W + 0F BA /7 <em>ib</em></td>, <td>BTC <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store selected bit in CF flag and complement.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>MR</td>, <td>ModRM:r/m (r, w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination operand points to a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>0F B3 /r</td>, <td>BTR <em>r/m16, r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Store selected bit in CF flag and clear.</td>, <td>0F B3 /r</td>, <td>BTR <em>r/m32, r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Store selected bit in CF flag and clear.</td>, <td>REX.W + 0F B3 /r</td>, <td>BTR <em>r/m64, r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store selected bit in CF flag and clear.</td>, <td>0F BA /6 <em>ib</em></td>, <td>BTR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Store selected bit in CF flag and clear.</td>, <td>0F BA /6 <em>ib</em></td>, <td>BTR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Store selected bit in CF flag and clear.</td>, <td>REX.W + 0F BA /6 <em>ib</em></td>, <td>BTR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store selected bit in CF flag and clear.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>MR</td>, <td>ModRM:r/m (r, w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination operand points to a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>0F AB /r</td>, <td>BTS <em>r/m16, r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Store selected bit in CF flag and set.</td>, <td>0F AB /r</td>, <td>BTS <em>r/m32, r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Store selected bit in CF flag and set.</td>, <td>REX.W + 0F AB /r</td>, <td>BTS <em>r/m64, r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store selected bit in CF flag and set.</td>, <td>0F BA /5 <em>ib</em></td>, <td>BTS <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Store selected bit in CF flag and set.</td>, <td>0F BA /5 <em>ib</em></td>, <td>BTS <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Store selected bit in CF flag and set.</td>, <td>REX.W + 0F BA /5 <em>ib</em></td>, <td>BTS <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store selected bit in CF flag and set.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>MR</td>, <td>ModRM:r/m (r, w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination operand points to a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>VEX.LZ.0F38.W0 F5 /r BZHI r32a, r/m32, r32b</td>, <td>RMV</td>, <td>V/V</td>, <td>BMI2</td>, <td>Zero bits in r/m32 starting with the position in r32b, write result to r32a.</td>, <td>VEX.LZ.0F38.W1 F5 /r BZHI r64a, r/m64, r64b</td>, <td>RMV</td>, <td>V/N.E.</td>, <td>BMI2</td>, <td>Zero bits in r/m64 starting with the position in r64b, write result to r64a.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMV</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>VEX.vvvv (r)</td>, <td>NA</td>]

[<td>E8 <em>cw</em></td>, <td>CALL <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Call near, relative, displacement relative to next instruction.</td>, <td>E8 <em>cd</em></td>, <td>CALL <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Call near, relative, displacement relative to next instruction. 32-bit displacement sign extended to 64-bits in 64-bit mode.</td>, <td>FF /2</td>, <td>CALL <em>r/m16</em></td>, <td>M</td>, <td>N.E.</td>, <td>Valid</td>, <td>Call near, absolute indirect, address given in <em>r/m16.</em></td>, <td>FF /2</td>, <td>CALL <em>r/m32</em></td>, <td>M</td>, <td>N.E.</td>, <td>Valid</td>, <td>Call near, absolute indirect, address given in <em>r/m32.</em></td>, <td>FF /2</td>, <td>CALL <em>r/m64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Call near, absolute indirect, address given in <em>r/m</em>64.</td>, <td>9A <em>cd</em></td>, <td>CALL <em>ptr16:16</em></td>, <td>D</td>, <td>Invalid</td>, <td>Valid</td>, <td>Call far, absolute, address given in operand.</td>, <td>9A <em>cp</em></td>, <td>CALL <em>ptr16:32</em></td>, <td>D</td>, <td>Invalid</td>, <td>Valid</td>, <td>Call far, absolute, address given in operand.</td>, <td>FF /3</td>, <td>CALL <em>m16:16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Call far, absolute indirect address given in <em>m16:16.</em> In 32-bit mode: if selector points to a gate, then RIP = 32-bit zero extended displacement taken from gate; else RIP = zero extended 16-bit offset from far pointer referenced in the instruction.</td>, <td>FF /3</td>, <td>CALL <em>m16:32</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>In 64-bit mode: If selector points to a gate, then RIP = 64-bit displacement taken from gate; else RIP = zero extended 32-bit offset from far pointer referenced in the instruction.</td>, <td>REX.W FF /3</td>, <td>CALL <em>m16:64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>In 64-bit mode: If selector points to a gate, then RIP = 64-bit displacement taken from gate; else RIP = 64-bit offset from far pointer referenced in the instruction.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>D</td>, <td>Offset</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="5">#GP(0)</td>, <td>If the target offset in destination operand is beyond the new code segment limit.</td>, <td>If the segment selector in the destination operand is NULL.</td>, <td>If the code segment selector in the gate is NULL.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td rowspan="10">#GP(selector)</td>, <td>If a code segment or gate or TSS selector index is outside descriptor table limits.</td>, <td>If the segment descriptor pointed to by the segment selector in the destination operand is not for a conforming-code segment, nonconforming-code segment, call gate, task gate, or task state segment.</td>, <td>If the DPL for a nonconforming-code segment is not equal to the CPL or the RPL for the segment’s segment selector is greater than the CPL.</td>, <td>If the DPL for a conforming-code segment is greater than the CPL.</td>, <td>If the DPL from a call-gate, task-gate, or TSS segment descriptor is less than the CPL or than the RPL of the call-gate, task-gate, or TSS’s segment selector.</td>, <td>If the segment descriptor for a segment selector from a call gate does not indicate it is a code segment.</td>, <td>If the segment selector from a call gate is beyond the descriptor table limits.</td>, <td>If the DPL for a code-segment obtained from a call gate is greater than the CPL.</td>, <td>If the segment selector for a TSS has its local/global bit set for local.</td>, <td>If a TSS segment descriptor specifies that the TSS is busy or not available.</td>, <td rowspan="2">#SS(0)</td>, <td>If pushing the return address, parameters, or stack segment pointer onto the stack exceeds the bounds of the stack segment, when no stack switch occurs.</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td rowspan="3">#SS(selector)</td>, <td>If pushing the return address, parameters, or stack segment pointer onto the stack exceeds the bounds of the stack segment, when a stack switch occurs.</td>, <td>If the SS register is being loaded as part of a stack switch and the segment pointed to is marked not present.</td>, <td>If stack segment does not have room for the return address, parameters, or stack segment pointer, when stack switch occurs.</td>, <td>#NP(selector)</td>, <td>If a code segment, data segment, call gate, task gate, or TSS is not present.</td>, <td rowspan="6">#TS(selector)</td>, <td>If the new stack segment selector and ESP are beyond the end of the TSS.</td>, <td>If the new stack segment selector is NULL.</td>, <td>If the RPL of the new stack segment selector in the TSS is not equal to the DPL of the code segment being accessed.</td>, <td>If DPL of the stack segment descriptor for the new stack segment is not equal to the DPL of the code segment descriptor.</td>, <td>If the new stack segment is not a writable data segment.</td>, <td>If segment-selector index for stack segment is outside descriptor table limits.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the target offset is beyond the code segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the target offset is beyond the code segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(selector)</td>, <td>If a memory address accessed by the selector is in non-canonical space.</td>, <td>#GP(0)</td>, <td>If the target offset in the destination operand is non-canonical.</td>, <td rowspan="4">#GP(0)</td>, <td>If a memory address is non-canonical.</td>, <td>If target offset in destination operand is non-canonical.</td>, <td>If the segment selector in the destination operand is NULL.</td>, <td>If the code segment selector in the 64-bit gate is NULL.</td>, <td rowspan="12">#GP(selector)</td>, <td>If code segment or 64-bit call gate is outside descriptor table limits.</td>, <td>If code segment or 64-bit call gate overlaps non-canonical space.</td>, <td>If the segment descriptor pointed to by the segment selector in the destination operand is not for a conforming-code segment, nonconforming-code segment, or 64-bit call gate.</td>, <td>If the segment descriptor pointed to by the segment selector in the destination operand is a code segment and has both the D-bit and the L- bit set.</td>, <td>If the DPL for a nonconforming-code segment is not equal to the CPL, or the RPL for the segment’s segment selector is greater than the CPL.</td>, <td>If the DPL for a conforming-code segment is greater than the CPL.</td>, <td>If the DPL from a 64-bit call-gate is less than the CPL or than the RPL of the 64-bit call-gate.</td>, <td>If the upper type field of a 64-bit call gate is not 0x0.</td>, <td>If the segment selector from a 64-bit call gate is beyond the descriptor table limits.</td>, <td>If the DPL for a code-segment obtained from a 64-bit call gate is greater than the CPL.</td>, <td>If the code segment descriptor pointed to by the selector in the 64-bit gate doesn't have the L-bit set and the D-bit clear.</td>, <td>If the segment descriptor for a segment selector from the 64-bit call gate does not indicate it is a code segment.</td>, <td rowspan="3">#SS(0)</td>, <td>If pushing the return offset or CS selector onto the stack exceeds the bounds of the stack segment when no stack switch occurs.</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>If the stack address is in a non-canonical form.</td>, <td>#SS(selector)</td>, <td>If pushing the old values of SS selector, stack pointer, EFLAGS, CS selector, offset, or error code onto the stack violates the canonical boundary when a stack switch occurs.</td>, <td>#NP(selector)</td>, <td>If a code segment or 64-bit call gate is not present.</td>, <td>#TS(selector)</td>, <td>If the load of the new RSP exceeds the limit of the TSS.</td>, <td rowspan="2">#UD</td>, <td>(64-bit mode only) If a far call is direct to an absolute address in memory.</td>, <td>If the LOCK prefix is used.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>]

[<td>98</td>, <td>CBW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>AX ← sign-extend of AL.</td>, <td>98</td>, <td>CWDE</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>EAX ← sign-extend of AX.</td>, <td>REX.W + 98</td>, <td>CDQE</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>RAX ← sign-extend of EAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>99</td>, <td>CWD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>DX:AX ← sign-extend of AX.</td>, <td>99</td>, <td>CDQ</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>EDX:EAX ← sign-extend of EAX.</td>, <td>REX.W + 99</td>, <td>CQO</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>RDX:RAX← sign-extend of RAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>98</td>, <td>CBW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>AX ← sign-extend of AL.</td>, <td>98</td>, <td>CWDE</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>EAX ← sign-extend of AX.</td>, <td>REX.W + 98</td>, <td>CDQE</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>RAX ← sign-extend of EAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>NP 0F 01 CA CLAC</td>, <td>ZO</td>, <td>V/V</td>, <td>SMAP</td>, <td>Clear the AC flag in the EFLAGS register.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If the CPL &gt; 0.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.SMAP[bit 20] = 0.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.SMAP[bit 20] = 0.</td>, <td>#UD</td>, <td>The CLAC instruction is not recognized in virtual-8086 mode.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If the CPL &gt; 0.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.SMAP[bit 20] = 0.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If the CPL &gt; 0.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.SMAP[bit 20] = 0.</td>]

[<td>F8</td>, <td>CLC</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Clear CF flag.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>FC</td>, <td>CLD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Clear DF flag.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>NP 0F 1C /0 CLDEMOTE m8</td>, <td>A</td>, <td>V/V</td>, <td>CLDEMOTE</td>, <td>Hint to hardware to move the cache line containing m8 to a more distant level of the cache without writing back to memory.</td>, <td>A</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>NP 0F AE /7 CLFLUSH <em>m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Flushes cache line containing <em>m8</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>For an illegal memory operand effective address in the CS, DS, ES, FS or GS segments.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:EDX.CLFSH[bit 19] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:EDX.CLFSH[bit 19] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:EDX.CLFSH[bit 19] = 0.</td>, <td>If the LOCK prefix is used.</td>]

[<td>NFx 66 0F AE /7 CLFLUSHOPT <em>m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Flushes cache line containing <em>m8</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>For an illegal memory operand effective address in the CS, DS, ES, FS or GS segments.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.(EAX=7,ECX=0):EBX.CLFLUSHOPT[bit 23] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>If an instruction prefix F2H or F3H is used.</td>, <td>#GP</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.(EAX=7,ECX=0):EBX.CLFLUSHOPT[bit 23] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>If an instruction prefix F2H or F3H is used.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.(EAX=7,ECX=0):EBX.CLFLUSHOPT[bit 23] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>If an instruction prefix F2H or F3H is used.</td>]

[<td>FA</td>, <td>CLI</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Clear interrupt flag; interrupts disabled when interrupt flag cleared.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>Real-address</td>, <td><sub>X</sub><sup>1</sup></td>, <td>IF = 0</td>, <td rowspan="2">Protected, not PVI<sup>2</sup></td>, <td>≥ CPL</td>, <td>IF = 0</td>, <td>&lt; CPL</td>, <td>#GP fault</td>, <td rowspan="2">Protected, PVI<sup>3</sup></td>, <td>3</td>, <td>IF = 0</td>, <td>0–2</td>, <td>VIF = 0</td>, <td rowspan="2">Virtual-8086, not VME<sup>3</sup></td>, <td>3</td>, <td>IF = 0</td>, <td>0–2</td>, <td>#GP fault</td>, <td rowspan="2">Virtual-8086, VME<sup>3</sup></td>, <td>3</td>, <td>IF = 0</td>, <td>0–2</td>, <td>VIF = 0</td>, <td rowspan="2">#GP(0)</td>, <td>If CPL is greater than IOPL and PVI mode is not active.</td>, <td>If CPL is greater than IOPL and less than 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If IOPL is less than 3 and VME mode is not active.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 06</td>, <td>CLTS</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Clears TS flag in CR0.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>CLTS is not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the CPL is greater than 0.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>66 0F AE /6 CLWB m8</td>, <td>M</td>, <td>V/V</td>, <td>CLWB</td>, <td>Writes back modified cache line containing m8, and may retain the line in cache hierarchy in non-modified state.</td>, <td>Op/En Operand 1 Operand 2 Operand 3 Operand 4</td>, <td>M ModRM:r/m (w) NA NA NA</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.CLWB[bit 24] = 0.</td>, <td>#GP(0)</td>, <td>For an illegal memory operand effective address in the CS, DS, ES, FS or GS segments.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.CLWB[bit 24] = 0.</td>, <td>#GP</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.CLWB[bit 24] = 0.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>]

[<td>F5</td>, <td>CMC</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Complement CF flag.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>0F 47 <em>/r</em></td>, <td>CMOVA <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if above (CF=0 and ZF=0).</td>, <td>0F 47 <em>/r</em></td>, <td>CMOVA <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if above (CF=0 and ZF=0).</td>, <td>REX.W + 0F 47 <em>/r</em></td>, <td>CMOVA <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if above (CF=0 and ZF=0).</td>, <td>0F 43 <em>/r</em></td>, <td>CMOVAE <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if above or equal (CF=0).</td>, <td>0F 43 <em>/r</em></td>, <td>CMOVAE <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if above or equal (CF=0).</td>, <td>REX.W + 0F 43 <em>/r</em></td>, <td>CMOVAE <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if above or equal (CF=0).</td>, <td>0F 42 <em>/r</em></td>, <td>CMOVB <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if below (CF=1).</td>, <td>0F 42 <em>/r</em></td>, <td>CMOVB <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if below (CF=1).</td>, <td>REX.W + 0F 42 <em>/r</em></td>, <td>CMOVB <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if below (CF=1).</td>, <td>0F 46 <em>/r</em></td>, <td>CMOVBE <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if below or equal (CF=1 or ZF=1).</td>, <td>0F 46 <em>/r</em></td>, <td>CMOVBE <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if below or equal (CF=1 or ZF=1).</td>, <td>REX.W + 0F 46 <em>/r</em></td>, <td>CMOVBE <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if below or equal (CF=1 or ZF=1).</td>, <td>0F 42 <em>/r</em></td>, <td>CMOVC <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if carry (CF=1).</td>, <td>0F 42 <em>/r</em></td>, <td>CMOVC <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if carry (CF=1).</td>, <td>REX.W + 0F 42 <em>/r</em></td>, <td>CMOVC <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if carry (CF=1).</td>, <td>0F 44 <em>/r</em></td>, <td>CMOVE <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if equal (ZF=1).</td>, <td>0F 44 <em>/r</em></td>, <td>CMOVE <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if equal (ZF=1).</td>, <td>REX.W + 0F 44 <em>/r</em></td>, <td>CMOVE <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if equal (ZF=1).</td>, <td>0F 4F <em>/r</em></td>, <td>CMOVG <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if greater (ZF=0 and SF=OF).</td>, <td>0F 4F <em>/r</em></td>, <td>CMOVG <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if greater (ZF=0 and SF=OF).</td>, <td>REX.W + 0F 4F <em>/r</em></td>, <td>CMOVG <em>r64, r/m64</em></td>, <td>RM</td>, <td>V/N.E.</td>, <td>NA</td>, <td>Move if greater (ZF=0 and SF=OF).</td>, <td>0F 4D <em>/r</em></td>, <td>CMOVGE <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if greater or equal (SF=OF).</td>, <td>0F 4D <em>/r</em></td>, <td>CMOVGE <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if greater or equal (SF=OF).</td>, <td>REX.W + 0F 4D <em>/r</em></td>, <td>CMOVGE <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if greater or equal (SF=OF).</td>, <td>0F 4C <em>/r</em></td>, <td>CMOVL <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if less (SF≠ OF).</td>, <td>0F 4C <em>/r</em></td>, <td>CMOVL <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if less (SF≠ OF).</td>, <td>REX.W + 0F 4C <em>/r</em></td>, <td>CMOVL <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if less (SF≠ OF).</td>, <td>0F 4E <em>/r</em></td>, <td>CMOVLE <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if less or equal (ZF=1 or SF≠ OF).</td>, <td>0F 4E <em>/r</em></td>, <td>CMOVLE <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if less or equal (ZF=1 or SF≠ OF).</td>, <td>REX.W + 0F 4E <em>/r</em></td>, <td>CMOVLE <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if less or equal (ZF=1 or SF≠ OF).</td>, <td>0F 46 <em>/r</em></td>, <td>CMOVNA <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not above (CF=1 or ZF=1).</td>, <td>0F 46 <em>/r</em></td>, <td>CMOVNA <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not above (CF=1 or ZF=1).</td>, <td>REX.W + 0F 46 <em>/r</em></td>, <td>CMOVNA <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if not above (CF=1 or ZF=1).</td>, <td>0F 42 <em>/r</em></td>, <td>CMOVNAE <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not above or equal (CF=1).</td>, <td>0F 42 <em>/r</em></td>, <td>CMOVNAE <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not above or equal (CF=1).</td>, <td>REX.W + 0F 42 <em>/r</em></td>, <td>CMOVNAE <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if not above or equal (CF=1).</td>, <td>0F 43 <em>/r</em></td>, <td>CMOVNB <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not below (CF=0).</td>, <td>0F 43 <em>/r</em></td>, <td>CMOVNB <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not below (CF=0).</td>, <td>REX.W + 0F 43 <em>/r</em></td>, <td>CMOVNB <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if not below (CF=0).</td>, <td>0F 47 <em>/r</em></td>, <td>CMOVNBE <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not below or equal (CF=0 and ZF=0).</td>, <td>0F 47 <em>/r</em></td>, <td>CMOVNBE <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not below or equal (CF=0 and ZF=0).</td>, <td>REX.W + 0F 47 <em>/r</em></td>, <td>CMOVNBE <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if not below or equal (CF=0 and ZF=0).</td>, <td>0F 43 <em>/r</em></td>, <td>CMOVNC <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not carry (CF=0).</td>, <td>0F 43 <em>/r</em></td>, <td>CMOVNC <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not carry (CF=0).</td>, <td>REX.W + 0F 43 <em>/r</em></td>, <td>CMOVNC <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if not carry (CF=0).</td>, <td>0F 45 <em>/r</em></td>, <td>CMOVNE <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not equal (ZF=0).</td>, <td>0F 45 <em>/r</em></td>, <td>CMOVNE <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not equal (ZF=0).</td>, <td>REX.W + 0F 45 <em>/r</em></td>, <td>CMOVNE <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if not equal (ZF=0).</td>, <td>0F 4E <em>/r</em></td>, <td>CMOVNG <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not greater (ZF=1 or SF≠ OF).</td>, <td>0F 4E <em>/r</em></td>, <td>CMOVNG <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not greater (ZF=1 or SF≠ OF).</td>, <td>REX.W + 0F 4E <em>/r</em></td>, <td>CMOVNG <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if not greater (ZF=1 or SF≠ OF).</td>, <td>0F 4C <em>/r</em></td>, <td>CMOVNGE <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not greater or equal (SF≠ OF).</td>, <td>0F 4C <em>/r</em></td>, <td>CMOVNGE <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not greater or equal (SF≠ OF).</td>, <td>REX.W + 0F 4C <em>/r</em></td>, <td>CMOVNGE <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if not greater or equal (SF≠ OF).</td>, <td>0F 4D <em>/r</em></td>, <td>CMOVNL <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not less (SF=OF).</td>, <td>0F 4D <em>/r</em></td>, <td>CMOVNL <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not less (SF=OF).</td>, <td>REX.W + 0F 4D <em>/r</em></td>, <td>CMOVNL <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if not less (SF=OF).</td>, <td>0F 4F <em>/r</em></td>, <td>CMOVNLE <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not less or equal (ZF=0 and SF=OF).</td>, <td>0F 4F <em>/r</em></td>, <td>CMOVNLE <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not less or equal (ZF=0 and SF=OF).</td>, <td>REX.W + 0F 4F <em>/r</em></td>, <td>CMOVNLE <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if not less or equal (ZF=0 and SF=OF).</td>, <td>0F 41 <em>/r</em></td>, <td>CMOVNO <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not overflow (OF=0).</td>, <td>0F 41 <em>/r</em></td>, <td>CMOVNO <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not overflow (OF=0).</td>, <td>REX.W + 0F 41 <em>/r</em></td>, <td>CMOVNO <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if not overflow (OF=0).</td>, <td>0F 4B <em>/r</em></td>, <td>CMOVNP <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not parity (PF=0).</td>, <td>0F 4B <em>/r</em></td>, <td>CMOVNP <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not parity (PF=0).</td>, <td>REX.W + 0F 4B <em>/r</em></td>, <td>CMOVNP <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if not parity (PF=0).</td>, <td>0F 49 <em>/r</em></td>, <td>CMOVNS <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not sign (SF=0).</td>, <td>0F 49 <em>/r</em></td>, <td>CMOVNS <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not sign (SF=0).</td>, <td>REX.W + 0F 49 <em>/r</em></td>, <td>CMOVNS <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if not sign (SF=0).</td>, <td>0F 45 <em>/r</em></td>, <td>CMOVNZ <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not zero (ZF=0).</td>, <td>0F 45 <em>/r</em></td>, <td>CMOVNZ <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not zero (ZF=0).</td>, <td>REX.W + 0F 45 <em>/r</em></td>, <td>CMOVNZ <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if not zero (ZF=0).</td>, <td>0F 40 <em>/r</em></td>, <td>CMOVO <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if overflow (OF=1).</td>, <td>0F 40 <em>/r</em></td>, <td>CMOVO <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if overflow (OF=1).</td>, <td>REX.W + 0F 40 <em>/r</em></td>, <td>CMOVO <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if overflow (OF=1).</td>, <td>0F 4A <em>/r</em></td>, <td>CMOVP <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if parity (PF=1).</td>, <td>0F 4A <em>/r</em></td>, <td>CMOVP <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if parity (PF=1).</td>, <td>REX.W + 0F 4A <em>/r</em></td>, <td>CMOVP <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if parity (PF=1).</td>, <td>0F 4A <em>/r</em></td>, <td>CMOVPE <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if parity even (PF=1).</td>, <td>0F 4A <em>/r</em></td>, <td>CMOVPE <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if parity even (PF=1).</td>, <td>REX.W + 0F 4A <em>/r</em></td>, <td>CMOVPE <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if parity even (PF=1).</td>, <td>0F 4B <em>/r</em></td>, <td>CMOVPO <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if parity odd (PF=0).</td>, <td>0F 4B <em>/r</em></td>, <td>CMOVPO <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if parity odd (PF=0).</td>, <td>REX.W + 0F 4B <em>/r</em></td>, <td>CMOVPO <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if parity odd (PF=0).</td>, <td>0F 48 <em>/r</em></td>, <td>CMOVS <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if sign (SF=1).</td>, <td>0F 48 <em>/r</em></td>, <td>CMOVS <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if sign (SF=1).</td>, <td>REX.W + 0F 48 <em>/r</em></td>, <td>CMOVS <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if sign (SF=1).</td>, <td>0F 44 <em>/r</em></td>, <td>CMOVZ <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if zero (ZF=1).</td>, <td>0F 44 <em>/r</em></td>, <td>CMOVZ <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if zero (ZF=1).</td>, <td>REX.W + 0F 44 <em>/r</em></td>, <td>CMOVZ <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move if zero (ZF=1).</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>3C <em>ib</em></td>, <td>CMP AL, <em>imm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare <em>imm8</em> with AL.</td>, <td>3D <em>iw</em></td>, <td>CMP AX, <em>imm16</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare <em>imm16</em> with AX.</td>, <td>3D <em>id</em></td>, <td>CMP EAX, <em>imm32</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare <em>imm32</em> with EAX.</td>, <td>REX.W + 3D <em>id</em></td>, <td>CMP RAX, <em>imm32</em></td>, <td>I</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare <em>imm32 sign-extended to 64-bits</em> with RAX.</td>, <td>80 /7 <em>ib</em></td>, <td>CMP <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare <em>imm8</em> with <em>r/m8.</em></td>, <td>REX + 80 /7 <em>ib</em></td>, <td>CMP <em>r/m8</em><sup>*</sup><em>, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare <em>imm8</em> with <em>r/m8.</em></td>, <td>81 /7 <em>iw</em></td>, <td>CMP <em>r/m16, imm16</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare <em>imm16</em> with <em>r/m16.</em></td>, <td>81 /7 <em>id</em></td>, <td>CMP <em>r/m32, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare <em>imm32</em> with <em>r/m32.</em></td>, <td>REX.W + 81 /7 <em>id</em></td>, <td>CMP <em>r/m64, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare <em>imm32 sign-extended to 64-bits</em> with <em>r/m64.</em></td>, <td>83 /7 <em>ib</em></td>, <td>CMP <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare <em>imm8</em> with <em>r/m16.</em></td>, <td>83 /7 <em>ib</em></td>, <td>CMP <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare <em>imm8</em> with <em>r/m32.</em></td>, <td>REX.W + 83 /7 <em>ib</em></td>, <td>CMP <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare <em>imm8</em> with <em>r/m64.</em></td>, <td>38 /<em>r</em></td>, <td>CMP <em>r/m8, r8</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare <em>r8</em> with <em>r/m8.</em></td>, <td>REX + 38 /<em>r</em></td>, <td>CMP <em>r/m8</em><sup>*</sup><em>, r8</em><sup>*</sup></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare <em>r8</em> with <em>r/m8.</em></td>, <td>39 /<em>r</em></td>, <td>CMP <em>r/m16, r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare <em>r16</em> with <em>r/m16.</em></td>, <td>39 /<em>r</em></td>, <td>CMP <em>r/m32, r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare <em>r32</em> with <em>r/m32.</em></td>, <td>REX.W + 39 /<em>r</em></td>, <td>CMP <em>r/m64,r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare <em>r64</em> with <em>r/m64.</em></td>, <td>3A /<em>r</em></td>, <td>CMP <em>r8, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare <em>r/m8</em> with <em>r8.</em></td>, <td>REX + 3A /<em>r</em></td>, <td>CMP <em>r8</em><sup>*</sup><em>, r/m8</em><sup>*</sup></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare <em>r/m8 with r8.</em></td>, <td>3B /<em>r</em></td>, <td>CMP <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare <em>r/m16</em> with <em>r16.</em></td>, <td>3B /<em>r</em></td>, <td>CMP <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare <em>r/m32</em> with <em>r32.</em></td>, <td>REX.W + 3B /<em>r</em></td>, <td>CMP <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare <em>r/m64</em> with <em>r64.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>MR</td>, <td>ModRM:r/m (r)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (r)</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td>I</td>, <td>AL/AX/EAX/RAX (r)</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>66 0F C2 /r ib CMPPD xmm1, xmm2/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed double-precision floating-point values in xmm2/m128 and xmm1 using bits 2:0 of imm8 as a comparison predicate.</td>, <td>VEX.128.66.0F.WIG C2 /r ib VCMPPD xmm1, xmm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed double-precision floating-point values in xmm3/m128 and xmm2 using bits 4:0 of imm8 as a comparison predicate.</td>, <td>VEX.256.66.0F.WIG C2 /r ib VCMPPD ymm1, ymm2, ymm3/m256, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed double-precision floating-point values in ymm3/m256 and ymm2 using bits 4:0 of imm8 as a comparison predicate.</td>, <td>EVEX.128.66.0F.W1 C2 /r ib VCMPPD k1 {k2}, xmm2, xmm3/m128/m64bcst, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed double-precision floating-point values in xmm3/m128/m64bcst and xmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F.W1 C2 /r ib VCMPPD k1 {k2}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed double-precision floating-point values in ymm3/m256/m64bcst and ymm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.512.66.0F.W1 C2 /r ib VCMPPD k1 {k2}, zmm2, zmm3/m512/m64bcst{sae}, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed double-precision floating-point values in zmm3/m512/m64bcst and zmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>EQ_OQ (EQ)</td>, <td>0H</td>, <td>Equal (ordered, non-signaling)</td>, <td>False</td>, <td>False</td>, <td>True</td>, <td>False</td>, <td>No</td>, <td>LT_OS (LT)</td>, <td>1H</td>, <td>Less-than (ordered, signaling)</td>, <td>False</td>, <td>True</td>, <td>False</td>, <td>False</td>, <td>Yes</td>, <td>LE_OS (LE)</td>, <td>2H</td>, <td>Less-than-or-equal (ordered, signaling)</td>, <td>False</td>, <td>True</td>, <td>True</td>, <td>False</td>, <td>Yes</td>, <td>UNORD_Q (UNORD)</td>, <td>3H</td>, <td>Unordered (non-signaling)</td>, <td>False</td>, <td>False</td>, <td>False</td>, <td>True</td>, <td>No</td>, <td>NEQ_UQ (NEQ)</td>, <td>4H</td>, <td>Not-equal (unordered, non-signaling)</td>, <td>True</td>, <td>True</td>, <td>False</td>, <td>True</td>, <td>No</td>, <td>NLT_US (NLT)</td>, <td>5H</td>, <td>Not-less-than (unordered, signaling)</td>, <td>True</td>, <td>False</td>, <td>True</td>, <td>True</td>, <td>Yes</td>, <td>NLE_US (NLE)</td>, <td>6H</td>, <td>Not-less-than-or-equal (unordered, signaling)</td>, <td>True</td>, <td>False</td>, <td>False</td>, <td>True</td>, <td>Yes</td>, <td>ORD_Q (ORD)</td>, <td>7H</td>, <td>Ordered (non-signaling)</td>, <td>True</td>, <td>True</td>, <td>True</td>, <td>False</td>, <td>No</td>, <td>EQ_UQ</td>, <td>8H</td>, <td>Equal (unordered, non-signaling)</td>, <td>False</td>, <td>False</td>, <td>True</td>, <td>True</td>, <td>No</td>, <td>NGE_US (NGE)</td>, <td>9H</td>, <td>Not-greater-than-or-equal (unordered, signaling)</td>, <td>False</td>, <td>True</td>, <td>False</td>, <td>True</td>, <td>Yes</td>, <td>NGT_US (NGT)</td>, <td>AH</td>, <td>Not-greater-than (unordered, signaling)</td>, <td>False</td>, <td>True</td>, <td>True</td>, <td>True</td>, <td>Yes</td>, <td>FALSE_OQ(FALSE)</td>, <td>BH</td>, <td>False (ordered, non-signaling)</td>, <td>False</td>, <td>False</td>, <td>False</td>, <td>False</td>, <td>No</td>, <td>NEQ_OQ</td>, <td>CH</td>, <td>Not-equal (ordered, non-signaling)</td>, <td>True</td>, <td>True</td>, <td>False</td>, <td>False</td>, <td>No</td>, <td>GE_OS (GE)</td>, <td>DH</td>, <td>Greater-than-or-equal (ordered, signaling)</td>, <td>True</td>, <td>False</td>, <td>True</td>, <td>False</td>, <td>Yes</td>, <td>GT_OS (GT)</td>, <td>EH</td>, <td>Greater-than (ordered, signaling)</td>, <td>True</td>, <td>False</td>, <td>False</td>, <td>False</td>, <td>Yes</td>, <td>TRUE_UQ(TRUE)</td>, <td>FH</td>, <td>True (unordered, non-signaling)</td>, <td>True</td>, <td>True</td>, <td>True</td>, <td>True</td>, <td>No</td>, <td>EQ_OS</td>, <td>10H</td>, <td>Equal (ordered, signaling)</td>, <td>False</td>, <td>False</td>, <td>True</td>, <td>False</td>, <td>Yes</td>, <td>LT_OQ</td>, <td>11H</td>, <td>Less-than (ordered, nonsignaling)</td>, <td>False</td>, <td>True</td>, <td>False</td>, <td>False</td>, <td>No</td>, <td>LE_OQ</td>, <td>12H</td>, <td>Less-than-or-equal (ordered, nonsignaling)</td>, <td>False</td>, <td>True</td>, <td>True</td>, <td>False</td>, <td>No</td>, <td>UNORD_S</td>, <td>13H</td>, <td>Unordered (signaling)</td>, <td>False</td>, <td>False</td>, <td>False</td>, <td>True</td>, <td>Yes</td>, <td>NEQ_US</td>, <td>14H</td>, <td>Not-equal (unordered, signaling)</td>, <td>True</td>, <td>True</td>, <td>False</td>, <td>True</td>, <td>Yes</td>, <td>NLT_UQ</td>, <td>15H</td>, <td>Not-less-than (unordered, nonsignaling)</td>, <td>True</td>, <td>False</td>, <td>True</td>, <td>True</td>, <td>No</td>, <td>NLE_UQ</td>, <td>16H</td>, <td>Not-less-than-or-equal (unordered, nonsignaling)</td>, <td>True</td>, <td>False</td>, <td>False</td>, <td>True</td>, <td>No</td>, <td>ORD_S</td>, <td>17H</td>, <td>Ordered (signaling)</td>, <td>True</td>, <td>True</td>, <td>True</td>, <td>False</td>, <td>Yes</td>, <td>EQ_US</td>, <td>18H</td>, <td>Equal (unordered, signaling)</td>, <td>False</td>, <td>False</td>, <td>True</td>, <td>True</td>, <td>Yes</td>, <td>NGE_UQ</td>, <td>19H</td>, <td>Not-greater-than-or-equal (unordered, non-signaling)</td>, <td>False</td>, <td>True</td>, <td>False</td>, <td>True</td>, <td>No</td>, <td>NGT_UQ</td>, <td>1AH</td>, <td>Not-greater-than (unordered, nonsignaling)</td>, <td>False</td>, <td>True</td>, <td>True</td>, <td>True</td>, <td>No</td>, <td>FALSE_OS</td>, <td>1BH</td>, <td>False (ordered, signaling)</td>, <td>False</td>, <td>False</td>, <td>False</td>, <td>False</td>, <td>Yes</td>, <td>NEQ_OS</td>, <td>1CH</td>, <td>Not-equal (ordered, signaling)</td>, <td>True</td>, <td>True</td>, <td>False</td>, <td>False</td>, <td>Yes</td>, <td>GE_OQ</td>, <td>1DH</td>, <td>Greater-than-or-equal (ordered, nonsignaling)</td>, <td>True</td>, <td>False</td>, <td>True</td>, <td>False</td>, <td>No</td>, <td>GT_OQ</td>, <td>1EH</td>, <td>Greater-than (ordered, nonsignaling)</td>, <td>True</td>, <td>False</td>, <td>False</td>, <td>False</td>, <td>No</td>, <td>TRUE_US</td>, <td>1FH</td>, <td>True (unordered, signaling)</td>, <td>True</td>, <td>True</td>, <td>True</td>, <td>True</td>, <td>Yes</td>, <td>CMPEQPD <em>xmm1, xmm2</em></td>, <td>CMPPD <em>xmm1, xmm2, 0</em></td>, <td>CMPLTPD <em>xmm1, xmm2</em></td>, <td>CMPPD <em>xmm1, xmm2, 1</em></td>, <td>CMPLEPD <em>xmm1, xmm2</em></td>, <td>CMPPD <em>xmm1, xmm2, 2</em></td>, <td>CMPUNORDPD <em>xmm1, xmm2</em></td>, <td>CMPPD <em>xmm1, xmm2, 3</em></td>, <td>CMPNEQPD <em>xmm1, xmm2</em></td>, <td>CMPPD <em>xmm1, xmm2, 4</em></td>, <td>CMPNLTPD <em>xmm1, xmm2</em></td>, <td>CMPPD <em>xmm1, xmm2, 5</em></td>, <td>CMPNLEPD <em>xmm1, xmm2</em></td>, <td>CMPPD <em>xmm1, xmm2, 6</em></td>, <td>CMPORDPD <em>xmm1, xmm2</em></td>, <td>CMPPD <em>xmm1, xmm2, 7</em></td>, <td>VCMPEQPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 0</em></td>, <td>VCMPLTPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 1</em></td>, <td>VCMPLEPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 2</em></td>, <td>VCMPUNORDPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 3</em></td>, <td>VCMPNEQPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 4</em></td>, <td>VCMPNLTPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 5</em></td>, <td>VCMPNLEPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 6</em></td>, <td>VCMPORDPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 7</em></td>, <td>VCMPEQ_UQPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 8</em></td>, <td>VCMPNGEPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 9</em></td>, <td>VCMPNGTPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 0AH</em></td>, <td>VCMPFALSEPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 0BH</em></td>, <td>VCMPNEQ_OQPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 0CH</em></td>, <td>VCMPGEPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 0DH</em></td>, <td>VCMPGTPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 0EH</em></td>, <td>VCMPTRUEPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 0FH</em></td>, <td>VCMPEQ_OSPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 10H</em></td>, <td>VCMPLT_OQPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 11H</em></td>, <td>VCMPLE_OQPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 12H</em></td>, <td>VCMPUNORD_SPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 13H</em></td>, <td>VCMPNEQ_USPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 14H</em></td>, <td>VCMPNLT_UQPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 15H</em></td>, <td>VCMPNLE_UQPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 16H</em></td>, <td>VCMPORD_SPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 17H</em></td>, <td>VCMPEQ_USPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 18H</em></td>, <td>VCMPNGE_UQPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 19H</em></td>, <td>VCMPNGT_UQPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 1AH</em></td>, <td>VCMPFALSE_OSPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 1BH</em></td>, <td>VCMPNEQ_OSPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 1CH</em></td>, <td>VCMPGE_OQPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 1DH</em></td>, <td>VCMPGT_OQPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 1EH</em></td>, <td>VCMPTRUE_USPD <em>reg1, reg2, reg3</em></td>, <td>VCMPPD <em>reg1, reg2, reg3, 1FH</em></td>]

[<td>NP 0F C2 /r ib CMPPS xmm1, xmm2/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Compare packed single-precision floating-point values in xmm2/m128 and xmm1 using bits 2:0 of imm8 as a comparison predicate.</td>, <td>VEX.128.0F.WIG C2 /r ib VCMPPS xmm1, xmm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed single-precision floating-point values in xmm3/m128 and xmm2 using bits 4:0 of imm8 as a comparison predicate.</td>, <td>VEX.256.0F.WIG C2 /r ib VCMPPS ymm1, ymm2, ymm3/m256, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed single-precision floating-point values in ymm3/m256 and ymm2 using bits 4:0 of imm8 as a comparison predicate.</td>, <td>EVEX.128.0F.W0 C2 /r ib VCMPPS k1 {k2}, xmm2, xmm3/m128/m32bcst, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed single-precision floating-point values in xmm3/m128/m32bcst and xmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.0F.W0 C2 /r ib VCMPPS k1 {k2}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed single-precision floating-point values in ymm3/m256/m32bcst and ymm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.512.0F.W0 C2 /r ib VCMPPS k1 {k2}, zmm2, zmm3/m512/m32bcst{sae}, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed single-precision floating-point values in zmm3/m512/m32bcst and zmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>CMPEQPS x<em>mm1, xmm2</em></td>, <td>CMPPS <em>xmm1, xmm2, 0</em></td>, <td>CMPLTPS x<em>mm1, xmm2</em></td>, <td>CMPPS <em>xmm1, xmm2, 1</em></td>, <td>CMPLEPS x<em>mm1, xmm2</em></td>, <td>CMPPS <em>xmm1, xmm2, 2</em></td>, <td>CMPUNORDPS x<em>mm1, xmm2</em></td>, <td>CMPPS <em>xmm1, xmm2, 3</em></td>, <td>CMPNEQPS x<em>mm1, xmm2</em></td>, <td>CMPPS <em>xmm1, xmm2, 4</em></td>, <td>CMPNLTPS x<em>mm1, xmm2</em></td>, <td>CMPPS <em>xmm1, xmm2, 5</em></td>, <td>CMPNLEPS x<em>mm1, xmm2</em></td>, <td>CMPPS <em>xmm1, xmm2, 6</em></td>, <td>CMPORDPS x<em>mm1, xmm2</em></td>, <td>CMPPS <em>xmm1, xmm2, 7</em></td>, <td>VCMPEQPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 0</em></td>, <td>VCMPLTPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 1</em></td>, <td>VCMPLEPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 2</em></td>, <td>VCMPUNORDPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 3</em></td>, <td>VCMPNEQPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 4</em></td>, <td>VCMPNLTPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 5</em></td>, <td>VCMPNLEPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 6</em></td>, <td>VCMPORDPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 7</em></td>, <td>VCMPEQ_UQPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 8</em></td>, <td>VCMPNGEPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 9</em></td>, <td>VCMPNGTPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 0AH</em></td>, <td>VCMPFALSEPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 0BH</em></td>, <td>VCMPNEQ_OQPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 0CH</em></td>, <td>VCMPGEPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 0DH</em></td>, <td>VCMPGTPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 0EH</em></td>, <td>VCMPTRUEPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 0FH</em></td>, <td>VCMPEQ_OSPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 10H</em></td>, <td>VCMPLT_OQPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 11H</em></td>, <td>VCMPLE_OQPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 12H</em></td>, <td>VCMPUNORD_SPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 13H</em></td>, <td>VCMPNEQ_USPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 14H</em></td>, <td>VCMPNLT_UQPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 15H</em></td>, <td>VCMPNLE_UQPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 16H</em></td>, <td>VCMPORD_SPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 17H</em></td>, <td>VCMPEQ_USPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 18H</em></td>, <td>VCMPNGE_UQPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 19H</em></td>, <td>VCMPNGT_UQPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 1AH</em></td>, <td>VCMPFALSE_OSPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 1BH</em></td>, <td>VCMPNEQ_OSPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 1CH</em></td>, <td>VCMPGE_OQPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 1DH</em></td>, <td>VCMPGT_OQPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 1EH</em></td>, <td>VCMPTRUE_USPS r<em>eg1, reg2, reg3</em></td>, <td>VCMPPS r<em>eg1, reg2, reg3, 1FH</em></td>]

[<td>A6</td>, <td>CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64-bit mode compare byte at address (R|E)SI to byte at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPS <em>m16</em>, <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64-bit mode compare word at address (R|E)SI with word at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare dword at address DS:(E)SI at dword at address ES:(E)DI; For 64-bit mode compare dword at address (R|E)SI at dword at address (R|E)DI. The status flags are set accordingly.</td>, <td>REX.W + A7</td>, <td>CMPS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compares quadword at address (R|E)SI with quadword at address (R|E)DI and sets the status flags accordingly.</td>, <td>A6</td>, <td>CMPSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64-bit mode compare byte at address (R|E)SI with byte at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64-bit mode compare word at address (R|E)SI with word at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare dword at address DS:(E)SI with dword at address ES:(E)DI; For 64-bit mode compare dword at address (R|E)SI with dword at address (R|E)DI. The status flags are set accordingly.</td>, <td>REX.W + A7</td>, <td>CMPSQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compares quadword at address (R|E)SI with quadword at address (R|E)DI and sets the status flags accordingly.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>A6</td>, <td>CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64-bit mode compare byte at address (R|E)SI to byte at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPS <em>m16</em>, <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64-bit mode compare word at address (R|E)SI with word at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare dword at address DS:(E)SI at dword at address ES:(E)DI; For 64-bit mode compare dword at address (R|E)SI at dword at address (R|E)DI. The status flags are set accordingly.</td>, <td>REX.W + A7</td>, <td>CMPS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compares quadword at address (R|E)SI with quadword at address (R|E)DI and sets the status flags accordingly.</td>, <td>A6</td>, <td>CMPSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64-bit mode compare byte at address (R|E)SI with byte at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64-bit mode compare word at address (R|E)SI with word at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare dword at address DS:(E)SI with dword at address ES:(E)DI; For 64-bit mode compare dword at address (R|E)SI with dword at address (R|E)DI. The status flags are set accordingly.</td>, <td>REX.W + A7</td>, <td>CMPSQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compares quadword at address (R|E)SI with quadword at address (R|E)DI and sets the status flags accordingly.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>A6</td>, <td>CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64-bit mode compare byte at address (R|E)SI to byte at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPS <em>m16</em>, <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64-bit mode compare word at address (R|E)SI with word at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare dword at address DS:(E)SI at dword at address ES:(E)DI; For 64-bit mode compare dword at address (R|E)SI at dword at address (R|E)DI. The status flags are set accordingly.</td>, <td>REX.W + A7</td>, <td>CMPS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compares quadword at address (R|E)SI with quadword at address (R|E)DI and sets the status flags accordingly.</td>, <td>A6</td>, <td>CMPSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64-bit mode compare byte at address (R|E)SI with byte at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64-bit mode compare word at address (R|E)SI with word at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare dword at address DS:(E)SI with dword at address ES:(E)DI; For 64-bit mode compare dword at address (R|E)SI with dword at address (R|E)DI. The status flags are set accordingly.</td>, <td>REX.W + A7</td>, <td>CMPSQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compares quadword at address (R|E)SI with quadword at address (R|E)DI and sets the status flags accordingly.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>F2 0F C2 /r ib CMPSD xmm1, xmm2/m64, imm8</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare low double-precision floating-point value in xmm2/m64 and xmm1 using bits 2:0 of imm8 as comparison predicate.</td>, <td>VEX.LIG.F2.0F.WIG C2 /r ib VCMPSD xmm1, xmm2, xmm3/m64, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare low double-precision floating-point value in xmm3/m64 and xmm2 using bits 4:0 of imm8 as comparison predicate.</td>, <td>EVEX.LIG.F2.0F.W1 C2 /r ib VCMPSD k1 {k2}, xmm2, xmm3/m64{sae}, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare low double-precision floating-point value in xmm3/m64 and xmm2 using bits 4:0 of imm8 as comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>CMPEQSD x<em>mm1, xmm2</em></td>, <td>CMPSD x<em>mm1, xmm2, 0</em></td>, <td>CMPLTSD x<em>mm1, xmm2</em></td>, <td>CMPSD x<em>mm1, xmm2, 1</em></td>, <td>CMPLESD x<em>mm1, xmm2</em></td>, <td>CMPSD x<em>mm1, xmm2, 2</em></td>, <td>CMPUNORDSD x<em>mm1, xmm2</em></td>, <td>CMPSD x<em>mm1, xmm2, 3</em></td>, <td>CMPNEQSD x<em>mm1, xmm2</em></td>, <td>CMPSD x<em>mm1, xmm2, 4</em></td>, <td>CMPNLTSD x<em>mm1, xmm2</em></td>, <td>CMPSD x<em>mm1, xmm2, 5</em></td>, <td>CMPNLESD x<em>mm1, xmm2</em></td>, <td>CMPSD x<em>mm1, xmm2, 6</em></td>, <td>CMPORDSD x<em>mm1, xmm2</em></td>, <td>CMPSD x<em>mm1, xmm2, 7</em></td>, <td>VCMPEQSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 0</em></td>, <td>VCMPLTSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 1</em></td>, <td>VCMPLESD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 2</em></td>, <td>VCMPUNORDSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 3</em></td>, <td>VCMPNEQSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 4</em></td>, <td>VCMPNLTSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 5</em></td>, <td>VCMPNLESD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 6</em></td>, <td>VCMPORDSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 7</em></td>, <td>VCMPEQ_UQSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 8</em></td>, <td>VCMPNGESD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 9</em></td>, <td>VCMPNGTSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 0AH</em></td>, <td>VCMPFALSESD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 0BH</em></td>, <td>VCMPNEQ_OQSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 0CH</em></td>, <td>VCMPGESD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 0DH</em></td>, <td>VCMPGTSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 0EH</em></td>, <td>VCMPTRUESD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 0FH</em></td>, <td>VCMPEQ_OSSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 10H</em></td>, <td>VCMPLT_OQSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 11H</em></td>, <td>VCMPLE_OQSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 12H</em></td>, <td>VCMPUNORD_SSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 13H</em></td>, <td>VCMPNEQ_USSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 14H</em></td>, <td>VCMPNLT_UQSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 15H</em></td>, <td>VCMPNLE_UQSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 16H</em></td>, <td>VCMPORD_SSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 17H</em></td>, <td>VCMPEQ_USSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 18H</em></td>, <td>VCMPNGE_UQSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 19H</em></td>, <td>VCMPNGT_UQSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 1AH</em></td>, <td>VCMPFALSE_OSSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 1BH</em></td>, <td>VCMPNEQ_OSSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 1CH</em></td>, <td>VCMPGE_OQSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 1DH</em></td>, <td>VCMPGT_OQSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 1EH</em></td>, <td>VCMPTRUE_USSD r<em>eg1, reg2, reg3</em></td>, <td>VCMPSD r<em>eg1, reg2, reg3, 1FH</em></td>]

[<td>A6</td>, <td>CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64-bit mode compare byte at address (R|E)SI to byte at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPS <em>m16</em>, <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64-bit mode compare word at address (R|E)SI with word at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare dword at address DS:(E)SI at dword at address ES:(E)DI; For 64-bit mode compare dword at address (R|E)SI at dword at address (R|E)DI. The status flags are set accordingly.</td>, <td>REX.W + A7</td>, <td>CMPS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compares quadword at address (R|E)SI with quadword at address (R|E)DI and sets the status flags accordingly.</td>, <td>A6</td>, <td>CMPSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64-bit mode compare byte at address (R|E)SI with byte at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64-bit mode compare word at address (R|E)SI with word at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare dword at address DS:(E)SI with dword at address ES:(E)DI; For 64-bit mode compare dword at address (R|E)SI with dword at address (R|E)DI. The status flags are set accordingly.</td>, <td>REX.W + A7</td>, <td>CMPSQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compares quadword at address (R|E)SI with quadword at address (R|E)DI and sets the status flags accordingly.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>F3 0F C2 /r ib CMPSS xmm1, xmm2/m32, imm8</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Compare low single-precision floating-point value in xmm2/m32 and xmm1 using bits 2:0 of imm8 as comparison predicate.</td>, <td>VEX.LIG.F3.0F.WIG C2 /r ib VCMPSS xmm1, xmm2, xmm3/m32, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare low single-precision floating-point value in xmm3/m32 and xmm2 using bits 4:0 of imm8 as comparison predicate.</td>, <td>EVEX.LIG.F3.0F.W0 C2 /r ib VCMPSS k1 {k2}, xmm2, xmm3/m32{sae}, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare low single-precision floating-point value in xmm3/m32 and xmm2 using bits 4:0 of imm8 as comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>CMPEQSS x<em>mm1, xmm2</em></td>, <td>CMPSS x<em>mm1, xmm2, 0</em></td>, <td>CMPLTSS x<em>mm1, xmm2</em></td>, <td>CMPSS x<em>mm1, xmm2, 1</em></td>, <td>CMPLESS x<em>mm1, xmm2</em></td>, <td>CMPSS x<em>mm1, xmm2, 2</em></td>, <td>CMPUNORDSS x<em>mm1, xmm2</em></td>, <td>CMPSS x<em>mm1, xmm2, 3</em></td>, <td>CMPNEQSS x<em>mm1, xmm2</em></td>, <td>CMPSS x<em>mm1, xmm2, 4</em></td>, <td>CMPNLTSS x<em>mm1, xmm2</em></td>, <td>CMPSS x<em>mm1, xmm2, 5</em></td>, <td>CMPNLESS x<em>mm1, xmm2</em></td>, <td>CMPSS x<em>mm1, xmm2, 6</em></td>, <td>CMPORDSS x<em>mm1, xmm2</em></td>, <td>CMPSS x<em>mm1, xmm2, 7</em></td>, <td>VCMPEQSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 0</em></td>, <td>VCMPLTSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 1</em></td>, <td>VCMPLESS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 2</em></td>, <td>VCMPUNORDSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 3</em></td>, <td>VCMPNEQSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 4</em></td>, <td>VCMPNLTSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 5</em></td>, <td>VCMPNLESS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 6</em></td>, <td>VCMPORDSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 7</em></td>, <td>VCMPEQ_UQSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 8</em></td>, <td>VCMPNGESS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 9</em></td>, <td>VCMPNGTSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 0AH</em></td>, <td>VCMPFALSESS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 0BH</em></td>, <td>VCMPNEQ_OQSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 0CH</em></td>, <td>VCMPGESS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 0DH</em></td>, <td>VCMPGTSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 0EH</em></td>, <td>VCMPTRUESS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 0FH</em></td>, <td>VCMPEQ_OSSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 10H</em></td>, <td>VCMPLT_OQSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 11H</em></td>, <td>VCMPLE_OQSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 12H</em></td>, <td>VCMPUNORD_SSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 13H</em></td>, <td>VCMPNEQ_USSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 14H</em></td>, <td>VCMPNLT_UQSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 15H</em></td>, <td>VCMPNLE_UQSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 16H</em></td>, <td>VCMPORD_SSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 17H</em></td>, <td>VCMPEQ_USSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 18H</em></td>, <td>VCMPNGE_UQSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 19H</em></td>, <td>VCMPNGT_UQSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 1AH</em></td>, <td>VCMPFALSE_OSSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 1BH</em></td>, <td>VCMPNEQ_OSSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 1CH</em></td>, <td>VCMPGE_OQSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 1DH</em></td>, <td>VCMPGT_OQSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 1EH</em></td>, <td>VCMPTRUE_USSS r<em>eg1, reg2, reg3</em></td>, <td>VCMPSS r<em>eg1, reg2, reg3, 1FH</em></td>]

[<td>A6</td>, <td>CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64-bit mode compare byte at address (R|E)SI to byte at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPS <em>m16</em>, <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64-bit mode compare word at address (R|E)SI with word at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare dword at address DS:(E)SI at dword at address ES:(E)DI; For 64-bit mode compare dword at address (R|E)SI at dword at address (R|E)DI. The status flags are set accordingly.</td>, <td>REX.W + A7</td>, <td>CMPS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compares quadword at address (R|E)SI with quadword at address (R|E)DI and sets the status flags accordingly.</td>, <td>A6</td>, <td>CMPSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64-bit mode compare byte at address (R|E)SI with byte at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64-bit mode compare word at address (R|E)SI with word at address (R|E)DI. The status flags are set accordingly.</td>, <td>A7</td>, <td>CMPSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, compare dword at address DS:(E)SI with dword at address ES:(E)DI; For 64-bit mode compare dword at address (R|E)SI with dword at address (R|E)DI. The status flags are set accordingly.</td>, <td>REX.W + A7</td>, <td>CMPSQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compares quadword at address (R|E)SI with quadword at address (R|E)DI and sets the status flags accordingly.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F B0/<em>r</em> CMPXCHG <em>r/m8, r8</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid*</td>, <td>Compare AL with <em>r/m8</em>. If equal, ZF is set and <em>r8</em> is loaded into <em>r/m8</em>. Else, clear ZF and load <em>r/m8</em> into AL.</td>, <td>REX + 0F B0/<em>r</em> CMPXCHG <em>r/m8**,r8</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare AL with <em>r/m8</em>. If equal, ZF is set and <em>r8</em> is loaded into <em>r/m8</em>. Else, clear ZF and load <em>r/m8</em> into AL.</td>, <td>0F B1/<em>r</em> CMPXCHG <em>r/m16, r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid*</td>, <td>Compare AX with <em>r/m16</em>. If equal, ZF is set and <em>r16</em> is loaded into <em>r/m16</em>. Else, clear ZF and load <em>r/m16</em> into AX.</td>, <td>0F B1/<em>r</em> CMPXCHG <em>r/m32, r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid*</td>, <td>Compare EAX with <em>r/m32</em>. If equal, ZF is set and <em>r32</em> is loaded into <em>r/m32</em>. Else, clear ZF and load <em>r/m32</em> into EAX.</td>, <td>REX.W + 0F B1/<em>r</em> CMPXCHG <em>r/m64, r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare RAX with <em>r/m64</em>. If equal, ZF is set and <em>r64</em> is loaded into <em>r/m64</em>. Else, clear ZF and load <em>r/m64</em> into RAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>MR</td>, <td>ModRM:r/m (r, w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>0F C7 /1 CMPXCHG8B <em>m64</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid*</td>, <td>Compare EDX:EAX with <em>m64</em>. If equal, set ZF and load ECX:EBX into <em>m64</em>. Else, clear ZF and load <em>m64</em> into EDX:EAX.</td>, <td>REX.W + 0F C7 /1 CMPXCHG16B <em>m128</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare RDX:RAX with <em>m128</em>. If equal, set ZF and load RCX:RBX into <em>m128</em>. Else, clear ZF and load <em>m128</em> into RDX:RAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r, w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If the destination is not a memory operand.</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the destination operand is not a memory location.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the destination operand is not a memory location.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="3">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If memory operand for CMPXCHG16B is not aligned on a 16-byte boundary.</td>, <td>If CPUID.01H:ECX.CMPXCHG16B[bit 13] = 0.</td>, <td>#UD</td>, <td>If the destination operand is not a memory location.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>]

[<td>0F C7 /1 CMPXCHG8B <em>m64</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid*</td>, <td>Compare EDX:EAX with <em>m64</em>. If equal, set ZF and load ECX:EBX into <em>m64</em>. Else, clear ZF and load <em>m64</em> into EDX:EAX.</td>, <td>REX.W + 0F C7 /1 CMPXCHG16B <em>m128</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare RDX:RAX with <em>m128</em>. If equal, set ZF and load RCX:RBX into <em>m128</em>. Else, clear ZF and load <em>m128</em> into RDX:RAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r, w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If the destination is not a memory operand.</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the destination operand is not a memory location.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the destination operand is not a memory location.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="3">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If memory operand for CMPXCHG16B is not aligned on a 16-byte boundary.</td>, <td>If CPUID.01H:ECX.CMPXCHG16B[bit 13] = 0.</td>, <td>#UD</td>, <td>If the destination operand is not a memory location.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>]

[<td>66 0F 2F /r COMISD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare low double-precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly.</td>, <td>VEX.LIG.66.0F.WIG 2F /r VCOMISD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare low double-precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly.</td>, <td>EVEX.LIG.66.0F.W1 2F /r VCOMISD xmm1, xmm2/m64{sae}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare low double-precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>NP 0F 2F /r COMISS xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.</td>, <td>VEX.LIG.0F.WIG 2F /r VCOMISS xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.</td>, <td>EVEX.LIG.0F.W0 2F /r VCOMISS xmm1, xmm2/m32{sae}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>0F A2</td>, <td>CPUID</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Returns processor identification and feature information to the EAX, EBX, ECX, and EDX registers, as determined by input entered in EAX (in some cases, ECX as well).</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td colspan="2"><em>Basic CPUID Information</em></td>, <td>0H</td>, <td>EAX Maximum Input Value for Basic CPUID Information. EBX “Genu” ECX “ntel” EDX “ineI”</td>, <td>01H</td>, <td>EAX Version Information: Type, Family, Model, and Stepping ID (see <a href="./CPUID.html#fig-3-6">Figure 3-6</a>). EBX Bits 07 - 00: Brand Index. Bits 15 - 08: CLFLUSH line size (Value ∗ 8 = cache line size in bytes; used also by CLFLUSHOPT). Bits 23 - 16: Maximum number of addressable IDs for logical processors in this physical package*. Bits 31 - 24: Initial APIC ID**. ECX Feature Information (see <a href="./CPUID.html#fig-3-7">Figure 3-7</a> and <a href="./CPUID.html#tbl-3-10">Table 3-10</a>). EDX Feature Information (see <a href="./CPUID.html#fig-3-8">Figure 3-8</a> and <a href="./CPUID.html#tbl-3-11">Table 3-11</a>). <strong>NOTES:</strong> * Thenearestpower-of-2integerthatisnotsmallerthanEBX[23:16]isthenumberofuniqueinitialAPIC IDs reserved for addressing different logical processors in a physical package. This field is only valid if CPUID.1.EDX.HTT[bit 28]= 1. ** <em>The 8-bit initial APIC ID in EBX[31:24] is replaced by the 32-bit x2APIC ID, available in Leaf 0BH and Leaf 1FH.</em></td>, <td>02H</td>, <td>EAX Cache and TLB Information (see <a href="./CPUID.html#tbl-3-12">Table 3-12</a>). EBX Cache and TLB Information. ECX Cache and TLB Information. EDX Cache and TLB Information.</td>, <td>03H</td>, <td>EAX Reserved. EBX Reserved. ECX Bits 00 - 31 of 96 bit processor serial number. (Available in Pentium III processor only; otherwise, the value in this register is reserved.) EDX Bits 32 - 63 of 96 bit processor serial number. (Available in Pentium III processor only; otherwise, the value in this register is reserved.) <strong>NOTES:</strong> Processor serial number (PSN) is not supported in the Pentium 4 processor or later. On all models, use the PSN flag (returned using CPUID) to check for PSN support before accessing the feature.</td>, <td colspan="2">CPUID leaves above 2 and below 80000000H are visible only when IA32_MISC_ENABLE[bit 22] has its default value of 0.</td>, <td colspan="2"><em>Deterministic Cache Parameters Leaf</em></td>, <td>04H</td>, <td><strong>NOTES:</strong> Leaf 04H output depends on the initial value in ECX.* See also: “INPUT EAX = 04H: Returns Deterministic Cache Parameters for Each Level” on page 221. EAX Bits 04 - 00: Cache Type Field. 0 = Null - No more caches. 1 = Data Cache. 2 = Instruction Cache. 3 = Unified Cache. 4-31 = Reserved.</td>, <td></td>, <td>Bits 07 - 05: Cache Level (starts at 1). Bit 08: Self Initializing cache level (does not need SW initialization). Bit 09: Fully Associative cache. Bits 13 - 10: Reserved. Bits 25 - 14: Maximum number of addressable IDs for logical processors sharing this cache**, ***. Bits 31 - 26: Maximum number of addressable IDs for processor cores in the physical package**, ****, *****. EBX Bits 11 - 00: L = System Coherency Line Size**. Bits 21 - 12: P = Physical Line partitions**. Bits 31 - 22: W = Ways of associativity**. ECX Bits 31-00: S = Number of Sets**. EDX Bit 00: Write-Back Invalidate/Invalidate. 0 = WBINVD/INVD from threads sharing this cache acts upon lower level caches for threads sharing this cache. 1 = WBINVD/INVD is not guaranteed to act upon lower level caches of non-originating threads sharing this cache. Bit 01: Cache Inclusiveness. 0 = Cache is not inclusive of lower cache levels. 1 = Cache is inclusive of lower cache levels. Bit 02: Complex Cache Indexing. 0 = Direct mapped cache. 1 = A complex function is used to index the cache, potentially using all address bits. Bits 31 - 03: Reserved = 0. <strong>NOTES:</strong> * If ECX contains an invalid sub leaf index, EAX/EBX/ECX/EDX return 0. Sub-leaf index n+1 is invalid if sub-leaf n returns EAX[4:0] as 0. ** Add one to the return value to get the result. ***The nearest power-of-2 integer that is not smaller than (1 + EAX[25:14]) is the number of unique initial APIC IDs reserved for addressing different logical processors sharing this cache. **** The nearest power-of-2 integer that is not smaller than (1 + EAX[31:26]) is the number of unique Core_IDs reserved for addressing different processor cores in a physical package. Core ID is a subset of bits of the initial APIC ID. ***** The returned value is constant for valid initial values in ECX. Valid ECX values start from 0.</td>, <td></td>, <td><em>MONITOR/MWAIT Leaf</em></td>, <td>05H</td>, <td>EAX Bits 15 - 00: Smallest monitor-line size in bytes (default is processor's monitor granularity). Bits 31 - 16: Reserved = 0. EBX Bits 15 - 00: Largest monitor-line size in bytes (default is processor's monitor granularity). Bits 31 - 16: Reserved = 0. ECX Bit 00: Enumeration of Monitor-Mwait extensions (beyond EAX and EBX registers) supported. Bit 01: Supports treating interrupts as break-event for MWAIT, even when interrupts disabled. Bits 31 - 02: Reserved.</td>, <td><strong>Initial EAX Value</strong></td>, <td><strong>Information Provided about the Processor</strong></td>, <td></td>, <td>EDX Bits 03 - 00: Number of C0* sub C-states supported using MWAIT. Bits 07 - 04: Number of C1* sub C-states supported using MWAIT. Bits 11 - 08: Number of C2* sub C-states supported using MWAIT. Bits 15 - 12: Number of C3* sub C-states supported using MWAIT. Bits 19 - 16: Number of C4* sub C-states supported using MWAIT. Bits 23 - 20: Number of C5* sub C-states supported using MWAIT. Bits 27 - 24: Number of C6* sub C-states supported using MWAIT. Bits 31 - 28: Number of C7* sub C-states supported using MWAIT. <strong>NOTE:</strong> * ThedefinitionofC0throughC7statesforMWAITextensionareprocessor-specificC-states,notACPIC-states.</td>, <td colspan="2"><em>Thermal and Power Management Leaf</em></td>, <td>06H</td>, <td>EAX Bit 00: Digital temperature sensor is supported if set. Bit 01: Intel Turbo Boost Technology available (see description of IA32_MISC_ENABLE[38]). Bit 02: ARAT. APIC-Timer-always-running feature is supported if set. Bit 03: Reserved. Bit 04: PLN. Power limit notification controls are supported if set. Bit 05: ECMD. Clock modulation duty cycle extension is supported if set. Bit 06: PTM. Package thermal management is supported if set. Bit 07: HWP. HWP base registers (IA32_PM_ENABLE[bit 0], IA32_HWP_CAPABILITIES, IA32_HWP_REQUEST, IA32_HWP_STATUS) are supported if set. Bit 08: HWP_Notification. IA32_HWP_INTERRUPT MSR is supported if set. Bit 09: HWP_Activity_Window. IA32_HWP_REQUEST[bits 41:32] is supported if set. Bit 10: HWP_Energy_Performance_Preference. IA32_HWP_REQUEST[bits 31:24] is supported if set. Bit 11: HWP_Package_Level_Request. IA32_HWP_REQUEST_PKG MSR is supported if set. Bit 12: Reserved. Bit 13: HDC. HDC base registers IA32_PKG_HDC_CTL, IA32_PM_CTL1, IA32_THREAD_STALL MSRs are supported if set. Bit 14: Intel® Turbo Boost Max Technology 3.0 available. Bit 15: HWP Capabilities. Highest Performance change is supported if set. Bit 16: HWP PECI override is supported if set. Bit 17: Flexible HWP is supported if set. Bit 18: Fast access mode for the IA32_HWP_REQUEST MSR is supported if set. Bit 19: Reserved. Bit 20: Ignoring Idle Logical Processor HWP request is supported if set. Bits 31 - 21: Reserved. EBX Bits 03 - 00: Number of Interrupt Thresholds in Digital Thermal Sensor. Bits 31 - 04: Reserved. ECX Bit 00: Hardware Coordination Feedback Capability (Presence of IA32_MPERF and IA32_APERF). The capability to provide a measure of delivered processor performance (since last reset of the counters), as a percentage of the expected processor performance when running at the TSC frequency. Bits 02 - 01: Reserved = 0. Bit 03: The processor supports performance-energy bias preference if CPUID.06H:ECX.SETBH[bit 3] is set and it also implies the presence of a new architectural MSR called IA32_ENERGY_PERF_BIAS (1B0H). Bits 31 - 04: Reserved = 0. EDX Reserved = 0.</td>, <td colspan="2"><em>Structured Extended Feature Flags Enumeration Leaf (Output depends on ECX input value)</em></td>, <td>07H</td>, <td>Sub-leaf 0 (Input ECX = 0). * EAX Bits 31 - 00: Reports the maximum input value for supported leaf 7 sub-leaves. EBX Bit 00: FSGSBASE. Supports RDFSBASE/RDGSBASE/WRFSBASE/WRGSBASE if 1. Bit 01: IA32_TSC_ADJUST MSR is supported if 1. Bit 02: SGX. Supports Intel® Software Guard Extensions (Intel® SGX Extensions) if 1. Bit 03: BMI1. Bit 04: HLE. Bit 05: AVX2. Bit 06: FDP_EXCPTN_ONLY. x87 FPU Data Pointer updated only on x87 exceptions if 1. Bit 07: SMEP. Supports Supervisor-Mode Execution Prevention if 1. Bit 08: BMI2. Bit 09: Supports Enhanced REP MOVSB/STOSB if 1. Bit 10: INVPCID. If 1, supports INVPCID instruction for system software that manages process-context identifiers. Bit 11: RTM. Bit 12: RDT-M. Supports Intel® Resource Director Technology (Intel® RDT) Monitoring capability if 1. Bit 13: Deprecates FPU CS and FPU DS values if 1. Bit 14: MPX. Supports Intel® Memory Protection Extensions if 1. Bit 15: RDT-A. Supports Intel® Resource Director Technology (Intel® RDT) Allocation capability if 1. Bit 16: AVX512F. Bit 17: AVX512DQ. Bit 18: RDSEED. Bit 19: ADX. Bit 20: SMAP. Supports Supervisor-Mode Access Prevention (and the CLAC/STAC instructions) if 1. Bit 21: AVX512_IFMA. Bit 22: Reserved. Bit 23: CLFLUSHOPT. Bit 24: CLWB. Bit 25: Intel Processor Trace. Bit 26: AVX512PF. (Intel® Xeon PhiTM only.) Bit 27: AVX512ER. (Intel® Xeon PhiTM only.) Bit 28: AVX512CD. Bit 29: SHA. supports Intel® Secure Hash Algorithm Extensions (Intel® SHA Extensions) if 1. Bit 30: AVX512BW. Bit 31: AVX512VL.</td>, <td></td>, <td>ECX Bit 00: PREFETCHWT1. (Intel® Xeon PhiTM only.) Bit 01: AVX512_VBMI. Bit 02: UMIP. Supports user-mode instruction prevention if 1. Bit 03: PKU. Supports protection keys for user-mode pages if 1. Bit 04: OSPKE. If 1, OS has set CR4.PKE to enable protection keys (and the RDPKRU/WRPKRU instructions). Bit 05: WAITPKG Bit 07 - 06: Reserved Bit 08: GFNI Bits 13 - 09: Reserved. Bit 14: AVX512_VPOPCNTDQ. (Intel® Xeon PhiTM only.) Bits 16 - 15: Reserved. Bits 21 - 17: The value of MAWAU used by the BNDLDX and BNDSTX instructions in 64-bit mode. Bit 22: RDPID and IA32_TSC_AUX are available if 1. Bits 24 - 23: Reserved. Bit 25: CLDEMOTE. Supports cache line demote if 1. Bit 26: Reserved Bit 27: MOVDIRI. Supports MOVDIRI if 1. Bit 28: MOVDIR64B. Supports MOVDIR64B if 1. Bit 29: Reserved Bit 30: SGX_LC. Supports SGX Launch Configuration if 1. Bit 31: Reserved. EDX Bit 01: Reserved. Bit 02: AVX512_4VNNIW. (Intel® Xeon PhiTM only.) Bit 03: AVX512_4FMAPS. (Intel® Xeon PhiTM only.) Bits 25-04: Reserved. Bit 26: Enumerates support for indirect branch restricted speculation (IBRS) and the indirect branch predictor barrier (IBPB). Processors that set this bit support the IA32_SPEC_CTRL MSR and the IA32_PRED_CMD MSR. They allow software to set IA32_SPEC_CTRL[0] (IBRS) and IA32_PRED_CMD[0] (IBPB). Bit 27: Enumerates support for single thread indirect branch predictors (STIBP). Processors that set this bit support the IA32_SPEC_CTRL MSR. They allow software to set IA32_SPEC_CTRL[1] (STIBP). Bit 28: Enumerates support for L1D_FLUSH. Processors that set this bit support the IA32_FLUSH_CMD MSR. They allow software to set IA32_FLUSH_CMD[0] (L1D_FLUSH). Bit 29: Enumerates support for the IA32_ARCH_CAPABILITIES MSR. Bit 30: Enumerates support for the IA32_CORE_CAPABILITIES MSR. Bit 31: Enumerates support for Speculative Store Bypass Disable (SSBD). Processors that set this bit support the IA32_SPEC_CTRL MSR. They allow software to set IA32_SPEC_CTRL[2] (SSBD). <strong>NOTE:</strong> * If ECX contains an invalid sub-leaf index, EAX/EBX/ECX/EDX return 0. Sub-leaf index n is invalid if n exceeds the value that sub-leaf 0 returns in EAX.</td>, <td colspan="2"><em>Direct Cache Access Information Leaf</em></td>, <td>09H</td>, <td>EAX Value of bits [31:0] of IA32_PLATFORM_DCA_CAP MSR (address 1F8H). EBX Reserved. ECX Reserved. EDX Reserved.</td>, <td colspan="2"><em>Architectural Performance Monitoring Leaf</em></td>, <td>0AH</td>, <td>EAX Bits 07 - 00: Version ID of architectural performance monitoring. Bits 15 - 08: Number of general-purpose performance monitoring counter per logical processor. Bits 23 - 16: Bit width of general-purpose, performance monitoring counter. Bits 31 - 24: Length of EBX bit vector to enumerate architectural performance monitoring events. EBX Bit 00: Core cycle event not available if 1. Bit 01: Instruction retired event not available if 1. Bit 02: Reference cycles event not available if 1. Bit 03: Last-level cache reference event not available if 1. Bit 04: Last-level cache misses event not available if 1. Bit 05: Branch instruction retired event not available if 1. Bit 06: Branch mispredict retired event not available if 1. Bits 31 - 07: Reserved = 0. ECX Reserved = 0. EDX Bits 04 - 00: Number of fixed-function performance counters (if Version ID &gt; 1). Bits 12 - 05: Bit width of fixed-function performance counters (if Version ID &gt; 1). Bits 14 - 13: Reserved = 0. Bit 15: AnyThread deprecation. Bits 31 - 16: Reserved = 0.</td>, <td colspan="2"><em>Extended Topology Enumeration Leaf</em></td>, <td>0BH</td>, <td><strong>NOTES:</strong> <em>CPUID leaf 1FH is a preferred superset to leaf 0BH. Intel recommends first checking for the existence of Leaf 1FH before using leaf 0BH.</em> Most of Leaf 0BH output depends on the initial value in ECX. The EDX output of leaf 0BH is always valid and does not vary with input value in ECX. Output value in ECX[7:0] always equals input value in ECX[7:0]. Sub-leaf index 0 enumerates SMT level. Each subsequent higher sub-leaf index enumerates a higher-level topological entity in hierarchical order. For sub-leaves that return an invalid level-type of 0 in ECX[15:8]; EAX and EBX will return 0. If an input value n in ECX returns the invalid level-type of 0 in ECX[15:8], other input values with ECX &gt; n also return 0 in ECX[15:8]. EAX Bits 04 - 00: Number of bits to shift right on x2APIC ID to get a unique topology ID of the next level type*. All logical processors with the same next level ID share current level. Bits 31 - 05: Reserved. EBX Bits 15 - 00: Number of logical processors at this level type. The number reflects configuration as shipped by Intel**. Bits 31- 16: Reserved. ECX Bits 07 - 00: Level number. Same value in ECX input. Bits 15 - 08: Level type***. Bits 31 - 16: Reserved. EDX Bits 31- 00: x2APIC ID the current logical processor. <strong>NOTES:</strong> * Software should use this field (EAX[4:0]) to enumerate processor topology of the system.</td>, <td></td>, <td>** Software must not use EBX[15:0] to enumerate processor topology of the system. This value in this field (EBX[15:0]) is only intended for display/diagnostic purposes. The actual number of logical processors available to BIOS/OS/Applications may be different from the value of EBX[15:0], depending on software and platform hardware configurations. *** The value of the “level type” field is not related to level numbers in any way, higher “level type” values do not mean higher levels. Level type field has the following encoding: 0: Invalid. 1: SMT. 2: Core. 3-255: Reserved.</td>, <td colspan="2"><em>Processor Extended State Enumeration Main Leaf (EAX = 0DH, ECX = 0)</em></td>, <td>0DH</td>, <td><strong>NOTES:</strong> Leaf 0DH main leaf (ECX = 0). EAX Bits 31 - 00: Reports the supported bits of the lower 32 bits of XCR0. XCR0[n] can be set to 1 only if EAX[n] is 1. Bit 00: x87 state. Bit 01: SSE state. Bit 02: AVX state. Bits 04 - 03: MPX state. Bits 07 - 05: AVX-512 state. Bit 08: Used for IA32_XSS. Bit 09: PKRU state. Bits 12 - 10: Reserved. Bit 13: Used for IA32_XSS. Bits 31 - 14: Reserved. EBX Bits 31 - 00: Maximum size (bytes, from the beginning of the XSAVE/XRSTOR save area) required by enabled features in XCR0. May be different than ECX if some features at the end of the XSAVE save area are not enabled. ECX Bit 31 - 00: Maximum size (bytes, from the beginning of the XSAVE/XRSTOR save area) of the XSAVE/XRSTOR save area required by all supported features in the processor, i.e., all the valid bit fields in XCR0. EDX Bit 31 - 00: Reports the supported bits of the upper 32 bits of XCR0. XCR0[n+32] can be set to 1 only if EDX[n] is 1. Bits 31 - 00: Reserved.</td>, <td colspan="2"><em>Processor Extended State Enumeration Sub-leaf (EAX = 0DH, ECX = 1)</em></td>, <td>0DH</td>, <td>EAX Bit 00: XSAVEOPT is available. Bit 01: Supports XSAVEC and the compacted form of XRSTOR if set. Bit 02: Supports XGETBV with ECX = 1 if set. Bit 03: Supports XSAVES/XRSTORS and IA32_XSS if set. Bits 31 - 04: Reserved. EBX Bits 31 - 00: The size in bytes of the XSAVE area containing all states enabled by XCRO | IA32_XSS. ECX Bits 31 - 00: Reports the supported bits of the lower 32 bits of the IA32_XSS MSR. IA32_XSS[n] can be set to 1 only if ECX[n] is 1. Bits 07 - 00: Used for XCR0. Bit 08: PT state. Bit 09: Used for XCR0. Bits 12 - 10: Reserved. Bit 13: HWP state. Bits 31 - 14: Reserved.</td>, <td></td>, <td>EDX Bits 31 - 00: Reports the supported bits of the upper 32 bits of the IA32_XSS MSR. IA32_XSS[n+32] can be set to 1 only if EDX[n] is 1. Bits 31 - 00: Reserved.</td>, <td colspan="2"><em>Processor Extended State Enumeration Sub-leaves (EAX = 0DH, ECX = n, n &gt; 1)</em></td>, <td>0DH</td>, <td><strong>NOTES:</strong> Leaf 0DH output depends on the initial value in ECX. Each sub-leaf index (starting at position 2) is supported if it corresponds to a supported bit in either the XCR0 register or the IA32_XSS MSR. * If ECX contains an invalid sub-leaf index, EAX/EBX/ECX/EDX return 0. Sub-leaf n (0 ≤ n ≤ 31) is invalid if sub-leaf 0 returns 0 in EAX[n] and sub-leaf 1 returns 0 in ECX[n]. Sub-leaf n (32 ≤ n ≤ 63) is invalid if sub-leaf 0 returns 0 in EDX[n-32] and sub-leaf 1 returns 0 in EDX[n-32]. EAX Bits 31 - 0: The size in bytes (from the offset specified in EBX) of the save area for an extended state feature associated with a valid sub-leaf index, <em>n</em>. EBX Bits 31 - 0: The offset in bytes of this extended state component’s save area from the beginning of the XSAVE/XRSTOR area. This field reports 0 if the sub-leaf index, n, does not map to a valid bit in the XCR0 register*. ECX Bit 00 is set if the bit n (corresponding to the sub-leaf index) is supported in the IA32_XSS MSR; it is clear if bit n is instead supported in XCR0. Bit 01 is set if, when the compacted format of an XSAVE area is used, this extended state component located on the next 64-byte boundary following the preceding state component (otherwise, it is located immediately following the preceding state component). Bits 31 - 02 are reserved. This field reports 0 if the sub-leaf index, n, is invalid*. EDX This field reports 0 if the sub-leaf index, <em>n</em>, is invalid*; otherwise it is reserved.</td>, <td colspan="2"><em>Intel Resource Director Technology (Intel RDT) Monitoring Enumeration Sub-leaf (EAX = 0FH, ECX = 0)</em></td>, <td>0FH</td>, <td><strong>NOTES:</strong> Leaf 0FH output depends on the initial value in ECX. Sub-leaf index 0 reports valid resource type starting at bit position 1 of EDX. EAX Reserved. EBX Bits 31 - 00: Maximum range (zero-based) of RMID within this physical processor of all types. ECX Reserved. EDX Bit 00: Reserved. Bit 01: Supports L3 Cache Intel RDT Monitoring if 1. Bits 31 - 02: Reserved.</td>, <td colspan="2"><em>L3 Cache Intel RDT Monitoring Capability Enumeration Sub-leaf (EAX = 0FH, ECX = 1)</em></td>, <td>0FH</td>, <td><strong>NOTES:</strong> Leaf 0FH output depends on the initial value in ECX. EAX Reserved. EBX Bits 31 - 00: Conversion factor from reported IA32_QM_CTR value to occupancy metric (bytes) and Memory Bandwidth Monitoring (MBM) metrics. ECX Maximum range (zero-based) of RMID of this resource type. EDX Bit 00: Supports L3 occupancy monitoring if 1. Bit 01: Supports L3 Total Bandwidth monitoring if 1. Bit 02: Supports L3 Local Bandwidth monitoring if 1. Bits 31 - 03: Reserved.</td>, <td colspan="2"><em>Intel Resource Director Technology (Intel RDT) Allocation Enumeration Sub-leaf (EAX = 10H, ECX = 0)</em></td>, <td>10H</td>, <td><strong>NOTES:</strong> Leaf 10H output depends on the initial value in ECX. Sub-leaf index 0 reports valid resource identification (ResID) starting at bit position 1 of EBX. EAX Reserved. EBX Bit 00: Reserved. Bit 01: Supports L3 Cache Allocation Technology if 1. Bit 02: Supports L2 Cache Allocation Technology if 1. Bit 03: Supports Memory Bandwidth Allocation if 1. Bits 31 - 04: Reserved. ECX Reserved. EDX Reserved.</td>, <td colspan="2"><em>L3 Cache Allocation Technology Enumeration Sub-leaf (EAX = 10H, ECX = ResID =1)</em></td>, <td>10H</td>, <td><strong>NOTES:</strong> Leaf 10H output depends on the initial value in ECX. EAX Bits 04 - 00: Length of the capacity bit mask for the corresponding ResID using minus-one notation. Bits 31 - 05: Reserved. EBX Bits 31 - 00: Bit-granular map of isolation/contention of allocation units. ECX Bits 01- 00: Reserved. Bit 02: Code and Data Prioritization Technology supported if 1. Bits 31 - 03: Reserved. EDX Bits 15 - 00: Highest COS number supported for this ResID. Bits 31 - 16: Reserved.</td>, <td colspan="2"><em>L2 Cache Allocation Technology Enumeration Sub-leaf (EAX = 10H, ECX = ResID =2)</em></td>, <td>10H</td>, <td><strong>NOTES:</strong> Leaf 10H output depends on the initial value in ECX. EAX Bits 04 - 00: Length of the capacity bit mask for the corresponding ResID using minus-one notation. Bits 31 - 05: Reserved. EBX Bits 31 - 00: Bit-granular map of isolation/contention of allocation units. ECX Bits 31 - 00: Reserved. EDX Bits 15 - 00: Highest COS number supported for this ResID. Bits 31 - 16: Reserved.</td>, <td colspan="2"><em>Memory Bandwidth Allocation Enumeration Sub-leaf (EAX = 10H, ECX = ResID =3)</em></td>, <td>10H</td>, <td><strong>NOTES:</strong> Leaf 10H output depends on the initial value in ECX. EAX Bits 11 - 00: Reports the maximum MBA throttling value supported for the corresponding ResID using minus-one notation. Bits 31 - 12: Reserved. EBX Bits 31 - 00: Reserved. ECX Bits 01 - 00: Reserved. Bit 02: Reports whether the response of the delay values is linear. Bits 31 - 03: Reserved.</td>, <td></td>, <td>EDX Bits 15 - 00: Highest COS number supported for this ResID. Bits 31 - 16: Reserved.</td>, <td colspan="2"><em>Intel SGX Capability Enumeration Leaf, sub-leaf 0 (EAX = 12H, ECX = 0)</em></td>, <td>12H</td>, <td><strong>NOTES:</strong> Leaf 12H sub-leaf 0 (ECX = 0) is supported if CPUID.(EAX=07H, ECX=0H):EBX[SGX] = 1. EAX Bit 00: SGX1. If 1, Indicates Intel SGX supports the collection of SGX1 leaf functions. Bit 01: SGX2. If 1, Indicates Intel SGX supports the collection of SGX2 leaf functions. Bits 04 - 02: Reserved. Bit 05: If 1, indicates Intel SGX supports ENCLV instruction leaves EINCVIRTCHILD, EDECVIRTCHILD, and ESETCONTEXT. Bit 06: If 1, indicates Intel SGX supports ENCLS instruction leaves ETRACKC, ERDINFO, ELDBC, and ELDUC. Bits 31 - 07: Reserved. EBX Bits 31 - 00: MISCSELECT. Bit vector of supported extended SGX features. ECX Bits 31 - 00: Reserved. EDX Bits 07 - 00: MaxEnclaveSize_Not64. The maximum supported enclave size in non-64-bit mode is 2^(EDX[7:0]). Bits 15 - 08: MaxEnclaveSize_64. The maximum supported enclave size in 64-bit mode is 2^(EDX[15:8]). Bits 31 - 16: Reserved.</td>, <td colspan="2"><em>Intel SGX Attributes Enumeration Leaf, sub-leaf 1 (EAX = 12H, ECX = 1)</em></td>, <td>12H</td>, <td><strong>NOTES:</strong> Leaf 12H sub-leaf 1 (ECX = 1) is supported if CPUID.(EAX=07H, ECX=0H):EBX[SGX] = 1. EAX Bit 31 - 00: Reports the valid bits of SECS.ATTRIBUTES[31:0] that software can set with ECREATE. EBX Bit 31 - 00: Reports the valid bits of SECS.ATTRIBUTES[63:32] that software can set with ECREATE. ECX Bit 31 - 00: Reports the valid bits of SECS.ATTRIBUTES[95:64] that software can set with ECREATE. EDX Bit 31 - 00: Reports the valid bits of SECS.ATTRIBUTES[127:96] that software can set with ECREATE.</td>, <td colspan="2"><em>Intel SGX EPC Enumeration Leaf, sub-leaves (EAX = 12H, ECX = 2 or higher)</em></td>, <td>12H</td>, <td><strong>NOTES:</strong> Leaf 12H sub-leaf 2 or higher (ECX &gt;= 2) is supported if CPUID.(EAX=07H, ECX=0H):EBX[SGX] = 1. For sub-leaves (ECX = 2 or higher), definition of EDX,ECX,EBX,EAX[31:4] depends on the sub-leaf type listed below. EAX Bit 03 - 00: Sub-leaf Type 0000b: Indicates this sub-leaf is invalid. 0001b: This sub-leaf enumerates an EPC section. EBX:EAX and EDX:ECX provide information on the Enclave Page Cache (EPC) section. All other type encodings are reserved. Type 0000b. This sub-leaf is invalid. EDX:ECX:EBX:EAX return 0.</td>, <td></td>, <td>Type 0001b. This sub-leaf enumerates an EPC sections with EDX:ECX, EBX:EAX defined as follows. EAX[11:04]: Reserved (enumerate 0). EAX[31:12]: Bits 31:12 of the physical address of the base of the EPC section. EBX[19:00]: Bits 51:32 of the physical address of the base of the EPC section. EBX[31:20]: Reserved. ECX[03:00]: EPC section property encoding defined as follows: If EAX[3:0] 0000b, then all bits of the EDX:ECX pair are enumerated as 0. If EAX[3:0] 0001b, then this section has confidentiality and integrity protection. All other encodings are reserved. ECX[11:04]: Reserved (enumerate 0). ECX[31:12]: Bits 31:12 of the size of the corresponding EPC section within the Processor Reserved Memory. EDX[19:00]: Bits 51:32 of the size of the corresponding EPC section within the Processor Reserved Memory. EDX[31:20]: Reserved.</td>, <td colspan="2"><em>Intel Processor Trace Enumeration Main Leaf (EAX = 14H, ECX = 0)</em></td>, <td>14H</td>, <td><strong>NOTES:</strong> Leaf 14H main leaf (ECX = 0). EAX Bits 31 - 00: Reports the maximum sub-leaf supported in leaf 14H. EBX Bit 00: If 1, indicates that IA32_RTIT_CTL.CR3Filter can be set to 1, and that IA32_RTIT_CR3_MATCH MSR can be accessed. Bit 01: If 1, indicates support of Configurable PSB and Cycle-Accurate Mode. Bit 02: If 1, indicates support of IP Filtering, TraceStop filtering, and preservation of Intel PT MSRs across warm reset. Bit 03: If 1, indicates support of MTC timing packet and suppression of COFI-based packets. Bit 04: If 1, indicates support of PTWRITE. Writes can set IA32_RTIT_CTL[12] (PTWEn) and IA32_RTIT_CTL[5] (FUPonPTW), and PTWRITE can generate packets. Bit 05: If 1, indicates support of Power Event Trace. Writes can set IA32_RTIT_CTL[4] (PwrEvtEn), enabling Power Event Trace packet generation. Bit 31 - 06: Reserved. ECX Bit 00: If 1, Tracing can be enabled with IA32_RTIT_CTL.ToPA = 1, hence utilizing the ToPA output scheme; IA32_RTIT_OUTPUT_BASE and IA32_RTIT_OUTPUT_MASK_PTRS MSRs can be accessed. Bit 01: If 1, ToPA tables can hold any number of output entries, up to the maximum allowed by the MaskOrTableOffset field of IA32_RTIT_OUTPUT_MASK_PTRS. Bit 02: If 1, indicates support of Single-Range Output scheme. Bit 03: If 1, indicates support of output to Trace Transport subsystem. Bit 30 - 04: Reserved. Bit 31: If 1, generated packets which contain IP payloads have LIP values, which include the CS base component. EDX Bits 31 - 00: Reserved.</td>, <td colspan="2"><em>Intel Processor Trace Enumeration Sub-leaf (EAX = 14H, ECX = 1)</em></td>, <td>14H</td>, <td>EAX Bits 02 - 00: Number of configurable Address Ranges for filtering. Bits 15 - 03: Reserved. Bits 31 - 16: Bitmap of supported MTC period encodings. EBX Bits 15 - 00: Bitmap of supported Cycle Threshold value encodings. Bit 31 - 16: Bitmap of supported Configurable PSB frequency encodings. ECX Bits 31 - 00: Reserved.</td>, <td></td>, <td>EDX Bits 31 - 00: Reserved.</td>, <td colspan="2"><em>Time Stamp Counter and Nominal Core Crystal Clock Information Leaf</em></td>, <td>15H</td>, <td><strong>NOTES:</strong> If EBX[31:0] is 0, the TSC/”core crystal clock” ratio is not enumerated. EBX[31:0]/EAX[31:0] indicates the ratio of the TSC frequency and the core crystal clock frequency. If ECX is 0, the nominal core crystal clock frequency is not enumerated. “TSC frequency” = “core crystal clock frequency” * EBX/EAX. The core crystal clock may differ from the reference clock, bus clock, or core clock frequencies. EAX Bits 31 - 00: An unsigned integer which is the denominator of the TSC/”core crystal clock” ratio. EBX Bits 31 - 00: An unsigned integer which is the numerator of the TSC/”core crystal clock” ratio. ECX Bits 31 - 00: An unsigned integer which is the nominal frequency of the core crystal clock in Hz. EDX Bits 31 - 00: Reserved = 0.</td>, <td colspan="2"><em>Processor Frequency Information Leaf</em></td>, <td>16H</td>, <td>EAX Bits 15 - 00: Processor Base Frequency (in MHz). Bits 31 - 16: Reserved =0. EBX Bits 15 - 00: Maximum Frequency (in MHz). Bits 31 - 16: Reserved = 0. ECX Bits 15 - 00: Bus (Reference) Frequency (in MHz). Bits 31 - 16: Reserved = 0. EDX Reserved. <strong>NOTES:</strong> * Data is returned from this interface in accordance with the processor's specification and does not reflect actual values. Suitable use of this data includes the display of processor information in like manner to the processor brand string and for determining the appropriate range to use when displaying processor information e.g. frequency history graphs. The returned information should not be used for any other purpose as the returned information does not accurately correlate to information / counters returned by other processor interfaces. While a processor may support the Processor Frequency Information leaf, fields that return a value of zero are not supported.</td>, <td colspan="2"><em>System-On-Chip Vendor Attribute Enumeration Main Leaf (EAX = 17H, ECX = 0)</em></td>, <td>17H</td>, <td><strong>NOTES:</strong> Leaf 17H main leaf (ECX = 0). Leaf 17H output depends on the initial value in ECX. Leaf 17H sub-leaves 1 through 3 reports SOC Vendor Brand String. Leaf 17H is valid if MaxSOCID_Index &gt;= 3. Leaf 17H sub-leaves 4 and above are reserved. EAX Bits 31 - 00: MaxSOCID_Index. Reports the maximum input value of supported sub-leaf in leaf 17H. EBX Bits 15 - 00: SOC Vendor ID. Bit 16: IsVendorScheme. If 1, the SOC Vendor ID field is assigned via an industry standard enumeration scheme. Otherwise, the SOC Vendor ID field is assigned by Intel. Bits 31 - 17: Reserved = 0. ECX Bits 31 - 00: Project ID. A unique number an SOC vendor assigns to its SOC projects. EDX Bits 31 - 00: Stepping ID. A unique number within an SOC project that an SOC vendor assigns.</td>, <td colspan="2"><em>System-On-Chip Vendor Attribute Enumeration Sub-leaf (EAX = 17H, ECX = 1..3)</em></td>, <td>17H</td>, <td>EAX Bit 31 - 00: SOC Vendor Brand String. UTF-8 encoded string. EBX Bit 31 - 00: SOC Vendor Brand String. UTF-8 encoded string. ECX Bit 31 - 00: SOC Vendor Brand String. UTF-8 encoded string. EDX Bit 31 - 00: SOC Vendor Brand String. UTF-8 encoded string. <strong>NOTES:</strong> Leaf 17H output depends on the initial value in ECX. SOC Vendor Brand String is a UTF-8 encoded string padded with trailing bytes of 00H. The complete SOC Vendor Brand String is constructed by concatenating in ascending order of EAX:EBX:ECX:EDX and from the sub-leaf 1 fragment towards sub-leaf 3.</td>, <td colspan="2"><em>System-On-Chip Vendor Attribute Enumeration Sub-leaves (EAX = 17H, ECX &gt; MaxSOCID_Index)</em></td>, <td>17H</td>, <td><strong>NOTES:</strong> Leaf 17H output depends on the initial value in ECX. EAX Bits 31 - 00: Reserved = 0. EBX Bits 31 - 00: Reserved = 0. ECX Bits 31 - 00: Reserved = 0. EDX Bits 31 - 00: Reserved = 0.</td>, <td colspan="2"><em>Deterministic Address Translation Parameters Main Leaf (EAX = 18H, ECX = 0)</em></td>, <td>18H</td>, <td><strong>NOTES:</strong> Each sub-leaf enumerates a different address translation structure. If ECX contains an invalid sub-leaf index, EAX/EBX/ECX/EDX return 0. Sub-leaf index n is invalid if n exceeds the value that sub-leaf 0 returns in EAX. A sub-leaf index is also invalid if EDX[4:0] returns 0. Valid sub-leaves do not need to be contiguous or in any particular order. A valid sub-leaf may be in a higher input ECX value than an invalid sub-leaf or than a valid sub-leaf of a higher or lower-level structure. * Some unified TLBs will allow a single TLB entry to satisfy data read/write and instruction fetches. Others will require separate entries (e.g., one loaded on data read/write and another loaded on an instruction fetch) . Please see the <em>Intel® 64 and IA-32 Architectures Optimization Reference Manual</em> for details of a particular product. ** Add one to the return value to get the result. EAX Bits 31 - 00: Reports the maximum input value of supported sub-leaf in leaf 18H. EBX Bit 00: 4K page size entries supported by this structure. Bit 01: 2MB page size entries supported by this structure. Bit 02: 4MB page size entries supported by this structure. Bit 03: 1 GB page size entries supported by this structure. Bits 07 - 04: Reserved. Bits 10 - 08: Partitioning (0: Soft partitioning between the logical processors sharing this structure). Bits 15 - 11: Reserved. Bits 31 - 16: W = Ways of associativity. ECX Bits 31 - 00: S = Number of Sets.</td>, <td></td>, <td>EDX Bits 04 - 00: Translation cache type field. 00000b: Null (indicates this sub-leaf is not valid). 00001b: Data TLB. 00010b: Instruction TLB. 00011b: Unified TLB*. All other encodings are reserved. Bits 07 - 05: Translation cache level (starts at 1). Bit 08: Fully associative structure. Bits 13 - 09: Reserved. Bits 25- 14: Maximum number of addressable IDs for logical processors sharing this translation cache** Bits 31 - 26: Reserved.</td>, <td colspan="2"><em>Deterministic Address Translation Parameters Sub-leaf (EAX = 18H, ECX ≥ 1)</em></td>, <td>18H</td>, <td><strong>NOTES:</strong> Each sub-leaf enumerates a different address translation structure. If ECX contains an invalid sub-leaf index, EAX/EBX/ECX/EDX return 0. Sub-leaf index n is invalid if n exceeds the value that sub-leaf 0 returns in EAX. A sub-leaf index is also invalid if EDX[4:0] returns 0. Valid sub-leaves do not need to be contiguous or in any particular order. A valid sub-leaf may be in a higher input ECX value than an invalid sub-leaf or than a valid sub-leaf of a higher or lower-level structure. * Some unified TLBs will allow a single TLB entry to satisfy data read/write and instruction fetches. Others will require separate entries (e.g., one loaded on data read/write and another loaded on an instruction fetch) . Please see the <em>Intel® 64 and IA-32 Architectures Optimization Reference Manual</em> for details of a particular product. ** Add one to the return value to get the result. EAX Bits 31 - 00: Reserved. EBX Bit 00: 4K page size entries supported by this structure. Bit 01: 2MB page size entries supported by this structure. Bit 02: 4MB page size entries supported by this structure. Bit 03: 1 GB page size entries supported by this structure. Bits 07 - 04: Reserved. Bits 10 - 08: Partitioning (0: Soft partitioning between the logical processors sharing this structure). Bits 15 - 11: Reserved. Bits 31 - 16: W = Ways of associativity. ECX Bits 31 - 00: S = Number of Sets. EDX Bits 04 - 00: Translation cache type field. 0000b: Null (indicates this sub-leaf is not valid). 0001b: Data TLB. 0010b: Instruction TLB. 0011b: Unified TLB*. All other encodings are reserved. Bits 07 - 05: Translation cache level (starts at 1). Bit 08: Fully associative structure. Bits 13 - 09: Reserved. Bits 25- 14: Maximum number of addressable IDs for logical processors sharing this translation cache** Bits 31 - 26: Reserved.</td>, <td colspan="2"><em>V2 Extended Topology Enumeration Leaf</em></td>, <td>1FH</td>, <td><strong>NOTES:</strong> <em>CPUID leaf 1FH is a preferred superset to leaf 0BH. Intel recommends first checking for the existence of Leaf 1FH and using this if available.</em> Most of Leaf 1FH output depends on the initial value in ECX. The EDX output of leaf 1FH is always valid and does not vary with input value in ECX. Output value in ECX[7:0] always equals input value in ECX[7:0]. Sub-leaf index 0 enumerates SMT level. Each subsequent higher sub-leaf index enumerates a higher-level topological entity in hierarchical order. For sub-leaves that return an invalid level-type of 0 in ECX[15:8]; EAX and EBX will return 0. If an input value n in ECX returns the invalid level-type of 0 in ECX[15:8], other input values with ECX &gt; n also return 0 in ECX[15:8]. EAX Bits 04 - 00: Number of bits to shift right on x2APIC ID to get a unique topology ID of the next level type*. All logical processors with the same next level ID share current level. Bits 31 - 05: Reserved. EBX Bits 15 - 00: Number of logical processors at this level type. The number reflects configuration as shipped by Intel**. Bits 31- 16: Reserved. ECX Bits 07 - 00: Level number. Same value in ECX input. Bits 15 - 08: Level type***. Bits 31 - 16: Reserved. EDX Bits 31- 00: x2APIC ID the current logical processor. <strong>NOTES:</strong> * Software should use this field (EAX[4:0]) to enumerate processor topology of the system. ** Software must not use EBX[15:0] to enumerate processor topology of the system. This value in this field (EBX[15:0]) is only intended for display/diagnostic purposes. The actual number of logical processors available to BIOS/OS/Applications may be different from the value of EBX[15:0], depending on software and platform hardware configurations. *** The value of the “level type” field is not related to level numbers in any way, higher “level type” values do not mean higher levels. Level type field has the following encoding: 0: Invalid. 1: SMT. 2: Core. 3: Module. 4: Tile. 5: Die. 6-255: Reserved.</td>, <td colspan="2"><em>Unimplemented CPUID Leaf Functions</em></td>, <td>40000000H -4FFFFFFFH</td>, <td>Invalid. No existing or future CPU will return processor identification or feature information if the initial EAX value is in the range 40000000H to 4FFFFFFFH.</td>, <td colspan="2"><em>Extended Function CPUID Information</em></td>, <td>80000000H</td>, <td>EAX Maximum Input Value for Extended Function CPUID Information. EBX Reserved. ECX Reserved.</td>, <td></td>, <td>EDX Reserved.</td>, <td>80000001H</td>, <td>EAX Extended Processor Signature and Feature Bits. EBX Reserved. ECX Bit 00: LAHF/SAHF available in 64-bit mode.* Bits 04 - 01: Reserved. Bit 05: LZCNT. Bits 07 - 06: Reserved. Bit 08: PREFETCHW. Bits 31 - 09: Reserved. EDX Bits 10 - 00: Reserved. Bit 11: SYSCALL/SYSRET.** Bits 19 - 12: Reserved = 0. Bit 20: Execute Disable Bit available. Bits 25 - 21: Reserved = 0. Bit 26: 1-GByte pages are available if 1. Bit 27: RDTSCP and IA32_TSC_AUX are available if 1. Bit 28: Reserved = 0. Bit 29: Intel<em><sup>® </sup></em>64 Architecture available if 1. Bits 31 - 30: Reserved = 0. <strong>NOTES:</strong> * LAHFandSAHFarealwaysavailableinothermodes,regardlessoftheenumerationofthisfeatureflag. ** Intel processors support SYSCALL and SYSRET only in 64-bit mode. This feature flag is always enumerated as 0 outside 64-bit mode.</td>, <td>80000002H</td>, <td>EAX Processor Brand String. EBX Processor Brand String Continued. ECX Processor Brand String Continued. EDX Processor Brand String Continued.</td>, <td>80000003H</td>, <td>EAX Processor Brand String Continued. EBX Processor Brand String Continued. ECX Processor Brand String Continued. EDX Processor Brand String Continued.</td>, <td>80000004H</td>, <td>EAX Processor Brand String Continued. EBX Processor Brand String Continued. ECX Processor Brand String Continued. EDX Processor Brand String Continued.</td>, <td>80000005H</td>, <td>EAX Reserved = 0. EBX Reserved = 0. ECX Reserved = 0. EDX Reserved = 0.</td>, <td>80000006H</td>, <td>EAX Reserved = 0. EBX Reserved = 0. ECX Bits 07 - 00: Cache Line size in bytes. Bits 11 - 08: Reserved. Bits 15 - 12: L2 Associativity field *. Bits 31 - 16: Cache size in 1K units. EDX Reserved = 0.</td>, <td></td>, <td><strong>NOTES:</strong> * L2 associativity field encodings: 00H - Disabled 08H - 16 ways 01H - 1 way (direct mapped) 09H - Reserved 02H - 2 ways 0AH - 32 ways 03H - Reserved 0BH - 48 ways 04H - 4 ways 0CH - 64 ways 05H - Reserved 0DH - 96 ways 06H - 8 ways 0EH - 128 ways 07H - See CPUID leaf 04H, sub-leaf 2** 0FH - Fully associative ** CPUID leaf 04H provides details of deterministic cache parameters, including the L2 cache in sub-leaf 2</td>, <td>80000007H</td>, <td>EAX Reserved = 0. EBX Reserved = 0. ECX Reserved = 0. EDX Bits 07 - 00: Reserved = 0. Bit 08: Invariant TSC available if 1. Bits 31 - 09: Reserved = 0.</td>, <td>80000008H</td>, <td>EAX Linear/Physical Address size. Bits 07 - 00: #Physical Address Bits*. Bits 15 - 08: #Linear Address Bits. Bits 31 - 16: Reserved = 0. EBX Reserved = 0. ECX Reserved = 0. EDX Reserved = 0. <strong>NOTES:</strong> * IfCPUID.80000008H:EAX[7:0]issupported,themaximumphysicaladdressnumbersupportedshould come from this field.</td>, <td>Original OEM Processor</td>, <td>00B</td>, <td>Intel OverDrive<sup>®</sup> Processor</td>, <td>01B</td>, <td>Dual processor (not applicable to Intel486 processors)</td>, <td>10B</td>, <td>Intel reserved</td>, <td>11B</td>, <td rowspan="3">31302928272625242322212019181716151413121110 9 8 7 6 5 4 3 2 1 0 ECX 0 RDRAND F16C AVX OSXSAVE XSAVE AES TSC-Deadline POPCNT MOVBE x2APIC SSE4_2 — SSE4.2 SSE4_1 — SSE4.1 DCA — Direct Cache Access PCID — Process-context Identifiers PDCM — Perf/Debug Capability MSR xTPR Update Control CMPXCHG16B FMA — Fused Multiply Add SDBG CNXT-ID — L1 Context ID SSSE3 — SSSE3 Extensions TM2 — Thermal Monitor 2 EIST — Enhanced Intel SpeedStep® Technology SMX — Safer Mode Extensions VMX — Virtual Machine Extensions DS-CPL — CPL Qualified Debug Store MONITOR — MONITOR/MWAIT DTES64 — 64-bit DS Area PCLMULQDQ — Carryless Multiplication SSE3 — SSE3 Extensions OM16524b Reserved</td>, <td>0</td>, <td>SSE3</td>, <td><strong>Streaming SIMD Extensions 3 (SSE3).</strong> A value of 1 indicates the processor supports this technology.</td>, <td>1</td>, <td>PCLMULQDQ</td>, <td><strong>PCLMULQDQ.</strong> A value of 1 indicates the processor supports the PCLMULQDQ instruction.</td>, <td>2</td>, <td>DTES64</td>, <td><strong>64-bit DS Area.</strong> A value of 1 indicates the processor supports DS area using 64-bit layout.</td>, <td>3</td>, <td>MONITOR</td>, <td><strong>MONITOR/MWAIT.</strong> A value of 1 indicates the processor supports this feature.</td>, <td>4</td>, <td>DS-CPL</td>, <td><strong>CPL Qualified Debug Store.</strong> A value of 1 indicates the processor supports the extensions to the Debug Store feature to allow for branch message storage qualified by CPL.</td>, <td>5</td>, <td>VMX</td>, <td><strong>Virtual Machine Extensions.</strong> A value of 1 indicates that the processor supports this technology.</td>, <td>6</td>, <td>SMX</td>, <td><strong>Safer Mode Extensions.</strong> A value of 1 indicates that the processor supports this technology. See Chapter 6, “Safer Mode Extensions Reference”.</td>, <td>7</td>, <td>EIST</td>, <td><strong>Enhanced Intel SpeedStep® technology.</strong> A value of 1 indicates that the processor supports this technology.</td>, <td>8</td>, <td>TM2</td>, <td><strong>Thermal Monitor 2.</strong> A value of 1 indicates whether the processor supports this technology.</td>, <td>9</td>, <td>SSSE3</td>, <td>A value of 1 indicates the presence of the Supplemental Streaming SIMD Extensions 3 (SSSE3). A value of 0 indicates the instruction extensions are not present in the processor.</td>, <td>10</td>, <td>CNXT-ID</td>, <td><strong>L1 Context ID.</strong> A value of 1 indicates the L1 data cache mode can be set to either adaptive mode or shared mode. A value of 0 indicates this feature is not supported. See definition of the IA32_MISC_ENABLE MSR Bit 24 (L1 Data Cache Context Mode) for details.</td>, <td>11</td>, <td>SDBG</td>, <td>A value of 1 indicates the processor supports IA32_DEBUG_INTERFACE MSR for silicon debug.</td>, <td>12</td>, <td>FMA</td>, <td>A value of 1 indicates the processor supports FMA extensions using YMM state.</td>, <td>13</td>, <td>CMPXCHG16B</td>, <td><strong>CMPXCHG16B Available.</strong> A value of 1 indicates that the feature is available. See the “CMPXCHG8B/CMPXCHG16B—Compare and Exchange Bytes” section in this chapter for a description.</td>, <td>14</td>, <td>xTPR Update Control</td>, <td><strong>xTPR Update Control.</strong> A value of 1 indicates that the processor supports changing IA32_MISC_ENABLE[bit 23].</td>, <td>15</td>, <td>PDCM</td>, <td><strong>Perfmon and Debug Capability:</strong> A value of 1 indicates the processor supports the performance and debug feature indication MSR IA32_PERF_CAPABILITIES.</td>, <td>16</td>, <td>Reserved</td>, <td>Reserved</td>, <td>17</td>, <td>PCID</td>, <td><strong>Process-context identifiers.</strong> A value of 1 indicates that the processor supports PCIDs and that software may set CR4.PCIDE to 1.</td>, <td>18</td>, <td>DCA</td>, <td>A value of 1 indicates the processor supports the ability to prefetch data from a memory mapped device.</td>, <td>19</td>, <td>SSE4.1</td>, <td>A value of 1 indicates that the processor supports SSE4.1.</td>, <td>20</td>, <td>SSE4.2</td>, <td>A value of 1 indicates that the processor supports SSE4.2.</td>, <td>21</td>, <td>x2APIC</td>, <td>A value of 1 indicates that the processor supports x2APIC feature.</td>, <td>22</td>, <td>MOVBE</td>, <td>A value of 1 indicates that the processor supports MOVBE instruction.</td>, <td>23</td>, <td>POPCNT</td>, <td>A value of 1 indicates that the processor supports the POPCNT instruction.</td>, <td>24</td>, <td>TSC-Deadline</td>, <td>A value of 1 indicates that the processor’s local APIC timer supports one-shot operation using a TSC deadline value.</td>, <td>25</td>, <td>AESNI</td>, <td>A value of 1 indicates that the processor supports the AESNI instruction extensions.</td>, <td>26</td>, <td>XSAVE</td>, <td>A value of 1 indicates that the processor supports the XSAVE/XRSTOR processor extended states feature, the XSETBV/XGETBV instructions, and XCR0.</td>, <td>27</td>, <td>OSXSAVE</td>, <td>A value of 1 indicates that the OS has set CR4.OSXSAVE[bit 18] to enable XSETBV/XGETBV instructions to access XCR0 and to support processor extended state management using XSAVE/XRSTOR.</td>, <td>28</td>, <td>AVX</td>, <td>A value of 1 indicates the processor supports the AVX instruction extensions.</td>, <td>29</td>, <td>F16C</td>, <td>A value of 1 indicates that processor supports 16-bit floating-point conversion instructions.</td>, <td>30</td>, <td>RDRAND</td>, <td>A value of 1 indicates that processor supports RDRAND instruction.</td>, <td>31</td>, <td>Not Used</td>, <td>Always returns 0.</td>, <td>0</td>, <td>FPU</td>, <td><strong>Floating Point Unit On-Chip.</strong> The processor contains an x87 FPU.</td>, <td>1</td>, <td>VME</td>, <td><strong>Virtual 8086 Mode Enhancements.</strong> Virtual 8086 mode enhancements, including CR4.VME for controlling the feature, CR4.PVI for protected mode virtual interrupts, software interrupt indirection, expansion of the TSS with the software indirection bitmap, and EFLAGS.VIF and EFLAGS.VIP flags.</td>, <td>2</td>, <td>DE</td>, <td><strong>Debugging Extensions.</strong> Support for I/O breakpoints, including CR4.DE for controlling the feature, and optional trapping of accesses to DR4 and DR5.</td>, <td>3</td>, <td>PSE</td>, <td><strong>Page Size Extension.</strong> Large pages of size 4 MByte are supported, including CR4.PSE for controlling the feature, the defined dirty bit in PDE (Page Directory Entries), optional reserved bit trapping in CR3, PDEs, and PTEs.</td>, <td>4</td>, <td>TSC</td>, <td><strong>Time Stamp Counter.</strong> The RDTSC instruction is supported, including CR4.TSD for controlling privilege.</td>, <td>5</td>, <td>MSR</td>, <td><strong>Model Specific Registers RDMSR and WRMSR Instructions.</strong> The RDMSR and WRMSR instructions are supported. Some of the MSRs are implementation dependent.</td>, <td>6</td>, <td>PAE</td>, <td><strong>Physical Address Extension.</strong> Physical addresses greater than 32 bits are supported: extended page table entry formats, an extra level in the page translation tables is defined, 2-MByte pages are supported instead of 4 Mbyte pages if PAE bit is 1.</td>, <td>7</td>, <td>MCE</td>, <td><strong>Machine Check Exception.</strong> Exception 18 is defined for Machine Checks, including CR4.MCE for controlling the feature. This feature does not define the model-specific implementations of machine-check error logging, reporting, and processor shutdowns. Machine Check exception handlers may have to depend on processor version to do model specific processing of the exception, or test for the presence of the Machine Check feature.</td>, <td>8</td>, <td>CX8</td>, <td><strong>CMPXCHG8B Instruction.</strong> The compare-and-exchange 8 bytes (64 bits) instruction is supported (implicitly locked and atomic).</td>, <td>9</td>, <td>APIC</td>, <td><strong>APIC On-Chip.</strong> The processor contains an Advanced Programmable Interrupt Controller (APIC), responding to memory mapped commands in the physical address range FFFE0000H to FFFE0FFFH (by default - some processors permit the APIC to be relocated).</td>, <td>10</td>, <td>Reserved</td>, <td>Reserved</td>, <td>11</td>, <td>SEP</td>, <td><strong>SYSENTER and SYSEXIT Instructions.</strong> The SYSENTER and SYSEXIT and associated MSRs are supported.</td>, <td>12</td>, <td>MTRR</td>, <td><strong>Memory Type Range Registers.</strong> MTRRs are supported. The MTRRcap MSR contains feature bits that describe what memory types are supported, how many variable MTRRs are supported, and whether fixed MTRRs are supported.</td>, <td>13</td>, <td>PGE</td>, <td><strong>Page Global Bit.</strong> The global bit is supported in paging-structure entries that map a page, indicating TLB entries that are common to different processes and need not be flushed. The CR4.PGE bit controls this feature.</td>, <td>14</td>, <td>MCA</td>, <td><strong>Machine Check Architecture.</strong> A value of 1 indicates the Machine Check Architecture of reporting machine errors is supported. The MCG_CAP MSR contains feature bits describing how many banks of error reporting MSRs are supported.</td>, <td>15</td>, <td>CMOV</td>, <td><strong>Conditional Move Instructions.</strong> The conditional move instruction CMOV is supported. In addition, if x87 FPU is present as indicated by the CPUID.FPU feature bit, then the FCOMI and FCMOV instructions are supported</td>, <td>16</td>, <td>PAT</td>, <td><strong>Page Attribute Table.</strong> Page Attribute Table is supported. This feature augments the Memory Type Range Registers (MTRRs), allowing an operating system to specify attributes of memory accessed through a linear address on a 4KB granularity.</td>, <td>17</td>, <td>PSE-36</td>, <td><strong>36-Bit Page Size Extension.</strong> 4-MByte pages addressing physical memory beyond 4 GBytes are supported with 32-bit paging. This feature indicates that upper bits of the physical address of a 4-MByte page are encoded in bits 20:13 of the page-directory entry. Such physical addresses are limited by MAXPHYADDR and may be up to 40 bits in size.</td>, <td>18</td>, <td>PSN</td>, <td><strong>Processor Serial Number.</strong> The processor supports the 96-bit processor identification number feature and the feature is enabled.</td>, <td>19</td>, <td>CLFSH</td>, <td><strong>CLFLUSH Instruction.</strong> CLFLUSH Instruction is supported.</td>, <td>20</td>, <td>Reserved</td>, <td>Reserved</td>, <td>21</td>, <td>DS</td>, <td><strong>Debug Store.</strong> The processor supports the ability to write debug information into a memory resident buffer. This feature is used by the branch trace store (BTS) and processor event-based sampling (PEBS) facilities (see Chapter 23, “Introduction to Virtual-Machine Extensions,” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 3C</em>).</td>, <td>22</td>, <td>ACPI</td>, <td><strong>Thermal Monitor and Software Controlled Clock Facilities.</strong> The processor implements internal MSRs that allow processor temperature to be monitored and processor performance to be modulated in predefined duty cycles under software control.</td>, <td>23</td>, <td>MMX</td>, <td><strong>Intel MMX Technology.</strong> The processor supports the Intel MMX technology.</td>, <td>24</td>, <td>FXSR</td>, <td><strong>FXSAVE and FXRSTOR Instructions.</strong> The FXSAVE and FXRSTOR instructions are supported for fast save and restore of the floating point context. Presence of this bit also indicates that CR4.OSFXSR is available for an operating system to indicate that it supports the FXSAVE and FXRSTOR instructions.</td>, <td>25</td>, <td>SSE</td>, <td><strong>SSE.</strong> The processor supports the SSE extensions.</td>, <td>26</td>, <td>SSE2</td>, <td><strong>SSE2.</strong> The processor supports the SSE2 extensions.</td>, <td>27</td>, <td>SS</td>, <td><strong>Self Snoop.</strong> The processor supports the management of conflicting memory types by performing a snoop of its own cache structure for transactions issued to the bus.</td>, <td>28</td>, <td>HTT</td>, <td><strong>Max APIC IDs reserved field is Valid.</strong> A value of 0 for HTT indicates there is only a single logical processor in the package and software should assume only a single APIC ID is reserved. A value of 1 for HTT indicates the value in CPUID.1.EBX[23:16] (the Maximum number of addressable IDs for logical processors in this package) is valid for the package.</td>, <td>29</td>, <td>TM</td>, <td><strong>Thermal Monitor.</strong> The processor implements the thermal monitor automatic thermal control circuitry (TCC).</td>, <td>30</td>, <td>Reserved</td>, <td>Reserved</td>, <td>31</td>, <td>PBE</td>, <td><strong>Pending Break Enable.</strong> The processor supports the use of the FERR#/PBE# pin when the processor is in the stop-clock state (STPCLK# is asserted) to signal the processor that an interrupt is pending and that the processor should return to normal operation to handle the interrupt. Bit 10 (PBE enable) in the IA32_MISC_ENABLE MSR enables this capability.</td>, <td>00H</td>, <td>General</td>, <td>Null descriptor, this byte contains no information</td>, <td>01H</td>, <td>TLB</td>, <td>Instruction TLB: 4 KByte pages, 4-way set associative, 32 entries</td>, <td>02H</td>, <td>TLB</td>, <td>Instruction TLB: 4 MByte pages, fully associative, 2 entries</td>, <td>03H</td>, <td>TLB</td>, <td>Data TLB: 4 KByte pages, 4-way set associative, 64 entries</td>, <td>04H</td>, <td>TLB</td>, <td>Data TLB: 4 MByte pages, 4-way set associative, 8 entries</td>, <td>05H</td>, <td>TLB</td>, <td>Data TLB1: 4 MByte pages, 4-way set associative, 32 entries</td>, <td>06H</td>, <td>Cache</td>, <td>1st-level instruction cache: 8 KBytes, 4-way set associative, 32 byte line size</td>, <td>08H</td>, <td>Cache</td>, <td>1st-level instruction cache: 16 KBytes, 4-way set associative, 32 byte line size</td>, <td>09H</td>, <td>Cache</td>, <td>1st-level instruction cache: 32KBytes, 4-way set associative, 64 byte line size</td>, <td>0AH</td>, <td>Cache</td>, <td>1st-level data cache: 8 KBytes, 2-way set associative, 32 byte line size</td>, <td>0BH</td>, <td>TLB</td>, <td>Instruction TLB: 4 MByte pages, 4-way set associative, 4 entries</td>, <td>0CH</td>, <td>Cache</td>, <td>1st-level data cache: 16 KBytes, 4-way set associative, 32 byte line size</td>, <td>0DH</td>, <td>Cache</td>, <td>1st-level data cache: 16 KBytes, 4-way set associative, 64 byte line size</td>, <td>0EH</td>, <td>Cache</td>, <td>1st-level data cache: 24 KBytes, 6-way set associative, 64 byte line size</td>, <td>1DH</td>, <td>Cache</td>, <td>2nd-level cache: 128 KBytes, 2-way set associative, 64 byte line size</td>, <td>21H</td>, <td>Cache</td>, <td>2nd-level cache: 256 KBytes, 8-way set associative, 64 byte line size</td>, <td>22H</td>, <td>Cache</td>, <td>3rd-level cache: 512 KBytes, 4-way set associative, 64 byte line size, 2 lines per sector</td>, <td>23H</td>, <td>Cache</td>, <td>3rd-level cache: 1 MBytes, 8-way set associative, 64 byte line size, 2 lines per sector</td>, <td>24H</td>, <td>Cache</td>, <td>2nd-level cache: 1 MBytes, 16-way set associative, 64 byte line size</td>, <td>25H</td>, <td>Cache</td>, <td>3rd-level cache: 2 MBytes, 8-way set associative, 64 byte line size, 2 lines per sector</td>, <td>29H</td>, <td>Cache</td>, <td>3rd-level cache: 4 MBytes, 8-way set associative, 64 byte line size, 2 lines per sector</td>, <td>2CH</td>, <td>Cache</td>, <td>1st-level data cache: 32 KBytes, 8-way set associative, 64 byte line size</td>, <td>30H</td>, <td>Cache</td>, <td>1st-level instruction cache: 32 KBytes, 8-way set associative, 64 byte line size</td>, <td>40H</td>, <td>Cache</td>, <td>No 2nd-level cache or, if processor contains a valid 2nd-level cache, no 3rd-level cache</td>, <td>41H</td>, <td>Cache</td>, <td>2nd-level cache: 128 KBytes, 4-way set associative, 32 byte line size</td>, <td>42H</td>, <td>Cache</td>, <td>2nd-level cache: 256 KBytes, 4-way set associative, 32 byte line size</td>, <td>43H</td>, <td>Cache</td>, <td>2nd-level cache: 512 KBytes, 4-way set associative, 32 byte line size</td>, <td>44H</td>, <td>Cache</td>, <td>2nd-level cache: 1 MByte, 4-way set associative, 32 byte line size</td>, <td>45H</td>, <td>Cache</td>, <td>2nd-level cache: 2 MByte, 4-way set associative, 32 byte line size</td>, <td>46H</td>, <td>Cache</td>, <td>3rd-level cache: 4 MByte, 4-way set associative, 64 byte line size</td>, <td>47H</td>, <td>Cache</td>, <td>3rd-level cache: 8 MByte, 8-way set associative, 64 byte line size</td>, <td>48H</td>, <td>Cache</td>, <td>2nd-level cache: 3MByte, 12-way set associative, 64 byte line size</td>, <td>49H</td>, <td>Cache</td>, <td>3rd-level cache: 4MB, 16-way set associative, 64-byte line size (Intel Xeon processor MP, Family 0FH, Model 06H); 2nd-level cache: 4 MByte, 16-way set associative, 64 byte line size</td>, <td>4AH</td>, <td>Cache</td>, <td>3rd-level cache: 6MByte, 12-way set associative, 64 byte line size</td>, <td>4BH</td>, <td>Cache</td>, <td>3rd-level cache: 8MByte, 16-way set associative, 64 byte line size</td>, <td>4CH</td>, <td>Cache</td>, <td>3rd-level cache: 12MByte, 12-way set associative, 64 byte line size</td>, <td>4DH</td>, <td>Cache</td>, <td>3rd-level cache: 16MByte, 16-way set associative, 64 byte line size</td>, <td>4EH</td>, <td>Cache</td>, <td>2nd-level cache: 6MByte, 24-way set associative, 64 byte line size</td>, <td>4FH</td>, <td>TLB</td>, <td>Instruction TLB: 4 KByte pages, 32 entries</td>, <td>50H</td>, <td>TLB</td>, <td>Instruction TLB: 4 KByte and 2-MByte or 4-MByte pages, 64 entries</td>, <td>51H</td>, <td>TLB</td>, <td>Instruction TLB: 4 KByte and 2-MByte or 4-MByte pages, 128 entries</td>, <td>52H</td>, <td>TLB</td>, <td>Instruction TLB: 4 KByte and 2-MByte or 4-MByte pages, 256 entries</td>, <td>55H</td>, <td>TLB</td>, <td>Instruction TLB: 2-MByte or 4-MByte pages, fully associative, 7 entries</td>, <td>56H</td>, <td>TLB</td>, <td>Data TLB0: 4 MByte pages, 4-way set associative, 16 entries</td>, <td>57H</td>, <td>TLB</td>, <td>Data TLB0: 4 KByte pages, 4-way associative, 16 entries</td>, <td>59H</td>, <td>TLB</td>, <td>Data TLB0: 4 KByte pages, fully associative, 16 entries</td>, <td>5AH</td>, <td>TLB</td>, <td>Data TLB0: 2 MByte or 4 MByte pages, 4-way set associative, 32 entries</td>, <td>5BH</td>, <td>TLB</td>, <td>Data TLB: 4 KByte and 4 MByte pages, 64 entries</td>, <td>5CH</td>, <td>TLB</td>, <td>Data TLB: 4 KByte and 4 MByte pages,128 entries</td>, <td>5DH</td>, <td>TLB</td>, <td>Data TLB: 4 KByte and 4 MByte pages,256 entries</td>, <td>60H</td>, <td>Cache</td>, <td>1st-level data cache: 16 KByte, 8-way set associative, 64 byte line size</td>, <td>61H</td>, <td>TLB</td>, <td>Instruction TLB: 4 KByte pages, fully associative, 48 entries</td>, <td>63H</td>, <td>TLB</td>, <td>Data TLB: 2 MByte or 4 MByte pages, 4-way set associative, 32 entries and a separate array with 1 GByte pages, 4-way set associative, 4 entries</td>, <td>64H</td>, <td>TLB</td>, <td>Data TLB: 4 KByte pages, 4-way set associative, 512 entries</td>, <td>66H</td>, <td>Cache</td>, <td>1st-level data cache: 8 KByte, 4-way set associative, 64 byte line size</td>, <td>67H</td>, <td>Cache</td>, <td>1st-level data cache: 16 KByte, 4-way set associative, 64 byte line size</td>, <td>68H</td>, <td>Cache</td>, <td>1st-level data cache: 32 KByte, 4-way set associative, 64 byte line size</td>, <td>6AH</td>, <td>Cache</td>, <td>uTLB: 4 KByte pages, 8-way set associative, 64 entries</td>, <td>6BH</td>, <td>Cache</td>, <td>DTLB: 4 KByte pages, 8-way set associative, 256 entries</td>, <td>6CH</td>, <td>Cache</td>, <td>DTLB: 2M/4M pages, 8-way set associative, 128 entries</td>, <td>6DH</td>, <td>Cache</td>, <td>DTLB: 1 GByte pages, fully associative, 16 entries</td>, <td>70H</td>, <td>Cache</td>, <td>Trace cache: 12 K-μop, 8-way set associative</td>, <td>71H</td>, <td>Cache</td>, <td>Trace cache: 16 K-μop, 8-way set associative</td>, <td>72H</td>, <td>Cache</td>, <td>Trace cache: 32 K-μop, 8-way set associative</td>, <td>76H</td>, <td>TLB</td>, <td>Instruction TLB: 2M/4M pages, fully associative, 8 entries</td>, <td>78H</td>, <td>Cache</td>, <td>2nd-level cache: 1 MByte, 4-way set associative, 64byte line size</td>, <td>79H</td>, <td>Cache</td>, <td>2nd-level cache: 128 KByte, 8-way set associative, 64 byte line size, 2 lines per sector</td>, <td>7AH</td>, <td>Cache</td>, <td>2nd-level cache: 256 KByte, 8-way set associative, 64 byte line size, 2 lines per sector</td>, <td>7BH</td>, <td>Cache</td>, <td>2nd-level cache: 512 KByte, 8-way set associative, 64 byte line size, 2 lines per sector</td>, <td>7CH</td>, <td>Cache</td>, <td>2nd-level cache: 1 MByte, 8-way set associative, 64 byte line size, 2 lines per sector</td>, <td>7DH</td>, <td>Cache</td>, <td>2nd-level cache: 2 MByte, 8-way set associative, 64byte line size</td>, <td>7FH</td>, <td>Cache</td>, <td>2nd-level cache: 512 KByte, 2-way set associative, 64-byte line size</td>, <td>80H</td>, <td>Cache</td>, <td>2nd-level cache: 512 KByte, 8-way set associative, 64-byte line size</td>, <td>82H</td>, <td>Cache</td>, <td>2nd-level cache: 256 KByte, 8-way set associative, 32 byte line size</td>, <td>83H</td>, <td>Cache</td>, <td>2nd-level cache: 512 KByte, 8-way set associative, 32 byte line size</td>, <td>84H</td>, <td>Cache</td>, <td>2nd-level cache: 1 MByte, 8-way set associative, 32 byte line size</td>, <td>85H</td>, <td>Cache</td>, <td>2nd-level cache: 2 MByte, 8-way set associative, 32 byte line size</td>, <td>86H</td>, <td>Cache</td>, <td>2nd-level cache: 512 KByte, 4-way set associative, 64 byte line size</td>, <td>87H</td>, <td>Cache</td>, <td>2nd-level cache: 1 MByte, 8-way set associative, 64 byte line size</td>, <td><strong>Value</strong></td>, <td><strong>Type</strong></td>, <td><strong>Description</strong></td>, <td>A0H</td>, <td>DTLB</td>, <td>DTLB: 4k pages, fully associative, 32 entries</td>, <td>B0H</td>, <td>TLB</td>, <td>Instruction TLB: 4 KByte pages, 4-way set associative, 128 entries</td>, <td>B1H</td>, <td>TLB</td>, <td>Instruction TLB: 2M pages, 4-way, 8 entries or 4M pages, 4-way, 4 entries</td>, <td>B2H</td>, <td>TLB</td>, <td>Instruction TLB: 4KByte pages, 4-way set associative, 64 entries</td>, <td>B3H</td>, <td>TLB</td>, <td>Data TLB: 4 KByte pages, 4-way set associative, 128 entries</td>, <td>B4H</td>, <td>TLB</td>, <td>Data TLB1: 4 KByte pages, 4-way associative, 256 entries</td>, <td>B5H</td>, <td>TLB</td>, <td>Instruction TLB: 4KByte pages, 8-way set associative, 64 entries</td>, <td>B6H</td>, <td>TLB</td>, <td>Instruction TLB: 4KByte pages, 8-way set associative, 128 entries</td>, <td>BAH</td>, <td>TLB</td>, <td>Data TLB1: 4 KByte pages, 4-way associative, 64 entries</td>, <td>C0H</td>, <td>TLB</td>, <td>Data TLB: 4 KByte and 4 MByte pages, 4-way associative, 8 entries</td>, <td>C1H</td>, <td>STLB</td>, <td>Shared 2nd-Level TLB: 4 KByte/2MByte pages, 8-way associative, 1024 entries</td>, <td>C2H</td>, <td>DTLB</td>, <td>DTLB: 4 KByte/2 MByte pages, 4-way associative, 16 entries</td>, <td>C3H</td>, <td>STLB</td>, <td>Shared 2nd-Level TLB: 4 KByte /2 MByte pages, 6-way associative, 1536 entries. Also 1GBbyte pages, 4-way, 16 entries.</td>, <td>C4H</td>, <td>DTLB</td>, <td>DTLB: 2M/4M Byte pages, 4-way associative, 32 entries</td>, <td>CAH</td>, <td>STLB</td>, <td>Shared 2nd-Level TLB: 4 KByte pages, 4-way associative, 512 entries</td>, <td>D0H</td>, <td>Cache</td>, <td>3rd-level cache: 512 KByte, 4-way set associative, 64 byte line size</td>, <td>D1H</td>, <td>Cache</td>, <td>3rd-level cache: 1 MByte, 4-way set associative, 64 byte line size</td>, <td>D2H</td>, <td>Cache</td>, <td>3rd-level cache: 2 MByte, 4-way set associative, 64 byte line size</td>, <td>D6H</td>, <td>Cache</td>, <td>3rd-level cache: 1 MByte, 8-way set associative, 64 byte line size</td>, <td>D7H</td>, <td>Cache</td>, <td>3rd-level cache: 2 MByte, 8-way set associative, 64 byte line size</td>, <td>D8H</td>, <td>Cache</td>, <td>3rd-level cache: 4 MByte, 8-way set associative, 64 byte line size</td>, <td>DCH</td>, <td>Cache</td>, <td>3rd-level cache: 1.5 MByte, 12-way set associative, 64 byte line size</td>, <td>DDH</td>, <td>Cache</td>, <td>3rd-level cache: 3 MByte, 12-way set associative, 64 byte line size</td>, <td>DEH</td>, <td>Cache</td>, <td>3rd-level cache: 6 MByte, 12-way set associative, 64 byte line size</td>, <td>E2H</td>, <td>Cache</td>, <td>3rd-level cache: 2 MByte, 16-way set associative, 64 byte line size</td>, <td>E3H</td>, <td>Cache</td>, <td>3rd-level cache: 4 MByte, 16-way set associative, 64 byte line size</td>, <td>E4H</td>, <td>Cache</td>, <td>3rd-level cache: 8 MByte, 16-way set associative, 64 byte line size</td>, <td>EAH</td>, <td>Cache</td>, <td>3rd-level cache: 12MByte, 24-way set associative, 64 byte line size</td>, <td>EBH</td>, <td>Cache</td>, <td>3rd-level cache: 18MByte, 24-way set associative, 64 byte line size</td>, <td>ECH</td>, <td>Cache</td>, <td>3rd-level cache: 24MByte, 24-way set associative, 64 byte line size</td>, <td>F0H</td>, <td>Prefetch</td>, <td>64-Byte prefetching</td>, <td>F1H</td>, <td>Prefetch</td>, <td>128-Byte prefetching</td>, <td>FEH</td>, <td>General</td>, <td>CPUID leaf 2 does not report TLB descriptor information; use CPUID leaf 18H to query TLB and other address translation parameters.</td>, <td>FFH</td>, <td>General</td>, <td>CPUID leaf 2 does not report cache descriptor information, use CPUID leaf 4 to query cache parameters</td>, <td>80000002H</td>, <td>EAX = 20202020H EBX = 20202020H ECX = 20202020H EDX = 6E492020H</td>, <td>“” “” “” “nI ”</td>, <td>80000003H</td>, <td>EAX = 286C6574H EBX = 50202952H ECX = 69746E65H EDX = 52286D75H</td>, <td>“(let” “P )R” “itne” “R(mu”</td>, <td>80000004H</td>, <td>EAX = 20342029H EBX = 20555043H ECX = 30303531H EDX = 007A484DH</td>, <td>“ 4 )” “ UPC” “0051” “\0zHM”</td>, <td>00H</td>, <td>This processor does not support the brand identification feature</td>, <td>01H</td>, <td>Intel(R) Celeron(R) processor<sup>1</sup></td>, <td>02H</td>, <td>Intel(R) Pentium(R) III processor<sup>1</sup></td>, <td>03H</td>, <td>Intel(R) Pentium(R) III Xeon(R) processor; If processor signature = 000006B1h, then Intel(R) Celeron(R) processor</td>, <td>04H</td>, <td>Intel(R) Pentium(R) III processor</td>, <td>06H</td>, <td>Mobile Intel(R) Pentium(R) III processor-M</td>, <td>07H</td>, <td>Mobile Intel(R) Celeron(R) processor<sup>1</sup></td>, <td>08H</td>, <td>Intel(R) Pentium(R) 4 processor</td>, <td>09H</td>, <td>Intel(R) Pentium(R) 4 processor</td>, <td>0AH</td>, <td>Intel(R) Celeron(R) processor<sup>1</sup></td>, <td>0BH</td>, <td>Intel(R) Xeon(R) processor; If processor signature = 00000F13h, then Intel(R) Xeon(R) processor MP</td>, <td>0CH</td>, <td>Intel(R) Xeon(R) processor MP</td>, <td>0EH</td>, <td>Mobile Intel(R) Pentium(R) 4 processor-M; If processor signature = 00000F13h, then Intel(R) Xeon(R) processor</td>, <td>0FH</td>, <td>Mobile Intel(R) Celeron(R) processor<sup>1</sup></td>, <td>11H</td>, <td>Mobile Genuine Intel(R) processor</td>, <td>12H</td>, <td>Intel(R) Celeron(R) M processor</td>, <td>13H</td>, <td>Mobile Intel(R) Celeron(R) processor<sup>1</sup></td>, <td>14H</td>, <td>Intel(R) Celeron(R) processor</td>, <td>15H</td>, <td>Mobile Genuine Intel(R) processor</td>, <td>16H</td>, <td>Intel(R) Pentium(R) M processor</td>, <td>17H</td>, <td>Mobile Intel(R) Celeron(R) processor<sup>1</sup></td>, <td>18H – 0FFH</td>, <td>RESERVED</td>]

[<td>99</td>, <td>CWD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>DX:AX ← sign-extend of AX.</td>, <td>99</td>, <td>CDQ</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>EDX:EAX ← sign-extend of EAX.</td>, <td>REX.W + 99</td>, <td>CQO</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>RDX:RAX← sign-extend of RAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>F2 0F 38 F0 <em>/r</em> CRC32 <em>r32, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Accumulate CRC32 on <em>r/m8</em>.</td>, <td>F2 REX 0F 38 F0 <em>/r</em> CRC32 <em>r32, r/m8*</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Accumulate CRC32 on <em>r/m8.</em></td>, <td>F2 0F 38 F1 <em>/r</em> CRC32 <em>r32, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Accumulate CRC32 on <em>r/m16</em>.</td>, <td>F2 0F 38 F1 <em>/r</em> CRC32 <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Accumulate CRC32 on <em>r/m32.</em></td>, <td>F2 REX.W 0F 38 F0 <em>/r</em> CRC32 <em>r64, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Accumulate CRC32 on <em>r/m8.</em></td>, <td>F2 REX.W 0F 38 F1 <em>/r</em> CRC32 <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Accumulate CRC32 on <em>r/m64.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS or GS segments.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:ECX.SSE4_2 [Bit 20] = 0.</td>, <td>If LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If any part of the operand lies outside of the effective address space from 0 to 0FFFFH.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:ECX.SSE4_2 [Bit 20] = 0.</td>, <td>If LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If any part of the operand lies outside of the effective address space from 0 to 0FFFFH.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:ECX.SSE4_2 [Bit 20] = 0.</td>, <td>If LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:ECX.SSE4_2 [Bit 20] = 0.</td>, <td>If LOCK prefix is used.</td>]

[<td>F3 0F E6 /r CVTDQ2PD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Convert two packed signed doubleword integers from xmm2/mem to two packed double-precision floating-point values in xmm1.</td>, <td>VEX.128.F3.0F.WIG E6 /r VCVTDQ2PD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert two packed signed doubleword integers from xmm2/mem to two packed double-precision floating-point values in xmm1.</td>, <td>VEX.256.F3.0F.WIG E6 /r VCVTDQ2PD ymm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert four packed signed doubleword integers from xmm2/mem to four packed double-precision floating-point values in ymm1.</td>, <td>EVEX.128.F3.0F.W0 E6 /r VCVTDQ2PD xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert 2 packed signed doubleword integers from xmm2/m128/m32bcst to eight packed double-precision floating-point values in xmm1 with writemask k1.</td>, <td>EVEX.256.F3.0F.W0 E6 /r VCVTDQ2PD ymm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert 4 packed signed doubleword integers from xmm2/m128/m32bcst to 4 packed double-precision floating-point values in ymm1 with writemask k1.</td>, <td>EVEX.512.F3.0F.W0 E6 /r VCVTDQ2PD zmm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert eight packed signed doubleword integers from ymm2/m256/m32bcst to eight packed double-precision floating-point values in zmm1 with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Half</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>NP 0F 5B /r CVTDQ2PS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Convert four packed signed doubleword integers from xmm2/mem to four packed single-precision floating-point values in xmm1.</td>, <td>VEX.128.0F.WIG 5B /r VCVTDQ2PS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert four packed signed doubleword integers from xmm2/mem to four packed single-precision floating-point values in xmm1.</td>, <td>VEX.256.0F.WIG 5B /r VCVTDQ2PS ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert eight packed signed doubleword integers from ymm2/mem to eight packed single-precision floating-point values in ymm1.</td>, <td>EVEX.128.0F.W0 5B /r VCVTDQ2PS xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert four packed signed doubleword integers from xmm2/m128/m32bcst to four packed single-precision floating-point values in xmm1with writemask k1.</td>, <td>EVEX.256.0F.W0 5B /r VCVTDQ2PS ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert eight packed signed doubleword integers from ymm2/m256/m32bcst to eight packed single-precision floating-point values in ymm1with writemask k1.</td>, <td>EVEX.512.0F.W0 5B /r VCVTDQ2PS zmm1 {k1}{z}, zmm2/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert sixteen packed signed doubleword integers from zmm2/m512/m32bcst to sixteen packed single-precision floating-point values in zmm1with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>F2 0F E6 /r CVTPD2DQ xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Convert two packed double-precision floating-point values in xmm2/mem to two signed doubleword integers in xmm1.</td>, <td>VEX.128.F2.0F.WIG E6 /r VCVTPD2DQ xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert two packed double-precision floating-point values in xmm2/mem to two signed doubleword integers in xmm1.</td>, <td>VEX.256.F2.0F.WIG E6 /r VCVTPD2DQ xmm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert four packed double-precision floating-point values in ymm2/mem to four signed doubleword integers in xmm1.</td>, <td>EVEX.128.F2.0F.W1 E6 /r VCVTPD2DQ xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert two packed double-precision floating-point values in xmm2/m128/m64bcst to two signed doubleword integers in xmm1 subject to writemask k1.</td>, <td>EVEX.256.F2.0F.W1 E6 /r VCVTPD2DQ xmm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert four packed double-precision floating-point values in ymm2/m256/m64bcst to four signed doubleword integers in xmm1 subject to writemask k1.</td>, <td>EVEX.512.F2.0F.W1 E6 /r VCVTPD2DQ ymm1 {k1}{z}, zmm2/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert eight packed double-precision floating-point values in zmm2/m512/m64bcst to eight signed doubleword integers in ymm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>66 0F 2D /<em>r</em> CVTPD2PI <em>mm</em>, <em>xmm/m128</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Convert two packed double-precision floating-point values from <em>xmm/m128</em> to two packed signed doubleword integers in <em>mm</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>66 0F 5A /r CVTPD2PS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Convert two packed double-precision floating-point values in xmm2/mem to two single-precision floating-point values in xmm1.</td>, <td>VEX.128.66.0F.WIG 5A /r VCVTPD2PS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert two packed double-precision floating-point values in xmm2/mem to two single-precision floating-point values in xmm1.</td>, <td>VEX.256.66.0F.WIG 5A /r VCVTPD2PS xmm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert four packed double-precision floating-point values in ymm2/mem to four single-precision floating-point values in xmm1.</td>, <td>EVEX.128.66.0F.W1 5A /r VCVTPD2PS xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert two packed double-precision floating-point values in xmm2/m128/m64bcst to two single-precision floating-point values in xmm1with writemask k1.</td>, <td>EVEX.256.66.0F.W1 5A /r VCVTPD2PS xmm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert four packed double-precision floating-point values in ymm2/m256/m64bcst to four single-precision floating-point values in xmm1with writemask k1.</td>, <td>EVEX.512.66.0F.W1 5A /r VCVTPD2PS ymm1 {k1}{z}, zmm2/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert eight packed double-precision floating-point values in zmm2/m512/m64bcst to eight single-precision floating-point values in ymm1with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>66 0F 2A /<em>r</em> CVTPI2PD <em>xmm</em>, <em>mm/m64*</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Convert two packed signed doubleword integers from <em>mm/mem64</em> to two packed double-precision floating-point values in <em>xmm</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>NP 0F 2A /<em>r</em> CVTPI2PS <em>xmm</em>, <em>mm</em>/<em>m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Convert two signed doubleword integers from <em>mm</em>/<em>m64</em> to two single-precision floating-point values in <em>xmm</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>66 0F 5B /r CVTPS2DQ xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Convert four packed single-precision floating-point values from xmm2/mem to four packed signed doubleword values in xmm1.</td>, <td>VEX.128.66.0F.WIG 5B /r VCVTPS2DQ xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert four packed single-precision floating-point values from xmm2/mem to four packed signed doubleword values in xmm1.</td>, <td>VEX.256.66.0F.WIG 5B /r VCVTPS2DQ ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert eight packed single-precision floating-point values from ymm2/mem to eight packed signed doubleword values in ymm1.</td>, <td>EVEX.128.66.0F.W0 5B /r VCVTPS2DQ xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed signed doubleword values in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F.W0 5B /r VCVTPS2DQ ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed signed doubleword values in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F.W0 5B /r VCVTPS2DQ zmm1 {k1}{z}, zmm2/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert sixteen packed single-precision floating-point values from zmm2/m512/m32bcst to sixteen packed signed doubleword values in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>NP 0F 5A /r CVTPS2PD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Convert two packed single-precision floating-point values in xmm2/m64 to two packed double-precision floating-point values in xmm1.</td>, <td>VEX.128.0F.WIG 5A /r VCVTPS2PD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert two packed single-precision floating-point values in xmm2/m64 to two packed double-precision floating-point values in xmm1.</td>, <td>VEX.256.0F.WIG 5A /r VCVTPS2PD ymm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert four packed single-precision floating-point values in xmm2/m128 to four packed double-precision floating-point values in ymm1.</td>, <td>EVEX.128.0F.W0 5A /r VCVTPS2PD xmm1 {k1}{z}, xmm2/m64/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert two packed single-precision floating-point values in xmm2/m64/m32bcst to packed double-precision floating-point values in xmm1 with writemask k1.</td>, <td>EVEX.256.0F.W0 5A /r VCVTPS2PD ymm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL</td>, <td>Convert four packed single-precision floating-point values in xmm2/m128/m32bcst to packed double-precision floating-point values in ymm1 with writemask k1.</td>, <td>EVEX.512.0F.W0 5A /r VCVTPS2PD zmm1 {k1}{z}, ymm2/m256/m32bcst{sae}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert eight packed single-precision floating-point values in ymm2/m256/b32bcst to eight packed double-precision floating-point values in zmm1 with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Half</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>NP 0F 2D /<em>r</em> CVTPS2PI <em>mm, xmm/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Convert two packed single-precision floating-point values from <em>xmm</em>/<em>m64</em> to two packed signed doubleword integers in <em>mm</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>F2 0F 2D /r CVTSD2SI r32, xmm1/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Convert one double-precision floating-point value from xmm1/m64 to one signed doubleword integer r32.</td>, <td>F2 REX.W 0F 2D /r CVTSD2SI r64, xmm1/m64</td>, <td>A</td>, <td>V/N.E.</td>, <td>SSE2</td>, <td>Convert one double-precision floating-point value from xmm1/m64 to one signed quadword integer sign-extended into r64.</td>, <td>VEX.LIG.F2.0F.W0 2D /r <sup>1</sup> VCVTSD2SI r32, xmm1/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert one double-precision floating-point value from xmm1/m64 to one signed doubleword integer r32.</td>, <td>VEX.LIG.F2.0F.W1 2D /r <sup>1</sup> VCVTSD2SI r64, xmm1/m64</td>, <td>A</td>, <td>V/N.E.<sup>2</sup></td>, <td>AVX</td>, <td>Convert one double-precision floating-point value from xmm1/m64 to one signed quadword integer sign-extended into r64.</td>, <td>EVEX.LIG.F2.0F.W0 2D /r VCVTSD2SI r32, xmm1/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert one double-precision floating-point value from xmm1/m64 to one signed doubleword integer r32.</td>, <td>EVEX.LIG.F2.0F.W1 2D /r VCVTSD2SI r64, xmm1/m64{er}</td>, <td>B</td>, <td>V/N.E.<sup>2</sup></td>, <td>AVX512F</td>, <td>Convert one double-precision floating-point value from xmm1/m64 to one signed quadword integer sign-extended into r64.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Fixed</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>F2 0F 5A /r CVTSD2SS xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Convert one double-precision floating-point value in xmm2/m64 to one single-precision floating-point value in xmm1.</td>, <td>VEX.LIG.F2.0F.WIG 5A /r VCVTSD2SS xmm1,xmm2, xmm3/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert one double-precision floating-point value in xmm3/m64 to one single-precision floating-point value and merge with high bits in xmm2.</td>, <td>EVEX.LIG.F2.0F.W1 5A /r VCVTSD2SS xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert one double-precision floating-point value in xmm3/m64 to one single-precision floating-point value and merge with high bits in xmm2 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F2 0F 2A /r CVTSI2SD xmm1, r32/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Convert one signed doubleword integer from r32/m32 to one double-precision floating-point value in xmm1.</td>, <td>F2 REX.W 0F 2A /r CVTSI2SD xmm1, r/m64</td>, <td>A</td>, <td>V/N.E.</td>, <td>SSE2</td>, <td>Convert one signed quadword integer from r/m64 to one double-precision floating-point value in xmm1.</td>, <td>VEX.LIG.F2.0F.W0 2A /r VCVTSI2SD xmm1, xmm2, r/m32</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert one signed doubleword integer from r/m32 to one double-precision floating-point value in xmm1.</td>, <td>VEX.LIG.F2.0F.W1 2A /r VCVTSI2SD xmm1, xmm2, r/m64</td>, <td>B</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX</td>, <td>Convert one signed quadword integer from r/m64 to one double-precision floating-point value in xmm1.</td>, <td>EVEX.LIG.F2.0F.W0 2A /r VCVTSI2SD xmm1, xmm2, r/m32</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert one signed doubleword integer from r/m32 to one double-precision floating-point value in xmm1.</td>, <td>EVEX.LIG.F2.0F.W1 2A /r VCVTSI2SD xmm1, xmm2, r/m64{er}</td>, <td>C</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512F</td>, <td>Convert one signed quadword integer from r/m64 to one double-precision floating-point value in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F3 0F 2A /r CVTSI2SS xmm1, r/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Convert one signed doubleword integer from r/m32 to one single-precision floating-point value in xmm1.</td>, <td>F3 REX.W 0F 2A /r CVTSI2SS xmm1, r/m64</td>, <td>A</td>, <td>V/N.E.</td>, <td>SSE</td>, <td>Convert one signed quadword integer from r/m64 to one single-precision floating-point value in xmm1.</td>, <td>VEX.LIG.F3.0F.W0 2A /r VCVTSI2SS xmm1, xmm2, r/m32</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert one signed doubleword integer from r/m32 to one single-precision floating-point value in xmm1.</td>, <td>VEX.LIG.F3.0F.W1 2A /r VCVTSI2SS xmm1, xmm2, r/m64</td>, <td>B</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX</td>, <td>Convert one signed quadword integer from r/m64 to one single-precision floating-point value in xmm1.</td>, <td>EVEX.LIG.F3.0F.W0 2A /r VCVTSI2SS xmm1, xmm2, r/m32{er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert one signed doubleword integer from r/m32 to one single-precision floating-point value in xmm1.</td>, <td>EVEX.LIG.F3.0F.W1 2A /r VCVTSI2SS xmm1, xmm2, r/m64{er}</td>, <td>C</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512F</td>, <td>Convert one signed quadword integer from r/m64 to one single-precision floating-point value in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F3 0F 5A /r CVTSS2SD xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Convert one single-precision floating-point value in xmm2/m32 to one double-precision floating-point value in xmm1.</td>, <td>VEX.LIG.F3.0F.WIG 5A /r VCVTSS2SD xmm1, xmm2, xmm3/m32</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert one single-precision floating-point value in xmm3/m32 to one double-precision floating-point value and merge with high bits of xmm2.</td>, <td>EVEX.LIG.F3.0F.W0 5A /r VCVTSS2SD xmm1 {k1}{z}, xmm2, xmm3/m32{sae}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert one single-precision floating-point value in xmm3/m32 to one double-precision floating-point value and merge with high bits of xmm2 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F3 0F 2D /r CVTSS2SI r32, xmm1/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Convert one single-precision floating-point value from xmm1/m32 to one signed doubleword integer in r32.</td>, <td>F3 REX.W 0F 2D /r CVTSS2SI r64, xmm1/m32</td>, <td>A</td>, <td>V/N.E.</td>, <td>SSE</td>, <td>Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64.</td>, <td>VEX.LIG.F3.0F.W0 2D /r <sup>1</sup> VCVTSS2SI r32, xmm1/m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert one single-precision floating-point value from xmm1/m32 to one signed doubleword integer in r32.</td>, <td>VEX.LIG.F3.0F.W1 2D /r <sup>1</sup> VCVTSS2SI r64, xmm1/m32</td>, <td>A</td>, <td>V/N.E.<sup>2</sup></td>, <td>AVX</td>, <td>Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64.</td>, <td>EVEX.LIG.F3.0F.W0 2D /r VCVTSS2SI r32, xmm1/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert one single-precision floating-point value from xmm1/m32 to one signed doubleword integer in r32.</td>, <td>EVEX.LIG.F3.0F.W1 2D /r VCVTSS2SI r64, xmm1/m32{er}</td>, <td>B</td>, <td>V/N.E.<sup>2</sup></td>, <td>AVX512F</td>, <td>Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Fixed</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B.</td>]

[<td>66 0F E6 /r CVTTPD2DQ xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Convert two packed double-precision floating-point values in xmm2/mem to two signed doubleword integers in xmm1 using truncation.</td>, <td>VEX.128.66.0F.WIG E6 /r VCVTTPD2DQ xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert two packed double-precision floating-point values in xmm2/mem to two signed doubleword integers in xmm1 using truncation.</td>, <td>VEX.256.66.0F.WIG E6 /r VCVTTPD2DQ xmm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert four packed double-precision floating-point values in ymm2/mem to four signed doubleword integers in xmm1 using truncation.</td>, <td>EVEX.128.66.0F.W1 E6 /r VCVTTPD2DQ xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert two packed double-precision floating-point values in xmm2/m128/m64bcst to two signed doubleword integers in xmm1 using truncation subject to writemask k1.</td>, <td>EVEX.256.66.0F.W1 E6 /r VCVTTPD2DQ xmm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert four packed double-precision floating-point values in ymm2/m256/m64bcst to four signed doubleword integers in xmm1 using truncation subject to writemask k1.</td>, <td>EVEX.512.66.0F.W1 E6 /r VCVTTPD2DQ ymm1 {k1}{z}, zmm2/m512/m64bcst{sae}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert eight packed double-precision floating-point values in zmm2/m512/m64bcst to eight signed doubleword integers in ymm1 using truncation subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>66 0F 2C /<em>r</em> CVTTPD2PI <em>mm</em>, <em>xmm/m128</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Convert two packer double-precision floating-point values from <em>xmm/m128</em> to two packed signed doubleword integers in <em>mm</em> using truncation.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>F3 0F 5B /r CVTTPS2DQ xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Convert four packed single-precision floating-point values from xmm2/mem to four packed signed doubleword values in xmm1 using truncation.</td>, <td>VEX.128.F3.0F.WIG 5B /r VCVTTPS2DQ xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert four packed single-precision floating-point values from xmm2/mem to four packed signed doubleword values in xmm1 using truncation.</td>, <td>VEX.256.F3.0F.WIG 5B /r VCVTTPS2DQ ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert eight packed single-precision floating-point values from ymm2/mem to eight packed signed doubleword values in ymm1 using truncation.</td>, <td>EVEX.128.F3.0F.W0 5B /r VCVTTPS2DQ xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed signed doubleword values in xmm1 using truncation subject to writemask k1.</td>, <td>EVEX.256.F3.0F.W0 5B /r VCVTTPS2DQ ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed signed doubleword values in ymm1 using truncation subject to writemask k1.</td>, <td>EVEX.512.F3.0F.W0 5B /r VCVTTPS2DQ zmm1 {k1}{z}, zmm2/m512/m32bcst {sae}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert sixteen packed single-precision floating-point values from zmm2/m512/m32bcst to sixteen packed signed doubleword values in zmm1 using truncation subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>NP 0F 2C /r CVTTPS2PI <em>mm</em>, <em>xmm/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Convert two single-precision floating-point values from <em>xmm</em>/<em>m64</em> to two signed doubleword signed integers in <em>mm</em> using truncation.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>F2 0F 2C /r CVTTSD2SI r32, xmm1/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Convert one double-precision floating-point value from xmm1/m64 to one signed doubleword integer in r32 using truncation.</td>, <td>F2 REX.W 0F 2C /r CVTTSD2SI r64, xmm1/m64</td>, <td>A</td>, <td>V/N.E.</td>, <td>SSE2</td>, <td>Convert one double-precision floating-point value from xmm1/m64 to one signed quadword integer in r64 using truncation.</td>, <td>VEX.LIG.F2.0F.W0 2C /r <sup>1</sup> VCVTTSD2SI r32, xmm1/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert one double-precision floating-point value from xmm1/m64 to one signed doubleword integer in r32 using truncation.</td>, <td>VEX.LIG.F2.0F.W1 2C /r <sup>1</sup> VCVTTSD2SI r64, xmm1/m64</td>, <td>B</td>, <td>V/N.E.<sup>2</sup></td>, <td>AVX</td>, <td>Convert one double-precision floating-point value from xmm1/m64 to one signed quadword integer in r64 using truncation.</td>, <td>EVEX.LIG.F2.0F.W0 2C /r VCVTTSD2SI r32, xmm1/m64{sae}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert one double-precision floating-point value from xmm1/m64 to one signed doubleword integer in r32 using truncation.</td>, <td>EVEX.LIG.F2.0F.W1 2C /r VCVTTSD2SI r64, xmm1/m64{sae}</td>, <td>B</td>, <td>V/N.E.<sup>2</sup></td>, <td>AVX512F</td>, <td>Convert one double-precision floating-point value from xmm1/m64 to one signed quadword integer in r64 using truncation.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Fixed</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B.</td>]

[<td>F3 0F 2C /r CVTTSS2SI r32, xmm1/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Convert one single-precision floating-point value from xmm1/m32 to one signed doubleword integer in r32 using truncation.</td>, <td>F3 REX.W 0F 2C /r CVTTSS2SI r64, xmm1/m32</td>, <td>A</td>, <td>V/N.E.</td>, <td>SSE</td>, <td>Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64 using truncation.</td>, <td>VEX.LIG.F3.0F.W0 2C /r <sup>1</sup> VCVTTSS2SI r32, xmm1/m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert one single-precision floating-point value from xmm1/m32 to one signed doubleword integer in r32 using truncation.</td>, <td>VEX.LIG.F3.0F.W1 2C /r <sup>1</sup> VCVTTSS2SI r64, xmm1/m32</td>, <td>A</td>, <td>V/N.E.<sup>2</sup></td>, <td>AVX</td>, <td>Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64 using truncation.</td>, <td>EVEX.LIG.F3.0F.W0 2C /r VCVTTSS2SI r32, xmm1/m32{sae}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert one single-precision floating-point value from xmm1/m32 to one signed doubleword integer in r32 using truncation.</td>, <td>EVEX.LIG.F3.0F.W1 2C /r VCVTTSS2SI r64, xmm1/m32{sae}</td>, <td>B</td>, <td>V/N.E.<sup>2</sup></td>, <td>AVX512F</td>, <td>Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64 using truncation.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Fixed</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B.</td>]

[<td>99</td>, <td>CWD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>DX:AX ← sign-extend of AX.</td>, <td>99</td>, <td>CDQ</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>EDX:EAX ← sign-extend of EAX.</td>, <td>REX.W + 99</td>, <td>CQO</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>RDX:RAX← sign-extend of RAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>98</td>, <td>CBW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>AX ← sign-extend of AL.</td>, <td>98</td>, <td>CWDE</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>EAX ← sign-extend of AX.</td>, <td>REX.W + 98</td>, <td>CDQE</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>RAX ← sign-extend of EAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>27</td>, <td>DAA</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Decimal adjust AL after addition.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If in 64-bit mode.</td>]

[<td>2F</td>, <td>DAS</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Decimal adjust AL after subtraction.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If in 64-bit mode.</td>]

[<td>FE /1</td>, <td>DEC <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Decrement <em>r/m8</em> by 1.</td>, <td>REX + FE /1</td>, <td>DEC <em>r/m8</em><sup>*</sup></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Decrement <em>r/m8</em> by 1.</td>, <td>FF /1</td>, <td>DEC <em>r/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Decrement <em>r/m16</em> by 1.</td>, <td>FF /1</td>, <td>DEC <em>r/m32</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Decrement <em>r/m32</em> by 1.</td>, <td>REX.W + FF /1</td>, <td>DEC <em>r/m64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Decrement <em>r/m64</em> by 1.</td>, <td>48+rw</td>, <td>DEC <em>r16</em></td>, <td>O</td>, <td>N.E.</td>, <td>Valid</td>, <td>Decrement <em>r16</em> by 1.</td>, <td>48+rd</td>, <td>DEC <em>r32</em></td>, <td>O</td>, <td>N.E.</td>, <td>Valid</td>, <td>Decrement <em>r32</em> by 1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r, w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>O</td>, <td>opcode + rd (r, w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination operand is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>F6 /6</td>, <td>DIV <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide AX by <em>r/m8</em>, with result stored in AL ← Quotient, AH ← Remainder.</td>, <td>REX + F6 /6</td>, <td>DIV <em>r/m8</em><sup>*</sup></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide AX by <em>r/m8</em>, with result stored in AL ← Quotient, AH ← Remainder.</td>, <td>F7 /6</td>, <td>DIV <em>r/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide DX:AX by <em>r/m16</em>, with result stored in AX ← Quotient, DX ← Remainder.</td>, <td>F7 /6</td>, <td>DIV <em>r/m32</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide EDX:EAX by <em>r/m32</em>, with result stored in EAX ← Quotient, EDX ← Remainder.</td>, <td>REX.W + F7 /6</td>, <td>DIV <em>r/m64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide RDX:RAX by <em>r/m64</em>, with result stored in RAX ← Quotient, RDX ← Remainder.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>Word/byte</td>, <td>AX</td>, <td>r/m8</td>, <td>AL</td>, <td>AH</td>, <td>255</td>, <td>Doubleword/word</td>, <td>DX:AX</td>, <td>r/m16</td>, <td>AX</td>, <td>DX</td>, <td>65,535</td>, <td>Quadword/doubleword</td>, <td>EDX:EAX</td>, <td>r/m32</td>, <td>EAX</td>, <td>EDX</td>, <td>2<sup>32</sup> − 1</td>, <td>Doublequadword/quadword</td>, <td>RDX:RAX</td>, <td>r/m64</td>, <td>RAX</td>, <td>RDX</td>, <td>2<sup>64</sup> − 1</td>, <td rowspan="2">#DE</td>, <td>If the source operand (divisor) is 0</td>, <td>If the quotient is too large for the designated register.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#DE</td>, <td>If the source operand (divisor) is 0.</td>, <td>If the quotient is too large for the designated register.</td>, <td rowspan="2">#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#DE</td>, <td>If the source operand (divisor) is 0.</td>, <td>If the quotient is too large for the designated register.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td rowspan="2">#DE</td>, <td>If the source operand (divisor) is 0</td>, <td>If the quotient is too large for the designated register.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>66 0F 5E /r DIVPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Divide packed double-precision floating-point values in xmm1 by packed double-precision floating-point values in xmm2/mem.</td>, <td>VEX.128.66.0F.WIG 5E /r VDIVPD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Divide packed double-precision floating-point values in xmm2 by packed double-precision floating-point values in xmm3/mem.</td>, <td>VEX.256.66.0F.WIG 5E /r VDIVPD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Divide packed double-precision floating-point values in ymm2 by packed double-precision floating-point values in ymm3/mem.</td>, <td>EVEX.128.66.0F.W1 5E /r VDIVPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Divide packed double-precision floating-point values in xmm2 by packed double-precision floating-point values in xmm3/m128/m64bcst and write results to xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F.W1 5E /r VDIVPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Divide packed double-precision floating-point values in ymm2 by packed double-precision floating-point values in ymm3/m256/m64bcst and write results to ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F.W1 5E /r VDIVPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Divide packed double-precision floating-point values in zmm2 by packed double-precision FP values in zmm3/m512/m64bcst and write results to zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 5E /r DIVPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Divide packed single-precision floating-point values in xmm1 by packed single-precision floating-point values in xmm2/mem.</td>, <td>VEX.128.0F.WIG 5E /r VDIVPS xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Divide packed single-precision floating-point values in xmm2 by packed single-precision floating-point values in xmm3/mem.</td>, <td>VEX.256.0F.WIG 5E /r VDIVPS ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Divide packed single-precision floating-point values in ymm2 by packed single-precision floating-point values in ymm3/mem.</td>, <td>EVEX.128.0F.W0 5E /r VDIVPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Divide packed single-precision floating-point values in xmm2 by packed single-precision floating-point values in xmm3/m128/m32bcst and write results to xmm1 subject to writemask k1.</td>, <td>EVEX.256.0F.W0 5E /r VDIVPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Divide packed single-precision floating-point values in ymm2 by packed single-precision floating-point values in ymm3/m256/m32bcst and write results to ymm1 subject to writemask k1.</td>, <td>EVEX.512.0F.W0 5E /r VDIVPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Divide packed single-precision floating-point values in zmm2 by packed single-precision floating-point values in zmm3/m512/m32bcst and write results to zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F2 0F 5E /r DIVSD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Divide low double-precision floating-point value in xmm1 by low double-precision floating-point value in xmm2/m64.</td>, <td>VEX.LIG.F2.0F.WIG 5E /r VDIVSD xmm1, xmm2, xmm3/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Divide low double-precision floating-point value in xmm2 by low double-precision floating-point value in xmm3/m64.</td>, <td>EVEX.LIG.F2.0F.W1 5E /r VDIVSD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Divide low double-precision floating-point value in xmm2 by low double-precision floating-point value in xmm3/m64.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F3 0F 5E /r DIVSS xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Divide low single-precision floating-point value in xmm1 by low single-precision floating-point value in xmm2/m32.</td>, <td>VEX.LIG.F3.0F.WIG 5E /r VDIVSS xmm1, xmm2, xmm3/m32</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Divide low single-precision floating-point value in xmm2 by low single-precision floating-point value in xmm3/m32.</td>, <td>EVEX.LIG.F3.0F.W0 5E /r VDIVSS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Divide low single-precision floating-point value in xmm2 by low single-precision floating-point value in xmm3/m32.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 3A 41 /r ib DPPD <em>xmm1, xmm2/m128, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Selectively multiply packed DP floating-point values from <em>xmm1</em> with packed DP floating-point values from <em>xmm2</em>, add and selectively store the packed DP floating-point values to <em>xmm1</em>.</td>, <td>VEX.128.66.0F3A.WIG 41 /r ib VDPPD xmm1,xmm2, xmm3/m128, imm8</td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Selectively multiply packed DP floating-point values from xmm2 with packed DP floating-point values from xmm3, add and selectively store the packed DP floating-point values to xmm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMI</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>RVMI</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>#UD</td>, <td>If VEX.L= 1.</td>]

[<td>66 0F 3A 40 /r ib DPPS <em>xmm1, xmm2/m128, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Selectively multiply packed SP floating-point values from <em>xmm1</em> with packed SP floating-point values from <em>xmm2</em>, add and selectively store the packed SP floating-point values or zero values to <em>xmm1</em>.</td>, <td>VEX.128.66.0F3A.WIG 40 /r ib VDPPS xmm1,xmm2, xmm3/m128, imm8</td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply packed SP floating point values from xmm1 with packed SP floating point values from xmm2/mem selectively add and store to xmm1.</td>, <td>VEX.256.66.0F3A.WIG 40 /r ib VDPPS ymm1, ymm2, ymm3/m256, imm8</td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply packed single-precision floating-point values from ymm2 with packed SP floating point values from ymm3/mem, selectively add pairs of elements and store to ymm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMI</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>RVMI</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>]

[<td>NP 0F 77</td>, <td>EMMS</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Set the x87 FPU tag word to empty.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If CR0.EM[bit 2] = 1.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>C8 <em>iw</em> 00</td>, <td>ENTER <em>imm16</em>, 0</td>, <td>II</td>, <td>Valid</td>, <td>Valid</td>, <td>Create a stack frame for a procedure.</td>, <td>C8 <em>iw</em> 01</td>, <td>ENTER <em>imm16</em>,1</td>, <td>II</td>, <td>Valid</td>, <td>Valid</td>, <td>Create a stack frame with a nested pointer for a procedure.</td>, <td>C8 <em>iw</em> ib</td>, <td>ENTER <em>imm16, imm8</em></td>, <td>II</td>, <td>Valid</td>, <td>Valid</td>, <td>Create a stack frame with nested pointers for a procedure.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>II</td>, <td>iw</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>#SS(0)</td>, <td>If the new value of the SP or ESP register is outside the stack segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs or if a write using the final value of the stack pointer (within the current stack segment) would cause a page fault.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS</td>, <td>If the new value of the SP or ESP register is outside the stack segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If the new value of the SP or ESP register is outside the stack segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs or if a write using the final value of the stack pointer (within the current stack segment) would cause a page fault.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If the stack address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs or if a write using the final value of the stack pointer (within the current stack segment) would cause a page fault.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>66 0F 3A 17 /r ib EXTRACTPS reg/m32, xmm1, imm8</td>, <td>A</td>, <td>VV</td>, <td>SSE4_1</td>, <td>Extract one single-precision floating-point value from xmm1 at the offset specified by imm8 and store the result in reg or m32. Zero extend the results in 64-bit register if applicable.</td>, <td>VEX.128.66.0F3A.WIG 17 /r ib VEXTRACTPS reg/m32, xmm1, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Extract one single-precision floating-point value from xmm1 at the offset specified by imm8 and store the result in reg or m32. Zero extend the results in 64-bit register if applicable.</td>, <td>EVEX.128.66.0F3A.WIG 17 /r ib VEXTRACTPS reg/m32, xmm1, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract one single-precision floating-point value from xmm1 at the offset specified by imm8 and store the result in reg or m32. Zero extend the results in 64-bit register if applicable.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>#UD</td>, <td>IF VEX.L = 0.</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>D9 F0</td>, <td>F2XM1</td>, <td>Valid</td>, <td>Valid</td>, <td>Replace ST(0) with (2<sup>ST(0)</sup> – 1).</td>, <td>− 1.0 to −0</td>, <td>− 0.5 to − 0</td>, <td>−0</td>, <td>−0</td>, <td>+0</td>, <td>+0</td>, <td>+ 0 to +1.0</td>, <td>+ 0 to 1.0</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>Source operand is an SNaN value or unsupported format.</td>, <td>#D</td>, <td>Source is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 E1</td>, <td>FABS</td>, <td>Valid</td>, <td>Valid</td>, <td>Replace ST with its absolute value.</td>, <td>−∞</td>, <td>+∞</td>, <td>−F</td>, <td>+F</td>, <td>−0</td>, <td>+0</td>, <td>+0</td>, <td>+0</td>, <td>+F</td>, <td>+F</td>, <td>+∞</td>, <td>+∞</td>, <td>NaN</td>, <td>NaN</td>, <td>C1</td>, <td>Set to 0.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /0</td>, <td>FADD <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>m32fp</em> to ST(0) and store result in ST(0).</td>, <td>DC /0</td>, <td>FADD <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>m64fp</em> to ST(0) and store result in ST(0).</td>, <td>D8 C0+i</td>, <td>FADD ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Add ST(0) to ST(i) and store result in ST(0).</td>, <td>DC C0+i</td>, <td>FADD ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Add ST(i) to ST(0) and store result in ST(i).</td>, <td>DE C0+i</td>, <td>FADDP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Add ST(0) to ST(i), store result in ST(i), and pop the register stack.</td>, <td>DE C1</td>, <td>FADDP</td>, <td>Valid</td>, <td>Valid</td>, <td>Add ST(0) to ST(1), store result in ST(1), and pop the register stack.</td>, <td>DA /0</td>, <td>FIADD <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>m32int</em> to ST(0) and store result in ST(0).</td>, <td>DE /0</td>, <td>FIADD <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>m16int</em> to ST(0) and store result in ST(0).</td>, <td rowspan="8"><strong>SRC</strong></td>, <td></td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>*</td>, <td>NaN</td>, <td>− F or − I</td>, <td>−∞</td>, <td>−F</td>, <td>SRC</td>, <td>SRC</td>, <td>± F or ± 0</td>, <td>+∞</td>, <td>NaN</td>, <td>−0</td>, <td>−∞</td>, <td>DEST</td>, <td>−0</td>, <td>±0</td>, <td>DEST</td>, <td>+∞</td>, <td>NaN</td>, <td>+0</td>, <td>−∞</td>, <td>DEST</td>, <td>±0</td>, <td>+0</td>, <td>DEST</td>, <td>+∞</td>, <td>NaN</td>, <td>+ F or + I</td>, <td>−∞</td>, <td>± F or ± 0</td>, <td>SRC</td>, <td>SRC</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+∞</td>, <td>*</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>Operands are infinities of unlike sign.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /0</td>, <td>FADD <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>m32fp</em> to ST(0) and store result in ST(0).</td>, <td>DC /0</td>, <td>FADD <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>m64fp</em> to ST(0) and store result in ST(0).</td>, <td>D8 C0+i</td>, <td>FADD ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Add ST(0) to ST(i) and store result in ST(0).</td>, <td>DC C0+i</td>, <td>FADD ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Add ST(i) to ST(0) and store result in ST(i).</td>, <td>DE C0+i</td>, <td>FADDP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Add ST(0) to ST(i), store result in ST(i), and pop the register stack.</td>, <td>DE C1</td>, <td>FADDP</td>, <td>Valid</td>, <td>Valid</td>, <td>Add ST(0) to ST(1), store result in ST(1), and pop the register stack.</td>, <td>DA /0</td>, <td>FIADD <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>m32int</em> to ST(0) and store result in ST(0).</td>, <td>DE /0</td>, <td>FIADD <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>m16int</em> to ST(0) and store result in ST(0).</td>, <td rowspan="8"><strong>SRC</strong></td>, <td></td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>*</td>, <td>NaN</td>, <td>− F or − I</td>, <td>−∞</td>, <td>−F</td>, <td>SRC</td>, <td>SRC</td>, <td>± F or ± 0</td>, <td>+∞</td>, <td>NaN</td>, <td>−0</td>, <td>−∞</td>, <td>DEST</td>, <td>−0</td>, <td>±0</td>, <td>DEST</td>, <td>+∞</td>, <td>NaN</td>, <td>+0</td>, <td>−∞</td>, <td>DEST</td>, <td>±0</td>, <td>+0</td>, <td>DEST</td>, <td>+∞</td>, <td>NaN</td>, <td>+ F or + I</td>, <td>−∞</td>, <td>± F or ± 0</td>, <td>SRC</td>, <td>SRC</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+∞</td>, <td>*</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>Operands are infinities of unlike sign.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DF /4</td>, <td>FBLD <em>m80bcd</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Convert BCD value to floating-point and push onto the FPU stack.</td>, <td>C1</td>, <td>Set to 1 if stack overflow occurred; otherwise, set to 0.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack overflow occurred.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DF /6</td>, <td>FBSTP m80bcd</td>, <td>Valid</td>, <td>Valid</td>, <td>Store ST(0) in m80bcd and pop ST(0).</td>, <td>− ∞ or Value Too Large for DEST Format</td>, <td>*</td>, <td>F≤−1</td>, <td>−D</td>, <td>−1 &lt; F &lt; -0</td>, <td>**</td>, <td>−0</td>, <td>−0</td>, <td>+0</td>, <td>+0</td>, <td>+ 0 &lt; F &lt; +1</td>, <td>**</td>, <td>F ≥ +1</td>, <td>+D</td>, <td>+ ∞ or Value Too Large for DEST Format</td>, <td>*</td>, <td>NaN</td>, <td>*</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Converted value that exceeds 18 BCD digits in length.</td>, <td>Source operand is an SNaN, QNaN, ±∞, or in an unsupported format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="3">#GP(0)</td>, <td>If a segment register is being loaded with a segment selector that points to a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 E0</td>, <td>FCHS</td>, <td>Valid</td>, <td>Valid</td>, <td>Complements sign of ST(0).</td>, <td>−∞</td>, <td>+∞</td>, <td>−F</td>, <td>+F</td>, <td>−0</td>, <td>+0</td>, <td>+0</td>, <td>−0</td>, <td>+F</td>, <td>−F</td>, <td>+∞</td>, <td>−∞</td>, <td>NaN</td>, <td>NaN</td>, <td>C1</td>, <td>Set to 0.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>9B DB E2</td>, <td>FCLEX</td>, <td>Valid</td>, <td>Valid</td>, <td>Clear floating-point exception flags after checking for pending unmasked floating-point exceptions.</td>, <td>DB E2</td>, <td>FNCLEX<sup>*</sup></td>, <td>Valid</td>, <td>Valid</td>, <td>Clear floating-point exception flags without checking for pending unmasked floating-point exceptions.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DA C0+i</td>, <td>FCMOVB ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if below (CF=1).</td>, <td>DA C8+i</td>, <td>FCMOVE ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if equal (ZF=1).</td>, <td>DA D0+i</td>, <td>FCMOVBE ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if below or equal (CF=1 or ZF=1).</td>, <td>DA D8+i</td>, <td>FCMOVU ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if unordered (PF=1).</td>, <td>DB C0+i</td>, <td>FCMOVNB ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not below (CF=0).</td>, <td>DB C8+i</td>, <td>FCMOVNE ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not equal (ZF=0).</td>, <td>DB D0+i</td>, <td>FCMOVNBE ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not below or equal (CF=0 and ZF=0).</td>, <td>DB D8+i</td>, <td>FCMOVNU ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Move if not unordered (PF=0).</td>, <td>C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /2</td>, <td>FCOM <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m32fp</em>.</td>, <td>DC /2</td>, <td>FCOM <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m64fp</em>.</td>, <td>D8 D0+i</td>, <td>FCOM ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i).</td>, <td>D8 D1</td>, <td>FCOM</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1).</td>, <td>D8 /3</td>, <td>FCOMP <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m32fp</em> and pop register stack.</td>, <td>DC /3</td>, <td>FCOMP <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with m64fp and pop register stack.</td>, <td>D8 D8+i</td>, <td>FCOMP ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i) and pop register stack.</td>, <td>D8 D9</td>, <td>FCOMP</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1) and pop register stack.</td>, <td>DE D9</td>, <td>FCOMPP</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1) and pop register stack twice.</td>, <td>ST(0) &gt; SRC</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>ST(0) &lt; SRC</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>ST(0) = SRC</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>Unordered*</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>C1</td>, <td>Set to 0.</td>, <td>C0, C2, C3</td>, <td>See table on previous page.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>One or both operands are NaN values or have unsupported formats.</td>, <td>Register is marked empty.</td>, <td>#D</td>, <td>One or both operands are denormal values.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DB F0+i</td>, <td>FCOMI ST, ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i) and set status flags accordingly.</td>, <td>DF F0+i</td>, <td>FCOMIP ST, ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i), set status flags accordingly, and pop register stack.</td>, <td>DB E8+i</td>, <td>FUCOMI ST, ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i), check for ordered values, and set status flags accordingly.</td>, <td>DF E8+i</td>, <td>FUCOMIP ST, ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i), check for ordered values, set status flags accordingly, and pop register stack.</td>, <td>ST0 &gt; ST(i)</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>ST0 &lt; ST(i)</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>ST0 = ST(i)</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>Unordered**</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>C1</td>, <td>Set to 0.</td>, <td>C0, C2, C3</td>, <td>Not affected.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>(FCOMI or FCOMIP instruction) One or both operands are NaN values or have unsupported formats.</td>, <td>(FUCOMI or FUCOMIP instruction) One or both operands are SNaN values (but not QNaNs) or have undefined formats. Detection of a QNaN value does not raise an invalid-operand exception.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DB F0+i</td>, <td>FCOMI ST, ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i) and set status flags accordingly.</td>, <td>DF F0+i</td>, <td>FCOMIP ST, ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i), set status flags accordingly, and pop register stack.</td>, <td>DB E8+i</td>, <td>FUCOMI ST, ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i), check for ordered values, and set status flags accordingly.</td>, <td>DF E8+i</td>, <td>FUCOMIP ST, ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i), check for ordered values, set status flags accordingly, and pop register stack.</td>, <td>ST0 &gt; ST(i)</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>ST0 &lt; ST(i)</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>ST0 = ST(i)</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>Unordered**</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>C1</td>, <td>Set to 0.</td>, <td>C0, C2, C3</td>, <td>Not affected.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>(FCOMI or FCOMIP instruction) One or both operands are NaN values or have unsupported formats.</td>, <td>(FUCOMI or FUCOMIP instruction) One or both operands are SNaN values (but not QNaNs) or have undefined formats. Detection of a QNaN value does not raise an invalid-operand exception.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /2</td>, <td>FCOM <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m32fp</em>.</td>, <td>DC /2</td>, <td>FCOM <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m64fp</em>.</td>, <td>D8 D0+i</td>, <td>FCOM ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i).</td>, <td>D8 D1</td>, <td>FCOM</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1).</td>, <td>D8 /3</td>, <td>FCOMP <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m32fp</em> and pop register stack.</td>, <td>DC /3</td>, <td>FCOMP <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with m64fp and pop register stack.</td>, <td>D8 D8+i</td>, <td>FCOMP ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i) and pop register stack.</td>, <td>D8 D9</td>, <td>FCOMP</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1) and pop register stack.</td>, <td>DE D9</td>, <td>FCOMPP</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1) and pop register stack twice.</td>, <td>ST(0) &gt; SRC</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>ST(0) &lt; SRC</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>ST(0) = SRC</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>Unordered*</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>C1</td>, <td>Set to 0.</td>, <td>C0, C2, C3</td>, <td>See table on previous page.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>One or both operands are NaN values or have unsupported formats.</td>, <td>Register is marked empty.</td>, <td>#D</td>, <td>One or both operands are denormal values.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /2</td>, <td>FCOM <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m32fp</em>.</td>, <td>DC /2</td>, <td>FCOM <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m64fp</em>.</td>, <td>D8 D0+i</td>, <td>FCOM ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i).</td>, <td>D8 D1</td>, <td>FCOM</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1).</td>, <td>D8 /3</td>, <td>FCOMP <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m32fp</em> and pop register stack.</td>, <td>DC /3</td>, <td>FCOMP <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with m64fp and pop register stack.</td>, <td>D8 D8+i</td>, <td>FCOMP ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i) and pop register stack.</td>, <td>D8 D9</td>, <td>FCOMP</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1) and pop register stack.</td>, <td>DE D9</td>, <td>FCOMPP</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1) and pop register stack twice.</td>, <td>ST(0) &gt; SRC</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>ST(0) &lt; SRC</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>ST(0) = SRC</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>Unordered*</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>C1</td>, <td>Set to 0.</td>, <td>C0, C2, C3</td>, <td>See table on previous page.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>One or both operands are NaN values or have unsupported formats.</td>, <td>Register is marked empty.</td>, <td>#D</td>, <td>One or both operands are denormal values.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 FF</td>, <td>FCOS</td>, <td>Valid</td>, <td>Valid</td>, <td>Replace ST(0) with its approximate cosine.</td>, <td>−∞</td>, <td>*</td>, <td>−F</td>, <td>−1 to +1</td>, <td>−0</td>, <td>+1</td>, <td>+0</td>, <td>+1</td>, <td>+F</td>, <td>− 1 to + 1</td>, <td>+∞</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="4">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>Undefined if C2 is 1.</td>, <td>Set to 1 if outside range (−263 &lt; source operand &lt; +263); otherwise, set to 0.</td>, <td>C2</td>, <td>C0, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>Source operand is an SNaN value, ∞, or unsupported format.</td>, <td>#D</td>, <td>Source is a denormal value.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 F6</td>, <td>FDECSTP</td>, <td>Valid</td>, <td>Valid</td>, <td>Decrement TOP field in FPU status word.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /6</td>, <td>FDIV <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by <em>m32fp</em> and store result in ST(0).</td>, <td>DC /6</td>, <td>FDIV <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by <em>m64fp</em> and store result in ST(0).</td>, <td>D8 F0+i</td>, <td>FDIV ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by ST(i) and store result in ST(0).</td>, <td>DC F8+i</td>, <td>FDIV ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(i) by ST(0) and store result in ST(i).</td>, <td>DE F8+i</td>, <td>FDIVP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(i) by ST(0), store result in ST(i), and pop the register stack.</td>, <td>DE F9</td>, <td>FDIVP</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(1) by ST(0), store result in ST(1), and pop the register stack.</td>, <td>DA /6</td>, <td>FIDIV <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by <em>m32int</em> and store result in ST(0).</td>, <td>DE /6</td>, <td>FIDIV <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by <em>m16int</em> and store result in ST(0).</td>, <td rowspan="10"><strong>SRC</strong></td>, <td></td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>*</td>, <td>+0</td>, <td>+0</td>, <td>−0</td>, <td>−0</td>, <td>*</td>, <td>NaN</td>, <td>−F</td>, <td>+∞</td>, <td>+F</td>, <td>+0</td>, <td>−0</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−I</td>, <td>+∞</td>, <td>+F</td>, <td>+0</td>, <td>−0</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−0</td>, <td>+∞</td>, <td>**</td>, <td>*</td>, <td>*</td>, <td>**</td>, <td>−∞</td>, <td>NaN</td>, <td>+0</td>, <td>−∞</td>, <td>**</td>, <td>*</td>, <td>*</td>, <td>**</td>, <td>+∞</td>, <td>NaN</td>, <td>+I</td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+F</td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+∞</td>, <td>*</td>, <td>−0</td>, <td>−0</td>, <td>+0</td>, <td>+0</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>±∞ / ±∞; ±0 / ±0</td>, <td>#D</td>, <td>Source is a denormal value.</td>, <td>#Z</td>, <td>DEST / ±0, where DEST is not equal to ±0.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /6</td>, <td>FDIV <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by <em>m32fp</em> and store result in ST(0).</td>, <td>DC /6</td>, <td>FDIV <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by <em>m64fp</em> and store result in ST(0).</td>, <td>D8 F0+i</td>, <td>FDIV ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by ST(i) and store result in ST(0).</td>, <td>DC F8+i</td>, <td>FDIV ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(i) by ST(0) and store result in ST(i).</td>, <td>DE F8+i</td>, <td>FDIVP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(i) by ST(0), store result in ST(i), and pop the register stack.</td>, <td>DE F9</td>, <td>FDIVP</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(1) by ST(0), store result in ST(1), and pop the register stack.</td>, <td>DA /6</td>, <td>FIDIV <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by <em>m32int</em> and store result in ST(0).</td>, <td>DE /6</td>, <td>FIDIV <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by <em>m16int</em> and store result in ST(0).</td>, <td rowspan="10"><strong>SRC</strong></td>, <td></td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>*</td>, <td>+0</td>, <td>+0</td>, <td>−0</td>, <td>−0</td>, <td>*</td>, <td>NaN</td>, <td>−F</td>, <td>+∞</td>, <td>+F</td>, <td>+0</td>, <td>−0</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−I</td>, <td>+∞</td>, <td>+F</td>, <td>+0</td>, <td>−0</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−0</td>, <td>+∞</td>, <td>**</td>, <td>*</td>, <td>*</td>, <td>**</td>, <td>−∞</td>, <td>NaN</td>, <td>+0</td>, <td>−∞</td>, <td>**</td>, <td>*</td>, <td>*</td>, <td>**</td>, <td>+∞</td>, <td>NaN</td>, <td>+I</td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+F</td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+∞</td>, <td>*</td>, <td>−0</td>, <td>−0</td>, <td>+0</td>, <td>+0</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>±∞ / ±∞; ±0 / ±0</td>, <td>#D</td>, <td>Source is a denormal value.</td>, <td>#Z</td>, <td>DEST / ±0, where DEST is not equal to ±0.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /7</td>, <td>FDIVR <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide <em>m32fp</em> by ST(0) and store result in ST(0).</td>, <td>DC /7</td>, <td>FDIVR <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide <em>m64fp</em> by ST(0) and store result in ST(0).</td>, <td>D8 F8+i</td>, <td>FDIVR ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(i) by ST(0) and store result in ST(0).</td>, <td>DC F0+i</td>, <td>FDIVR ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by ST(i) and store result in ST(i).</td>, <td>DE F0+i</td>, <td>FDIVRP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by ST(i), store result in ST(i), and pop the register stack.</td>, <td>DE F1</td>, <td>FDIVRP</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by ST(1), store result in ST(1), and pop the register stack.</td>, <td>DA /7</td>, <td>FIDIVR <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide <em>m32int</em> by ST(0) and store result in ST(0).</td>, <td>DE /7</td>, <td>FIDIVR <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide <em>m16int</em> by ST(0) and store result in ST(0).</td>, <td rowspan="10"><strong>SRC</strong></td>, <td></td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>*</td>, <td>+∞</td>, <td>+∞</td>, <td>−∞</td>, <td>−∞</td>, <td>*</td>, <td>NaN</td>, <td>−F</td>, <td>+0</td>, <td>+F</td>, <td>**</td>, <td>**</td>, <td>−F</td>, <td>−0</td>, <td>NaN</td>, <td>−I</td>, <td>+0</td>, <td>+F</td>, <td>**</td>, <td>**</td>, <td>−F</td>, <td>−0</td>, <td>NaN</td>, <td>−0</td>, <td>+0</td>, <td>+0</td>, <td>*</td>, <td>*</td>, <td>−0</td>, <td>−0</td>, <td>NaN</td>, <td>+0</td>, <td>−0</td>, <td>−0</td>, <td>*</td>, <td>*</td>, <td>+0</td>, <td>+0</td>, <td>NaN</td>, <td>+I</td>, <td>−0</td>, <td>−F</td>, <td>**</td>, <td>**</td>, <td>+F</td>, <td>+0</td>, <td>NaN</td>, <td>+F</td>, <td>−0</td>, <td>−F</td>, <td>**</td>, <td>**</td>, <td>+F</td>, <td>+0</td>, <td>NaN</td>, <td>+∞</td>, <td>*</td>, <td>−∞</td>, <td>−∞</td>, <td>+∞</td>, <td>+∞</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>±∞ / ±∞; ±0 / ±0</td>, <td>#D</td>, <td>Source is a denormal value.</td>, <td>#Z</td>, <td>SRC / ±0, where SRC is not equal to ±0.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /7</td>, <td>FDIVR <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide <em>m32fp</em> by ST(0) and store result in ST(0).</td>, <td>DC /7</td>, <td>FDIVR <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide <em>m64fp</em> by ST(0) and store result in ST(0).</td>, <td>D8 F8+i</td>, <td>FDIVR ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(i) by ST(0) and store result in ST(0).</td>, <td>DC F0+i</td>, <td>FDIVR ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by ST(i) and store result in ST(i).</td>, <td>DE F0+i</td>, <td>FDIVRP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by ST(i), store result in ST(i), and pop the register stack.</td>, <td>DE F1</td>, <td>FDIVRP</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by ST(1), store result in ST(1), and pop the register stack.</td>, <td>DA /7</td>, <td>FIDIVR <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide <em>m32int</em> by ST(0) and store result in ST(0).</td>, <td>DE /7</td>, <td>FIDIVR <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide <em>m16int</em> by ST(0) and store result in ST(0).</td>, <td rowspan="10"><strong>SRC</strong></td>, <td></td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>*</td>, <td>+∞</td>, <td>+∞</td>, <td>−∞</td>, <td>−∞</td>, <td>*</td>, <td>NaN</td>, <td>−F</td>, <td>+0</td>, <td>+F</td>, <td>**</td>, <td>**</td>, <td>−F</td>, <td>−0</td>, <td>NaN</td>, <td>−I</td>, <td>+0</td>, <td>+F</td>, <td>**</td>, <td>**</td>, <td>−F</td>, <td>−0</td>, <td>NaN</td>, <td>−0</td>, <td>+0</td>, <td>+0</td>, <td>*</td>, <td>*</td>, <td>−0</td>, <td>−0</td>, <td>NaN</td>, <td>+0</td>, <td>−0</td>, <td>−0</td>, <td>*</td>, <td>*</td>, <td>+0</td>, <td>+0</td>, <td>NaN</td>, <td>+I</td>, <td>−0</td>, <td>−F</td>, <td>**</td>, <td>**</td>, <td>+F</td>, <td>+0</td>, <td>NaN</td>, <td>+F</td>, <td>−0</td>, <td>−F</td>, <td>**</td>, <td>**</td>, <td>+F</td>, <td>+0</td>, <td>NaN</td>, <td>+∞</td>, <td>*</td>, <td>−∞</td>, <td>−∞</td>, <td>+∞</td>, <td>+∞</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>±∞ / ±∞; ±0 / ±0</td>, <td>#D</td>, <td>Source is a denormal value.</td>, <td>#Z</td>, <td>SRC / ±0, where SRC is not equal to ±0.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DD C0+i</td>, <td>FFREE ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Sets tag for ST(i) to empty.</td>, <td>C0, C1, C2, C3</td>, <td>undefined.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /0</td>, <td>FADD <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>m32fp</em> to ST(0) and store result in ST(0).</td>, <td>DC /0</td>, <td>FADD <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>m64fp</em> to ST(0) and store result in ST(0).</td>, <td>D8 C0+i</td>, <td>FADD ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Add ST(0) to ST(i) and store result in ST(0).</td>, <td>DC C0+i</td>, <td>FADD ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Add ST(i) to ST(0) and store result in ST(i).</td>, <td>DE C0+i</td>, <td>FADDP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Add ST(0) to ST(i), store result in ST(i), and pop the register stack.</td>, <td>DE C1</td>, <td>FADDP</td>, <td>Valid</td>, <td>Valid</td>, <td>Add ST(0) to ST(1), store result in ST(1), and pop the register stack.</td>, <td>DA /0</td>, <td>FIADD <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>m32int</em> to ST(0) and store result in ST(0).</td>, <td>DE /0</td>, <td>FIADD <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Add <em>m16int</em> to ST(0) and store result in ST(0).</td>, <td rowspan="8"><strong>SRC</strong></td>, <td></td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>*</td>, <td>NaN</td>, <td>− F or − I</td>, <td>−∞</td>, <td>−F</td>, <td>SRC</td>, <td>SRC</td>, <td>± F or ± 0</td>, <td>+∞</td>, <td>NaN</td>, <td>−0</td>, <td>−∞</td>, <td>DEST</td>, <td>−0</td>, <td>±0</td>, <td>DEST</td>, <td>+∞</td>, <td>NaN</td>, <td>+0</td>, <td>−∞</td>, <td>DEST</td>, <td>±0</td>, <td>+0</td>, <td>DEST</td>, <td>+∞</td>, <td>NaN</td>, <td>+ F or + I</td>, <td>−∞</td>, <td>± F or ± 0</td>, <td>SRC</td>, <td>SRC</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+∞</td>, <td>*</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>Operands are infinities of unlike sign.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DE /2</td>, <td>FICOM <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m16int.</em></td>, <td>DA /2</td>, <td>FICOM <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m32int.</em></td>, <td>DE /3</td>, <td>FICOMP <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m16int</em> and pop stack register.</td>, <td>DA /3</td>, <td>FICOMP <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m32int</em> and pop stack register.</td>, <td>ST(0) &gt; SRC</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>ST(0) &lt; SRC</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>ST(0) = SRC</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>Unordered</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>C1</td>, <td>Set to 0.</td>, <td>C0, C2, C3</td>, <td>See table on previous page.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>One or both operands are NaN values or have unsupported formats.</td>, <td>#D</td>, <td>One or both operands are denormal values.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DE /2</td>, <td>FICOM <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m16int.</em></td>, <td>DA /2</td>, <td>FICOM <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m32int.</em></td>, <td>DE /3</td>, <td>FICOMP <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m16int</em> and pop stack register.</td>, <td>DA /3</td>, <td>FICOMP <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with <em>m32int</em> and pop stack register.</td>, <td>ST(0) &gt; SRC</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>ST(0) &lt; SRC</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>ST(0) = SRC</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>Unordered</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>C1</td>, <td>Set to 0.</td>, <td>C0, C2, C3</td>, <td>See table on previous page.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>One or both operands are NaN values or have unsupported formats.</td>, <td>#D</td>, <td>One or both operands are denormal values.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /6</td>, <td>FDIV <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by <em>m32fp</em> and store result in ST(0).</td>, <td>DC /6</td>, <td>FDIV <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by <em>m64fp</em> and store result in ST(0).</td>, <td>D8 F0+i</td>, <td>FDIV ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by ST(i) and store result in ST(0).</td>, <td>DC F8+i</td>, <td>FDIV ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(i) by ST(0) and store result in ST(i).</td>, <td>DE F8+i</td>, <td>FDIVP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(i) by ST(0), store result in ST(i), and pop the register stack.</td>, <td>DE F9</td>, <td>FDIVP</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(1) by ST(0), store result in ST(1), and pop the register stack.</td>, <td>DA /6</td>, <td>FIDIV <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by <em>m32int</em> and store result in ST(0).</td>, <td>DE /6</td>, <td>FIDIV <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by <em>m16int</em> and store result in ST(0).</td>, <td rowspan="10"><strong>SRC</strong></td>, <td></td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>*</td>, <td>+0</td>, <td>+0</td>, <td>−0</td>, <td>−0</td>, <td>*</td>, <td>NaN</td>, <td>−F</td>, <td>+∞</td>, <td>+F</td>, <td>+0</td>, <td>−0</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−I</td>, <td>+∞</td>, <td>+F</td>, <td>+0</td>, <td>−0</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−0</td>, <td>+∞</td>, <td>**</td>, <td>*</td>, <td>*</td>, <td>**</td>, <td>−∞</td>, <td>NaN</td>, <td>+0</td>, <td>−∞</td>, <td>**</td>, <td>*</td>, <td>*</td>, <td>**</td>, <td>+∞</td>, <td>NaN</td>, <td>+I</td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+F</td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+∞</td>, <td>*</td>, <td>−0</td>, <td>−0</td>, <td>+0</td>, <td>+0</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>±∞ / ±∞; ±0 / ±0</td>, <td>#D</td>, <td>Source is a denormal value.</td>, <td>#Z</td>, <td>DEST / ±0, where DEST is not equal to ±0.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /7</td>, <td>FDIVR <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide <em>m32fp</em> by ST(0) and store result in ST(0).</td>, <td>DC /7</td>, <td>FDIVR <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide <em>m64fp</em> by ST(0) and store result in ST(0).</td>, <td>D8 F8+i</td>, <td>FDIVR ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(i) by ST(0) and store result in ST(0).</td>, <td>DC F0+i</td>, <td>FDIVR ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by ST(i) and store result in ST(i).</td>, <td>DE F0+i</td>, <td>FDIVRP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by ST(i), store result in ST(i), and pop the register stack.</td>, <td>DE F1</td>, <td>FDIVRP</td>, <td>Valid</td>, <td>Valid</td>, <td>Divide ST(0) by ST(1), store result in ST(1), and pop the register stack.</td>, <td>DA /7</td>, <td>FIDIVR <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide <em>m32int</em> by ST(0) and store result in ST(0).</td>, <td>DE /7</td>, <td>FIDIVR <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Divide <em>m16int</em> by ST(0) and store result in ST(0).</td>, <td rowspan="10"><strong>SRC</strong></td>, <td></td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>*</td>, <td>+∞</td>, <td>+∞</td>, <td>−∞</td>, <td>−∞</td>, <td>*</td>, <td>NaN</td>, <td>−F</td>, <td>+0</td>, <td>+F</td>, <td>**</td>, <td>**</td>, <td>−F</td>, <td>−0</td>, <td>NaN</td>, <td>−I</td>, <td>+0</td>, <td>+F</td>, <td>**</td>, <td>**</td>, <td>−F</td>, <td>−0</td>, <td>NaN</td>, <td>−0</td>, <td>+0</td>, <td>+0</td>, <td>*</td>, <td>*</td>, <td>−0</td>, <td>−0</td>, <td>NaN</td>, <td>+0</td>, <td>−0</td>, <td>−0</td>, <td>*</td>, <td>*</td>, <td>+0</td>, <td>+0</td>, <td>NaN</td>, <td>+I</td>, <td>−0</td>, <td>−F</td>, <td>**</td>, <td>**</td>, <td>+F</td>, <td>+0</td>, <td>NaN</td>, <td>+F</td>, <td>−0</td>, <td>−F</td>, <td>**</td>, <td>**</td>, <td>+F</td>, <td>+0</td>, <td>NaN</td>, <td>+∞</td>, <td>*</td>, <td>−∞</td>, <td>−∞</td>, <td>+∞</td>, <td>+∞</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>±∞ / ±∞; ±0 / ±0</td>, <td>#D</td>, <td>Source is a denormal value.</td>, <td>#Z</td>, <td>SRC / ±0, where SRC is not equal to ±0.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DF /0</td>, <td>FILD <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Push <em>m16int</em> onto the FPU register stack.</td>, <td>DB /0</td>, <td>FILD <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Push <em>m32int</em> onto the FPU register stack.</td>, <td>DF /5</td>, <td>FILD <em>m64int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Push <em>m64int</em> onto the FPU register stack.</td>, <td>C1</td>, <td>Set to 1 if stack overflow occurred; set to 0 otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack overflow occurred.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /1</td>, <td>FMUL <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(0) by <em>m32fp</em> and store result in ST(0).</td>, <td>DC /1</td>, <td>FMUL <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(0) by <em>m64fp</em> and store result in ST(0).</td>, <td>D8 C8+i</td>, <td>FMUL ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(0) by ST(i) and store result in ST(0).</td>, <td>DC C8+i</td>, <td>FMUL ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(i) by ST(0) and store result in ST(i).</td>, <td>DE C8+i</td>, <td>FMULP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(i) by ST(0), store result in ST(i), and pop the register stack.</td>, <td>DE C9</td>, <td>FMULP</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(1) by ST(0), store result in ST(1), and pop the register stack.</td>, <td>DA /1</td>, <td>FIMUL <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(0) by <em>m32int</em> and store result in ST(0).</td>, <td>DE /1</td>, <td>FIMUL <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(0) by <em>m16int</em> and store result in ST(0).</td>, <td rowspan="10"><strong>SRC</strong></td>, <td></td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>+∞</td>, <td>+∞</td>, <td>*</td>, <td>*</td>, <td>−∞</td>, <td>−∞</td>, <td>NaN</td>, <td>−F</td>, <td>+∞</td>, <td>+F</td>, <td>+0</td>, <td>−0</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−I</td>, <td>+∞</td>, <td>+F</td>, <td>+0</td>, <td>−0</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−0</td>, <td>*</td>, <td>+0</td>, <td>+0</td>, <td>−0</td>, <td>−0</td>, <td>*</td>, <td>NaN</td>, <td>+0</td>, <td>*</td>, <td>−0</td>, <td>−0</td>, <td>+0</td>, <td>+0</td>, <td>*</td>, <td>NaN</td>, <td>+I</td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+F</td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+∞</td>, <td>−∞</td>, <td>−∞</td>, <td>*</td>, <td>*</td>, <td>+∞</td>, <td>+∞</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>One operand is ±0 and the other is ±∞.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 F7</td>, <td>FINCSTP</td>, <td>Valid</td>, <td>Valid</td>, <td>Increment the TOP field in the FPU status register.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>9B DB E3</td>, <td>FINIT</td>, <td>Valid</td>, <td>Valid</td>, <td>Initialize FPU after checking for pending unmasked floating-point exceptions.</td>, <td>DB E3</td>, <td>FNINIT<sup>*</sup></td>, <td>Valid</td>, <td>Valid</td>, <td>Initialize FPU without checking for pending unmasked floating-point exceptions.</td>, <td>C0, C1, C2, C3</td>, <td>set to 0.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DF /2</td>, <td>FIST <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store ST(0) in <em>m16int.</em></td>, <td>DB /2</td>, <td>FIST <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store ST(0) in <em>m32int.</em></td>, <td>DF /3</td>, <td>FISTP <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store ST(0) in <em>m16int</em> and pop register stack.</td>, <td>DB /3</td>, <td>FISTP <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store ST(0) in <em>m32int</em> and pop register stack.</td>, <td>DF /7</td>, <td>FISTP <em>m64int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store ST(0) in <em>m64int</em> and pop register stack.</td>, <td>− ∞ or Value Too Large for DEST Format</td>, <td>*</td>, <td>F ≤ −1</td>, <td>−I</td>, <td>−1 &lt; F &lt; −0</td>, <td>**</td>, <td>−0</td>, <td>0</td>, <td>+0</td>, <td>0</td>, <td>+0&lt;F&lt;+1</td>, <td>**</td>, <td>F≥+1</td>, <td>+I</td>, <td>+ ∞ or Value Too Large for DEST Format</td>, <td>*</td>, <td>NaN</td>, <td>*</td>, <td colspan="2"><strong>NOTES:</strong> F Meansfinitefloating-pointvalue. I Means integer. * Indicatesfloating-pointinvalid-operation(#IA)exception. ** 0 or ±1, depending on the rounding mode.</td>, <td rowspan="3">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Indicates rounding direction of if the inexact exception (#P) is generated: 0 ← not roundup; 1 ← roundup.</td>, <td>Set to 0 otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Converted value is too large for the destination format.</td>, <td>Source operand is an SNaN, QNaN, ±∞, or unsupported format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DF /2</td>, <td>FIST <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store ST(0) in <em>m16int.</em></td>, <td>DB /2</td>, <td>FIST <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store ST(0) in <em>m32int.</em></td>, <td>DF /3</td>, <td>FISTP <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store ST(0) in <em>m16int</em> and pop register stack.</td>, <td>DB /3</td>, <td>FISTP <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store ST(0) in <em>m32int</em> and pop register stack.</td>, <td>DF /7</td>, <td>FISTP <em>m64int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store ST(0) in <em>m64int</em> and pop register stack.</td>, <td>− ∞ or Value Too Large for DEST Format</td>, <td>*</td>, <td>F ≤ −1</td>, <td>−I</td>, <td>−1 &lt; F &lt; −0</td>, <td>**</td>, <td>−0</td>, <td>0</td>, <td>+0</td>, <td>0</td>, <td>+0&lt;F&lt;+1</td>, <td>**</td>, <td>F≥+1</td>, <td>+I</td>, <td>+ ∞ or Value Too Large for DEST Format</td>, <td>*</td>, <td>NaN</td>, <td>*</td>, <td colspan="2"><strong>NOTES:</strong> F Meansfinitefloating-pointvalue. I Means integer. * Indicatesfloating-pointinvalid-operation(#IA)exception. ** 0 or ±1, depending on the rounding mode.</td>, <td rowspan="3">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Indicates rounding direction of if the inexact exception (#P) is generated: 0 ← not roundup; 1 ← roundup.</td>, <td>Set to 0 otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Converted value is too large for the destination format.</td>, <td>Source operand is an SNaN, QNaN, ±∞, or unsupported format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DF /1</td>, <td>FISTTP <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store ST(0) in <em>m16int with truncation.</em></td>, <td>DB /1</td>, <td>FISTTP <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store ST(0) in <em>m32int with truncation.</em></td>, <td>DD /1</td>, <td>FISTTP <em>m64int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store ST(0) in <em>m64int</em> with truncation.</td>, <td>− ∞ or Value Too Large for DEST Format</td>, <td>*</td>, <td>F≤ −1</td>, <td>−I</td>, <td>−1&lt;F&lt;+1</td>, <td>0</td>, <td>FŠ+1</td>, <td>+I</td>, <td>+ ∞ or Value Too Large for DEST Format</td>, <td>*</td>, <td>NaN</td>, <td>*</td>, <td rowspan="2">#GP(0)</td>, <td>If the destination is in a nonwritable segment.</td>, <td>For an illegal memory operand effective address in the CS, DS, ES, FS or GS segments.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="2">#NM</td>, <td>If CR0.EM[bit 2] = 1.</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:ECX.SSE3[bit 0] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#NM</td>, <td>If CR0.EM[bit 2] = 1.</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:ECX.SSE3[bit 0] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#NM</td>, <td>If CR0.EM[bit 2] = 1.</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:ECX.SSE3[bit 0] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#AC(0)</td>, <td>For unaligned memory reference if the current privilege is 3.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td rowspan="2">#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /4</td>, <td>FSUB <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>m32fp</em> from ST(0) and store result in ST(0).</td>, <td>DC /4</td>, <td>FSUB <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>m64fp</em> from ST(0) and store result in ST(0).</td>, <td>D8 E0+i</td>, <td>FSUB ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(i) from ST(0) and store result in ST(0).</td>, <td>DC E8+i</td>, <td>FSUB ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from ST(i) and store result in ST(i).</td>, <td>DE E8+i</td>, <td>FSUBP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from ST(i), store result in ST(i), and pop register stack.</td>, <td>DE E9</td>, <td>FSUBP</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from ST(1), store result in ST(1), and pop register stack.</td>, <td>DA /4</td>, <td>FISUB <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>m32int</em> from ST(0) and store result in ST(0).</td>, <td>DE /4</td>, <td>FISUB <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>m16int</em> from ST(0) and store result in ST(0).</td>, <td rowspan="8"><strong>DEST</strong></td>, <td></td>, <td>−∞</td>, <td>− F or − I</td>, <td>−0</td>, <td>+0</td>, <td>+ F or + I</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>*</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>NaN</td>, <td>−F</td>, <td>+∞</td>, <td>±F or ±0</td>, <td>DEST</td>, <td>DEST</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−0</td>, <td>+∞</td>, <td>−SRC</td>, <td>±0</td>, <td>−0</td>, <td>− SRC</td>, <td>−∞</td>, <td>NaN</td>, <td>+0</td>, <td>+∞</td>, <td>−SRC</td>, <td>+0</td>, <td>±0</td>, <td>− SRC</td>, <td>−∞</td>, <td>NaN</td>, <td>+F</td>, <td>+∞</td>, <td>+F</td>, <td>DEST</td>, <td>DEST</td>, <td>±F or ±0</td>, <td>−∞</td>, <td>NaN</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>Operands are infinities of like sign.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /5</td>, <td>FSUBR <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from <em>m32fp</em> and store result in ST(0).</td>, <td>DC /5</td>, <td>FSUBR <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from <em>m64fp</em> and store result in ST(0).</td>, <td>D8 E8+i</td>, <td>FSUBR ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from ST(i) and store result in ST(0).</td>, <td>DC E0+i</td>, <td>FSUBR ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(i) from ST(0) and store result in ST(i).</td>, <td>DE E0+i</td>, <td>FSUBRP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(i) from ST(0), store result in ST(i), and pop register stack.</td>, <td>DE E1</td>, <td>FSUBRP</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(1) from ST(0), store result in ST(1), and pop register stack.</td>, <td>DA /5</td>, <td>FISUBR <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from <em>m32int</em> and store result in ST(0).</td>, <td>DE /5</td>, <td>FISUBR <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from <em>m16int</em> and store result in ST(0).</td>, <td rowspan="8"><strong>DEST</strong></td>, <td></td>, <td>−∞</td>, <td>−F or −I</td>, <td>−0</td>, <td>+0</td>, <td>+F or +I</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>*</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>NaN</td>, <td>−F</td>, <td>−∞</td>, <td>±F or ±0</td>, <td>−DEST</td>, <td>−DEST</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−0</td>, <td>−∞</td>, <td>SRC</td>, <td>±0</td>, <td>+0</td>, <td>SRC</td>, <td>+∞</td>, <td>NaN</td>, <td>+0</td>, <td>−∞</td>, <td>SRC</td>, <td>−0</td>, <td>±0</td>, <td>SRC</td>, <td>+∞</td>, <td>NaN</td>, <td>+F</td>, <td>−∞</td>, <td>−F</td>, <td>−DEST</td>, <td>−DEST</td>, <td>±F or ±0</td>, <td>+∞</td>, <td>NaN</td>, <td>+∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>Operands are infinities of like sign.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 /0</td>, <td>FLD <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Push <em>m32fp</em> onto the FPU register stack.</td>, <td>DD /0</td>, <td>FLD <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Push <em>m64fp</em> onto the FPU register stack.</td>, <td>DB /5</td>, <td>FLD <em>m80fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Push <em>m80fp</em> onto the FPU register stack.</td>, <td>D9 C0+i</td>, <td>FLD ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Push ST(i) onto the FPU register stack.</td>, <td>C1</td>, <td>Set to 1 if stack overflow occurred; otherwise, set to 0.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow or overflow occurred.</td>, <td>#IA</td>, <td>Source operand is an SNaN. Does not occur if the source operand is in double extended-precision floating-point format (FLD m80fp or FLD ST(i)).</td>, <td>#D</td>, <td>Source operand is a denormal value. Does not occur if the source operand is in double extended-precision floating-point format.</td>, <td rowspan="3">#GP(0)</td>, <td>If destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 E8</td>, <td>FLD1</td>, <td>Valid</td>, <td>Valid</td>, <td>Push +1.0 onto the FPU register stack.</td>, <td>D9 E9</td>, <td>FLDL2T</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>2</sub>10 onto the FPU register stack.</td>, <td>D9 EA</td>, <td>FLDL2E</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>2</sub>e onto the FPU register stack.</td>, <td>D9 EB</td>, <td>FLDPI</td>, <td>Valid</td>, <td>Valid</td>, <td>Push π onto the FPU register stack.</td>, <td>D9 EC</td>, <td>FLDLG2</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>10</sub>2 onto the FPU register stack.</td>, <td>D9 ED</td>, <td>FLDLN2</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>e</sub>2 onto the FPU register stack.</td>, <td>D9 EE</td>, <td>FLDZ</td>, <td>Valid</td>, <td>Valid</td>, <td>Push +0.0 onto the FPU register stack.</td>, <td>C1</td>, <td>Set to 1 if stack overflow occurred; otherwise, set to 0.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack overflow occurred.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 /5</td>, <td>FLDCW m2byte</td>, <td>Valid</td>, <td>Valid</td>, <td>Load FPU control word from <em>m2byte.</em></td>, <td>C0, C1, C2, C3</td>, <td>undefined.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 /4</td>, <td>FLDENV <em>m14/28byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Load FPU environment from <em>m14byte</em> or <em>m28byte.</em></td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 E8</td>, <td>FLD1</td>, <td>Valid</td>, <td>Valid</td>, <td>Push +1.0 onto the FPU register stack.</td>, <td>D9 E9</td>, <td>FLDL2T</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>2</sub>10 onto the FPU register stack.</td>, <td>D9 EA</td>, <td>FLDL2E</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>2</sub>e onto the FPU register stack.</td>, <td>D9 EB</td>, <td>FLDPI</td>, <td>Valid</td>, <td>Valid</td>, <td>Push π onto the FPU register stack.</td>, <td>D9 EC</td>, <td>FLDLG2</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>10</sub>2 onto the FPU register stack.</td>, <td>D9 ED</td>, <td>FLDLN2</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>e</sub>2 onto the FPU register stack.</td>, <td>D9 EE</td>, <td>FLDZ</td>, <td>Valid</td>, <td>Valid</td>, <td>Push +0.0 onto the FPU register stack.</td>, <td>C1</td>, <td>Set to 1 if stack overflow occurred; otherwise, set to 0.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack overflow occurred.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 E8</td>, <td>FLD1</td>, <td>Valid</td>, <td>Valid</td>, <td>Push +1.0 onto the FPU register stack.</td>, <td>D9 E9</td>, <td>FLDL2T</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>2</sub>10 onto the FPU register stack.</td>, <td>D9 EA</td>, <td>FLDL2E</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>2</sub>e onto the FPU register stack.</td>, <td>D9 EB</td>, <td>FLDPI</td>, <td>Valid</td>, <td>Valid</td>, <td>Push π onto the FPU register stack.</td>, <td>D9 EC</td>, <td>FLDLG2</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>10</sub>2 onto the FPU register stack.</td>, <td>D9 ED</td>, <td>FLDLN2</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>e</sub>2 onto the FPU register stack.</td>, <td>D9 EE</td>, <td>FLDZ</td>, <td>Valid</td>, <td>Valid</td>, <td>Push +0.0 onto the FPU register stack.</td>, <td>C1</td>, <td>Set to 1 if stack overflow occurred; otherwise, set to 0.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack overflow occurred.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 E8</td>, <td>FLD1</td>, <td>Valid</td>, <td>Valid</td>, <td>Push +1.0 onto the FPU register stack.</td>, <td>D9 E9</td>, <td>FLDL2T</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>2</sub>10 onto the FPU register stack.</td>, <td>D9 EA</td>, <td>FLDL2E</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>2</sub>e onto the FPU register stack.</td>, <td>D9 EB</td>, <td>FLDPI</td>, <td>Valid</td>, <td>Valid</td>, <td>Push π onto the FPU register stack.</td>, <td>D9 EC</td>, <td>FLDLG2</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>10</sub>2 onto the FPU register stack.</td>, <td>D9 ED</td>, <td>FLDLN2</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>e</sub>2 onto the FPU register stack.</td>, <td>D9 EE</td>, <td>FLDZ</td>, <td>Valid</td>, <td>Valid</td>, <td>Push +0.0 onto the FPU register stack.</td>, <td>C1</td>, <td>Set to 1 if stack overflow occurred; otherwise, set to 0.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack overflow occurred.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 E8</td>, <td>FLD1</td>, <td>Valid</td>, <td>Valid</td>, <td>Push +1.0 onto the FPU register stack.</td>, <td>D9 E9</td>, <td>FLDL2T</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>2</sub>10 onto the FPU register stack.</td>, <td>D9 EA</td>, <td>FLDL2E</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>2</sub>e onto the FPU register stack.</td>, <td>D9 EB</td>, <td>FLDPI</td>, <td>Valid</td>, <td>Valid</td>, <td>Push π onto the FPU register stack.</td>, <td>D9 EC</td>, <td>FLDLG2</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>10</sub>2 onto the FPU register stack.</td>, <td>D9 ED</td>, <td>FLDLN2</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>e</sub>2 onto the FPU register stack.</td>, <td>D9 EE</td>, <td>FLDZ</td>, <td>Valid</td>, <td>Valid</td>, <td>Push +0.0 onto the FPU register stack.</td>, <td>C1</td>, <td>Set to 1 if stack overflow occurred; otherwise, set to 0.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack overflow occurred.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 E8</td>, <td>FLD1</td>, <td>Valid</td>, <td>Valid</td>, <td>Push +1.0 onto the FPU register stack.</td>, <td>D9 E9</td>, <td>FLDL2T</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>2</sub>10 onto the FPU register stack.</td>, <td>D9 EA</td>, <td>FLDL2E</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>2</sub>e onto the FPU register stack.</td>, <td>D9 EB</td>, <td>FLDPI</td>, <td>Valid</td>, <td>Valid</td>, <td>Push π onto the FPU register stack.</td>, <td>D9 EC</td>, <td>FLDLG2</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>10</sub>2 onto the FPU register stack.</td>, <td>D9 ED</td>, <td>FLDLN2</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>e</sub>2 onto the FPU register stack.</td>, <td>D9 EE</td>, <td>FLDZ</td>, <td>Valid</td>, <td>Valid</td>, <td>Push +0.0 onto the FPU register stack.</td>, <td>C1</td>, <td>Set to 1 if stack overflow occurred; otherwise, set to 0.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack overflow occurred.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 E8</td>, <td>FLD1</td>, <td>Valid</td>, <td>Valid</td>, <td>Push +1.0 onto the FPU register stack.</td>, <td>D9 E9</td>, <td>FLDL2T</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>2</sub>10 onto the FPU register stack.</td>, <td>D9 EA</td>, <td>FLDL2E</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>2</sub>e onto the FPU register stack.</td>, <td>D9 EB</td>, <td>FLDPI</td>, <td>Valid</td>, <td>Valid</td>, <td>Push π onto the FPU register stack.</td>, <td>D9 EC</td>, <td>FLDLG2</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>10</sub>2 onto the FPU register stack.</td>, <td>D9 ED</td>, <td>FLDLN2</td>, <td>Valid</td>, <td>Valid</td>, <td>Push log<sub>e</sub>2 onto the FPU register stack.</td>, <td>D9 EE</td>, <td>FLDZ</td>, <td>Valid</td>, <td>Valid</td>, <td>Push +0.0 onto the FPU register stack.</td>, <td>C1</td>, <td>Set to 1 if stack overflow occurred; otherwise, set to 0.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack overflow occurred.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /1</td>, <td>FMUL <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(0) by <em>m32fp</em> and store result in ST(0).</td>, <td>DC /1</td>, <td>FMUL <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(0) by <em>m64fp</em> and store result in ST(0).</td>, <td>D8 C8+i</td>, <td>FMUL ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(0) by ST(i) and store result in ST(0).</td>, <td>DC C8+i</td>, <td>FMUL ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(i) by ST(0) and store result in ST(i).</td>, <td>DE C8+i</td>, <td>FMULP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(i) by ST(0), store result in ST(i), and pop the register stack.</td>, <td>DE C9</td>, <td>FMULP</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(1) by ST(0), store result in ST(1), and pop the register stack.</td>, <td>DA /1</td>, <td>FIMUL <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(0) by <em>m32int</em> and store result in ST(0).</td>, <td>DE /1</td>, <td>FIMUL <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(0) by <em>m16int</em> and store result in ST(0).</td>, <td rowspan="10"><strong>SRC</strong></td>, <td></td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>+∞</td>, <td>+∞</td>, <td>*</td>, <td>*</td>, <td>−∞</td>, <td>−∞</td>, <td>NaN</td>, <td>−F</td>, <td>+∞</td>, <td>+F</td>, <td>+0</td>, <td>−0</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−I</td>, <td>+∞</td>, <td>+F</td>, <td>+0</td>, <td>−0</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−0</td>, <td>*</td>, <td>+0</td>, <td>+0</td>, <td>−0</td>, <td>−0</td>, <td>*</td>, <td>NaN</td>, <td>+0</td>, <td>*</td>, <td>−0</td>, <td>−0</td>, <td>+0</td>, <td>+0</td>, <td>*</td>, <td>NaN</td>, <td>+I</td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+F</td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+∞</td>, <td>−∞</td>, <td>−∞</td>, <td>*</td>, <td>*</td>, <td>+∞</td>, <td>+∞</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>One operand is ±0 and the other is ±∞.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /1</td>, <td>FMUL <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(0) by <em>m32fp</em> and store result in ST(0).</td>, <td>DC /1</td>, <td>FMUL <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(0) by <em>m64fp</em> and store result in ST(0).</td>, <td>D8 C8+i</td>, <td>FMUL ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(0) by ST(i) and store result in ST(0).</td>, <td>DC C8+i</td>, <td>FMUL ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(i) by ST(0) and store result in ST(i).</td>, <td>DE C8+i</td>, <td>FMULP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(i) by ST(0), store result in ST(i), and pop the register stack.</td>, <td>DE C9</td>, <td>FMULP</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(1) by ST(0), store result in ST(1), and pop the register stack.</td>, <td>DA /1</td>, <td>FIMUL <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(0) by <em>m32int</em> and store result in ST(0).</td>, <td>DE /1</td>, <td>FIMUL <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply ST(0) by <em>m16int</em> and store result in ST(0).</td>, <td rowspan="10"><strong>SRC</strong></td>, <td></td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>+∞</td>, <td>+∞</td>, <td>*</td>, <td>*</td>, <td>−∞</td>, <td>−∞</td>, <td>NaN</td>, <td>−F</td>, <td>+∞</td>, <td>+F</td>, <td>+0</td>, <td>−0</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−I</td>, <td>+∞</td>, <td>+F</td>, <td>+0</td>, <td>−0</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−0</td>, <td>*</td>, <td>+0</td>, <td>+0</td>, <td>−0</td>, <td>−0</td>, <td>*</td>, <td>NaN</td>, <td>+0</td>, <td>*</td>, <td>−0</td>, <td>−0</td>, <td>+0</td>, <td>+0</td>, <td>*</td>, <td>NaN</td>, <td>+I</td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+F</td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+∞</td>, <td>−∞</td>, <td>−∞</td>, <td>*</td>, <td>*</td>, <td>+∞</td>, <td>+∞</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>One operand is ±0 and the other is ±∞.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>9B DB E2</td>, <td>FCLEX</td>, <td>Valid</td>, <td>Valid</td>, <td>Clear floating-point exception flags after checking for pending unmasked floating-point exceptions.</td>, <td>DB E2</td>, <td>FNCLEX<sup>*</sup></td>, <td>Valid</td>, <td>Valid</td>, <td>Clear floating-point exception flags without checking for pending unmasked floating-point exceptions.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>9B DB E3</td>, <td>FINIT</td>, <td>Valid</td>, <td>Valid</td>, <td>Initialize FPU after checking for pending unmasked floating-point exceptions.</td>, <td>DB E3</td>, <td>FNINIT<sup>*</sup></td>, <td>Valid</td>, <td>Valid</td>, <td>Initialize FPU without checking for pending unmasked floating-point exceptions.</td>, <td>C0, C1, C2, C3</td>, <td>set to 0.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 D0</td>, <td>FNOP</td>, <td>Valid</td>, <td>Valid</td>, <td>No operation is performed.</td>, <td>C0, C1, C2, C3</td>, <td>undefined.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>9B DD /6</td>, <td>FSAVE <em>m94/108byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU state to <em>m94byte</em> or <em>m108byte</em> after checking for pending unmasked floating-point exceptions. Then re-initialize the FPU.</td>, <td>DD /6</td>, <td>FNSAVE<sup>*</sup> <em>m94/108byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU environment to <em>m94byte</em> or <em>m108byte</em> without checking for pending unmasked floating-point exceptions. Then re-initialize the FPU.</td>, <td rowspan="3">#GP(0)</td>, <td>If destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>]

[<td>9B D9 /7</td>, <td>FSTCW <em>m2byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU control word to <em>m2byte</em> after checking for pending unmasked floating-point exceptions.</td>, <td>D9 /7</td>, <td>FNSTCW<sup>*</sup> <em>m2byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU control word to <em>m2byte</em> without checking for pending unmasked floating-point exceptions.</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>9B D9 /6</td>, <td>FSTENV <em>m14/28byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU environment to <em>m14byte</em> or <em>m28byte</em> after checking for pending unmasked floating-point exceptions. Then mask all floating-point exceptions.</td>, <td>D9 /6</td>, <td>FNSTENV<sup>*</sup> <em>m14/28byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU environment to <em>m14byte</em> or <em>m28byte</em> without checking for pending unmasked floating-point exceptions. Then mask all floating-point exceptions.</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>9B DD /7</td>, <td>FSTSW <em>m2byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU status word at <em>m2byte</em> after checking for pending unmasked floating-point exceptions.</td>, <td>9B DF E0</td>, <td>FSTSW AX</td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU status word in AX register after checking for pending unmasked floating-point exceptions.</td>, <td>DD /7</td>, <td>FNSTSW<sup>*</sup> <em>m2byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU status word at <em>m2byte</em> without checking for pending unmasked floating-point exceptions.</td>, <td>DF E0</td>, <td>FNSTSW<sup>*</sup> AX</td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU status word in AX register without checking for pending unmasked floating-point exceptions.</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 F3</td>, <td>FPATAN</td>, <td>Valid</td>, <td>Valid</td>, <td>Replace ST(1) with arctan(ST(1)/ST(0)) and pop the register stack.</td>, <td rowspan="8"><strong>ST(1)</strong></td>, <td></td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>− 3π/4*</td>, <td>− π/2</td>, <td>− π/2</td>, <td>− π/2</td>, <td>− π/2</td>, <td>− π/4*</td>, <td>NaN</td>, <td>−F</td>, <td>-p</td>, <td>−π to −π/2</td>, <td>−π/2</td>, <td>−π/2</td>, <td>−π/2 to −0</td>, <td>-0</td>, <td>NaN</td>, <td>−0</td>, <td>-p</td>, <td>-p</td>, <td>-p*</td>, <td>− 0*</td>, <td>−0</td>, <td>−0</td>, <td>NaN</td>, <td>+0</td>, <td>+p</td>, <td>+p</td>, <td>+ π*</td>, <td>+ 0*</td>, <td>+0</td>, <td>+0</td>, <td>NaN</td>, <td>+F</td>, <td>+p</td>, <td>+π to +π/2</td>, <td>+ π/2</td>, <td>+π/2</td>, <td>+π/2 to +0</td>, <td>+0</td>, <td>NaN</td>, <td>+∞</td>, <td>+3π/4*</td>, <td>+π/2</td>, <td>+π/2</td>, <td>+π/2</td>, <td>+ π/2</td>, <td>+ π/4*</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>Source operand is an SNaN value or unsupported format.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 F8</td>, <td>FPREM</td>, <td>Valid</td>, <td>Valid</td>, <td>Replace ST(0) with the remainder obtained from dividing ST(0) by ST(1).</td>, <td rowspan="8"><strong>ST(0)</strong></td>, <td></td>, <td>-∞</td>, <td>-F</td>, <td>-0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>-∞</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>NaN</td>, <td>-F</td>, <td>ST(0)</td>, <td>-F or -0</td>, <td>**</td>, <td>**</td>, <td>-F or -0</td>, <td>ST(0)</td>, <td>NaN</td>, <td>-0</td>, <td>-0</td>, <td>-0</td>, <td>*</td>, <td>*</td>, <td>-0</td>, <td>-0</td>, <td>NaN</td>, <td>+0</td>, <td>+0</td>, <td>+0</td>, <td>*</td>, <td>*</td>, <td>+0</td>, <td>+0</td>, <td>NaN</td>, <td>+F</td>, <td>ST(0)</td>, <td>+F or +0</td>, <td>**</td>, <td>**</td>, <td>+F or +0</td>, <td>ST(0)</td>, <td>NaN</td>, <td>+∞</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>C0</td>, <td>Set to bit 2 (Q2) of the quotient.</td>, <td>C1</td>, <td>Set to 0 if stack underflow occurred; otherwise, set to least significant bit of quotient (Q0).</td>, <td>C2</td>, <td>Set to 0 if reduction complete; set to 1 if incomplete.</td>, <td>C3</td>, <td>Set to bit 1 (Q1) of the quotient.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>Source operand is an SNaN value, modulus is 0, dividend is ∞, or unsupported format.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 F5</td>, <td>FPREM1</td>, <td>Valid</td>, <td>Valid</td>, <td>Replace ST(0) with the IEEE remainder obtained from dividing ST(0) by ST(1).</td>, <td rowspan="8"><strong>ST(0)</strong></td>, <td></td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>NaN</td>, <td>−F</td>, <td>ST(0)</td>, <td>±F or −0</td>, <td>**</td>, <td>**</td>, <td>± F or − 0</td>, <td>ST(0)</td>, <td>NaN</td>, <td>−0</td>, <td>−0</td>, <td>−0</td>, <td>*</td>, <td>*</td>, <td>−0</td>, <td>-0</td>, <td>NaN</td>, <td>+0</td>, <td>+0</td>, <td>+0</td>, <td>*</td>, <td>*</td>, <td>+0</td>, <td>+0</td>, <td>NaN</td>, <td>+F</td>, <td>ST(0)</td>, <td>± F or + 0</td>, <td>**</td>, <td>**</td>, <td>± F or + 0</td>, <td>ST(0)</td>, <td>NaN</td>, <td>+∞</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>C0</td>, <td>Set to bit 2 (Q2) of the quotient.</td>, <td>C1</td>, <td>Set to 0 if stack underflow occurred; otherwise, set to least significant bit of quotient (Q0).</td>, <td>C2</td>, <td>Set to 0 if reduction complete; set to 1 if incomplete.</td>, <td>C3</td>, <td>Set to bit 1 (Q1) of the quotient.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>Source operand is an SNaN value, modulus (divisor) is 0, dividend is ∞, or unsupported format.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 F2</td>, <td>FPTAN</td>, <td>Valid</td>, <td>Valid</td>, <td>Replace ST(0) with its approximate tangent and push 1 onto the FPU stack.</td>, <td>−∞</td>, <td>*</td>, <td>−F</td>, <td>− F to + F</td>, <td>−0</td>, <td>-0</td>, <td>+0</td>, <td>+0</td>, <td>+F</td>, <td>− F to + F</td>, <td>+∞</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="3">C1</td>, <td>Set to 0 if stack underflow occurred; set to 1 if stack overflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>Set to 1 if outside range (−263 &lt; source operand &lt; +263); otherwise, set to 0.</td>, <td>C2</td>, <td>C0, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow or overflow occurred.</td>, <td>#IA</td>, <td>Source operand is an SNaN value, ∞, or unsupported format.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 FC</td>, <td>FRNDINT</td>, <td>Valid</td>, <td>Valid</td>, <td>Round ST(0) to an integer.</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>Source operand is an SNaN value or unsupported format.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#P</td>, <td>Source operand is not an integral value.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DD /4</td>, <td>FRSTOR <em>m94/108byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Load FPU state from <em>m94byte</em> or <em>m108byte</em>.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>9B DD /6</td>, <td>FSAVE <em>m94/108byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU state to <em>m94byte</em> or <em>m108byte</em> after checking for pending unmasked floating-point exceptions. Then re-initialize the FPU.</td>, <td>DD /6</td>, <td>FNSAVE<sup>*</sup> <em>m94/108byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU environment to <em>m94byte</em> or <em>m108byte</em> without checking for pending unmasked floating-point exceptions. Then re-initialize the FPU.</td>, <td rowspan="3">#GP(0)</td>, <td>If destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>]

[<td>D9 FD</td>, <td>FSCALE</td>, <td>Valid</td>, <td>Valid</td>, <td>Scale ST(0) by ST(1).</td>, <td rowspan="8"><strong>ST(0)</strong></td>, <td></td>, <td>−∞</td>, <td>−F</td>, <td>−0</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td></td>, <td>NaN</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>NaN</td>, <td>−F</td>, <td>−0</td>, <td>−F</td>, <td>−F</td>, <td>−F</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−0</td>, <td>−0</td>, <td>−0</td>, <td>−0</td>, <td>−0</td>, <td>−0</td>, <td>NaN</td>, <td>NaN</td>, <td>+0</td>, <td>+0</td>, <td>+0</td>, <td>+0</td>, <td>+0</td>, <td>+0</td>, <td>NaN</td>, <td>NaN</td>, <td>+F</td>, <td>+0</td>, <td>+F</td>, <td>+F</td>, <td>+F</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+∞</td>, <td>NaN</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>Source operand is an SNaN value or unsupported format.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 FE</td>, <td>FSIN</td>, <td>Valid</td>, <td>Valid</td>, <td>Replace ST(0) with the approximate of its sine.</td>, <td>−∞</td>, <td>*</td>, <td>−F</td>, <td>− 1 to + 1</td>, <td>−0</td>, <td>−0</td>, <td>+0</td>, <td>+0</td>, <td>+F</td>, <td>− 1 to +1</td>, <td>+∞</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="3">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>Set to 1 if outside range (−263 &lt; source operand &lt; +263); otherwise, set to 0.</td>, <td>C2</td>, <td>C0, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>Source operand is an SNaN value, ∞, or unsupported format.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 FB</td>, <td>FSINCOS</td>, <td>Valid</td>, <td>Valid</td>, <td>Compute the sine and cosine of ST(0); replace ST(0) with the approximate sine, and push the approximate cosine onto the register stack.</td>, <td>−∞</td>, <td>*</td>, <td>*</td>, <td>−F</td>, <td>− 1 to + 1</td>, <td>− 1 to + 1</td>, <td>−0</td>, <td>+1</td>, <td>−0</td>, <td>+0</td>, <td>+1</td>, <td>+0</td>, <td>+F</td>, <td>− 1 to + 1</td>, <td>− 1 to + 1</td>, <td>+∞</td>, <td>*</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="3">C1</td>, <td>Set to 0 if stack underflow occurred; set to 1 of stack overflow occurs.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>Set to 1 if outside range (−263 &lt; source operand &lt; +263); otherwise, set to 0.</td>, <td>C2</td>, <td>C0, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow or overflow occurred.</td>, <td>#IA</td>, <td>Source operand is an SNaN value, ∞, or unsupported format.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 FA</td>, <td>FSQRT</td>, <td>Valid</td>, <td>Valid</td>, <td>Computes square root of ST(0) and stores the result in ST(0).</td>, <td>−∞</td>, <td>*</td>, <td>−F</td>, <td>*</td>, <td>−0</td>, <td>−0</td>, <td>+0</td>, <td>+0</td>, <td>+F</td>, <td>+F</td>, <td>+∞</td>, <td>+∞</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Source operand is an SNaN value or unsupported format.</td>, <td>Source operand is a negative value (except for −0).</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 /2</td>, <td>FST <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Copy ST(0) to <em>m32fp</em>.</td>, <td>DD /2</td>, <td>FST <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Copy ST(0) to <em>m64fp.</em></td>, <td>DD D0+i</td>, <td>FST ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Copy ST(0) to ST(i).</td>, <td>D9 /3</td>, <td>FSTP <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Copy ST(0) to <em>m32fp</em> and pop register stack.</td>, <td>DD /3</td>, <td>FSTP <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Copy ST(0) to <em>m64fp</em> and pop register stack.</td>, <td>DB /7</td>, <td>FSTP <em>m80fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Copy ST(0) to <em>m80fp</em> and pop register stack.</td>, <td>DD D8+i</td>, <td>FSTP ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Copy ST(0) to ST(i) and pop register stack.</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Indicates rounding direction of if the floating-point inexact exception (#P) is generated: 0 ← not roundup; 1 ← roundup.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>If destination result is an SNaN value or unsupported format, except when the destination format is in double extended-precision floating-point format.</td>, <td>#U</td>, <td>Result is too small for the destination format.</td>, <td>#O</td>, <td>Result is too large for the destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>9B D9 /7</td>, <td>FSTCW <em>m2byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU control word to <em>m2byte</em> after checking for pending unmasked floating-point exceptions.</td>, <td>D9 /7</td>, <td>FNSTCW<sup>*</sup> <em>m2byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU control word to <em>m2byte</em> without checking for pending unmasked floating-point exceptions.</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>9B D9 /6</td>, <td>FSTENV <em>m14/28byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU environment to <em>m14byte</em> or <em>m28byte</em> after checking for pending unmasked floating-point exceptions. Then mask all floating-point exceptions.</td>, <td>D9 /6</td>, <td>FNSTENV<sup>*</sup> <em>m14/28byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU environment to <em>m14byte</em> or <em>m28byte</em> without checking for pending unmasked floating-point exceptions. Then mask all floating-point exceptions.</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 /2</td>, <td>FST <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Copy ST(0) to <em>m32fp</em>.</td>, <td>DD /2</td>, <td>FST <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Copy ST(0) to <em>m64fp.</em></td>, <td>DD D0+i</td>, <td>FST ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Copy ST(0) to ST(i).</td>, <td>D9 /3</td>, <td>FSTP <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Copy ST(0) to <em>m32fp</em> and pop register stack.</td>, <td>DD /3</td>, <td>FSTP <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Copy ST(0) to <em>m64fp</em> and pop register stack.</td>, <td>DB /7</td>, <td>FSTP <em>m80fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Copy ST(0) to <em>m80fp</em> and pop register stack.</td>, <td>DD D8+i</td>, <td>FSTP ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Copy ST(0) to ST(i) and pop register stack.</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Indicates rounding direction of if the floating-point inexact exception (#P) is generated: 0 ← not roundup; 1 ← roundup.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>If destination result is an SNaN value or unsupported format, except when the destination format is in double extended-precision floating-point format.</td>, <td>#U</td>, <td>Result is too small for the destination format.</td>, <td>#O</td>, <td>Result is too large for the destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>9B DD /7</td>, <td>FSTSW <em>m2byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU status word at <em>m2byte</em> after checking for pending unmasked floating-point exceptions.</td>, <td>9B DF E0</td>, <td>FSTSW AX</td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU status word in AX register after checking for pending unmasked floating-point exceptions.</td>, <td>DD /7</td>, <td>FNSTSW<sup>*</sup> <em>m2byte</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU status word at <em>m2byte</em> without checking for pending unmasked floating-point exceptions.</td>, <td>DF E0</td>, <td>FNSTSW<sup>*</sup> AX</td>, <td>Valid</td>, <td>Valid</td>, <td>Store FPU status word in AX register without checking for pending unmasked floating-point exceptions.</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /4</td>, <td>FSUB <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>m32fp</em> from ST(0) and store result in ST(0).</td>, <td>DC /4</td>, <td>FSUB <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>m64fp</em> from ST(0) and store result in ST(0).</td>, <td>D8 E0+i</td>, <td>FSUB ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(i) from ST(0) and store result in ST(0).</td>, <td>DC E8+i</td>, <td>FSUB ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from ST(i) and store result in ST(i).</td>, <td>DE E8+i</td>, <td>FSUBP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from ST(i), store result in ST(i), and pop register stack.</td>, <td>DE E9</td>, <td>FSUBP</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from ST(1), store result in ST(1), and pop register stack.</td>, <td>DA /4</td>, <td>FISUB <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>m32int</em> from ST(0) and store result in ST(0).</td>, <td>DE /4</td>, <td>FISUB <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>m16int</em> from ST(0) and store result in ST(0).</td>, <td rowspan="8"><strong>DEST</strong></td>, <td></td>, <td>−∞</td>, <td>− F or − I</td>, <td>−0</td>, <td>+0</td>, <td>+ F or + I</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>*</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>NaN</td>, <td>−F</td>, <td>+∞</td>, <td>±F or ±0</td>, <td>DEST</td>, <td>DEST</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−0</td>, <td>+∞</td>, <td>−SRC</td>, <td>±0</td>, <td>−0</td>, <td>− SRC</td>, <td>−∞</td>, <td>NaN</td>, <td>+0</td>, <td>+∞</td>, <td>−SRC</td>, <td>+0</td>, <td>±0</td>, <td>− SRC</td>, <td>−∞</td>, <td>NaN</td>, <td>+F</td>, <td>+∞</td>, <td>+F</td>, <td>DEST</td>, <td>DEST</td>, <td>±F or ±0</td>, <td>−∞</td>, <td>NaN</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>Operands are infinities of like sign.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /4</td>, <td>FSUB <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>m32fp</em> from ST(0) and store result in ST(0).</td>, <td>DC /4</td>, <td>FSUB <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>m64fp</em> from ST(0) and store result in ST(0).</td>, <td>D8 E0+i</td>, <td>FSUB ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(i) from ST(0) and store result in ST(0).</td>, <td>DC E8+i</td>, <td>FSUB ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from ST(i) and store result in ST(i).</td>, <td>DE E8+i</td>, <td>FSUBP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from ST(i), store result in ST(i), and pop register stack.</td>, <td>DE E9</td>, <td>FSUBP</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from ST(1), store result in ST(1), and pop register stack.</td>, <td>DA /4</td>, <td>FISUB <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>m32int</em> from ST(0) and store result in ST(0).</td>, <td>DE /4</td>, <td>FISUB <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>m16int</em> from ST(0) and store result in ST(0).</td>, <td rowspan="8"><strong>DEST</strong></td>, <td></td>, <td>−∞</td>, <td>− F or − I</td>, <td>−0</td>, <td>+0</td>, <td>+ F or + I</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>*</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>NaN</td>, <td>−F</td>, <td>+∞</td>, <td>±F or ±0</td>, <td>DEST</td>, <td>DEST</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−0</td>, <td>+∞</td>, <td>−SRC</td>, <td>±0</td>, <td>−0</td>, <td>− SRC</td>, <td>−∞</td>, <td>NaN</td>, <td>+0</td>, <td>+∞</td>, <td>−SRC</td>, <td>+0</td>, <td>±0</td>, <td>− SRC</td>, <td>−∞</td>, <td>NaN</td>, <td>+F</td>, <td>+∞</td>, <td>+F</td>, <td>DEST</td>, <td>DEST</td>, <td>±F or ±0</td>, <td>−∞</td>, <td>NaN</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>Operands are infinities of like sign.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /5</td>, <td>FSUBR <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from <em>m32fp</em> and store result in ST(0).</td>, <td>DC /5</td>, <td>FSUBR <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from <em>m64fp</em> and store result in ST(0).</td>, <td>D8 E8+i</td>, <td>FSUBR ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from ST(i) and store result in ST(0).</td>, <td>DC E0+i</td>, <td>FSUBR ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(i) from ST(0) and store result in ST(i).</td>, <td>DE E0+i</td>, <td>FSUBRP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(i) from ST(0), store result in ST(i), and pop register stack.</td>, <td>DE E1</td>, <td>FSUBRP</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(1) from ST(0), store result in ST(1), and pop register stack.</td>, <td>DA /5</td>, <td>FISUBR <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from <em>m32int</em> and store result in ST(0).</td>, <td>DE /5</td>, <td>FISUBR <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from <em>m16int</em> and store result in ST(0).</td>, <td rowspan="8"><strong>DEST</strong></td>, <td></td>, <td>−∞</td>, <td>−F or −I</td>, <td>−0</td>, <td>+0</td>, <td>+F or +I</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>*</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>NaN</td>, <td>−F</td>, <td>−∞</td>, <td>±F or ±0</td>, <td>−DEST</td>, <td>−DEST</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−0</td>, <td>−∞</td>, <td>SRC</td>, <td>±0</td>, <td>+0</td>, <td>SRC</td>, <td>+∞</td>, <td>NaN</td>, <td>+0</td>, <td>−∞</td>, <td>SRC</td>, <td>−0</td>, <td>±0</td>, <td>SRC</td>, <td>+∞</td>, <td>NaN</td>, <td>+F</td>, <td>−∞</td>, <td>−F</td>, <td>−DEST</td>, <td>−DEST</td>, <td>±F or ±0</td>, <td>+∞</td>, <td>NaN</td>, <td>+∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>Operands are infinities of like sign.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D8 /5</td>, <td>FSUBR <em>m32fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from <em>m32fp</em> and store result in ST(0).</td>, <td>DC /5</td>, <td>FSUBR <em>m64fp</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from <em>m64fp</em> and store result in ST(0).</td>, <td>D8 E8+i</td>, <td>FSUBR ST(0), ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from ST(i) and store result in ST(0).</td>, <td>DC E0+i</td>, <td>FSUBR ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(i) from ST(0) and store result in ST(i).</td>, <td>DE E0+i</td>, <td>FSUBRP ST(i), ST(0)</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(i) from ST(0), store result in ST(i), and pop register stack.</td>, <td>DE E1</td>, <td>FSUBRP</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(1) from ST(0), store result in ST(1), and pop register stack.</td>, <td>DA /5</td>, <td>FISUBR <em>m32int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from <em>m32int</em> and store result in ST(0).</td>, <td>DE /5</td>, <td>FISUBR <em>m16int</em></td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract ST(0) from <em>m16int</em> and store result in ST(0).</td>, <td rowspan="8"><strong>DEST</strong></td>, <td></td>, <td>−∞</td>, <td>−F or −I</td>, <td>−0</td>, <td>+0</td>, <td>+F or +I</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>*</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>+∞</td>, <td>NaN</td>, <td>−F</td>, <td>−∞</td>, <td>±F or ±0</td>, <td>−DEST</td>, <td>−DEST</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>−0</td>, <td>−∞</td>, <td>SRC</td>, <td>±0</td>, <td>+0</td>, <td>SRC</td>, <td>+∞</td>, <td>NaN</td>, <td>+0</td>, <td>−∞</td>, <td>SRC</td>, <td>−0</td>, <td>±0</td>, <td>SRC</td>, <td>+∞</td>, <td>NaN</td>, <td>+F</td>, <td>−∞</td>, <td>−F</td>, <td>−DEST</td>, <td>−DEST</td>, <td>±F or ±0</td>, <td>+∞</td>, <td>NaN</td>, <td>+∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>−∞</td>, <td>*</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Operand is an SNaN value or unsupported format.</td>, <td>Operands are infinities of like sign.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 E4</td>, <td>FTST</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with 0.0.</td>, <td>ST(0) &gt; 0.0</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>ST(0) &lt; 0.0</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>ST(0) = 0.0</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>Unordered</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>C1</td>, <td>Set to 0.</td>, <td>C0, C2, C3</td>, <td>See Table 3-40.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>The source operand is a NaN value or is in an unsupported format.</td>, <td>#D</td>, <td>The source operand is a denormal value.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DD E0+i</td>, <td>FUCOM ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i).</td>, <td>DD E1</td>, <td>FUCOM</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1).</td>, <td>DD E8+i</td>, <td>FUCOMP ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i) and pop register stack.</td>, <td>DD E9</td>, <td>FUCOMP</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1) and pop register stack.</td>, <td>DA E9</td>, <td>FUCOMPP</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1) and pop register stack twice.</td>, <td>ST0 &gt; ST(i)</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>ST0 &lt; ST(i)</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>ST0 = ST(i)</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>Unordered</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>C0, C2, C3</td>, <td>See Table 3-41.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>One or both operands are SNaN values or have unsupported formats. Detection of a QNaN value in and of itself does not raise an invalid-operand exception.</td>, <td>#D</td>, <td>One or both operands are denormal values.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DB F0+i</td>, <td>FCOMI ST, ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i) and set status flags accordingly.</td>, <td>DF F0+i</td>, <td>FCOMIP ST, ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i), set status flags accordingly, and pop register stack.</td>, <td>DB E8+i</td>, <td>FUCOMI ST, ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i), check for ordered values, and set status flags accordingly.</td>, <td>DF E8+i</td>, <td>FUCOMIP ST, ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i), check for ordered values, set status flags accordingly, and pop register stack.</td>, <td>ST0 &gt; ST(i)</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>ST0 &lt; ST(i)</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>ST0 = ST(i)</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>Unordered**</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>C1</td>, <td>Set to 0.</td>, <td>C0, C2, C3</td>, <td>Not affected.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>(FCOMI or FCOMIP instruction) One or both operands are NaN values or have unsupported formats.</td>, <td>(FUCOMI or FUCOMIP instruction) One or both operands are SNaN values (but not QNaNs) or have undefined formats. Detection of a QNaN value does not raise an invalid-operand exception.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DB F0+i</td>, <td>FCOMI ST, ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i) and set status flags accordingly.</td>, <td>DF F0+i</td>, <td>FCOMIP ST, ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i), set status flags accordingly, and pop register stack.</td>, <td>DB E8+i</td>, <td>FUCOMI ST, ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i), check for ordered values, and set status flags accordingly.</td>, <td>DF E8+i</td>, <td>FUCOMIP ST, ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i), check for ordered values, set status flags accordingly, and pop register stack.</td>, <td>ST0 &gt; ST(i)</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>ST0 &lt; ST(i)</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>ST0 = ST(i)</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>Unordered**</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>C1</td>, <td>Set to 0.</td>, <td>C0, C2, C3</td>, <td>Not affected.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>(FCOMI or FCOMIP instruction) One or both operands are NaN values or have unsupported formats.</td>, <td>(FUCOMI or FUCOMIP instruction) One or both operands are SNaN values (but not QNaNs) or have undefined formats. Detection of a QNaN value does not raise an invalid-operand exception.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DD E0+i</td>, <td>FUCOM ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i).</td>, <td>DD E1</td>, <td>FUCOM</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1).</td>, <td>DD E8+i</td>, <td>FUCOMP ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i) and pop register stack.</td>, <td>DD E9</td>, <td>FUCOMP</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1) and pop register stack.</td>, <td>DA E9</td>, <td>FUCOMPP</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1) and pop register stack twice.</td>, <td>ST0 &gt; ST(i)</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>ST0 &lt; ST(i)</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>ST0 = ST(i)</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>Unordered</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>C0, C2, C3</td>, <td>See Table 3-41.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>One or both operands are SNaN values or have unsupported formats. Detection of a QNaN value in and of itself does not raise an invalid-operand exception.</td>, <td>#D</td>, <td>One or both operands are denormal values.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>DD E0+i</td>, <td>FUCOM ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i).</td>, <td>DD E1</td>, <td>FUCOM</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1).</td>, <td>DD E8+i</td>, <td>FUCOMP ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(i) and pop register stack.</td>, <td>DD E9</td>, <td>FUCOMP</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1) and pop register stack.</td>, <td>DA E9</td>, <td>FUCOMPP</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare ST(0) with ST(1) and pop register stack twice.</td>, <td>ST0 &gt; ST(i)</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>ST0 &lt; ST(i)</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>ST0 = ST(i)</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>Unordered</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>C0, C2, C3</td>, <td>See Table 3-41.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>One or both operands are SNaN values or have unsupported formats. Detection of a QNaN value in and of itself does not raise an invalid-operand exception.</td>, <td>#D</td>, <td>One or both operands are denormal values.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>9B</td>, <td>WAIT</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Check pending unmasked floating-point exceptions.</td>, <td>9B</td>, <td>FWAIT</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Check pending unmasked floating-point exceptions.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#NM</td>, <td>If CR0.MP[bit 1] = 1 and CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 E5</td>, <td>FXAM</td>, <td>Valid</td>, <td>Valid</td>, <td>Classify value or number in ST(0).</td>, <td>Unsupported</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>NaN</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>Normal finite number</td>, <td>0</td>, <td>1</td>, <td>0</td>, <td>Infinity</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>Zero</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>Empty</td>, <td>1</td>, <td>0</td>, <td>1</td>, <td>Denormal number</td>, <td>1</td>, <td>1</td>, <td>0</td>, <td>C1</td>, <td>Sign of value in ST(0).</td>, <td>C0, C2, C3</td>, <td>See Table 3-42.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 C8+i</td>, <td>FXCH ST(i)</td>, <td>Valid</td>, <td>Valid</td>, <td>Exchange the contents of ST(0) and ST(i).</td>, <td>D9 C9</td>, <td>FXCH</td>, <td>Valid</td>, <td>Valid</td>, <td>Exchange the contents of ST(0) and ST(1).</td>, <td>C1</td>, <td>Set to 0.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>NP 0F AE /1 FXRSTOR <em>m512byte</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Restore the x87 FPU, MMX, XMM, and MXCSR register state from <em>m512byte</em>.</td>, <td>NP REX.W + 0F AE /1 FXRSTOR64 <em>m512byte</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Restore the x87 FPU, MMX, XMM, and MXCSR register state from <em>m512byte</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>For an illegal memory operand effective address in the CS, DS, ES, FS or GS segments.</td>, <td>If a memory operand is not aligned on a 16-byte boundary, regardless of segment. (See alignment check exception [#AC] below.)</td>, <td>For an attempt to set reserved bits in MXCSR.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td rowspan="2">#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td>If CR0.EM[bit 2] = 1.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:EDX.FXSR[bit 24] = 0.</td>, <td>If instruction is preceded by a LOCK prefix.</td>, <td>#AC</td>, <td>If this exception is disabled a general protection exception (#GP) is signaled if the memory operand is not aligned on a 16-byte boundary, as described above. If the alignment check exception (#AC) is enabled (and the CPL is 3), signaling of #AC is not guaranteed and may vary with implementation, as follows. In all implementations where #AC is not signaled, a general protection exception is signaled in its place. In addition, the width of the alignment check may also vary with implementation. For instance, for a given implementation, an alignment check exception might be signaled for a 2-byte misalignment, whereas a general protection exception might be signaled for all other misalignments (4-, 8-, or 16-byte misalignments).</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="3">#GP</td>, <td>If a memory operand is not aligned on a 16-byte boundary, regardless of segment.</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td>For an attempt to set reserved bits in MXCSR.</td>, <td rowspan="2">#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td>If CR0.EM[bit 2] = 1.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:EDX.FXSR[bit 24] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#AC</td>, <td>For unaligned memory reference.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="3">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If memory operand is not aligned on a 16-byte boundary, regardless of segment.</td>, <td>For an attempt to set reserved bits in MXCSR.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td rowspan="2">#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td>If CR0.EM[bit 2] = 1.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:EDX.FXSR[bit 24] = 0.</td>, <td>If instruction is preceded by a LOCK prefix.</td>, <td>#AC</td>, <td>If this exception is disabled a general protection exception (#GP) is signaled if the memory operand is not aligned on a 16-byte boundary, as described above. If the alignment check exception (#AC) is enabled (and the CPL is 3), signaling of #AC is not guaranteed and may vary with implementation, as follows. In all implementations where #AC is not signaled, a general protection exception is signaled in its place. In addition, the width of the alignment check may also vary with implementation. For instance, for a given implementation, an alignment check exception might be signaled for a 2-byte misalignment, whereas a general protection exception might be signaled for all other misalignments (4-, 8-, or 16-byte misalignments).</td>]

[<td>NP 0F AE /0 FXSAVE <em>m512byte</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Save the x87 FPU, MMX, XMM, and MXCSR register state to <em>m512byte</em>.</td>, <td>NP REX.W + 0F AE /0 FXSAVE64 <em>m512byte</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Save the x87 FPU, MMX, XMM, and MXCSR register state to <em>m512byte</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>Rsvd</td>, <td>FCS</td>, <td colspan="2">FIP[31:0]</td>, <td>FOP</td>, <td>Rsvd</td>, <td>FTW</td>, <td>FSW</td>, <td>FCW</td>, <td><strong>0</strong></td>, <td colspan="2">MXCSR_MASK</td>, <td colspan="2">MXCSR</td>, <td>Rsrvd</td>, <td colspan="2">FDS</td>, <td colspan="2">FDP[31:0]</td>, <td><strong>16</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST0/MM0</td>, <td><strong>32</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST1/MM1</td>, <td><strong>48</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST2/MM2</td>, <td><strong>64</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST3/MM3</td>, <td><strong>80</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST4/MM4</td>, <td><strong>96</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST5/MM5</td>, <td><strong>112</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST6/MM6</td>, <td><strong>128</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST7/MM7</td>, <td><strong>144</strong></td>, <td colspan="9">XMM0</td>, <td><strong>160</strong></td>, <td colspan="9">XMM1</td>, <td><strong>176</strong></td>, <td colspan="9">XMM2</td>, <td><strong>192</strong></td>, <td colspan="9">XMM3</td>, <td><strong>208</strong></td>, <td colspan="9">XMM4</td>, <td><strong>224</strong></td>, <td colspan="9">XMM5</td>, <td><strong>240</strong></td>, <td colspan="9">XMM6</td>, <td><strong>256</strong></td>, <td colspan="9">XMM7</td>, <td><strong>272</strong></td>, <td colspan="9">Reserved</td>, <td><strong>288</strong></td>, <td colspan="9">Reserved</td>, <td><strong>304</strong></td>, <td colspan="9">Reserved</td>, <td><strong>320</strong></td>, <td colspan="9">Reserved</td>, <td><strong>336</strong></td>, <td colspan="9">Reserved</td>, <td><strong>352</strong></td>, <td colspan="9">Reserved</td>, <td><strong>368</strong></td>, <td colspan="9">Reserved</td>, <td><strong>384</strong></td>, <td colspan="9">Reserved</td>, <td><strong>400</strong></td>, <td colspan="9">Reserved</td>, <td><strong>416</strong></td>, <td colspan="9">Reserved</td>, <td><strong>432</strong></td>, <td colspan="9">Reserved</td>, <td><strong>448</strong></td>, <td colspan="9">Available</td>, <td><strong>464</strong></td>, <td colspan="9">Available</td>, <td><strong>480</strong></td>, <td colspan="9">Available</td>, <td><strong>496</strong></td>, <td>FCW</td>, <td>x87 FPU Control Word (16 bits). See <span class="not-imported">Figure 8-6</span> in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1</em>, for the layout of the x87 FPU control word.</td>, <td>FSW</td>, <td>x87 FPU Status Word (16 bits). See <span class="not-imported">Figure 8-4</span> in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1</em>, for the layout of the x87 FPU status word.</td>, <td>Abridged FTW</td>, <td>x87 FPU Tag Word (8 bits). The tag information saved here is abridged, as described in the following paragraphs.</td>, <td>FOP</td>, <td>x87 FPU Opcode (16 bits). The lower 11 bits of this field contain the opcode, upper 5 bits are reserved. See <span class="not-imported">Figure 8-8</span> in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1</em>, for the layout of the x87 FPU opcode field.</td>, <td>FIP</td>, <td>x87 FPU Instruction Pointer Offset (64 bits). The contents of this field differ depending on the current addressing mode (32-bit, 16-bit, or 64-bit) of the processor when the FXSAVE instruction was executed: 32-bit mode — 32-bit IP offset. 16-bit mode — low 16 bits are IP offset; high 16 bits are reserved. 64-bit mode with REX.W — 64-bit IP offset. 64-bit mode without REX.W — 32-bit IP offset. See “x87 FPU Instruction and Operand (Data) Pointers” in Chapter 8 of the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1</em>, for a description of the x87 FPU instruction pointer.</td>, <td>FCS</td>, <td>x87 FPU Instruction Pointer Selector (16 bits). If CPUID.(EAX=07H,ECX=0H):EBX[bit 13] = 1, the processor deprecates FCS and FDS, and this field is saved as 0000H.</td>, <td>FDP</td>, <td>x87 FPU Instruction Operand (Data) Pointer Offset (64 bits). The contents of this field differ depending on the current addressing mode (32-bit, 16-bit, or 64-bit) of the processor when the FXSAVE instruction was executed: 32-bit mode — 32-bit DP offset. 16-bit mode — low 16 bits are DP offset; high 16 bits are reserved. 64-bit mode with REX.W — 64-bit DP offset. 64-bit mode without REX.W — 32-bit DP offset. See “x87 FPU Instruction and Operand (Data) Pointers” in Chapter 8 of the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1</em>, for a description of the x87 FPU operand pointer.</td>, <td>FDS</td>, <td>x87 FPU Instruction Operand (Data) Pointer Selector (16 bits). If CPUID.(EAX=07H,ECX=0H):EBX[bit 13] = 1, the processor deprecates FCS and FDS, and this field is saved as 0000H.</td>, <td>MXCSR</td>, <td>MXCSR Register State (32 bits). See <span class="not-imported">Figure 10-3</span> in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1</em>, for the layout of the MXCSR register. If the OSFXSR bit in control register CR4 is not set, the FXSAVE instruction may not save this register. This behavior is implementation dependent.</td>, <td>MXCSR_ MASK</td>, <td>MXCSR_MASK (32 bits). This mask can be used to adjust values written to the MXCSR register, ensuring that reserved bits are set to 0. Set the mask bits and flags in MXCSR to the mode of operation desired for SSE and SSE2 SIMD floating-point instructions. See “Guidelines for Writing to the MXCSR Register” in Chapter 11 of the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1</em>, for instructions for how to determine and use the MXCSR_MASK value.</td>, <td>ST0/MM0 through ST7/MM7</td>, <td>x87 FPU or MMX technology registers. These 80-bit fields contain the x87 FPU data registers or the MMX technology registers, depending on the state of the processor prior to the execution of the FXSAVE instruction. If the processor had been executing x87 FPU instruction prior to the FXSAVE instruction, the x87 FPU data registers are saved; if it had been executing MMX instructions (or SSE or SSE2 instructions that operated on the MMX technology registers), the MMX technology registers are saved. When the MMX technology registers are saved, the high 16 bits of the field are reserved.</td>, <td>XMM0 through XMM7</td>, <td>XMM registers (128 bits per field). If the OSFXSR bit in control register CR4 is not set, the FXSAVE instruction may not save these registers. This behavior is implementation dependent.</td>, <td>0 0</td>, <td>0 0</td>, <td>0 0</td>, <td>0x 1x</td>, <td>1 1</td>, <td>Special 10 Valid 00</td>, <td>0 0</td>, <td>0 0</td>, <td>1 1</td>, <td>00 10</td>, <td>1 1</td>, <td>Special 10 Valid 00</td>, <td>0 0</td>, <td>1 1</td>, <td>0 0</td>, <td>0x 1x</td>, <td>1 1</td>, <td>Special 10 Special 10</td>, <td>0 0</td>, <td>1 1</td>, <td>1 1</td>, <td>00 10</td>, <td>1 1</td>, <td>Zero 01 Special 10</td>, <td>1 1</td>, <td>0 0</td>, <td>0 0</td>, <td>1x 1x</td>, <td>1 1</td>, <td>Special 10 Special 10</td>, <td>1 1</td>, <td>0 0</td>, <td>1 1</td>, <td>00 10</td>, <td>1 1</td>, <td>Special 10 Special 10</td>, <td colspan="4">For all legal combinations above.</td>, <td>0</td>, <td>Empty 11</td>, <td>15 14</td>, <td>13 12</td>, <td>11 10</td>, <td>98</td>, <td>76</td>, <td>5</td>, <td>4</td>, <td>32</td>, <td>10</td>, <td></td>, <td colspan="4">FIP</td>, <td>FOP</td>, <td>Reserved</td>, <td>FTW</td>, <td>FSW</td>, <td>FCW</td>, <td><strong>0</strong></td>, <td colspan="2">MXCSR_MASK</td>, <td colspan="2">MXCSR</td>, <td colspan="5">FDP</td>, <td><strong>16</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST0/MM0</td>, <td><strong>32</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST1/MM1</td>, <td><strong>48</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST2/MM2</td>, <td><strong>64</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST3/MM3</td>, <td><strong>80</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST4/MM4</td>, <td><strong>96</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST5/MM5</td>, <td><strong>112</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST6/MM6</td>, <td><strong>128</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST7/MM7</td>, <td><strong>144</strong></td>, <td colspan="9">XMM0</td>, <td><strong>160</strong></td>, <td colspan="9">XMM1</td>, <td><strong>176</strong></td>, <td colspan="9">XMM2</td>, <td><strong>192</strong></td>, <td colspan="9">XMM3</td>, <td><strong>208</strong></td>, <td colspan="9">XMM4</td>, <td><strong>224</strong></td>, <td colspan="9">XMM5</td>, <td><strong>240</strong></td>, <td colspan="9">XMM6</td>, <td><strong>256</strong></td>, <td colspan="9">XMM7</td>, <td><strong>272</strong></td>, <td colspan="9">XMM8</td>, <td><strong>288</strong></td>, <td colspan="9">XMM9</td>, <td><strong>304</strong></td>, <td colspan="9">XMM10</td>, <td><strong>320</strong></td>, <td colspan="9">XMM11</td>, <td><strong>336</strong></td>, <td colspan="9">XMM12</td>, <td><strong>352</strong></td>, <td colspan="9">XMM13</td>, <td><strong>368</strong></td>, <td colspan="9">XMM14</td>, <td><strong>384</strong></td>, <td colspan="9">XMM15</td>, <td><strong>400</strong></td>, <td colspan="9">Reserved</td>, <td><strong>416</strong></td>, <td colspan="9">Reserved</td>, <td><strong>432</strong></td>, <td colspan="9">Reserved</td>, <td><strong>448</strong></td>, <td colspan="9">Available</td>, <td><strong>464</strong></td>, <td colspan="9">Available</td>, <td><strong>480</strong></td>, <td colspan="9">Available</td>, <td><strong>496</strong></td>, <td>15 14</td>, <td>13 12</td>, <td>11 10</td>, <td>98</td>, <td>76</td>, <td>5</td>, <td>4</td>, <td>32</td>, <td>10</td>, <td></td>, <td>Reserved</td>, <td>FCS</td>, <td colspan="2">FIP[31:0]</td>, <td>FOP</td>, <td>Reserved</td>, <td>FTW</td>, <td>FSW</td>, <td>FCW</td>, <td><strong>0</strong></td>, <td colspan="2">MXCSR_MASK</td>, <td colspan="2">MXCSR</td>, <td>Reserved</td>, <td colspan="2">FDS</td>, <td colspan="2">FDP[31:0]</td>, <td><strong>16</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST0/MM0</td>, <td><strong>32</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST1/MM1</td>, <td><strong>48</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST2/MM2</td>, <td><strong>64</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST3/MM3</td>, <td><strong>80</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST4/MM4</td>, <td><strong>96</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST5/MM5</td>, <td><strong>112</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST6/MM6</td>, <td><strong>128</strong></td>, <td colspan="3">Reserved</td>, <td colspan="6">ST7/MM7</td>, <td><strong>144</strong></td>, <td colspan="9">XMM0</td>, <td><strong>160</strong></td>, <td colspan="9">XMM1</td>, <td><strong>176</strong></td>, <td colspan="9">XMM2</td>, <td><strong>192</strong></td>, <td colspan="9">XMM3</td>, <td><strong>208</strong></td>, <td colspan="9">XMM4</td>, <td><strong>224</strong></td>, <td colspan="9">XMM5</td>, <td><strong>240</strong></td>, <td colspan="9">XMM6</td>, <td><strong>256</strong></td>, <td colspan="9">XMM7</td>, <td><strong>272</strong></td>, <td colspan="9">XMM8</td>, <td><strong>288</strong></td>, <td colspan="9">XMM9</td>, <td><strong>304</strong></td>, <td colspan="9">XMM10</td>, <td><strong>320</strong></td>, <td colspan="9">XMM11</td>, <td><strong>336</strong></td>, <td colspan="9">XMM12</td>, <td><strong>352</strong></td>, <td colspan="9">XMM13</td>, <td><strong>368</strong></td>, <td colspan="9">XMM14</td>, <td><strong>384</strong></td>, <td colspan="9">XMM15</td>, <td><strong>400</strong></td>, <td colspan="9">Reserved</td>, <td><strong>416</strong></td>, <td colspan="9">Reserved</td>, <td><strong>432</strong></td>, <td colspan="9">Reserved</td>, <td><strong>448</strong></td>, <td colspan="9">Available</td>, <td><strong>464</strong></td>, <td colspan="9">Available</td>, <td><strong>480</strong></td>, <td colspan="9">Available</td>, <td><strong>496</strong></td>, <td rowspan="2">#GP(0)</td>, <td>For an illegal memory operand effective address in the CS, DS, ES, FS or GS segments.</td>, <td>If a memory operand is not aligned on a 16-byte boundary, regardless of segment. (See the description of the alignment check exception [#AC] below.)</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td rowspan="2">#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td>If CR0.EM[bit 2] = 1.</td>, <td>#UD</td>, <td>If CPUID.01H:EDX.FXSR[bit 24] = 0.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#AC</td>, <td>If this exception is disabled a general protection exception (#GP) is signaled if the memory operand is not aligned on a 16-byte boundary, as described above. If the alignment check exception (#AC) is enabled (and the CPL is 3), signaling of #AC is not guaranteed and may vary with implementation, as follows. In all implementations where #AC is not signaled, a general protection exception is signaled in its place. In addition, the width of the alignment check may also vary with implementation. For instance, for a given implementation, an alignment check exception might be signaled for a 2-byte misalignment, whereas a general protection exception might be signaled for all other misalignments (4-, 8-, or 16-byte misalignments).</td>, <td rowspan="2">#GP</td>, <td>If a memory operand is not aligned on a 16-byte boundary, regardless of segment.</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td rowspan="2">#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td>If CR0.EM[bit 2] = 1.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:EDX.FXSR[bit 24] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#AC</td>, <td>For unaligned memory reference.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If memory operand is not aligned on a 16-byte boundary, regardless of segment.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td rowspan="2">#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td>If CR0.EM[bit 2] = 1.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:EDX.FXSR[bit 24] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#AC</td>, <td>If this exception is disabled a general protection exception (#GP) is signaled if the memory operand is not aligned on a 16-byte boundary, as described above. If the alignment check exception (#AC) is enabled (and the CPL is 3), signaling of #AC is not guaranteed and may vary with implementation, as follows. In all implementations where #AC is not signaled, a general protection exception is signaled in its place. In addition, the width of the alignment check may also vary with implementation. For instance, for a given implementation, an alignment check exception might be signaled for a 2-byte misalignment, whereas a general protection exception might be signaled for all other misalignments (4-, 8-, or 16-byte misalignments).</td>]

[<td>D9 F4 FXTRACT</td>, <td>Valid</td>, <td>Valid</td>, <td>Separate value in ST(0) into exponent and significand, store exponent in ST(0), and push the significand onto the register stack.</td>, <td>C1</td>, <td>Set to 0 if stack underflow occurred; set to 1 if stack overflow occurred.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow or overflow occurred.</td>, <td>#IA</td>, <td>Source operand is an SNaN value or unsupported format.</td>, <td>#Z</td>, <td>ST(0) operand is ±0.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 F1</td>, <td>FYL2X</td>, <td>Valid</td>, <td>Valid</td>, <td>Replace ST(1) with (ST(1) ∗ log<sub>2</sub>ST(0)) and pop the register stack.</td>, <td rowspan="8"><strong>ST(1)</strong></td>, <td></td>, <td>−∞</td>, <td>−F</td>, <td>±0</td>, <td>+0&lt;+F&lt;+1</td>, <td>+1</td>, <td>+F&gt;+1</td>, <td>+∞</td>, <td>NaN</td>, <td>−∞</td>, <td>*</td>, <td>*</td>, <td>+∞</td>, <td>+∞</td>, <td>*</td>, <td>−∞</td>, <td>−∞</td>, <td>NaN</td>, <td>−F</td>, <td>*</td>, <td>*</td>, <td>**</td>, <td>+F</td>, <td>−0</td>, <td>−F</td>, <td>−∞</td>, <td>NaN</td>, <td>−0</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>+0</td>, <td>−0</td>, <td>−0</td>, <td>*</td>, <td>NaN</td>, <td>+0</td>, <td>*</td>, <td>*</td>, <td>*</td>, <td>−0</td>, <td>+0</td>, <td>+0</td>, <td>*</td>, <td>NaN</td>, <td>+F</td>, <td>*</td>, <td>*</td>, <td>**</td>, <td>−F</td>, <td>+0</td>, <td>+F</td>, <td>+∞</td>, <td>NaN</td>, <td>+∞</td>, <td>*</td>, <td>*</td>, <td>−∞</td>, <td>−∞</td>, <td>*</td>, <td>+∞</td>, <td>+∞</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td>NaN</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td rowspan="2">#IA</td>, <td>Either operand is an SNaN or unsupported format.</td>, <td>Source operand in register ST(0) is a negative finite value (not -0).</td>, <td>#Z</td>, <td>Source operand in register ST(0) is ±0.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D9 F9</td>, <td>FYL2XP1</td>, <td>Valid</td>, <td>Valid</td>, <td>Replace ST(1) with ST(1) ∗ log<sub>2</sub>(ST(0) + 1.0) and pop the register stack.</td>, <td rowspan="2">C1</td>, <td>Set to 0 if stack underflow occurred.</td>, <td>Set if result was rounded up; cleared otherwise.</td>, <td>C0, C2, C3</td>, <td>Undefined.</td>, <td>#IS</td>, <td>Stack underflow occurred.</td>, <td>#IA</td>, <td>Either operand is an SNaN value or unsupported format.</td>, <td>#D</td>, <td>Source operand is a denormal value.</td>, <td>#U</td>, <td>Result is too small for destination format.</td>, <td>#O</td>, <td>Result is too large for destination format.</td>, <td>#P</td>, <td>Value cannot be represented exactly in destination format.</td>, <td>#NM</td>, <td>CR0.EM[bit 2] or CR0.TS[bit 3] = 1.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>66 0F3A CF /r /ib GF2P8AFFINEINVQB xmm1, xmm2/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>GFNI</td>, <td>Computes inverse affine transformation in the finite field GF(2^8).</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8 (r)</td>, <td>NA</td>, <td>-</td>, <td>0</td>, <td>1</td>, <td>2</td>, <td>3</td>, <td>4</td>, <td>5</td>, <td>6</td>, <td>7</td>, <td>8</td>, <td>9</td>, <td>A</td>, <td>B</td>, <td>C</td>, <td>D</td>, <td>E</td>, <td>F</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>8D</td>, <td>F6</td>, <td>CB</td>, <td>52</td>, <td>7B</td>, <td>D1</td>, <td>E8</td>, <td>4F</td>, <td>29</td>, <td>C0</td>, <td>B0</td>, <td>E1</td>, <td>E5</td>, <td>C7</td>, <td>1</td>, <td>74</td>, <td>B4</td>, <td>AA</td>, <td>4B</td>, <td>99</td>, <td>2B</td>, <td>60</td>, <td>5F</td>, <td>58</td>, <td>3F</td>, <td>FD</td>, <td>CC</td>, <td>FF</td>, <td>40</td>, <td>EE</td>, <td>B2</td>, <td>2</td>, <td>3A</td>, <td>6E</td>, <td>5A</td>, <td>F1</td>, <td>55</td>, <td>4D</td>, <td>A8</td>, <td>C9</td>, <td>C1</td>, <td>A</td>, <td>98</td>, <td>15</td>, <td>30</td>, <td>44</td>, <td>A2</td>, <td>C2</td>, <td>3</td>, <td>2C</td>, <td>45</td>, <td>92</td>, <td>6C</td>, <td>F3</td>, <td>39</td>, <td>66</td>, <td>42</td>, <td>F2</td>, <td>35</td>, <td>20</td>, <td>6F</td>, <td>77</td>, <td>BB</td>, <td>59</td>, <td>19</td>, <td>4</td>, <td>1D</td>, <td>FE</td>, <td>37</td>, <td>67</td>, <td>2D</td>, <td>31</td>, <td>F5</td>, <td>69</td>, <td>A7</td>, <td>64</td>, <td>AB</td>, <td>13</td>, <td>54</td>, <td>25</td>, <td>E9</td>, <td>9</td>, <td>5</td>, <td>ED</td>, <td>5C</td>, <td>5</td>, <td>CA</td>, <td>4C</td>, <td>24</td>, <td>87</td>, <td>BF</td>, <td>18</td>, <td>3E</td>, <td>22</td>, <td>F0</td>, <td>51</td>, <td>EC</td>, <td>61</td>, <td>17</td>, <td>6</td>, <td>16</td>, <td>5E</td>, <td>AF</td>, <td>D3</td>, <td>49</td>, <td>A6</td>, <td>36</td>, <td>43</td>, <td>F4</td>, <td>47</td>, <td>91</td>, <td>DF</td>, <td>33</td>, <td>93</td>, <td>21</td>, <td>3B</td>, <td>7</td>, <td>79</td>, <td>B7</td>, <td>97</td>, <td>85</td>, <td>10</td>, <td>B5</td>, <td>BA</td>, <td>3C</td>, <td>B6</td>, <td>70</td>, <td>D0</td>, <td>6</td>, <td>A1</td>, <td>FA</td>, <td>81</td>, <td>82</td>, <td>8</td>, <td>83</td>, <td>7E</td>, <td>7F</td>, <td>80</td>, <td>96</td>, <td>73</td>, <td>BE</td>, <td>56</td>, <td>9B</td>, <td>9E</td>, <td>95</td>, <td>D9</td>, <td>F7</td>, <td>2</td>, <td>B9</td>, <td>A4</td>, <td>9</td>, <td>DE</td>, <td>6A</td>, <td>32</td>, <td>6D</td>, <td>D8</td>, <td>8A</td>, <td>84</td>, <td>72</td>, <td>2A</td>, <td>14</td>, <td>9F</td>, <td>88</td>, <td>F9</td>, <td>DC</td>, <td>89</td>, <td>9A</td>, <td>A</td>, <td>FB</td>, <td>7C</td>, <td>2E</td>, <td>C3</td>, <td>8F</td>, <td>B8</td>, <td>65</td>, <td>48</td>, <td>26</td>, <td>C8</td>, <td>12</td>, <td>4A</td>, <td>CE</td>, <td>E7</td>, <td>D2</td>, <td>62</td>, <td>B</td>, <td>C</td>, <td>E0</td>, <td>1F</td>, <td>EF</td>, <td>11</td>, <td>75</td>, <td>78</td>, <td>71</td>, <td>A5</td>, <td>8E</td>, <td>76</td>, <td>3D</td>, <td>BD</td>, <td>BC</td>, <td>86</td>, <td>57</td>, <td>C</td>, <td>B</td>, <td>28</td>, <td>2F</td>, <td>A3</td>, <td>DA</td>, <td>D4</td>, <td>E4</td>, <td>F</td>, <td>A9</td>, <td>27</td>, <td>53</td>, <td>4</td>, <td>1B</td>, <td>FC</td>, <td>AC</td>, <td>E6</td>, <td>D</td>, <td>7A</td>, <td>7</td>, <td>AE</td>, <td>63</td>, <td>C5</td>, <td>DB</td>, <td>E2</td>, <td>EA</td>, <td>94</td>, <td>8B</td>, <td>C4</td>, <td>D5</td>, <td>9D</td>, <td>F8</td>, <td>90</td>, <td>6B</td>, <td>E</td>, <td>B1</td>, <td>D</td>, <td>D6</td>, <td>EB</td>, <td>C6</td>, <td>E</td>, <td>CF</td>, <td>AD</td>, <td>8</td>, <td>4E</td>, <td>D7</td>, <td>E3</td>, <td>5D</td>, <td>50</td>, <td>1E</td>, <td>B3</td>, <td>F</td>, <td>5B</td>, <td>23</td>, <td>38</td>, <td>34</td>, <td>68</td>, <td>46</td>, <td>3</td>, <td>8C</td>, <td>DD</td>, <td>9C</td>, <td>7D</td>, <td>A0</td>, <td>CD</td>, <td>1A</td>, <td>41</td>, <td>1C</td>]

[<td>66 0F3A CE /r /ib GF2P8AFFINEQB xmm1, xmm2/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>GFNI</td>, <td>Computes affine transformation in the finite field GF(2^8).</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8 (r)</td>, <td>NA</td>]

[<td>66 0F38 CF /r GF2P8MULB xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>GFNI</td>, <td>Multiplies elements in the finite field GF(2^8).</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>66 0F 7C /<em>r</em> HADDPD <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE3</td>, <td>Horizontal add packed double-precision floating-point values from <em>xmm2/m128</em> to <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 7C /r VHADDPD xmm1,xmm2, xmm3/m128</td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Horizontal add packed double-precision floating-point values from xmm2 and xmm3/mem.</td>, <td>VEX.256.66.0F.WIG 7C /r VHADDPD ymm1, ymm2, ymm3/m256</td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Horizontal add packed double-precision floating-point values from ymm2 and ymm3/mem.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F2 0F 7C /<em>r</em> HADDPS <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE3</td>, <td>Horizontal add packed single-precision floating-point values from <em>xmm2/m128</em> to <em>xmm1</em>.</td>, <td>VEX.128.F2.0F.WIG 7C /r VHADDPS xmm1, xmm2, xmm3/m128</td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Horizontal add packed single-precision floating-point values from xmm2 and xmm3/mem.</td>, <td>VEX.256.F2.0F.WIG 7C /r VHADDPS ymm1, ymm2, ymm3/m256</td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Horizontal add packed single-precision floating-point values from ymm2 and ymm3/mem.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F4</td>, <td>HLT</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Halt</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>66 0F 7D /<em>r</em> HSUBPD <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE3</td>, <td>Horizontal subtract packed double-precision floating-point values from <em>xmm2/m128</em> to <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 7D /r VHSUBPD xmm1,xmm2, xmm3/m128</td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Horizontal subtract packed double-precision floating-point values from xmm2 and xmm3/mem.</td>, <td>VEX.256.66.0F.WIG 7D /r VHSUBPD ymm1, ymm2, ymm3/m256</td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Horizontal subtract packed double-precision floating-point values from ymm2 and ymm3/mem.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F2 0F 7D /<em>r</em> HSUBPS <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE3</td>, <td>Horizontal subtract packed single-precision floating-point values from <em>xmm2/m128</em> to <em>xmm1</em>.</td>, <td>VEX.128.F2.0F.WIG 7D /r VHSUBPS xmm1, xmm2, xmm3/m128</td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Horizontal subtract packed single-precision floating-point values from xmm2 and xmm3/mem.</td>, <td>VEX.256.F2.0F.WIG 7D /r VHSUBPS ymm1, ymm2, ymm3/m256</td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Horizontal subtract packed single-precision floating-point values from ymm2 and ymm3/mem.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F6 /7</td>, <td>IDIV <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide AX by <em>r/m</em>8, with result stored in: AL ← Quotient, AH ← Remainder.</td>, <td>REX + F6 /7</td>, <td>IDIV <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide AX by <em>r/m</em>8, with result stored in AL ← Quotient, AH ← Remainder.</td>, <td>F7 /7</td>, <td>IDIV <em>r/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide DX:AX by <em>r/m16</em>, with result stored in AX ← Quotient, DX ← Remainder.</td>, <td>F7 /7</td>, <td>IDIV <em>r/m32</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide EDX:EAX by <em>r/m32</em>, with result stored in EAX ← Quotient, EDX ← Remainder.</td>, <td>REX.W + F7 /7</td>, <td>IDIV <em>r/m64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide RDX:RAX by <em>r/m64</em>, with result stored in RAX ← Quotient, RDX ← Remainder.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>Word/byte Doubleword/word Quadword/doubleword Doublequadword/ quadword</td>, <td>AX DX:AX EDX:EAX RDX:RAX</td>, <td>r/m8 r/m16 r/m32 r/m64</td>, <td>AL AX EAX RAX</td>, <td>AH DX EDX RDX</td>, <td>−128 to +127 −32,768 to +32,767 −2<sup>31</sup> to 2<sup>31</sup> − 1 −2<sup>63</sup> to 2<sup>63</sup> − 1</td>, <td rowspan="2">#DE</td>, <td>If the source operand (divisor) is 0.</td>, <td>The signed result (quotient) is too large for the destination.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#DE</td>, <td>If the source operand (divisor) is 0.</td>, <td>The signed result (quotient) is too large for the destination.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#DE</td>, <td>If the source operand (divisor) is 0.</td>, <td>The signed result (quotient) is too large for the destination.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td rowspan="2">#DE</td>, <td>If the source operand (divisor) is 0</td>, <td>If the quotient is too large for the designated register.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>F6 /5</td>, <td>IMUL <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>AX← AL ∗ <em>r/m</em> byte.</td>, <td>F7 /5</td>, <td>IMUL <em>r/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>DX:AX ← AX ∗ <em>r/m</em> word.</td>, <td>F7 /5</td>, <td>IMUL <em>r/m32</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>EDX:EAX ← EAX ∗ <em>r/m</em>32.</td>, <td>REX.W + F7 /5</td>, <td>IMUL <em>r/m64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>RDX:RAX ← RAX ∗ <em>r/m</em>64.</td>, <td>0F AF /<em>r</em></td>, <td>IMUL <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>word register ← word register ∗ <em>r/m</em>16.</td>, <td>0F AF /<em>r</em></td>, <td>IMUL <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>doubleword register ← doubleword register ∗ <em>r/m32.</em></td>, <td>REX.W + 0F AF /<em>r</em></td>, <td>IMUL <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Quadword register ← Quadword register ∗ <em>r/m64</em>.</td>, <td>6B /<em>r ib</em></td>, <td>IMUL <em>r16, r/m16, imm8</em></td>, <td>RMI</td>, <td>Valid</td>, <td>Valid</td>, <td>word register ← <em>r/m16</em> ∗ sign-extended immediate byte.</td>, <td>6B /<em>r ib</em></td>, <td>IMUL <em>r32, r/m32, imm8</em></td>, <td>RMI</td>, <td>Valid</td>, <td>Valid</td>, <td>doubleword register ← <em>r/m32</em> ∗ sign-extended immediate byte.</td>, <td>REX.W + 6B /<em>r ib</em></td>, <td>IMUL <em>r64, r/m64, imm8</em></td>, <td>RMI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Quadword register ← <em>r/m64</em> ∗ sign-extended immediate byte.</td>, <td>69 /<em>r iw</em></td>, <td>IMUL <em>r16, r/m16, imm16</em></td>, <td>RMI</td>, <td>Valid</td>, <td>Valid</td>, <td>word register ← <em>r/m16</em> ∗ immediate word.</td>, <td>69 /<em>r id</em></td>, <td>IMUL <em>r32, r/m32, imm32</em></td>, <td>RMI</td>, <td>Valid</td>, <td>Valid</td>, <td>doubleword register ← <em>r/m32</em> ∗ immediate doubleword.</td>, <td>REX.W + 69 /<em>r id</em></td>, <td>IMUL <em>r64, r/m64, imm32</em></td>, <td>RMI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Quadword register ← <em>r/m64</em> ∗ immediate doubleword.</td>, <td colspan="6"><strong>NOTES:</strong> * In64-bitmode,r/m8cannotbeencodedtoaccessthefollowingbyteregistersifaREXprefixisused:AH,BH,CH,DH.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r, w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RMI</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8/16/32</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>E4 <em>ib</em></td>, <td>IN AL, i<em>mm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Input byte from <em>imm8</em> I/O port address into AL.</td>, <td>E5 <em>ib</em></td>, <td>IN AX, i<em>mm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Input word from <em>imm8</em> I/O port address into AX.</td>, <td>E5 <em>ib</em></td>, <td>IN EAX, i<em>mm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Input dword from <em>imm8</em> I/O port address into EAX.</td>, <td>EC</td>, <td>IN AL,DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input byte from I/O port in DX into AL.</td>, <td>ED</td>, <td>IN AX,DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input word from I/O port in DX into AX.</td>, <td>ED</td>, <td>IN EAX,DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input doubleword from I/O port in DX into EAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>I</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If any of the I/O permission bits in the TSS for the I/O port being accessed is 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>FE /0</td>, <td>INC <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Increment <em>r/m</em> byte by 1.</td>, <td>REX + FE /0</td>, <td>INC <em>r/m8</em><sup>*</sup></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Increment <em>r/m</em> byte by 1.</td>, <td>FF /0</td>, <td>INC <em>r/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Increment <em>r/m</em> word by 1.</td>, <td>FF /0</td>, <td>INC <em>r/m32</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Increment <em>r/m</em> doubleword by 1.</td>, <td>REX.W + FF /0</td>, <td>INC <em>r/m64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Increment <em>r/m</em> quadword by 1.</td>, <td>40+ <em>rw<sup>**</sup></em></td>, <td>INC <em>r16</em></td>, <td>O</td>, <td>N.E.</td>, <td>Valid</td>, <td>Increment word register by 1.</td>, <td>40+ <em>rd</em></td>, <td>INC <em>r32</em></td>, <td>O</td>, <td>N.E.</td>, <td>Valid</td>, <td>Increment doubleword register by 1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r, w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>O</td>, <td>opcode + rd (r, w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination operand is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULLsegment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>6C</td>, <td>INS <em>m8</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input byte from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.*</td>, <td>6D</td>, <td>INS <em>m16</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input word from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.<sup>1</sup></td>, <td>6D</td>, <td>INS <em>m32</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input doubleword from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.<sup>1</sup></td>, <td>6C</td>, <td>INSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input byte from I/O port specified in DX into memory location specified with ES:(E)DI or RDI.<sup>1</sup></td>, <td>6D</td>, <td>INSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input word from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.<sup>1</sup></td>, <td>6D</td>, <td>INSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input doubleword from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.<sup>1</sup></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If an illegal memory operand effective address in the ES segments is given.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If any of the I/O permission bits in the TSS for the I/O port being accessed is 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>6C</td>, <td>INS <em>m8</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input byte from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.*</td>, <td>6D</td>, <td>INS <em>m16</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input word from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.<sup>1</sup></td>, <td>6D</td>, <td>INS <em>m32</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input doubleword from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.<sup>1</sup></td>, <td>6C</td>, <td>INSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input byte from I/O port specified in DX into memory location specified with ES:(E)DI or RDI.<sup>1</sup></td>, <td>6D</td>, <td>INSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input word from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.<sup>1</sup></td>, <td>6D</td>, <td>INSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input doubleword from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.<sup>1</sup></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If an illegal memory operand effective address in the ES segments is given.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If any of the I/O permission bits in the TSS for the I/O port being accessed is 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>6C</td>, <td>INS <em>m8</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input byte from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.*</td>, <td>6D</td>, <td>INS <em>m16</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input word from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.<sup>1</sup></td>, <td>6D</td>, <td>INS <em>m32</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input doubleword from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.<sup>1</sup></td>, <td>6C</td>, <td>INSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input byte from I/O port specified in DX into memory location specified with ES:(E)DI or RDI.<sup>1</sup></td>, <td>6D</td>, <td>INSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input word from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.<sup>1</sup></td>, <td>6D</td>, <td>INSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input doubleword from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.<sup>1</sup></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If an illegal memory operand effective address in the ES segments is given.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If any of the I/O permission bits in the TSS for the I/O port being accessed is 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>66 0F 3A 21 /r ib INSERTPS xmm1, xmm2/m32, imm8</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Insert a single-precision floating-point value selected by imm8 from xmm2/m32 into xmm1 at the specified destination element specified by imm8 and zero out destination elements in xmm1 as indicated in imm8.</td>, <td>VEX.128.66.0F3A.WIG 21 /r ib VINSERTPS xmm1, xmm2, xmm3/m32, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Insert a single-precision floating-point value selected by imm8 from xmm3/m32 and merge with values in xmm2 at the specified destination element specified by imm8 and write out the result and zero out destination elements in xmm1 as indicated in imm8.</td>, <td>EVEX.128.66.0F3A.W0 21 /r ib VINSERTPS xmm1, xmm2, xmm3/m32, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert a single-precision floating-point value selected by imm8 from xmm3/m32 and merge with values in xmm2 at the specified destination element specified by imm8 and write out the result and zero out destination elements in xmm1 as indicated in imm8.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>#UD</td>, <td>If VEX.L = 0.</td>]

[<td>6C</td>, <td>INS <em>m8</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input byte from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.*</td>, <td>6D</td>, <td>INS <em>m16</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input word from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.<sup>1</sup></td>, <td>6D</td>, <td>INS <em>m32</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input doubleword from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.<sup>1</sup></td>, <td>6C</td>, <td>INSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input byte from I/O port specified in DX into memory location specified with ES:(E)DI or RDI.<sup>1</sup></td>, <td>6D</td>, <td>INSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input word from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.<sup>1</sup></td>, <td>6D</td>, <td>INSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input doubleword from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.<sup>1</sup></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If an illegal memory operand effective address in the ES segments is given.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If any of the I/O permission bits in the TSS for the I/O port being accessed is 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>CC</td>, <td>INT3</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Generate breakpoint trap.</td>, <td>CD <em>ib</em></td>, <td>INT <em>imm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Generate software interrupt with vector specified by immediate byte.</td>, <td>CE</td>, <td>INTO</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Generate overflow trap if overflow flag is 1.</td>, <td>F1</td>, <td>INT1</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Generate debug trap.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>I</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td><strong>PE</strong></td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td><strong>VM</strong></td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td><strong>IOPL</strong></td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>&lt;3</td>, <td>=3</td>, <td><strong>DPL/CPL RELATIONSHIP</strong></td>, <td>–</td>, <td>DPL&lt; CPL</td>, <td>–</td>, <td>DPL&gt; CPL</td>, <td>DPL= CPL or C</td>, <td>DPL&lt; CPL &amp; NC</td>, <td>–</td>, <td>–</td>, <td><strong>INTERRUPT TYPE</strong></td>, <td>–</td>, <td>S/W</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td><strong>GATE TYPE</strong></td>, <td>–</td>, <td>–</td>, <td>Task</td>, <td>Trap or Interrupt</td>, <td>Trap or Interrupt</td>, <td>Trap or Interrupt</td>, <td>Trap or Interrupt</td>, <td>Trap or Interrupt</td>, <td><strong>REAL-ADDRESS-MODE</strong></td>, <td>Y</td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td><strong>PROTECTED-MODE</strong></td>, <td></td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td><strong>TRAP-OR-INTERRUPTGATE</strong></td>, <td></td>, <td></td>, <td></td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td><strong>INTER-PRIVILEGE-LEVELINTERRUPT</strong></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td>Y</td>, <td></td>, <td></td>, <td><strong>INTRA-PRIVILEGE-LEVELINTERRUPT</strong></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td>Y</td>, <td></td>, <td></td>, <td></td>, <td><strong>INTERRUPT-FROM-VIRTUAL-8086-MODE</strong></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td>Y</td>, <td><strong>TASK-GATE</strong></td>, <td></td>, <td></td>, <td>Y</td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td><strong>#GP</strong></td>, <td></td>, <td>Y</td>, <td></td>, <td>Y</td>, <td></td>, <td></td>, <td>Y</td>, <td></td>, <td rowspan="9">#GP(error_code)</td>, <td>If the instruction pointer in the IDT or in the interrupt, trap, or task gate is beyond the code segment limits.</td>, <td>If the segment selector in the interrupt, trap, or task gate is NULL.</td>, <td>If an interrupt, trap, or task gate, code segment, or TSS segment selector index is outside its descriptor table limits.</td>, <td>If the vector selects a descriptor outside the IDT limits.</td>, <td>If an IDT descriptor is not an interrupt, trap, or task gate.</td>, <td>If an interrupt is generated by the INT n, INT3, or INTO instruction and the DPL of an interrupt, trap, or task gate is less than the CPL.</td>, <td>If the segment selector in an interrupt or trap gate does not point to a segment descriptor for a code segment.</td>, <td>If the segment selector for a TSS has its local/global bit set for local.</td>, <td>If a TSS segment descriptor specifies that the TSS is busy or not available.</td>, <td rowspan="3">#SS(error_code)</td>, <td>If pushing the return address, flags, or error code onto the stack exceeds the bounds of the stack segment and no stack switch occurs.</td>, <td>If the SS register is being loaded and the segment pointed to is marked not present.</td>, <td>If pushing the return address, flags, error code, or stack segment pointer exceeds the bounds of the new stack segment when a stack switch occurs.</td>, <td>#NP(error_code)</td>, <td>If code segment, interrupt gate, trap gate, task gate, or TSS is not present.</td>, <td rowspan="5">#TS(error_code)</td>, <td>If the RPL of the stack segment selector in the TSS is not equal to the DPL of the code segment being accessed by the interrupt or trap gate.</td>, <td>If DPL of the stack segment descriptor pointed to by the stack segment selector in the TSS is not equal to the DPL of the code segment descriptor for the interrupt or trap gate.</td>, <td>If the stack segment selector in the TSS is NULL.</td>, <td>If the stack segment for the TSS is not a writable data segment.</td>, <td>If segment-selector index for stack segment is outside descriptor table limits.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#AC(EXT)</td>, <td>If alignment checking is enabled, the gate DPL is 3, and a stack push is unaligned.</td>, <td rowspan="2">#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the interrupt vector number is outside the IDT limits.</td>, <td rowspan="2">#SS</td>, <td>If stack limit violation on push.</td>, <td>If pushing the return address, flags, or error code onto the stack exceeds the bounds of the stack segment.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="9">#GP(error_code)</td>, <td>(For INT <em>n,</em> INTO, or BOUND instruction) If the IOPL is less than 3 or the DPL of the interrupt, trap, or task gate is not equal to 3.</td>, <td>If the instruction pointer in the IDT or in the interrupt, trap, or task gate is beyond the code segment limits.</td>, <td>If the segment selector in the interrupt, trap, or task gate is NULL.</td>, <td>If a interrupt gate, trap gate, task gate, code segment, or TSS segment selector index is outside its descriptor table limits.</td>, <td>If the vector selects a descriptor outside the IDT limits.</td>, <td>If an IDT descriptor is not an interrupt, trap, or task gate.</td>, <td>If an interrupt is generated by INT n, INT3, or INTO and the DPL of an interrupt, trap, or task gate is less than the CPL.</td>, <td>If the segment selector in an interrupt or trap gate does not point to a segment descriptor for a code segment.</td>, <td>If the segment selector for a TSS has its local/global bit set for local.</td>, <td rowspan="2">#SS(error_code)</td>, <td>If the SS register is being loaded and the segment pointed to is marked not present.</td>, <td>If pushing the return address, flags, error code, stack segment pointer, or data segments exceeds the bounds of the stack segment.</td>, <td>#NP(error_code)</td>, <td>If code segment, interrupt gate, trap gate, task gate, or TSS is not present.</td>, <td rowspan="5">#TS(error_code)</td>, <td>If the RPL of the stack segment selector in the TSS is not equal to the DPL of the code segment being accessed by the interrupt or trap gate.</td>, <td>If DPL of the stack segment descriptor for the TSS’s stack segment is not equal to the DPL of the code segment descriptor for the interrupt or trap gate.</td>, <td>If the stack segment selector in the TSS is NULL.</td>, <td>If the stack segment for the TSS is not a writable data segment.</td>, <td>If segment-selector index for stack segment is outside descriptor table limits.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#OF</td>, <td>If the INTO instruction is executed and the OF flag is set.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#AC(EXT)</td>, <td>If alignment checking is enabled, the gate DPL is 3, and a stack push is unaligned.</td>, <td rowspan="10">#GP(error_code)</td>, <td>If the instruction pointer in the 64-bit interrupt gate or trap gate is non-canonical.</td>, <td>If the segment selector in the 64-bit interrupt or trap gate is NULL.</td>, <td>If the vector selects a descriptor outside the IDT limits.</td>, <td>If the vector points to a gate which is in non-canonical space.</td>, <td>If the vector points to a descriptor which is not a 64-bit interrupt gate or a 64-bit trap gate.</td>, <td>If the descriptor pointed to by the gate selector is outside the descriptor table limit.</td>, <td>If the descriptor pointed to by the gate selector is in non-canonical space.</td>, <td>If the descriptor pointed to by the gate selector is not a code segment.</td>, <td>If the descriptor pointed to by the gate selector doesn’t have the L-bit set, or has both the L-bit and D-bit set.</td>, <td>If the descriptor pointed to by the gate selector has DPL &gt; CPL.</td>, <td rowspan="2">#SS(error_code)</td>, <td>If a push of the old EFLAGS, CS selector, EIP, or error code is in non-canonical space with no stack switch.</td>, <td>If a push of the old SS selector, ESP, EFLAGS, CS selector, EIP, or error code is in non-canonical space on a stack switch (either CPL change or no-CPL with IST).</td>, <td>#NP(error_code)</td>, <td>If the 64-bit interrupt-gate, 64-bit trap-gate, or code segment is not present.</td>, <td rowspan="2">#TS(error_code)</td>, <td>If an attempt to load RSP from the TSS causes an access to non-canonical space.</td>, <td>If the RSP from the TSS is outside descriptor table limits.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#AC(EXT)</td>, <td>If alignment checking is enabled, the gate DPL is 3, and a stack push is unaligned.</td>]

[<td>CC</td>, <td>INT3</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Generate breakpoint trap.</td>, <td>CD <em>ib</em></td>, <td>INT <em>imm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Generate software interrupt with vector specified by immediate byte.</td>, <td>CE</td>, <td>INTO</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Generate overflow trap if overflow flag is 1.</td>, <td>F1</td>, <td>INT1</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Generate debug trap.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>I</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td><strong>PE</strong></td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td><strong>VM</strong></td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td><strong>IOPL</strong></td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>&lt;3</td>, <td>=3</td>, <td><strong>DPL/CPL RELATIONSHIP</strong></td>, <td>–</td>, <td>DPL&lt; CPL</td>, <td>–</td>, <td>DPL&gt; CPL</td>, <td>DPL= CPL or C</td>, <td>DPL&lt; CPL &amp; NC</td>, <td>–</td>, <td>–</td>, <td><strong>INTERRUPT TYPE</strong></td>, <td>–</td>, <td>S/W</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td><strong>GATE TYPE</strong></td>, <td>–</td>, <td>–</td>, <td>Task</td>, <td>Trap or Interrupt</td>, <td>Trap or Interrupt</td>, <td>Trap or Interrupt</td>, <td>Trap or Interrupt</td>, <td>Trap or Interrupt</td>, <td><strong>REAL-ADDRESS-MODE</strong></td>, <td>Y</td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td><strong>PROTECTED-MODE</strong></td>, <td></td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td><strong>TRAP-OR-INTERRUPTGATE</strong></td>, <td></td>, <td></td>, <td></td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td><strong>INTER-PRIVILEGE-LEVELINTERRUPT</strong></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td>Y</td>, <td></td>, <td></td>, <td><strong>INTRA-PRIVILEGE-LEVELINTERRUPT</strong></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td>Y</td>, <td></td>, <td></td>, <td></td>, <td><strong>INTERRUPT-FROM-VIRTUAL-8086-MODE</strong></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td>Y</td>, <td><strong>TASK-GATE</strong></td>, <td></td>, <td></td>, <td>Y</td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td><strong>#GP</strong></td>, <td></td>, <td>Y</td>, <td></td>, <td>Y</td>, <td></td>, <td></td>, <td>Y</td>, <td></td>, <td rowspan="9">#GP(error_code)</td>, <td>If the instruction pointer in the IDT or in the interrupt, trap, or task gate is beyond the code segment limits.</td>, <td>If the segment selector in the interrupt, trap, or task gate is NULL.</td>, <td>If an interrupt, trap, or task gate, code segment, or TSS segment selector index is outside its descriptor table limits.</td>, <td>If the vector selects a descriptor outside the IDT limits.</td>, <td>If an IDT descriptor is not an interrupt, trap, or task gate.</td>, <td>If an interrupt is generated by the INT n, INT3, or INTO instruction and the DPL of an interrupt, trap, or task gate is less than the CPL.</td>, <td>If the segment selector in an interrupt or trap gate does not point to a segment descriptor for a code segment.</td>, <td>If the segment selector for a TSS has its local/global bit set for local.</td>, <td>If a TSS segment descriptor specifies that the TSS is busy or not available.</td>, <td rowspan="3">#SS(error_code)</td>, <td>If pushing the return address, flags, or error code onto the stack exceeds the bounds of the stack segment and no stack switch occurs.</td>, <td>If the SS register is being loaded and the segment pointed to is marked not present.</td>, <td>If pushing the return address, flags, error code, or stack segment pointer exceeds the bounds of the new stack segment when a stack switch occurs.</td>, <td>#NP(error_code)</td>, <td>If code segment, interrupt gate, trap gate, task gate, or TSS is not present.</td>, <td rowspan="5">#TS(error_code)</td>, <td>If the RPL of the stack segment selector in the TSS is not equal to the DPL of the code segment being accessed by the interrupt or trap gate.</td>, <td>If DPL of the stack segment descriptor pointed to by the stack segment selector in the TSS is not equal to the DPL of the code segment descriptor for the interrupt or trap gate.</td>, <td>If the stack segment selector in the TSS is NULL.</td>, <td>If the stack segment for the TSS is not a writable data segment.</td>, <td>If segment-selector index for stack segment is outside descriptor table limits.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#AC(EXT)</td>, <td>If alignment checking is enabled, the gate DPL is 3, and a stack push is unaligned.</td>, <td rowspan="2">#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the interrupt vector number is outside the IDT limits.</td>, <td rowspan="2">#SS</td>, <td>If stack limit violation on push.</td>, <td>If pushing the return address, flags, or error code onto the stack exceeds the bounds of the stack segment.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="9">#GP(error_code)</td>, <td>(For INT <em>n,</em> INTO, or BOUND instruction) If the IOPL is less than 3 or the DPL of the interrupt, trap, or task gate is not equal to 3.</td>, <td>If the instruction pointer in the IDT or in the interrupt, trap, or task gate is beyond the code segment limits.</td>, <td>If the segment selector in the interrupt, trap, or task gate is NULL.</td>, <td>If a interrupt gate, trap gate, task gate, code segment, or TSS segment selector index is outside its descriptor table limits.</td>, <td>If the vector selects a descriptor outside the IDT limits.</td>, <td>If an IDT descriptor is not an interrupt, trap, or task gate.</td>, <td>If an interrupt is generated by INT n, INT3, or INTO and the DPL of an interrupt, trap, or task gate is less than the CPL.</td>, <td>If the segment selector in an interrupt or trap gate does not point to a segment descriptor for a code segment.</td>, <td>If the segment selector for a TSS has its local/global bit set for local.</td>, <td rowspan="2">#SS(error_code)</td>, <td>If the SS register is being loaded and the segment pointed to is marked not present.</td>, <td>If pushing the return address, flags, error code, stack segment pointer, or data segments exceeds the bounds of the stack segment.</td>, <td>#NP(error_code)</td>, <td>If code segment, interrupt gate, trap gate, task gate, or TSS is not present.</td>, <td rowspan="5">#TS(error_code)</td>, <td>If the RPL of the stack segment selector in the TSS is not equal to the DPL of the code segment being accessed by the interrupt or trap gate.</td>, <td>If DPL of the stack segment descriptor for the TSS’s stack segment is not equal to the DPL of the code segment descriptor for the interrupt or trap gate.</td>, <td>If the stack segment selector in the TSS is NULL.</td>, <td>If the stack segment for the TSS is not a writable data segment.</td>, <td>If segment-selector index for stack segment is outside descriptor table limits.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#OF</td>, <td>If the INTO instruction is executed and the OF flag is set.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#AC(EXT)</td>, <td>If alignment checking is enabled, the gate DPL is 3, and a stack push is unaligned.</td>, <td rowspan="10">#GP(error_code)</td>, <td>If the instruction pointer in the 64-bit interrupt gate or trap gate is non-canonical.</td>, <td>If the segment selector in the 64-bit interrupt or trap gate is NULL.</td>, <td>If the vector selects a descriptor outside the IDT limits.</td>, <td>If the vector points to a gate which is in non-canonical space.</td>, <td>If the vector points to a descriptor which is not a 64-bit interrupt gate or a 64-bit trap gate.</td>, <td>If the descriptor pointed to by the gate selector is outside the descriptor table limit.</td>, <td>If the descriptor pointed to by the gate selector is in non-canonical space.</td>, <td>If the descriptor pointed to by the gate selector is not a code segment.</td>, <td>If the descriptor pointed to by the gate selector doesn’t have the L-bit set, or has both the L-bit and D-bit set.</td>, <td>If the descriptor pointed to by the gate selector has DPL &gt; CPL.</td>, <td rowspan="2">#SS(error_code)</td>, <td>If a push of the old EFLAGS, CS selector, EIP, or error code is in non-canonical space with no stack switch.</td>, <td>If a push of the old SS selector, ESP, EFLAGS, CS selector, EIP, or error code is in non-canonical space on a stack switch (either CPL change or no-CPL with IST).</td>, <td>#NP(error_code)</td>, <td>If the 64-bit interrupt-gate, 64-bit trap-gate, or code segment is not present.</td>, <td rowspan="2">#TS(error_code)</td>, <td>If an attempt to load RSP from the TSS causes an access to non-canonical space.</td>, <td>If the RSP from the TSS is outside descriptor table limits.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#AC(EXT)</td>, <td>If alignment checking is enabled, the gate DPL is 3, and a stack push is unaligned.</td>]

[<td>CC</td>, <td>INT3</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Generate breakpoint trap.</td>, <td>CD <em>ib</em></td>, <td>INT <em>imm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Generate software interrupt with vector specified by immediate byte.</td>, <td>CE</td>, <td>INTO</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Generate overflow trap if overflow flag is 1.</td>, <td>F1</td>, <td>INT1</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Generate debug trap.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>I</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td><strong>PE</strong></td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td><strong>VM</strong></td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td><strong>IOPL</strong></td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>&lt;3</td>, <td>=3</td>, <td><strong>DPL/CPL RELATIONSHIP</strong></td>, <td>–</td>, <td>DPL&lt; CPL</td>, <td>–</td>, <td>DPL&gt; CPL</td>, <td>DPL= CPL or C</td>, <td>DPL&lt; CPL &amp; NC</td>, <td>–</td>, <td>–</td>, <td><strong>INTERRUPT TYPE</strong></td>, <td>–</td>, <td>S/W</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td><strong>GATE TYPE</strong></td>, <td>–</td>, <td>–</td>, <td>Task</td>, <td>Trap or Interrupt</td>, <td>Trap or Interrupt</td>, <td>Trap or Interrupt</td>, <td>Trap or Interrupt</td>, <td>Trap or Interrupt</td>, <td><strong>REAL-ADDRESS-MODE</strong></td>, <td>Y</td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td><strong>PROTECTED-MODE</strong></td>, <td></td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td><strong>TRAP-OR-INTERRUPTGATE</strong></td>, <td></td>, <td></td>, <td></td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td><strong>INTER-PRIVILEGE-LEVELINTERRUPT</strong></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td>Y</td>, <td></td>, <td></td>, <td><strong>INTRA-PRIVILEGE-LEVELINTERRUPT</strong></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td>Y</td>, <td></td>, <td></td>, <td></td>, <td><strong>INTERRUPT-FROM-VIRTUAL-8086-MODE</strong></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td>Y</td>, <td><strong>TASK-GATE</strong></td>, <td></td>, <td></td>, <td>Y</td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td><strong>#GP</strong></td>, <td></td>, <td>Y</td>, <td></td>, <td>Y</td>, <td></td>, <td></td>, <td>Y</td>, <td></td>, <td rowspan="9">#GP(error_code)</td>, <td>If the instruction pointer in the IDT or in the interrupt, trap, or task gate is beyond the code segment limits.</td>, <td>If the segment selector in the interrupt, trap, or task gate is NULL.</td>, <td>If an interrupt, trap, or task gate, code segment, or TSS segment selector index is outside its descriptor table limits.</td>, <td>If the vector selects a descriptor outside the IDT limits.</td>, <td>If an IDT descriptor is not an interrupt, trap, or task gate.</td>, <td>If an interrupt is generated by the INT n, INT3, or INTO instruction and the DPL of an interrupt, trap, or task gate is less than the CPL.</td>, <td>If the segment selector in an interrupt or trap gate does not point to a segment descriptor for a code segment.</td>, <td>If the segment selector for a TSS has its local/global bit set for local.</td>, <td>If a TSS segment descriptor specifies that the TSS is busy or not available.</td>, <td rowspan="3">#SS(error_code)</td>, <td>If pushing the return address, flags, or error code onto the stack exceeds the bounds of the stack segment and no stack switch occurs.</td>, <td>If the SS register is being loaded and the segment pointed to is marked not present.</td>, <td>If pushing the return address, flags, error code, or stack segment pointer exceeds the bounds of the new stack segment when a stack switch occurs.</td>, <td>#NP(error_code)</td>, <td>If code segment, interrupt gate, trap gate, task gate, or TSS is not present.</td>, <td rowspan="5">#TS(error_code)</td>, <td>If the RPL of the stack segment selector in the TSS is not equal to the DPL of the code segment being accessed by the interrupt or trap gate.</td>, <td>If DPL of the stack segment descriptor pointed to by the stack segment selector in the TSS is not equal to the DPL of the code segment descriptor for the interrupt or trap gate.</td>, <td>If the stack segment selector in the TSS is NULL.</td>, <td>If the stack segment for the TSS is not a writable data segment.</td>, <td>If segment-selector index for stack segment is outside descriptor table limits.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#AC(EXT)</td>, <td>If alignment checking is enabled, the gate DPL is 3, and a stack push is unaligned.</td>, <td rowspan="2">#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the interrupt vector number is outside the IDT limits.</td>, <td rowspan="2">#SS</td>, <td>If stack limit violation on push.</td>, <td>If pushing the return address, flags, or error code onto the stack exceeds the bounds of the stack segment.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="9">#GP(error_code)</td>, <td>(For INT <em>n,</em> INTO, or BOUND instruction) If the IOPL is less than 3 or the DPL of the interrupt, trap, or task gate is not equal to 3.</td>, <td>If the instruction pointer in the IDT or in the interrupt, trap, or task gate is beyond the code segment limits.</td>, <td>If the segment selector in the interrupt, trap, or task gate is NULL.</td>, <td>If a interrupt gate, trap gate, task gate, code segment, or TSS segment selector index is outside its descriptor table limits.</td>, <td>If the vector selects a descriptor outside the IDT limits.</td>, <td>If an IDT descriptor is not an interrupt, trap, or task gate.</td>, <td>If an interrupt is generated by INT n, INT3, or INTO and the DPL of an interrupt, trap, or task gate is less than the CPL.</td>, <td>If the segment selector in an interrupt or trap gate does not point to a segment descriptor for a code segment.</td>, <td>If the segment selector for a TSS has its local/global bit set for local.</td>, <td rowspan="2">#SS(error_code)</td>, <td>If the SS register is being loaded and the segment pointed to is marked not present.</td>, <td>If pushing the return address, flags, error code, stack segment pointer, or data segments exceeds the bounds of the stack segment.</td>, <td>#NP(error_code)</td>, <td>If code segment, interrupt gate, trap gate, task gate, or TSS is not present.</td>, <td rowspan="5">#TS(error_code)</td>, <td>If the RPL of the stack segment selector in the TSS is not equal to the DPL of the code segment being accessed by the interrupt or trap gate.</td>, <td>If DPL of the stack segment descriptor for the TSS’s stack segment is not equal to the DPL of the code segment descriptor for the interrupt or trap gate.</td>, <td>If the stack segment selector in the TSS is NULL.</td>, <td>If the stack segment for the TSS is not a writable data segment.</td>, <td>If segment-selector index for stack segment is outside descriptor table limits.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#OF</td>, <td>If the INTO instruction is executed and the OF flag is set.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#AC(EXT)</td>, <td>If alignment checking is enabled, the gate DPL is 3, and a stack push is unaligned.</td>, <td rowspan="10">#GP(error_code)</td>, <td>If the instruction pointer in the 64-bit interrupt gate or trap gate is non-canonical.</td>, <td>If the segment selector in the 64-bit interrupt or trap gate is NULL.</td>, <td>If the vector selects a descriptor outside the IDT limits.</td>, <td>If the vector points to a gate which is in non-canonical space.</td>, <td>If the vector points to a descriptor which is not a 64-bit interrupt gate or a 64-bit trap gate.</td>, <td>If the descriptor pointed to by the gate selector is outside the descriptor table limit.</td>, <td>If the descriptor pointed to by the gate selector is in non-canonical space.</td>, <td>If the descriptor pointed to by the gate selector is not a code segment.</td>, <td>If the descriptor pointed to by the gate selector doesn’t have the L-bit set, or has both the L-bit and D-bit set.</td>, <td>If the descriptor pointed to by the gate selector has DPL &gt; CPL.</td>, <td rowspan="2">#SS(error_code)</td>, <td>If a push of the old EFLAGS, CS selector, EIP, or error code is in non-canonical space with no stack switch.</td>, <td>If a push of the old SS selector, ESP, EFLAGS, CS selector, EIP, or error code is in non-canonical space on a stack switch (either CPL change or no-CPL with IST).</td>, <td>#NP(error_code)</td>, <td>If the 64-bit interrupt-gate, 64-bit trap-gate, or code segment is not present.</td>, <td rowspan="2">#TS(error_code)</td>, <td>If an attempt to load RSP from the TSS causes an access to non-canonical space.</td>, <td>If the RSP from the TSS is outside descriptor table limits.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#AC(EXT)</td>, <td>If alignment checking is enabled, the gate DPL is 3, and a stack push is unaligned.</td>]

[<td>CC</td>, <td>INT3</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Generate breakpoint trap.</td>, <td>CD <em>ib</em></td>, <td>INT <em>imm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Generate software interrupt with vector specified by immediate byte.</td>, <td>CE</td>, <td>INTO</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Generate overflow trap if overflow flag is 1.</td>, <td>F1</td>, <td>INT1</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Generate debug trap.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>I</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td><strong>PE</strong></td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td><strong>VM</strong></td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td><strong>IOPL</strong></td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>&lt;3</td>, <td>=3</td>, <td><strong>DPL/CPL RELATIONSHIP</strong></td>, <td>–</td>, <td>DPL&lt; CPL</td>, <td>–</td>, <td>DPL&gt; CPL</td>, <td>DPL= CPL or C</td>, <td>DPL&lt; CPL &amp; NC</td>, <td>–</td>, <td>–</td>, <td><strong>INTERRUPT TYPE</strong></td>, <td>–</td>, <td>S/W</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td>–</td>, <td><strong>GATE TYPE</strong></td>, <td>–</td>, <td>–</td>, <td>Task</td>, <td>Trap or Interrupt</td>, <td>Trap or Interrupt</td>, <td>Trap or Interrupt</td>, <td>Trap or Interrupt</td>, <td>Trap or Interrupt</td>, <td><strong>REAL-ADDRESS-MODE</strong></td>, <td>Y</td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td><strong>PROTECTED-MODE</strong></td>, <td></td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td><strong>TRAP-OR-INTERRUPTGATE</strong></td>, <td></td>, <td></td>, <td></td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td>Y</td>, <td><strong>INTER-PRIVILEGE-LEVELINTERRUPT</strong></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td>Y</td>, <td></td>, <td></td>, <td><strong>INTRA-PRIVILEGE-LEVELINTERRUPT</strong></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td>Y</td>, <td></td>, <td></td>, <td></td>, <td><strong>INTERRUPT-FROM-VIRTUAL-8086-MODE</strong></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td>Y</td>, <td><strong>TASK-GATE</strong></td>, <td></td>, <td></td>, <td>Y</td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td><strong>#GP</strong></td>, <td></td>, <td>Y</td>, <td></td>, <td>Y</td>, <td></td>, <td></td>, <td>Y</td>, <td></td>, <td rowspan="9">#GP(error_code)</td>, <td>If the instruction pointer in the IDT or in the interrupt, trap, or task gate is beyond the code segment limits.</td>, <td>If the segment selector in the interrupt, trap, or task gate is NULL.</td>, <td>If an interrupt, trap, or task gate, code segment, or TSS segment selector index is outside its descriptor table limits.</td>, <td>If the vector selects a descriptor outside the IDT limits.</td>, <td>If an IDT descriptor is not an interrupt, trap, or task gate.</td>, <td>If an interrupt is generated by the INT n, INT3, or INTO instruction and the DPL of an interrupt, trap, or task gate is less than the CPL.</td>, <td>If the segment selector in an interrupt or trap gate does not point to a segment descriptor for a code segment.</td>, <td>If the segment selector for a TSS has its local/global bit set for local.</td>, <td>If a TSS segment descriptor specifies that the TSS is busy or not available.</td>, <td rowspan="3">#SS(error_code)</td>, <td>If pushing the return address, flags, or error code onto the stack exceeds the bounds of the stack segment and no stack switch occurs.</td>, <td>If the SS register is being loaded and the segment pointed to is marked not present.</td>, <td>If pushing the return address, flags, error code, or stack segment pointer exceeds the bounds of the new stack segment when a stack switch occurs.</td>, <td>#NP(error_code)</td>, <td>If code segment, interrupt gate, trap gate, task gate, or TSS is not present.</td>, <td rowspan="5">#TS(error_code)</td>, <td>If the RPL of the stack segment selector in the TSS is not equal to the DPL of the code segment being accessed by the interrupt or trap gate.</td>, <td>If DPL of the stack segment descriptor pointed to by the stack segment selector in the TSS is not equal to the DPL of the code segment descriptor for the interrupt or trap gate.</td>, <td>If the stack segment selector in the TSS is NULL.</td>, <td>If the stack segment for the TSS is not a writable data segment.</td>, <td>If segment-selector index for stack segment is outside descriptor table limits.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#AC(EXT)</td>, <td>If alignment checking is enabled, the gate DPL is 3, and a stack push is unaligned.</td>, <td rowspan="2">#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the interrupt vector number is outside the IDT limits.</td>, <td rowspan="2">#SS</td>, <td>If stack limit violation on push.</td>, <td>If pushing the return address, flags, or error code onto the stack exceeds the bounds of the stack segment.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="9">#GP(error_code)</td>, <td>(For INT <em>n,</em> INTO, or BOUND instruction) If the IOPL is less than 3 or the DPL of the interrupt, trap, or task gate is not equal to 3.</td>, <td>If the instruction pointer in the IDT or in the interrupt, trap, or task gate is beyond the code segment limits.</td>, <td>If the segment selector in the interrupt, trap, or task gate is NULL.</td>, <td>If a interrupt gate, trap gate, task gate, code segment, or TSS segment selector index is outside its descriptor table limits.</td>, <td>If the vector selects a descriptor outside the IDT limits.</td>, <td>If an IDT descriptor is not an interrupt, trap, or task gate.</td>, <td>If an interrupt is generated by INT n, INT3, or INTO and the DPL of an interrupt, trap, or task gate is less than the CPL.</td>, <td>If the segment selector in an interrupt or trap gate does not point to a segment descriptor for a code segment.</td>, <td>If the segment selector for a TSS has its local/global bit set for local.</td>, <td rowspan="2">#SS(error_code)</td>, <td>If the SS register is being loaded and the segment pointed to is marked not present.</td>, <td>If pushing the return address, flags, error code, stack segment pointer, or data segments exceeds the bounds of the stack segment.</td>, <td>#NP(error_code)</td>, <td>If code segment, interrupt gate, trap gate, task gate, or TSS is not present.</td>, <td rowspan="5">#TS(error_code)</td>, <td>If the RPL of the stack segment selector in the TSS is not equal to the DPL of the code segment being accessed by the interrupt or trap gate.</td>, <td>If DPL of the stack segment descriptor for the TSS’s stack segment is not equal to the DPL of the code segment descriptor for the interrupt or trap gate.</td>, <td>If the stack segment selector in the TSS is NULL.</td>, <td>If the stack segment for the TSS is not a writable data segment.</td>, <td>If segment-selector index for stack segment is outside descriptor table limits.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#OF</td>, <td>If the INTO instruction is executed and the OF flag is set.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#AC(EXT)</td>, <td>If alignment checking is enabled, the gate DPL is 3, and a stack push is unaligned.</td>, <td rowspan="10">#GP(error_code)</td>, <td>If the instruction pointer in the 64-bit interrupt gate or trap gate is non-canonical.</td>, <td>If the segment selector in the 64-bit interrupt or trap gate is NULL.</td>, <td>If the vector selects a descriptor outside the IDT limits.</td>, <td>If the vector points to a gate which is in non-canonical space.</td>, <td>If the vector points to a descriptor which is not a 64-bit interrupt gate or a 64-bit trap gate.</td>, <td>If the descriptor pointed to by the gate selector is outside the descriptor table limit.</td>, <td>If the descriptor pointed to by the gate selector is in non-canonical space.</td>, <td>If the descriptor pointed to by the gate selector is not a code segment.</td>, <td>If the descriptor pointed to by the gate selector doesn’t have the L-bit set, or has both the L-bit and D-bit set.</td>, <td>If the descriptor pointed to by the gate selector has DPL &gt; CPL.</td>, <td rowspan="2">#SS(error_code)</td>, <td>If a push of the old EFLAGS, CS selector, EIP, or error code is in non-canonical space with no stack switch.</td>, <td>If a push of the old SS selector, ESP, EFLAGS, CS selector, EIP, or error code is in non-canonical space on a stack switch (either CPL change or no-CPL with IST).</td>, <td>#NP(error_code)</td>, <td>If the 64-bit interrupt-gate, 64-bit trap-gate, or code segment is not present.</td>, <td rowspan="2">#TS(error_code)</td>, <td>If an attempt to load RSP from the TSS causes an access to non-canonical space.</td>, <td>If the RSP from the TSS is outside descriptor table limits.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#AC(EXT)</td>, <td>If alignment checking is enabled, the gate DPL is 3, and a stack push is unaligned.</td>]

[<td>0F 08</td>, <td>INVD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Flush internal caches; initiate flushing of external caches.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the processor reserved memory protections are activated.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>The INVD instruction cannot be executed in virtual-8086 mode.</td>]

[<td></td>, <td></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Invalidate TLB entries for page containing <em>m.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td rowspan="2">#UD</td>, <td>Operand is a register.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#UD</td>, <td>Operand is a register.</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>The INVLPG instruction cannot be executed at the virtual-8086 mode.</td>, <td>#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td rowspan="2">#UD</td>, <td>Operand is a register.</td>, <td>If the LOCK prefix is used.</td>]

[<td>66 0F 38 82 /r INVPCID r32, m128</td>, <td>RM</td>, <td>NE/V</td>, <td>INVPCID</td>, <td>Invalidates entries in the TLBs and paging-structure caches based on invalidation type in r32 and descriptor in m128.</td>, <td>66 0F 38 82 /r INVPCID r64, m128</td>, <td>RM</td>, <td>V/NE</td>, <td>INVPCID</td>, <td>Invalidates entries in the TLBs and paging-structure caches based on invalidation type in r64 and descriptor in m128.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="8">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains an unusable segment.</td>, <td>If the source operand is located in an execute-only code segment.</td>, <td>If an invalid type is specified in the register operand, i.e., INVPCID_TYPE &gt; 3.</td>, <td>If bits 63:12 of INVPCID_DESC are not all zero.</td>, <td>If INVPCID_TYPE is either 0 or 1 and INVPCID_DESC[11:0] is not zero.</td>, <td>If INVPCID_TYPE is 0 and the linear address in INVPCID_DESC[127:64] is not canonical.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing the memory operand.</td>, <td rowspan="2">#SS(0)</td>, <td>If the memory operand effective address is outside the SS segment limit.</td>, <td>If the SS register contains an unusable segment.</td>, <td rowspan="2">#UD</td>, <td>If if CPUID.(EAX=07H, ECX=0H):EBX.INVPCID (bit 10) = 0.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="4">#GP</td>, <td>If an invalid type is specified in the register operand, i.e., INVPCID_TYPE &gt; 3.</td>, <td>If bits 63:12 of INVPCID_DESC are not all zero.</td>, <td>If INVPCID_TYPE is either 0 or 1 and INVPCID_DESC[11:0] is not zero.</td>, <td>If INVPCID_TYPE is 0 and the linear address in INVPCID_DESC[127:64] is not canonical.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.INVPCID (bit 10) = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>The INVPCID instruction is not recognized in virtual-8086 mode.</td>, <td rowspan="6">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the memory operand is in the CS, DS, ES, FS, or GS segments and the memory address is in a non-canonical form.</td>, <td>If an invalid type is specified in the register operand, i.e., INVPCID_TYPE &gt; 3.</td>, <td>If bits 63:12 of INVPCID_DESC are not all zero.</td>, <td>If CR4.PCIDE=0, INVPCID_TYPE is either 0 or 1, and INVPCID_DESC[11:0] is not zero.</td>, <td>If INVPCID_TYPE is 0 and the linear address in INVPCID_DESC[127:64] is not canonical.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing the memory operand.</td>, <td>#SS(0)</td>, <td>If the memory destination operand is in the SS segment and the memory address is in a non-canonical form.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.INVPCID (bit 10) = 0.</td>]

[<td>CF</td>, <td>IRET</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Interrupt return (16-bit operand size).</td>, <td>CF</td>, <td>IRETD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Interrupt return (32-bit operand size).</td>, <td>REX.W + CF</td>, <td>IRETQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Interrupt return (64-bit operand size).</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If the return code or stack segment selector is NULL.</td>, <td>If the return instruction pointer is not within the return code segment limit.</td>, <td rowspan="11">#GP(selector)</td>, <td>If a segment selector index is outside its descriptor table limits.</td>, <td>If the return code segment selector RPL is less than the CPL.</td>, <td>If the DPL of a conforming-code segment is greater than the return code segment selector RPL.</td>, <td>If the DPL for a nonconforming-code segment is not equal to the RPL of the code segment selector.</td>, <td>If the stack segment descriptor DPL is not equal to the RPL of the return code segment selector.</td>, <td>If the stack segment is not a writable data segment.</td>, <td>If the stack segment selector RPL is not equal to the RPL of the return code segment selector.</td>, <td>If the segment descriptor for a code segment does not indicate it is a code segment.</td>, <td>If the segment selector for a TSS has its local/global bit set for local.</td>, <td>If a TSS segment descriptor specifies that the TSS is not busy.</td>, <td>If a TSS segment descriptor specifies that the TSS is not available.</td>, <td rowspan="2">#SS(0)</td>, <td>If the top bytes of stack are not within stack limits.</td>, <td>If the return stack segment is not present.</td>, <td>#NP</td>, <td>(selector) If the return code segment is not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference occurs when the CPL is 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If the return instruction pointer is not within the return code segment limit.</td>, <td>#SS</td>, <td>If the top bytes of stack are not within stack limits.</td>, <td rowspan="2">#GP(0)</td>, <td>If the return instruction pointer is not within the return code segment limit.</td>, <td>IF IOPL not equal to 3.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#SS(0)</td>, <td>If the top bytes of stack are not within stack limits.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference occurs and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If EFLAGS.NT[bit 14] = 1.</td>, <td rowspan="7">#GP(0)</td>, <td>If EFLAGS.NT[bit 14] = 1.</td>, <td>If the return code segment selector is NULL.</td>, <td>If the stack segment selector is NULL going back to compatibility mode.</td>, <td>If the stack segment selector is NULL going back to CPL3 64-bit mode.</td>, <td>If a NULL stack segment selector RPL is not equal to CPL going back to non-CPL3 64-bit mode.</td>, <td>If the return instruction pointer is not within the return code segment limit.</td>, <td>If the return instruction pointer is non-canonical.</td>, <td rowspan="10">#GP(Selector)</td>, <td>If a segment selector index is outside its descriptor table limits.</td>, <td>If a segment descriptor memory address is non-canonical.</td>, <td>If the segment descriptor for a code segment does not indicate it is a code segment.</td>, <td>If the proposed new code segment descriptor has both the D-bit and L-bit set.</td>, <td>If the DPL for a nonconforming-code segment is not equal to the RPL of the code segment selector.</td>, <td>If CPL is greater than the RPL of the code segment selector.</td>, <td>If the DPL of a conforming-code segment is greater than the return code segment selector RPL.</td>, <td>If the stack segment is not a writable data segment.</td>, <td>If the stack segment descriptor DPL is not equal to the RPL of the return code segment selector.</td>, <td>If the stack segment selector RPL is not equal to the RPL of the return code segment selector.</td>, <td rowspan="3">#SS(0)</td>, <td>If an attempt to pop a value off the stack violates the SS limit.</td>, <td>If an attempt to pop a value off the stack causes a non-canonical address to be referenced.</td>, <td>If the return stack segment is not present.</td>, <td>#NP</td>, <td>(selector) If the return code segment is not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference occurs when the CPL is 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>CF</td>, <td>IRET</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Interrupt return (16-bit operand size).</td>, <td>CF</td>, <td>IRETD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Interrupt return (32-bit operand size).</td>, <td>REX.W + CF</td>, <td>IRETQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Interrupt return (64-bit operand size).</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If the return code or stack segment selector is NULL.</td>, <td>If the return instruction pointer is not within the return code segment limit.</td>, <td rowspan="11">#GP(selector)</td>, <td>If a segment selector index is outside its descriptor table limits.</td>, <td>If the return code segment selector RPL is less than the CPL.</td>, <td>If the DPL of a conforming-code segment is greater than the return code segment selector RPL.</td>, <td>If the DPL for a nonconforming-code segment is not equal to the RPL of the code segment selector.</td>, <td>If the stack segment descriptor DPL is not equal to the RPL of the return code segment selector.</td>, <td>If the stack segment is not a writable data segment.</td>, <td>If the stack segment selector RPL is not equal to the RPL of the return code segment selector.</td>, <td>If the segment descriptor for a code segment does not indicate it is a code segment.</td>, <td>If the segment selector for a TSS has its local/global bit set for local.</td>, <td>If a TSS segment descriptor specifies that the TSS is not busy.</td>, <td>If a TSS segment descriptor specifies that the TSS is not available.</td>, <td rowspan="2">#SS(0)</td>, <td>If the top bytes of stack are not within stack limits.</td>, <td>If the return stack segment is not present.</td>, <td>#NP</td>, <td>(selector) If the return code segment is not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference occurs when the CPL is 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If the return instruction pointer is not within the return code segment limit.</td>, <td>#SS</td>, <td>If the top bytes of stack are not within stack limits.</td>, <td rowspan="2">#GP(0)</td>, <td>If the return instruction pointer is not within the return code segment limit.</td>, <td>IF IOPL not equal to 3.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#SS(0)</td>, <td>If the top bytes of stack are not within stack limits.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference occurs and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If EFLAGS.NT[bit 14] = 1.</td>, <td rowspan="7">#GP(0)</td>, <td>If EFLAGS.NT[bit 14] = 1.</td>, <td>If the return code segment selector is NULL.</td>, <td>If the stack segment selector is NULL going back to compatibility mode.</td>, <td>If the stack segment selector is NULL going back to CPL3 64-bit mode.</td>, <td>If a NULL stack segment selector RPL is not equal to CPL going back to non-CPL3 64-bit mode.</td>, <td>If the return instruction pointer is not within the return code segment limit.</td>, <td>If the return instruction pointer is non-canonical.</td>, <td rowspan="10">#GP(Selector)</td>, <td>If a segment selector index is outside its descriptor table limits.</td>, <td>If a segment descriptor memory address is non-canonical.</td>, <td>If the segment descriptor for a code segment does not indicate it is a code segment.</td>, <td>If the proposed new code segment descriptor has both the D-bit and L-bit set.</td>, <td>If the DPL for a nonconforming-code segment is not equal to the RPL of the code segment selector.</td>, <td>If CPL is greater than the RPL of the code segment selector.</td>, <td>If the DPL of a conforming-code segment is greater than the return code segment selector RPL.</td>, <td>If the stack segment is not a writable data segment.</td>, <td>If the stack segment descriptor DPL is not equal to the RPL of the return code segment selector.</td>, <td>If the stack segment selector RPL is not equal to the RPL of the return code segment selector.</td>, <td rowspan="3">#SS(0)</td>, <td>If an attempt to pop a value off the stack violates the SS limit.</td>, <td>If an attempt to pop a value off the stack causes a non-canonical address to be referenced.</td>, <td>If the return stack segment is not present.</td>, <td>#NP</td>, <td>(selector) If the return code segment is not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference occurs when the CPL is 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>EB <em>cb</em></td>, <td>JMP <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short, RIP = RIP + 8-bit displacement sign extended to 64-bits</td>, <td>E9 <em>cw</em></td>, <td>JMP <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near, relative, displacement relative to next instruction. Not supported in 64-bit mode.</td>, <td>E9 <em>cd</em></td>, <td>JMP <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near, relative, RIP = RIP + 32-bit displacement sign extended to 64-bits</td>, <td>FF /4</td>, <td>JMP <em>r/m16</em></td>, <td>M</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near, absolute indirect, address = zero-extended <em>r/m16.</em> Not supported in 64-bit mode.</td>, <td>FF /4</td>, <td>JMP <em>r/m32</em></td>, <td>M</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near, absolute indirect, address given in <em>r/m32.</em> Not supported in 64-bit mode.</td>, <td>FF /4</td>, <td>JMP <em>r/m64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Jump near, absolute indirect, RIP = 64-Bit offset from register or memory</td>, <td>EA <em>cd</em></td>, <td>JMP <em>ptr16:16</em></td>, <td>D</td>, <td>Inv.</td>, <td>Valid</td>, <td>Jump far, absolute, address given in operand</td>, <td>EA <em>cp</em></td>, <td>JMP <em>ptr16:32</em></td>, <td>D</td>, <td>Inv.</td>, <td>Valid</td>, <td>Jump far, absolute, address given in operand</td>, <td>FF /5</td>, <td>JMP <em>m16:16</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump far, absolute indirect, address given in <em>m16:16</em></td>, <td>FF /5</td>, <td>JMP <em>m16:32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump far, absolute indirect, address given in <em>m16:32.</em></td>, <td>REX.W FF /5</td>, <td>JMP <em>m16:64</em></td>, <td>D</td>, <td>Valid</td>, <td>N.E.</td>, <td>Jump far, absolute indirect, address given in <em>m16:64</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>D</td>, <td>Offset</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="4">#GP(0)</td>, <td>If offset in target operand, call gate, or TSS is beyond the code segment limits.</td>, <td>If the segment selector in the destination operand, call gate, task gate, or TSS is NULL.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td rowspan="7">#GP(selector)</td>, <td>If the segment selector index is outside descriptor table limits.</td>, <td>If the segment descriptor pointed to by the segment selector in the destination operand is not for a conforming-code segment, nonconforming-code segment, call gate, task gate, or task state segment.</td>, <td>If the DPL for a nonconforming-code segment is not equal to the CPL</td>, <td>(When not using a call gate.) If the RPL for the segment’s segment selector is greater than the CPL.</td>, <td>If the DPL for a conforming-code segment is greater than the CPL.</td>, <td>If the DPL from a call-gate, task-gate, or TSS segment descriptor is less than the CPL or than the RPL of the call-gate, task-gate, or TSS’s segment selector.</td>, <td>If the segment descriptor for selector in a call gate does not indicate it is a code segment. If the segment descriptor for the segment selector in a task gate does not indicate an available TSS. If the segment selector for a TSS has its local/global bit set for local. If a TSS segment descriptor specifies that the TSS is busy or not available.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td rowspan="2">#NP</td>, <td>(selector) If the code segment being accessed is not present.</td>, <td>If call gate, task gate, or TSS not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3. (Only occurs when fetching target from memory.)</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP(0)</td>, <td>If the target operand is beyond the code segment limits.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made. (Only occurs when fetching target from memory.)</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="5">#GP(0)</td>, <td>If a memory address is non-canonical.</td>, <td>If target offset in destination operand is non-canonical.</td>, <td>If target offset in destination operand is beyond the new code segment limit.</td>, <td>If the segment selector in the destination operand is NULL.</td>, <td>If the code segment selector in the 64-bit gate is NULL.</td>, <td rowspan="10">#GP(selector)</td>, <td>If the code segment or 64-bit call gate is outside descriptor table limits.</td>, <td>If the code segment or 64-bit call gate overlaps non-canonical space.</td>, <td>If the segment descriptor from a 64-bit call gate is in non-canonical space.</td>, <td>If the segment descriptor pointed to by the segment selector in the destination operand is not for a conforming-code segment, nonconforming-code segment, 64-bit call gate.</td>, <td>If the segment descriptor pointed to by the segment selector in the destination operand is a code segment, and has both the D-bit and the L-bit set.</td>, <td>If the DPL for a nonconforming-code segment is not equal to the CPL, or the RPL for the segment’s segment selector is greater than the CPL.</td>, <td>If the DPL for a conforming-code segment is greater than the CPL.</td>, <td>If the DPL from a 64-bit call-gate is less than the CPL or than the RPL of the 64-bit call-gate.</td>, <td>If the upper type field of a 64-bit call gate is not 0x0.</td>, <td>If the segment selector from a 64-bit call gate is beyond the descriptor table limits. If the code segment descriptor pointed to by the selector in the 64-bit gate doesn't have the L-bit set and the D-bit clear. If the segment descriptor for a segment selector from the 64-bit call gate does not indicate it is a code segment. If the code segment is non-conforming and CPL ≠ DPL. If the code segment is confirming and CPL &lt; DPL.</td>, <td>#NP(selector)</td>, <td>If a code segment or 64-bit call gate is not present.</td>, <td rowspan="2">#UD</td>, <td>(64-bit mode only) If a far jump is direct to an absolute address in memory.</td>, <td>If the LOCK prefix is used.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>]

[<td>77 <em>cb</em></td>, <td>JA <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if above (CF=0 and ZF=0).</td>, <td>73 <em>cb</em></td>, <td>JAE <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if above or equal (CF=0).</td>, <td>72 <em>cb</em></td>, <td>JB <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if below (CF=1).</td>, <td>76 <em>cb</em></td>, <td>JBE <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if below or equal (CF=1 or ZF=1).</td>, <td>72 <em>cb</em></td>, <td>JC <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if carry (CF=1).</td>, <td>E3 <em>cb</em></td>, <td>JCXZ <em>rel8</em></td>, <td>D</td>, <td>N.E.</td>, <td>Valid</td>, <td>Jump short if CX register is 0.</td>, <td>E3 <em>cb</em></td>, <td>JECXZ <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if ECX register is 0.</td>, <td>E3 <em>cb</em></td>, <td>JRCXZ <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>N.E.</td>, <td>Jump short if RCX register is 0.</td>, <td>74 <em>cb</em></td>, <td>JE <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if equal (ZF=1).</td>, <td>7F <em>cb</em></td>, <td>JG <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if greater (ZF=0 and SF=OF).</td>, <td>7D <em>cb</em></td>, <td>JGE <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if greater or equal (SF=OF).</td>, <td>7C <em>cb</em></td>, <td>JL <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if less (SF≠ OF).</td>, <td>7E <em>cb</em></td>, <td>JLE <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if less or equal (ZF=1 or SF≠ OF).</td>, <td>76 <em>cb</em></td>, <td>JNA <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if not above (CF=1 or ZF=1).</td>, <td>72 <em>cb</em></td>, <td>JNAE <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if not above or equal (CF=1).</td>, <td>73 <em>cb</em></td>, <td>JNB <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if not below (CF=0).</td>, <td>77 <em>cb</em></td>, <td>JNBE <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if not below or equal (CF=0 and ZF=0).</td>, <td>73 <em>cb</em></td>, <td>JNC <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if not carry (CF=0).</td>, <td>75 <em>cb</em></td>, <td>JNE <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if not equal (ZF=0).</td>, <td>7E <em>cb</em></td>, <td>JNG <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if not greater (ZF=1 or SF≠ OF).</td>, <td>7C <em>cb</em></td>, <td>JNGE <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if not greater or equal (SF≠ OF).</td>, <td>7D <em>cb</em></td>, <td>JNL <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if not less (SF=OF).</td>, <td>7F <em>cb</em></td>, <td>JNLE <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if not less or equal (ZF=0 and SF=OF).</td>, <td>71 <em>cb</em></td>, <td>JNO <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if not overflow (OF=0).</td>, <td>7B <em>cb</em></td>, <td>JNP <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if not parity (PF=0).</td>, <td>79 <em>cb</em></td>, <td>JNS <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if not sign (SF=0).</td>, <td>75 <em>cb</em></td>, <td>JNZ <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if not zero (ZF=0).</td>, <td>70 <em>cb</em></td>, <td>JO <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if overflow (OF=1).</td>, <td>7A <em>cb</em></td>, <td>JP <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if parity (PF=1).</td>, <td>7A <em>cb</em></td>, <td>JPE <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if parity even (PF=1).</td>, <td>7B <em>cb</em></td>, <td>JPO <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if parity odd (PF=0).</td>, <td>78 <em>cb</em></td>, <td>JS <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if sign (SF=1).</td>, <td>74 <em>cb</em></td>, <td>JZ <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump short if zero (ZF = 1).</td>, <td>0F 87 <em>cw</em></td>, <td>JA <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if above (CF=0 and ZF=0). Not supported in 64-bit mode.</td>, <td>0F 87 <em>cd</em></td>, <td>JA <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if above (CF=0 and ZF=0).</td>, <td>0F 83 <em>cw</em></td>, <td>JAE <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if above or equal (CF=0). Not supported in 64-bit mode.</td>, <td>0F 83 <em>cd</em></td>, <td>JAE <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if above or equal (CF=0).</td>, <td>0F 82 <em>cw</em></td>, <td>JB <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if below (CF=1). Not supported in 64-bit mode.</td>, <td>0F 82 <em>cd</em></td>, <td>JB <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if below (CF=1).</td>, <td>0F 86 <em>cw</em></td>, <td>JBE <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if below or equal (CF=1 or ZF=1). Not supported in 64-bit mode.</td>, <td>0F 86 <em>cd</em></td>, <td>JBE <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if below or equal (CF=1 or ZF=1).</td>, <td>0F 82 <em>cw</em></td>, <td>JC <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if carry (CF=1). Not supported in 64-bit mode.</td>, <td>0F 82 <em>cd</em></td>, <td>JC <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if carry (CF=1).</td>, <td>0F 84 <em>cw</em></td>, <td>JE <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if equal (ZF=1). Not supported in 64-bit mode.</td>, <td>0F 84 <em>cd</em></td>, <td>JE <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if equal (ZF=1).</td>, <td>0F 84 <em>cw</em></td>, <td>JZ <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if 0 (ZF=1). Not supported in 64-bit mode.</td>, <td>0F 84 <em>cd</em></td>, <td>JZ <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if 0 (ZF=1).</td>, <td>0F 8F <em>cw</em></td>, <td>JG <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if greater (ZF=0 and SF=OF). Not supported in 64-bit mode.</td>, <td>0F 8F <em>cd</em></td>, <td>JG <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if greater (ZF=0 and SF=OF).</td>, <td>0F 8D <em>cw</em></td>, <td>JGE <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if greater or equal (SF=OF). Not supported in 64-bit mode.</td>, <td>0F 8D <em>cd</em></td>, <td>JGE <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if greater or equal (SF=OF).</td>, <td>0F 8C <em>cw</em></td>, <td>JL <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if less (SF≠ OF). Not supported in 64-bit mode.</td>, <td>0F 8C <em>cd</em></td>, <td>JL <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if less (SF≠ OF).</td>, <td>0F 8E <em>cw</em></td>, <td>JLE <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if less or equal (ZF=1 or SF≠ OF). Not supported in 64-bit mode.</td>, <td>0F 8E <em>cd</em></td>, <td>JLE <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if less or equal (ZF=1 or SF≠ OF).</td>, <td>0F 86 <em>cw</em></td>, <td>JNA <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if not above (CF=1 or ZF=1). Not supported in 64-bit mode.</td>, <td>0F 86 <em>cd</em></td>, <td>JNA <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if not above (CF=1 or ZF=1).</td>, <td>0F 82 <em>cw</em></td>, <td>JNAE <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if not above or equal (CF=1). Not supported in 64-bit mode.</td>, <td>0F 82 <em>cd</em></td>, <td>JNAE <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if not above or equal (CF=1).</td>, <td>0F 83 <em>cw</em></td>, <td>JNB <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if not below (CF=0). Not supported in 64-bit mode.</td>, <td>0F 83 <em>cd</em></td>, <td>JNB <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if not below (CF=0).</td>, <td>0F 87 <em>cw</em></td>, <td>JNBE <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if not below or equal (CF=0 and ZF=0). Not supported in 64-bit mode.</td>, <td>0F 87 <em>cd</em></td>, <td>JNBE <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if not below or equal (CF=0 and ZF=0).</td>, <td>0F 83 <em>cw</em></td>, <td>JNC <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if not carry (CF=0). Not supported in 64-bit mode.</td>, <td>0F 83 <em>cd</em></td>, <td>JNC <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if not carry (CF=0).</td>, <td>0F 85 <em>cw</em></td>, <td>JNE <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if not equal (ZF=0). Not supported in 64-bit mode.</td>, <td>0F 85 <em>cd</em></td>, <td>JNE <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if not equal (ZF=0).</td>, <td>0F 8E <em>cw</em></td>, <td>JNG <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if not greater (ZF=1 or SF≠ OF). Not supported in 64-bit mode.</td>, <td>0F 8E <em>cd</em></td>, <td>JNG <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if not greater (ZF=1 or SF≠ OF).</td>, <td>0F 8C <em>cw</em></td>, <td>JNGE <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if not greater or equal (SF≠ OF). Not supported in 64-bit mode.</td>, <td>0F 8C <em>cd</em></td>, <td>JNGE <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if not greater or equal (SF≠ OF).</td>, <td>0F 8D <em>cw</em></td>, <td>JNL <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if not less (SF=OF). Not supported in 64-bit mode.</td>, <td>0F 8D <em>cd</em></td>, <td>JNL <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if not less (SF=OF).</td>, <td>0F 8F <em>cw</em></td>, <td>JNLE <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if not less or equal (ZF=0 and SF=OF). Not supported in 64-bit mode.</td>, <td>0F 8F <em>cd</em></td>, <td>JNLE <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if not less or equal (ZF=0 and SF=OF).</td>, <td>0F 81 <em>cw</em></td>, <td>JNO <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if not overflow (OF=0). Not supported in 64-bit mode.</td>, <td>0F 81 <em>cd</em></td>, <td>JNO <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if not overflow (OF=0).</td>, <td>0F 8B <em>cw</em></td>, <td>JNP <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if not parity (PF=0). Not supported in 64-bit mode.</td>, <td>0F 8B <em>cd</em></td>, <td>JNP <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if not parity (PF=0).</td>, <td>0F 89 <em>cw</em></td>, <td>JNS <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if not sign (SF=0). Not supported in 64-bit mode.</td>, <td>0F 89 <em>cd</em></td>, <td>JNS <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if not sign (SF=0).</td>, <td>0F 85 <em>cw</em></td>, <td>JNZ <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if not zero (ZF=0). Not supported in 64-bit mode.</td>, <td>0F 85 <em>cd</em></td>, <td>JNZ <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if not zero (ZF=0).</td>, <td>0F 80 <em>cw</em></td>, <td>JO <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if overflow (OF=1). Not supported in 64-bit mode.</td>, <td>0F 80 <em>cd</em></td>, <td>JO <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if overflow (OF=1).</td>, <td>0F 8A <em>cw</em></td>, <td>JP <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if parity (PF=1). Not supported in 64-bit mode.</td>, <td>0F 8A <em>cd</em></td>, <td>JP <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if parity (PF=1).</td>, <td>0F 8A <em>cw</em></td>, <td>JPE <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if parity even (PF=1). Not supported in 64-bit mode.</td>, <td>0F 8A <em>cd</em></td>, <td>JPE <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if parity even (PF=1).</td>, <td>0F 8B <em>cw</em></td>, <td>JPO <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if parity odd (PF=0). Not supported in 64-bit mode.</td>, <td>0F 8B <em>cd</em></td>, <td>JPO <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if parity odd (PF=0).</td>, <td>0F 88 <em>cw</em></td>, <td>JS <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if sign (SF=1). Not supported in 64-bit mode.</td>, <td>0F 88 <em>cd</em></td>, <td>JS <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if sign (SF=1).</td>, <td>0F 84 <em>cw</em></td>, <td>JZ <em>rel16</em></td>, <td>D</td>, <td>N.S.</td>, <td>Valid</td>, <td>Jump near if 0 (ZF=1). Not supported in 64-bit mode.</td>, <td>0F 84 <em>cd</em></td>, <td>JZ <em>rel32</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Jump near if 0 (ZF=1).</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>D</td>, <td>Offset</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If the offset being jumped to is beyond the limits of the CS segment.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If the offset being jumped to is beyond the limits of the CS segment or is outside of the effective address space from 0 to FFFFH. This condition can occur if a 32-bit address size override prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>VEX.L1.0F.W0 4A /r KADDW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Add 16 bits masks in k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 4A /r KADDB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Add 8 bits masks in k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 4A /r KADDQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add 64 bits masks in k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 4A /r KADDD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add 32 bits masks in k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 4A /r KADDW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Add 16 bits masks in k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 4A /r KADDB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Add 8 bits masks in k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 4A /r KADDQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add 64 bits masks in k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 4A /r KADDD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add 32 bits masks in k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 4A /r KADDW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Add 16 bits masks in k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 4A /r KADDB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Add 8 bits masks in k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 4A /r KADDQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add 64 bits masks in k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 4A /r KADDD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add 32 bits masks in k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 4A /r KADDW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Add 16 bits masks in k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 4A /r KADDB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Add 8 bits masks in k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 4A /r KADDQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add 64 bits masks in k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 4A /r KADDD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add 32 bits masks in k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 41 /r KANDW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND 16 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 41 /r KANDB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise AND 8 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 41 /r KANDQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND 64 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 41 /r KANDD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND 32 bits masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 41 /r KANDW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND 16 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 41 /r KANDB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise AND 8 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 41 /r KANDQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND 64 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 41 /r KANDD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND 32 bits masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 42 /r KANDNW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND NOT 16 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 42 /r KANDNB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise AND NOT 8 bits masks k1 and k2 and place result in k1.</td>, <td>VEX.L1.0F.W1 42 /r KANDNQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND NOT 64 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 42 /r KANDND k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND NOT 32 bits masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 42 /r KANDNW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND NOT 16 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 42 /r KANDNB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise AND NOT 8 bits masks k1 and k2 and place result in k1.</td>, <td>VEX.L1.0F.W1 42 /r KANDNQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND NOT 64 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 42 /r KANDND k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND NOT 32 bits masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 42 /r KANDNW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND NOT 16 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 42 /r KANDNB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise AND NOT 8 bits masks k1 and k2 and place result in k1.</td>, <td>VEX.L1.0F.W1 42 /r KANDNQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND NOT 64 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 42 /r KANDND k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND NOT 32 bits masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 42 /r KANDNW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND NOT 16 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 42 /r KANDNB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise AND NOT 8 bits masks k1 and k2 and place result in k1.</td>, <td>VEX.L1.0F.W1 42 /r KANDNQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND NOT 64 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 42 /r KANDND k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND NOT 32 bits masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 41 /r KANDW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND 16 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 41 /r KANDB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise AND 8 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 41 /r KANDQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND 64 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 41 /r KANDD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND 32 bits masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 41 /r KANDW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND 16 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 41 /r KANDB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise AND 8 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 41 /r KANDQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND 64 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 41 /r KANDD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND 32 bits masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L0.0F.W0 90 /r KMOVW k1, k2/m16</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 16 bits mask from k2/m16 and store the result in k1.</td>, <td>VEX.L0.66.0F.W0 90 /r KMOVB k1, k2/m8</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Move 8 bits mask from k2/m8 and store the result in k1.</td>, <td>VEX.L0.0F.W1 90 /r KMOVQ k1, k2/m64</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 64 bits mask from k2/m64 and store the result in k1.</td>, <td>VEX.L0.66.0F.W1 90 /r KMOVD k1, k2/m32</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 32 bits mask from k2/m32 and store the result in k1.</td>, <td>VEX.L0.0F.W0 91 /r KMOVW m16, k1</td>, <td>MR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 16 bits mask from k1 and store the result in m16.</td>, <td>VEX.L0.66.0F.W0 91 /r KMOVB m8, k1</td>, <td>MR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Move 8 bits mask from k1 and store the result in m8.</td>, <td>VEX.L0.0F.W1 91 /r KMOVQ m64, k1</td>, <td>MR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 64 bits mask from k1 and store the result in m64.</td>, <td>VEX.L0.66.0F.W1 91 /r KMOVD m32, k1</td>, <td>MR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 32 bits mask from k1 and store the result in m32.</td>, <td>VEX.L0.0F.W0 92 /r KMOVW k1, r32</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 16 bits mask from r32 to k1.</td>, <td>VEX.L0.66.0F.W0 92 /r KMOVB k1, r32</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Move 8 bits mask from r32 to k1.</td>, <td>VEX.L0.F2.0F.W1 92 /r KMOVQ k1, r64</td>, <td>RR</td>, <td>V/I</td>, <td>AVX512BW</td>, <td>Move 64 bits mask from r64 to k1.</td>, <td>VEX.L0.F2.0F.W0 92 /r KMOVD k1, r32</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 32 bits mask from r32 to k1.</td>, <td>VEX.L0.0F.W0 93 /r KMOVW r32, k1</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 16 bits mask from k1 to r32.</td>, <td>VEX.L0.66.0F.W0 93 /r KMOVB r32, k1</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Move 8 bits mask from k1 to r32.</td>, <td>VEX.L0.F2.0F.W1 93 /r KMOVQ r64, k1</td>, <td>RR</td>, <td>V/I</td>, <td>AVX512BW</td>, <td>Move 64 bits mask from k1 to r64.</td>, <td>VEX.L0.F2.0F.W0 93 /r KMOVD r32, k1</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 32 bits mask from k1 to r32.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>MR</td>, <td>ModRM:r/m (w, ModRM:[7:6] must not be 11b)</td>, <td>ModRM:reg (r)</td>, <td>RR</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L0.0F.W0 90 /r KMOVW k1, k2/m16</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 16 bits mask from k2/m16 and store the result in k1.</td>, <td>VEX.L0.66.0F.W0 90 /r KMOVB k1, k2/m8</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Move 8 bits mask from k2/m8 and store the result in k1.</td>, <td>VEX.L0.0F.W1 90 /r KMOVQ k1, k2/m64</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 64 bits mask from k2/m64 and store the result in k1.</td>, <td>VEX.L0.66.0F.W1 90 /r KMOVD k1, k2/m32</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 32 bits mask from k2/m32 and store the result in k1.</td>, <td>VEX.L0.0F.W0 91 /r KMOVW m16, k1</td>, <td>MR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 16 bits mask from k1 and store the result in m16.</td>, <td>VEX.L0.66.0F.W0 91 /r KMOVB m8, k1</td>, <td>MR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Move 8 bits mask from k1 and store the result in m8.</td>, <td>VEX.L0.0F.W1 91 /r KMOVQ m64, k1</td>, <td>MR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 64 bits mask from k1 and store the result in m64.</td>, <td>VEX.L0.66.0F.W1 91 /r KMOVD m32, k1</td>, <td>MR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 32 bits mask from k1 and store the result in m32.</td>, <td>VEX.L0.0F.W0 92 /r KMOVW k1, r32</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 16 bits mask from r32 to k1.</td>, <td>VEX.L0.66.0F.W0 92 /r KMOVB k1, r32</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Move 8 bits mask from r32 to k1.</td>, <td>VEX.L0.F2.0F.W1 92 /r KMOVQ k1, r64</td>, <td>RR</td>, <td>V/I</td>, <td>AVX512BW</td>, <td>Move 64 bits mask from r64 to k1.</td>, <td>VEX.L0.F2.0F.W0 92 /r KMOVD k1, r32</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 32 bits mask from r32 to k1.</td>, <td>VEX.L0.0F.W0 93 /r KMOVW r32, k1</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 16 bits mask from k1 to r32.</td>, <td>VEX.L0.66.0F.W0 93 /r KMOVB r32, k1</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Move 8 bits mask from k1 to r32.</td>, <td>VEX.L0.F2.0F.W1 93 /r KMOVQ r64, k1</td>, <td>RR</td>, <td>V/I</td>, <td>AVX512BW</td>, <td>Move 64 bits mask from k1 to r64.</td>, <td>VEX.L0.F2.0F.W0 93 /r KMOVD r32, k1</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 32 bits mask from k1 to r32.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>MR</td>, <td>ModRM:r/m (w, ModRM:[7:6] must not be 11b)</td>, <td>ModRM:reg (r)</td>, <td>RR</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L0.0F.W0 90 /r KMOVW k1, k2/m16</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 16 bits mask from k2/m16 and store the result in k1.</td>, <td>VEX.L0.66.0F.W0 90 /r KMOVB k1, k2/m8</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Move 8 bits mask from k2/m8 and store the result in k1.</td>, <td>VEX.L0.0F.W1 90 /r KMOVQ k1, k2/m64</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 64 bits mask from k2/m64 and store the result in k1.</td>, <td>VEX.L0.66.0F.W1 90 /r KMOVD k1, k2/m32</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 32 bits mask from k2/m32 and store the result in k1.</td>, <td>VEX.L0.0F.W0 91 /r KMOVW m16, k1</td>, <td>MR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 16 bits mask from k1 and store the result in m16.</td>, <td>VEX.L0.66.0F.W0 91 /r KMOVB m8, k1</td>, <td>MR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Move 8 bits mask from k1 and store the result in m8.</td>, <td>VEX.L0.0F.W1 91 /r KMOVQ m64, k1</td>, <td>MR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 64 bits mask from k1 and store the result in m64.</td>, <td>VEX.L0.66.0F.W1 91 /r KMOVD m32, k1</td>, <td>MR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 32 bits mask from k1 and store the result in m32.</td>, <td>VEX.L0.0F.W0 92 /r KMOVW k1, r32</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 16 bits mask from r32 to k1.</td>, <td>VEX.L0.66.0F.W0 92 /r KMOVB k1, r32</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Move 8 bits mask from r32 to k1.</td>, <td>VEX.L0.F2.0F.W1 92 /r KMOVQ k1, r64</td>, <td>RR</td>, <td>V/I</td>, <td>AVX512BW</td>, <td>Move 64 bits mask from r64 to k1.</td>, <td>VEX.L0.F2.0F.W0 92 /r KMOVD k1, r32</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 32 bits mask from r32 to k1.</td>, <td>VEX.L0.0F.W0 93 /r KMOVW r32, k1</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 16 bits mask from k1 to r32.</td>, <td>VEX.L0.66.0F.W0 93 /r KMOVB r32, k1</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Move 8 bits mask from k1 to r32.</td>, <td>VEX.L0.F2.0F.W1 93 /r KMOVQ r64, k1</td>, <td>RR</td>, <td>V/I</td>, <td>AVX512BW</td>, <td>Move 64 bits mask from k1 to r64.</td>, <td>VEX.L0.F2.0F.W0 93 /r KMOVD r32, k1</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 32 bits mask from k1 to r32.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>MR</td>, <td>ModRM:r/m (w, ModRM:[7:6] must not be 11b)</td>, <td>ModRM:reg (r)</td>, <td>RR</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L0.0F.W0 90 /r KMOVW k1, k2/m16</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 16 bits mask from k2/m16 and store the result in k1.</td>, <td>VEX.L0.66.0F.W0 90 /r KMOVB k1, k2/m8</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Move 8 bits mask from k2/m8 and store the result in k1.</td>, <td>VEX.L0.0F.W1 90 /r KMOVQ k1, k2/m64</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 64 bits mask from k2/m64 and store the result in k1.</td>, <td>VEX.L0.66.0F.W1 90 /r KMOVD k1, k2/m32</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 32 bits mask from k2/m32 and store the result in k1.</td>, <td>VEX.L0.0F.W0 91 /r KMOVW m16, k1</td>, <td>MR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 16 bits mask from k1 and store the result in m16.</td>, <td>VEX.L0.66.0F.W0 91 /r KMOVB m8, k1</td>, <td>MR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Move 8 bits mask from k1 and store the result in m8.</td>, <td>VEX.L0.0F.W1 91 /r KMOVQ m64, k1</td>, <td>MR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 64 bits mask from k1 and store the result in m64.</td>, <td>VEX.L0.66.0F.W1 91 /r KMOVD m32, k1</td>, <td>MR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 32 bits mask from k1 and store the result in m32.</td>, <td>VEX.L0.0F.W0 92 /r KMOVW k1, r32</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 16 bits mask from r32 to k1.</td>, <td>VEX.L0.66.0F.W0 92 /r KMOVB k1, r32</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Move 8 bits mask from r32 to k1.</td>, <td>VEX.L0.F2.0F.W1 92 /r KMOVQ k1, r64</td>, <td>RR</td>, <td>V/I</td>, <td>AVX512BW</td>, <td>Move 64 bits mask from r64 to k1.</td>, <td>VEX.L0.F2.0F.W0 92 /r KMOVD k1, r32</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 32 bits mask from r32 to k1.</td>, <td>VEX.L0.0F.W0 93 /r KMOVW r32, k1</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 16 bits mask from k1 to r32.</td>, <td>VEX.L0.66.0F.W0 93 /r KMOVB r32, k1</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Move 8 bits mask from k1 to r32.</td>, <td>VEX.L0.F2.0F.W1 93 /r KMOVQ r64, k1</td>, <td>RR</td>, <td>V/I</td>, <td>AVX512BW</td>, <td>Move 64 bits mask from k1 to r64.</td>, <td>VEX.L0.F2.0F.W0 93 /r KMOVD r32, k1</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move 32 bits mask from k1 to r32.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>MR</td>, <td>ModRM:r/m (w, ModRM:[7:6] must not be 11b)</td>, <td>ModRM:reg (r)</td>, <td>RR</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L0.0F.W0 44 /r KNOTW k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise NOT of 16 bits mask k2.</td>, <td>VEX.L0.66.0F.W0 44 /r KNOTB k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise NOT of 8 bits mask k2.</td>, <td>VEX.L0.0F.W1 44 /r KNOTQ k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise NOT of 64 bits mask k2.</td>, <td>VEX.L0.66.0F.W1 44 /r KNOTD k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise NOT of 32 bits mask k2.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>RR</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L0.0F.W0 44 /r KNOTW k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise NOT of 16 bits mask k2.</td>, <td>VEX.L0.66.0F.W0 44 /r KNOTB k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise NOT of 8 bits mask k2.</td>, <td>VEX.L0.0F.W1 44 /r KNOTQ k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise NOT of 64 bits mask k2.</td>, <td>VEX.L0.66.0F.W1 44 /r KNOTD k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise NOT of 32 bits mask k2.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>RR</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L0.0F.W0 44 /r KNOTW k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise NOT of 16 bits mask k2.</td>, <td>VEX.L0.66.0F.W0 44 /r KNOTB k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise NOT of 8 bits mask k2.</td>, <td>VEX.L0.0F.W1 44 /r KNOTQ k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise NOT of 64 bits mask k2.</td>, <td>VEX.L0.66.0F.W1 44 /r KNOTD k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise NOT of 32 bits mask k2.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>RR</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L0.0F.W0 44 /r KNOTW k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise NOT of 16 bits mask k2.</td>, <td>VEX.L0.66.0F.W0 44 /r KNOTB k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise NOT of 8 bits mask k2.</td>, <td>VEX.L0.0F.W1 44 /r KNOTQ k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise NOT of 64 bits mask k2.</td>, <td>VEX.L0.66.0F.W1 44 /r KNOTD k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise NOT of 32 bits mask k2.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>RR</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 45 /r KORW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise OR 16 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 45 /r KORB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise OR 8 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 45 /r KORQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise OR 64 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 45 /r KORD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise OR 32 bits masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 45 /r KORW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise OR 16 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 45 /r KORB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise OR 8 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 45 /r KORQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise OR 64 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 45 /r KORD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise OR 32 bits masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 45 /r KORW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise OR 16 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 45 /r KORB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise OR 8 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 45 /r KORQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise OR 64 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 45 /r KORD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise OR 32 bits masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L0.0F.W0 98 /r KORTESTW k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise OR 16 bits masks k1 and k2 and update ZF and CF accordingly.</td>, <td>VEX.L0.66.0F.W0 98 /r KORTESTB k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise OR 8 bits masks k1 and k2 and update ZF and CF accordingly.</td>, <td>VEX.L0.0F.W1 98 /r KORTESTQ k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise OR 64 bits masks k1 and k2 and update ZF and CF accordingly.</td>, <td>VEX.L0.66.0F.W1 98 /r KORTESTD k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise OR 32 bits masks k1 and k2 and update ZF and CF accordingly.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>RR</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L0.0F.W0 98 /r KORTESTW k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise OR 16 bits masks k1 and k2 and update ZF and CF accordingly.</td>, <td>VEX.L0.66.0F.W0 98 /r KORTESTB k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise OR 8 bits masks k1 and k2 and update ZF and CF accordingly.</td>, <td>VEX.L0.0F.W1 98 /r KORTESTQ k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise OR 64 bits masks k1 and k2 and update ZF and CF accordingly.</td>, <td>VEX.L0.66.0F.W1 98 /r KORTESTD k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise OR 32 bits masks k1 and k2 and update ZF and CF accordingly.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>RR</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L0.0F.W0 98 /r KORTESTW k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise OR 16 bits masks k1 and k2 and update ZF and CF accordingly.</td>, <td>VEX.L0.66.0F.W0 98 /r KORTESTB k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise OR 8 bits masks k1 and k2 and update ZF and CF accordingly.</td>, <td>VEX.L0.0F.W1 98 /r KORTESTQ k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise OR 64 bits masks k1 and k2 and update ZF and CF accordingly.</td>, <td>VEX.L0.66.0F.W1 98 /r KORTESTD k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise OR 32 bits masks k1 and k2 and update ZF and CF accordingly.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>RR</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L0.0F.W0 98 /r KORTESTW k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise OR 16 bits masks k1 and k2 and update ZF and CF accordingly.</td>, <td>VEX.L0.66.0F.W0 98 /r KORTESTB k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise OR 8 bits masks k1 and k2 and update ZF and CF accordingly.</td>, <td>VEX.L0.0F.W1 98 /r KORTESTQ k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise OR 64 bits masks k1 and k2 and update ZF and CF accordingly.</td>, <td>VEX.L0.66.0F.W1 98 /r KORTESTD k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise OR 32 bits masks k1 and k2 and update ZF and CF accordingly.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>RR</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 45 /r KORW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise OR 16 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 45 /r KORB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise OR 8 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 45 /r KORQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise OR 64 bits masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 45 /r KORD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise OR 32 bits masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L0.66.0F3A.W1 32 /r KSHIFTLW k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift left 16 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W0 32 /r KSHIFTLB k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Shift left 8 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W1 33 /r KSHIFTLQ k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift left 64 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W0 33 /r KSHIFTLD k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift left 32 bits in k2 by immediate and write result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RRI</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>, <td>Imm8</td>]

[<td>VEX.L0.66.0F3A.W1 32 /r KSHIFTLW k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift left 16 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W0 32 /r KSHIFTLB k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Shift left 8 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W1 33 /r KSHIFTLQ k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift left 64 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W0 33 /r KSHIFTLD k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift left 32 bits in k2 by immediate and write result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RRI</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>, <td>Imm8</td>]

[<td>VEX.L0.66.0F3A.W1 32 /r KSHIFTLW k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift left 16 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W0 32 /r KSHIFTLB k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Shift left 8 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W1 33 /r KSHIFTLQ k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift left 64 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W0 33 /r KSHIFTLD k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift left 32 bits in k2 by immediate and write result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RRI</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>, <td>Imm8</td>]

[<td>VEX.L0.66.0F3A.W1 32 /r KSHIFTLW k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift left 16 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W0 32 /r KSHIFTLB k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Shift left 8 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W1 33 /r KSHIFTLQ k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift left 64 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W0 33 /r KSHIFTLD k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift left 32 bits in k2 by immediate and write result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RRI</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>, <td>Imm8</td>]

[<td>VEX.L0.66.0F3A.W1 30 /r KSHIFTRW k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift right 16 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W0 30 /r KSHIFTRB k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Shift right 8 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W1 31 /r KSHIFTRQ k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift right 64 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W0 31 /r KSHIFTRD k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift right 32 bits in k2 by immediate and write result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RRI</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>, <td>Imm8</td>]

[<td>VEX.L0.66.0F3A.W1 30 /r KSHIFTRW k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift right 16 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W0 30 /r KSHIFTRB k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Shift right 8 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W1 31 /r KSHIFTRQ k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift right 64 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W0 31 /r KSHIFTRD k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift right 32 bits in k2 by immediate and write result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RRI</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>, <td>Imm8</td>]

[<td>VEX.L0.66.0F3A.W1 30 /r KSHIFTRW k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift right 16 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W0 30 /r KSHIFTRB k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Shift right 8 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W1 31 /r KSHIFTRQ k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift right 64 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W0 31 /r KSHIFTRD k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift right 32 bits in k2 by immediate and write result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RRI</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>, <td>Imm8</td>]

[<td>VEX.L0.66.0F3A.W1 30 /r KSHIFTRW k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift right 16 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W0 30 /r KSHIFTRB k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Shift right 8 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W1 31 /r KSHIFTRQ k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift right 64 bits in k2 by immediate and write result in k1.</td>, <td>VEX.L0.66.0F3A.W0 31 /r KSHIFTRD k1, k2, imm8</td>, <td>RRI</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift right 32 bits in k2 by immediate and write result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RRI</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>, <td>Imm8</td>]

[<td>VEX.L0.0F.W0 99 /r KTESTW k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of 16 bits mask register sources.</td>, <td>VEX.L0.66.0F.W0 99 /r KTESTB k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of 8 bits mask register sources.</td>, <td>VEX.L0.0F.W1 99 /r KTESTQ k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of 64 bits mask register sources.</td>, <td>VEX.L0.66.0F.W1 99 /r KTESTD k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of 32 bits mask register sources.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand2</td>, <td>RR</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L0.0F.W0 99 /r KTESTW k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of 16 bits mask register sources.</td>, <td>VEX.L0.66.0F.W0 99 /r KTESTB k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of 8 bits mask register sources.</td>, <td>VEX.L0.0F.W1 99 /r KTESTQ k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of 64 bits mask register sources.</td>, <td>VEX.L0.66.0F.W1 99 /r KTESTD k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of 32 bits mask register sources.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand2</td>, <td>RR</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L0.0F.W0 99 /r KTESTW k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of 16 bits mask register sources.</td>, <td>VEX.L0.66.0F.W0 99 /r KTESTB k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of 8 bits mask register sources.</td>, <td>VEX.L0.0F.W1 99 /r KTESTQ k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of 64 bits mask register sources.</td>, <td>VEX.L0.66.0F.W1 99 /r KTESTD k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of 32 bits mask register sources.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand2</td>, <td>RR</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L0.0F.W0 99 /r KTESTW k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of 16 bits mask register sources.</td>, <td>VEX.L0.66.0F.W0 99 /r KTESTB k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of 8 bits mask register sources.</td>, <td>VEX.L0.0F.W1 99 /r KTESTQ k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of 64 bits mask register sources.</td>, <td>VEX.L0.66.0F.W1 99 /r KTESTD k1, k2</td>, <td>RR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of 32 bits mask register sources.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand2</td>, <td>RR</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.66.0F.W0 4B /r KUNPCKBW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Unpack 8-bit masks in k2 and k3 and write word result in k1.</td>, <td>VEX.L1.0F.W0 4B /r KUNPCKWD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Unpack 16-bit masks in k2 and k3 and write doubleword result in k1.</td>, <td>VEX.L1.0F.W1 4B /r KUNPCKDQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Unpack 32-bit masks in k2 and k3 and write quadword result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.66.0F.W0 4B /r KUNPCKBW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Unpack 8-bit masks in k2 and k3 and write word result in k1.</td>, <td>VEX.L1.0F.W0 4B /r KUNPCKWD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Unpack 16-bit masks in k2 and k3 and write doubleword result in k1.</td>, <td>VEX.L1.0F.W1 4B /r KUNPCKDQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Unpack 32-bit masks in k2 and k3 and write quadword result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.66.0F.W0 4B /r KUNPCKBW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Unpack 8-bit masks in k2 and k3 and write word result in k1.</td>, <td>VEX.L1.0F.W0 4B /r KUNPCKWD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Unpack 16-bit masks in k2 and k3 and write doubleword result in k1.</td>, <td>VEX.L1.0F.W1 4B /r KUNPCKDQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Unpack 32-bit masks in k2 and k3 and write quadword result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 46 /r KXNORW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise XNOR 16-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 46 /r KXNORB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise XNOR 8-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 46 /r KXNORQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise XNOR 64-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 46 /r KXNORD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise XNOR 32-bit masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 46 /r KXNORW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise XNOR 16-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 46 /r KXNORB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise XNOR 8-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 46 /r KXNORQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise XNOR 64-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 46 /r KXNORD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise XNOR 32-bit masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 46 /r KXNORW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise XNOR 16-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 46 /r KXNORB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise XNOR 8-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 46 /r KXNORQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise XNOR 64-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 46 /r KXNORD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise XNOR 32-bit masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 46 /r KXNORW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise XNOR 16-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 46 /r KXNORB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise XNOR 8-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 46 /r KXNORQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise XNOR 64-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 46 /r KXNORD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise XNOR 32-bit masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 47 /r KXORW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise XOR 16-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 47 /r KXORB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise XOR 8-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 47 /r KXORQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise XOR 64-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 47 /r KXORD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise XOR 32-bit masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 47 /r KXORW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise XOR 16-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 47 /r KXORB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise XOR 8-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 47 /r KXORQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise XOR 64-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 47 /r KXORD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise XOR 32-bit masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 47 /r KXORW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise XOR 16-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 47 /r KXORB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise XOR 8-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 47 /r KXORQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise XOR 64-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 47 /r KXORD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise XOR 32-bit masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td>VEX.L1.0F.W0 47 /r KXORW k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise XOR 16-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W0 47 /r KXORB k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Bitwise XOR 8-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.0F.W1 47 /r KXORQ k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise XOR 64-bit masks k2 and k3 and place result in k1.</td>, <td>VEX.L1.66.0F.W1 47 /r KXORD k1, k2, k3</td>, <td>RVR</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise XOR 32-bit masks k2 and k3 and place result in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RVR</td>, <td>ModRM:reg (w)</td>, <td>VEX.1vvv (r)</td>, <td>ModRM:r/m (r, ModRM:[7:6] must be 11b)</td>]

[<td></td>, <td></td>, <td></td>, <td>Invalid*</td>, <td>Valid</td>, <td>Load: AH ← EFLAGS(SF:ZF:0:AF:0:PF:1:CF).</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.80000001H:ECX.LAHF-SAHF[bit 0] = 0.</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 02 /<em>r</em></td>, <td>LAR <em>r16, r16/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r16</em> ← access rights referenced by <em>r16/m16</em></td>, <td>0F 02 /<em>r</em></td>, <td>LAR <em>reg, r32/m16</em><sup>1</sup></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td><em>reg</em> ← access rights referenced by <em>r32/m16</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>0 1 2 3 4 5 6 7 8 9 A B C D E F</td>, <td>Reserved Available 16-bit TSS LDT Busy 16-bit TSS 16-bit call gate 16-bit/32-bit task gate 16-bit interrupt gate 16-bit trap gate Reserved Available 32-bit TSS Reserved Busy 32-bit TSS 32-bit call gate Reserved 32-bit interrupt gate 32-bit trap gate</td>, <td>No Yes Yes Yes Yes Yes No No No Yes No Yes Yes No No No</td>, <td>Reserved Reserved LDT Reserved Reserved Reserved Reserved Reserved Reserved Available 64-bit TSS Reserved Busy 64-bit TSS 64-bit call gate Reserved 64-bit interrupt gate 64-bit trap gate</td>, <td>No No Yes No No No No No No Yes No Yes Yes No No No</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and the memory operand effective address is unaligned while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>The LAR instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>The LAR instruction cannot be executed in virtual-8086 mode.</td>, <td>#SS(0)</td>, <td>If the memory operand effective address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory operand effective address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and the memory operand effective address is unaligned while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>F2 0F F0 /<em>r</em> LDDQU <em>xmm1</em>, <em>mem</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE3</td>, <td>Load unaligned data from <em>mem</em> and return double quadword in <em>xmm1</em>.</td>, <td>VEX.128.F2.0F.WIG F0 /r VLDDQU xmm1, m128</td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Load unaligned packed integer values from mem to xmm1.</td>, <td>VEX.256.F2.0F.WIG F0 /r VLDDQU ymm1, m256</td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Load unaligned packed integer values from mem to ymm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>NP 0F AE /2 LDMXCSR <em>m32</em></td>, <td>M</td>, <td>V/V</td>, <td>SSE</td>, <td>Load MXCSR register from <em>m32</em>.</td>, <td>VEX.LZ.0F.WIG AE /2 VLDMXCSR <em>m32</em></td>, <td>M</td>, <td>V/V</td>, <td>AVX</td>, <td>Load MXCSR register from <em>m32.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP</td>, <td>For an attempt to set reserved bits in MXCSR.</td>, <td>#UD</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>C5 /<em>r</em></td>, <td>LDS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load DS:<em>r16</em> with far pointer from memory.</td>, <td>C5 /<em>r</em></td>, <td>LDS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load DS:<em>r32</em> with far pointer from memory.</td>, <td>0F B2 /<em>r</em></td>, <td>LSS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load SS:<em>r16</em> with far pointer from memory.</td>, <td>0F B2 /<em>r</em></td>, <td>LSS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load SS:<em>r32</em> with far pointer from memory.</td>, <td>REX + 0F B2 /<em>r</em></td>, <td>LSS <em>r64,m16:64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load SS:<em>r64</em> with far pointer from memory.</td>, <td>C4 /<em>r</em></td>, <td>LES <em>r16,m16:16</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load ES:<em>r16</em> with far pointer from memory.</td>, <td>C4 /<em>r</em></td>, <td>LES <em>r32,m16:32</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load ES:<em>r32</em> with far pointer from memory.</td>, <td>0F B4 /<em>r</em></td>, <td>LFS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load FS:<em>r16</em> with far pointer from memory.</td>, <td>0F B4 /<em>r</em></td>, <td>LFS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load FS:<em>r32</em> with far pointer from memory.</td>, <td>REX + 0F B4 /<em>r</em></td>, <td>LFS <em>r64,m16:64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load FS:<em>r64</em> with far pointer from memory.</td>, <td>0F B5 /<em>r</em></td>, <td>LGS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load GS:<em>r16</em> with far pointer from memory.</td>, <td>0F B5 /<em>r</em></td>, <td>LGS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load GS:<em>r32</em> with far pointer from memory.</td>, <td>REX + 0F B5 /<em>r</em></td>, <td>LGS <em>r64,m16:64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load GS:<em>r64</em> with far pointer from memory.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="3">#GP(0)</td>, <td>If a NULL selector is loaded into the SS register.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td rowspan="2">#GP(selector)</td>, <td>If the SS register is being loaded and any of the following is true: the segment selector index is not within the descriptor table limits, the segment selector RPL is not equal to CPL, the segment is a non-writable data segment, or DPL is not equal to CPL.</td>, <td>If the DS, ES, FS, or GS register is being loaded with a non-NULL segment selector and any of the following is true: the segment selector index is not within descriptor table limits, the segment is neither a data nor a readable code segment, or the segment is a data or nonconforming-code segment and both RPL and CPL are greater than DPL.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#SS(selector)</td>, <td>If the SS register is being loaded and the segment is marked not present.</td>, <td>#NP(selector)</td>, <td>If DS, ES, FS, or GS register is being loaded with a non-NULL segment selector and the segment is marked not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td rowspan="4">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If a NULL selector is attempted to be loaded into the SS register in compatibility mode.</td>, <td>If a NULL selector is attempted to be loaded into the SS register in CPL3 and 64-bit mode.</td>, <td>If a NULL selector is attempted to be loaded into the SS register in non-CPL3 and 64-bit mode where its RPL is not equal to CPL.</td>, <td rowspan="2">#GP(Selector)</td>, <td>If the FS, or GS register is being loaded with a non-NULL segment selector and any of the following is true: the segment selector index is not within descriptor table limits, the memory address of the descriptor is non-canonical, the segment is neither a data nor a readable code segment, or the segment is a data or nonconforming-code segment and both RPL and CPL are greater than DPL.</td>, <td>If the SS register is being loaded and any of the following is true: the segment selector index is not within the descriptor table limits, the memory address of the descriptor is non-canonical, the segment selector RPL is not equal to CPL, the segment is a nonwritable data segment, or DPL is not equal to CPL.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is non-canonical</td>, <td>#SS(Selector)</td>, <td>If the SS register is being loaded and the segment is marked not present.</td>, <td>#NP(selector)</td>, <td>If FS, or GS register is being loaded with a non-NULL segment selector and the segment is marked not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>]

[<td>8D /<em>r</em></td>, <td>LEA <em>r16,m</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Store effective address for <em>m</em> in register <em>r16.</em></td>, <td>8D /<em>r</em></td>, <td>LEA <em>r32,m</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Store effective address for <em>m</em> in register <em>r32.</em></td>, <td>REX.W + 8D /<em>r</em></td>, <td>LEA <em>r64,m</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store effective address for <em>m</em> in register <em>r64.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>16</td>, <td>16</td>, <td>16-bit effective address is calculated and stored in requested 16-bit register destination.</td>, <td>16</td>, <td>32</td>, <td>32-bit effective address is calculated. The lower 16 bits of the address are stored in the requested 16-bit register destination.</td>, <td>32</td>, <td>16</td>, <td>16-bit effective address is calculated. The 16-bit address is zero-extended and stored in the requested 32-bit register destination.</td>, <td>32</td>, <td>32</td>, <td>32-bit effective address is calculated and stored in the requested 32-bit register destination.</td>, <td>16</td>, <td>32</td>, <td>32-bit effective address is calculated (using 67H prefix). The lower 16 bits of the address are stored in the requested 16-bit register destination (using 66H prefix).</td>, <td>16</td>, <td>64</td>, <td>64-bit effective address is calculated (default address size). The lower 16 bits of the address are stored in the requested 16-bit register destination (using 66H prefix).</td>, <td>32</td>, <td>32</td>, <td>32-bit effective address is calculated (using 67H prefix) and stored in the requested 32-bit register destination.</td>, <td>32</td>, <td>64</td>, <td>64-bit effective address is calculated (default address size) and the lower 32 bits of the address are stored in the requested 32-bit register destination.</td>, <td>64</td>, <td>32</td>, <td>32-bit effective address is calculated (using 67H prefix), zero-extended to 64-bits, and stored in the requested 64-bit register destination (using REX.W).</td>, <td>64</td>, <td>64</td>, <td>64-bit effective address is calculated (default address size) and all 64-bits of the address are stored in the requested 64-bit register destination (using REX.W).</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>]

[<td>C9</td>, <td>LEAVE</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Set SP to BP, then pop BP.</td>, <td>C9</td>, <td>LEAVE</td>, <td>ZO</td>, <td>N.E.</td>, <td>Valid</td>, <td>Set ESP to EBP, then pop EBP.</td>, <td>C9</td>, <td>LEAVE</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set RSP to RBP, then pop RBP.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#SS(0)</td>, <td>If the EBP register points to a location that is not within the limits of the current stack segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If the EBP register points to a location outside of the effective address space from 0 to FFFFH.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the EBP register points to a location outside of the effective address space from 0 to FFFFH.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If the stack address is in a non-canonical form.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>C5 /<em>r</em></td>, <td>LDS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load DS:<em>r16</em> with far pointer from memory.</td>, <td>C5 /<em>r</em></td>, <td>LDS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load DS:<em>r32</em> with far pointer from memory.</td>, <td>0F B2 /<em>r</em></td>, <td>LSS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load SS:<em>r16</em> with far pointer from memory.</td>, <td>0F B2 /<em>r</em></td>, <td>LSS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load SS:<em>r32</em> with far pointer from memory.</td>, <td>REX + 0F B2 /<em>r</em></td>, <td>LSS <em>r64,m16:64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load SS:<em>r64</em> with far pointer from memory.</td>, <td>C4 /<em>r</em></td>, <td>LES <em>r16,m16:16</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load ES:<em>r16</em> with far pointer from memory.</td>, <td>C4 /<em>r</em></td>, <td>LES <em>r32,m16:32</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load ES:<em>r32</em> with far pointer from memory.</td>, <td>0F B4 /<em>r</em></td>, <td>LFS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load FS:<em>r16</em> with far pointer from memory.</td>, <td>0F B4 /<em>r</em></td>, <td>LFS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load FS:<em>r32</em> with far pointer from memory.</td>, <td>REX + 0F B4 /<em>r</em></td>, <td>LFS <em>r64,m16:64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load FS:<em>r64</em> with far pointer from memory.</td>, <td>0F B5 /<em>r</em></td>, <td>LGS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load GS:<em>r16</em> with far pointer from memory.</td>, <td>0F B5 /<em>r</em></td>, <td>LGS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load GS:<em>r32</em> with far pointer from memory.</td>, <td>REX + 0F B5 /<em>r</em></td>, <td>LGS <em>r64,m16:64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load GS:<em>r64</em> with far pointer from memory.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="3">#GP(0)</td>, <td>If a NULL selector is loaded into the SS register.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td rowspan="2">#GP(selector)</td>, <td>If the SS register is being loaded and any of the following is true: the segment selector index is not within the descriptor table limits, the segment selector RPL is not equal to CPL, the segment is a non-writable data segment, or DPL is not equal to CPL.</td>, <td>If the DS, ES, FS, or GS register is being loaded with a non-NULL segment selector and any of the following is true: the segment selector index is not within descriptor table limits, the segment is neither a data nor a readable code segment, or the segment is a data or nonconforming-code segment and both RPL and CPL are greater than DPL.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#SS(selector)</td>, <td>If the SS register is being loaded and the segment is marked not present.</td>, <td>#NP(selector)</td>, <td>If DS, ES, FS, or GS register is being loaded with a non-NULL segment selector and the segment is marked not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td rowspan="4">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If a NULL selector is attempted to be loaded into the SS register in compatibility mode.</td>, <td>If a NULL selector is attempted to be loaded into the SS register in CPL3 and 64-bit mode.</td>, <td>If a NULL selector is attempted to be loaded into the SS register in non-CPL3 and 64-bit mode where its RPL is not equal to CPL.</td>, <td rowspan="2">#GP(Selector)</td>, <td>If the FS, or GS register is being loaded with a non-NULL segment selector and any of the following is true: the segment selector index is not within descriptor table limits, the memory address of the descriptor is non-canonical, the segment is neither a data nor a readable code segment, or the segment is a data or nonconforming-code segment and both RPL and CPL are greater than DPL.</td>, <td>If the SS register is being loaded and any of the following is true: the segment selector index is not within the descriptor table limits, the memory address of the descriptor is non-canonical, the segment selector RPL is not equal to CPL, the segment is a nonwritable data segment, or DPL is not equal to CPL.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is non-canonical</td>, <td>#SS(Selector)</td>, <td>If the SS register is being loaded and the segment is marked not present.</td>, <td>#NP(selector)</td>, <td>If FS, or GS register is being loaded with a non-NULL segment selector and the segment is marked not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>]

[<td>NP 0F AE E8</td>, <td>LFENCE</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Serializes load operations.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>C5 /<em>r</em></td>, <td>LDS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load DS:<em>r16</em> with far pointer from memory.</td>, <td>C5 /<em>r</em></td>, <td>LDS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load DS:<em>r32</em> with far pointer from memory.</td>, <td>0F B2 /<em>r</em></td>, <td>LSS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load SS:<em>r16</em> with far pointer from memory.</td>, <td>0F B2 /<em>r</em></td>, <td>LSS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load SS:<em>r32</em> with far pointer from memory.</td>, <td>REX + 0F B2 /<em>r</em></td>, <td>LSS <em>r64,m16:64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load SS:<em>r64</em> with far pointer from memory.</td>, <td>C4 /<em>r</em></td>, <td>LES <em>r16,m16:16</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load ES:<em>r16</em> with far pointer from memory.</td>, <td>C4 /<em>r</em></td>, <td>LES <em>r32,m16:32</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load ES:<em>r32</em> with far pointer from memory.</td>, <td>0F B4 /<em>r</em></td>, <td>LFS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load FS:<em>r16</em> with far pointer from memory.</td>, <td>0F B4 /<em>r</em></td>, <td>LFS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load FS:<em>r32</em> with far pointer from memory.</td>, <td>REX + 0F B4 /<em>r</em></td>, <td>LFS <em>r64,m16:64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load FS:<em>r64</em> with far pointer from memory.</td>, <td>0F B5 /<em>r</em></td>, <td>LGS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load GS:<em>r16</em> with far pointer from memory.</td>, <td>0F B5 /<em>r</em></td>, <td>LGS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load GS:<em>r32</em> with far pointer from memory.</td>, <td>REX + 0F B5 /<em>r</em></td>, <td>LGS <em>r64,m16:64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load GS:<em>r64</em> with far pointer from memory.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="3">#GP(0)</td>, <td>If a NULL selector is loaded into the SS register.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td rowspan="2">#GP(selector)</td>, <td>If the SS register is being loaded and any of the following is true: the segment selector index is not within the descriptor table limits, the segment selector RPL is not equal to CPL, the segment is a non-writable data segment, or DPL is not equal to CPL.</td>, <td>If the DS, ES, FS, or GS register is being loaded with a non-NULL segment selector and any of the following is true: the segment selector index is not within descriptor table limits, the segment is neither a data nor a readable code segment, or the segment is a data or nonconforming-code segment and both RPL and CPL are greater than DPL.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#SS(selector)</td>, <td>If the SS register is being loaded and the segment is marked not present.</td>, <td>#NP(selector)</td>, <td>If DS, ES, FS, or GS register is being loaded with a non-NULL segment selector and the segment is marked not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td rowspan="4">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If a NULL selector is attempted to be loaded into the SS register in compatibility mode.</td>, <td>If a NULL selector is attempted to be loaded into the SS register in CPL3 and 64-bit mode.</td>, <td>If a NULL selector is attempted to be loaded into the SS register in non-CPL3 and 64-bit mode where its RPL is not equal to CPL.</td>, <td rowspan="2">#GP(Selector)</td>, <td>If the FS, or GS register is being loaded with a non-NULL segment selector and any of the following is true: the segment selector index is not within descriptor table limits, the memory address of the descriptor is non-canonical, the segment is neither a data nor a readable code segment, or the segment is a data or nonconforming-code segment and both RPL and CPL are greater than DPL.</td>, <td>If the SS register is being loaded and any of the following is true: the segment selector index is not within the descriptor table limits, the memory address of the descriptor is non-canonical, the segment selector RPL is not equal to CPL, the segment is a nonwritable data segment, or DPL is not equal to CPL.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is non-canonical</td>, <td>#SS(Selector)</td>, <td>If the SS register is being loaded and the segment is marked not present.</td>, <td>#NP(selector)</td>, <td>If FS, or GS register is being loaded with a non-NULL segment selector and the segment is marked not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 01 /2</td>, <td>LGDT <em>m16&amp;32</em></td>, <td>M</td>, <td>N.E.</td>, <td>Valid</td>, <td>Load <em>m</em> into GDTR.</td>, <td>0F 01 /3</td>, <td>LIDT <em>m16&amp;32</em></td>, <td>M</td>, <td>N.E.</td>, <td>Valid</td>, <td>Load <em>m</em> into IDTR.</td>, <td>0F 01 /2</td>, <td>LGDT <em>m16&amp;64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load <em>m</em> into GDTR.</td>, <td>0F 01 /3</td>, <td>LIDT <em>m16&amp;64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load <em>m</em> into IDTR.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="3">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If the current privilege level is not 0.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>]

[<td>C5 /<em>r</em></td>, <td>LDS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load DS:<em>r16</em> with far pointer from memory.</td>, <td>C5 /<em>r</em></td>, <td>LDS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load DS:<em>r32</em> with far pointer from memory.</td>, <td>0F B2 /<em>r</em></td>, <td>LSS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load SS:<em>r16</em> with far pointer from memory.</td>, <td>0F B2 /<em>r</em></td>, <td>LSS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load SS:<em>r32</em> with far pointer from memory.</td>, <td>REX + 0F B2 /<em>r</em></td>, <td>LSS <em>r64,m16:64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load SS:<em>r64</em> with far pointer from memory.</td>, <td>C4 /<em>r</em></td>, <td>LES <em>r16,m16:16</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load ES:<em>r16</em> with far pointer from memory.</td>, <td>C4 /<em>r</em></td>, <td>LES <em>r32,m16:32</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load ES:<em>r32</em> with far pointer from memory.</td>, <td>0F B4 /<em>r</em></td>, <td>LFS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load FS:<em>r16</em> with far pointer from memory.</td>, <td>0F B4 /<em>r</em></td>, <td>LFS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load FS:<em>r32</em> with far pointer from memory.</td>, <td>REX + 0F B4 /<em>r</em></td>, <td>LFS <em>r64,m16:64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load FS:<em>r64</em> with far pointer from memory.</td>, <td>0F B5 /<em>r</em></td>, <td>LGS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load GS:<em>r16</em> with far pointer from memory.</td>, <td>0F B5 /<em>r</em></td>, <td>LGS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load GS:<em>r32</em> with far pointer from memory.</td>, <td>REX + 0F B5 /<em>r</em></td>, <td>LGS <em>r64,m16:64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load GS:<em>r64</em> with far pointer from memory.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="3">#GP(0)</td>, <td>If a NULL selector is loaded into the SS register.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td rowspan="2">#GP(selector)</td>, <td>If the SS register is being loaded and any of the following is true: the segment selector index is not within the descriptor table limits, the segment selector RPL is not equal to CPL, the segment is a non-writable data segment, or DPL is not equal to CPL.</td>, <td>If the DS, ES, FS, or GS register is being loaded with a non-NULL segment selector and any of the following is true: the segment selector index is not within descriptor table limits, the segment is neither a data nor a readable code segment, or the segment is a data or nonconforming-code segment and both RPL and CPL are greater than DPL.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#SS(selector)</td>, <td>If the SS register is being loaded and the segment is marked not present.</td>, <td>#NP(selector)</td>, <td>If DS, ES, FS, or GS register is being loaded with a non-NULL segment selector and the segment is marked not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td rowspan="4">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If a NULL selector is attempted to be loaded into the SS register in compatibility mode.</td>, <td>If a NULL selector is attempted to be loaded into the SS register in CPL3 and 64-bit mode.</td>, <td>If a NULL selector is attempted to be loaded into the SS register in non-CPL3 and 64-bit mode where its RPL is not equal to CPL.</td>, <td rowspan="2">#GP(Selector)</td>, <td>If the FS, or GS register is being loaded with a non-NULL segment selector and any of the following is true: the segment selector index is not within descriptor table limits, the memory address of the descriptor is non-canonical, the segment is neither a data nor a readable code segment, or the segment is a data or nonconforming-code segment and both RPL and CPL are greater than DPL.</td>, <td>If the SS register is being loaded and any of the following is true: the segment selector index is not within the descriptor table limits, the memory address of the descriptor is non-canonical, the segment selector RPL is not equal to CPL, the segment is a nonwritable data segment, or DPL is not equal to CPL.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is non-canonical</td>, <td>#SS(Selector)</td>, <td>If the SS register is being loaded and the segment is marked not present.</td>, <td>#NP(selector)</td>, <td>If FS, or GS register is being loaded with a non-NULL segment selector and the segment is marked not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 01 /2</td>, <td>LGDT <em>m16&amp;32</em></td>, <td>M</td>, <td>N.E.</td>, <td>Valid</td>, <td>Load <em>m</em> into GDTR.</td>, <td>0F 01 /3</td>, <td>LIDT <em>m16&amp;32</em></td>, <td>M</td>, <td>N.E.</td>, <td>Valid</td>, <td>Load <em>m</em> into IDTR.</td>, <td>0F 01 /2</td>, <td>LGDT <em>m16&amp;64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load <em>m</em> into GDTR.</td>, <td>0F 01 /3</td>, <td>LIDT <em>m16&amp;64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load <em>m</em> into IDTR.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="3">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If the current privilege level is not 0.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>]

[<td>0F 00 /2</td>, <td>LLDT <em>r/m</em>16</td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Load segment selector <em>r/m</em>16 into LDTR.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td rowspan="2">#GP(selector)</td>, <td>If the selector operand does not point into the Global Descriptor Table or if the entry in the GDT is not a Local Descriptor Table.</td>, <td>Segment selector is beyond GDT limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#NP(selector)</td>, <td>If the LDT descriptor is not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>The LLDT instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>The LLDT instruction is not recognized in virtual-8086 mode.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the memory address is in a non-canonical form.</td>, <td rowspan="2">#GP(selector)</td>, <td>If the selector operand does not point into the Global Descriptor Table or if the entry in the GDT is not a Local Descriptor Table.</td>, <td>Segment selector is beyond GDT limit.</td>, <td>#NP(selector)</td>, <td>If the LDT descriptor is not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 01 /6</td>, <td>LMSW <em>r/m</em>16</td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Loads <em>r/m</em>16 in machine status word of CR0.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>The LMSW instruction is not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>F0</td>, <td>LOCK</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Asserts LOCK# signal for duration of the accompanying instruction.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used with an instruction not listed: ADD, ADC, AND, BTC, BTR, BTS, CMPXCHG, CMPXCH8B, CMPXCHG16B, DEC, INC, NEG, NOT, OR, SBB, SUB, XOR, XADD, XCHG.</td>, <td>Other exceptions can be generated by the instruction when the LOCK prefix is applied.</td>]

[<td>AC</td>, <td>LODS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load byte at address DS:(E)SI into AL. For 64-bit mode load byte at address (R)SI into AL.</td>, <td>AD</td>, <td>LODS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load word at address DS:(E)SI into AX. For 64-bit mode load word at address (R)SI into AX.</td>, <td>AD</td>, <td>LODS m32</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load dword at address DS:(E)SI into EAX. For 64-bit mode load dword at address (R)SI into EAX.</td>, <td>REX.W + AD</td>, <td>LODS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load qword at address (R)SI into RAX.</td>, <td>AC</td>, <td>LODSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load byte at address DS:(E)SI into AL. For 64-bit mode load byte at address (R)SI into AL.</td>, <td>AD</td>, <td>LODSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load word at address DS:(E)SI into AX. For 64-bit mode load word at address (R)SI into AX.</td>, <td>AD</td>, <td>LODSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load dword at address DS:(E)SI into EAX. For 64-bit mode load dword at address (R)SI into EAX.</td>, <td>REX.W + AD</td>, <td>LODSQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load qword at address (R)SI into RAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>AC</td>, <td>LODS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load byte at address DS:(E)SI into AL. For 64-bit mode load byte at address (R)SI into AL.</td>, <td>AD</td>, <td>LODS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load word at address DS:(E)SI into AX. For 64-bit mode load word at address (R)SI into AX.</td>, <td>AD</td>, <td>LODS m32</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load dword at address DS:(E)SI into EAX. For 64-bit mode load dword at address (R)SI into EAX.</td>, <td>REX.W + AD</td>, <td>LODS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load qword at address (R)SI into RAX.</td>, <td>AC</td>, <td>LODSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load byte at address DS:(E)SI into AL. For 64-bit mode load byte at address (R)SI into AL.</td>, <td>AD</td>, <td>LODSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load word at address DS:(E)SI into AX. For 64-bit mode load word at address (R)SI into AX.</td>, <td>AD</td>, <td>LODSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load dword at address DS:(E)SI into EAX. For 64-bit mode load dword at address (R)SI into EAX.</td>, <td>REX.W + AD</td>, <td>LODSQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load qword at address (R)SI into RAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>AC</td>, <td>LODS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load byte at address DS:(E)SI into AL. For 64-bit mode load byte at address (R)SI into AL.</td>, <td>AD</td>, <td>LODS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load word at address DS:(E)SI into AX. For 64-bit mode load word at address (R)SI into AX.</td>, <td>AD</td>, <td>LODS m32</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load dword at address DS:(E)SI into EAX. For 64-bit mode load dword at address (R)SI into EAX.</td>, <td>REX.W + AD</td>, <td>LODS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load qword at address (R)SI into RAX.</td>, <td>AC</td>, <td>LODSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load byte at address DS:(E)SI into AL. For 64-bit mode load byte at address (R)SI into AL.</td>, <td>AD</td>, <td>LODSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load word at address DS:(E)SI into AX. For 64-bit mode load word at address (R)SI into AX.</td>, <td>AD</td>, <td>LODSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load dword at address DS:(E)SI into EAX. For 64-bit mode load dword at address (R)SI into EAX.</td>, <td>REX.W + AD</td>, <td>LODSQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load qword at address (R)SI into RAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>AC</td>, <td>LODS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load byte at address DS:(E)SI into AL. For 64-bit mode load byte at address (R)SI into AL.</td>, <td>AD</td>, <td>LODS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load word at address DS:(E)SI into AX. For 64-bit mode load word at address (R)SI into AX.</td>, <td>AD</td>, <td>LODS m32</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load dword at address DS:(E)SI into EAX. For 64-bit mode load dword at address (R)SI into EAX.</td>, <td>REX.W + AD</td>, <td>LODS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load qword at address (R)SI into RAX.</td>, <td>AC</td>, <td>LODSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load byte at address DS:(E)SI into AL. For 64-bit mode load byte at address (R)SI into AL.</td>, <td>AD</td>, <td>LODSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load word at address DS:(E)SI into AX. For 64-bit mode load word at address (R)SI into AX.</td>, <td>AD</td>, <td>LODSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load dword at address DS:(E)SI into EAX. For 64-bit mode load dword at address (R)SI into EAX.</td>, <td>REX.W + AD</td>, <td>LODSQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load qword at address (R)SI into RAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>AC</td>, <td>LODS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load byte at address DS:(E)SI into AL. For 64-bit mode load byte at address (R)SI into AL.</td>, <td>AD</td>, <td>LODS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load word at address DS:(E)SI into AX. For 64-bit mode load word at address (R)SI into AX.</td>, <td>AD</td>, <td>LODS m32</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load dword at address DS:(E)SI into EAX. For 64-bit mode load dword at address (R)SI into EAX.</td>, <td>REX.W + AD</td>, <td>LODS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load qword at address (R)SI into RAX.</td>, <td>AC</td>, <td>LODSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load byte at address DS:(E)SI into AL. For 64-bit mode load byte at address (R)SI into AL.</td>, <td>AD</td>, <td>LODSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load word at address DS:(E)SI into AX. For 64-bit mode load word at address (R)SI into AX.</td>, <td>AD</td>, <td>LODSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Load dword at address DS:(E)SI into EAX. For 64-bit mode load dword at address (R)SI into EAX.</td>, <td>REX.W + AD</td>, <td>LODSQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load qword at address (R)SI into RAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>E2 <em>cb</em></td>, <td>LOOP <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Decrement count; jump short if count ≠ 0.</td>, <td>E1 <em>cb</em></td>, <td>LOOPE <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Decrement count; jump short if count ≠ 0 and ZF = 1.</td>, <td>E0 <em>cb</em></td>, <td>LOOPNE <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Decrement count; jump short if count ≠ 0 and ZF = 0.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>D</td>, <td>Offset</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If the offset being jumped to is beyond the limits of the CS segment.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If the offset being jumped to is beyond the limits of the CS segment or is outside of the effective address space from 0 to FFFFH. This condition can occur if a 32-bit address size override prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the offset being jumped to is in a non-canonical form.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>E2 <em>cb</em></td>, <td>LOOP <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Decrement count; jump short if count ≠ 0.</td>, <td>E1 <em>cb</em></td>, <td>LOOPE <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Decrement count; jump short if count ≠ 0 and ZF = 1.</td>, <td>E0 <em>cb</em></td>, <td>LOOPNE <em>rel8</em></td>, <td>D</td>, <td>Valid</td>, <td>Valid</td>, <td>Decrement count; jump short if count ≠ 0 and ZF = 0.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>D</td>, <td>Offset</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If the offset being jumped to is beyond the limits of the CS segment.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If the offset being jumped to is beyond the limits of the CS segment or is outside of the effective address space from 0 to FFFFH. This condition can occur if a 32-bit address size override prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the offset being jumped to is in a non-canonical form.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 03 /<em>r</em></td>, <td>LSL <em>r16, r16/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load: <em>r16</em> ← segment limit, selector <em>r16/m16.</em></td>, <td>0F 03 /<em>r</em></td>, <td>LSL <em>r32, r32/m16</em><sup>*</sup></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load: <em>r32</em> ← segment limit, selector <em>r32/m16.</em></td>, <td>REX.W + 0F 03 /<em>r</em></td>, <td>LSL <em>r64, r32/m16</em><sup>*</sup></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load: <em>r64</em> ← segment limit, selector <em>r32/m16</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>0 1 2 3 4 5 6 7 8 9 A B C D E F</td>, <td>Reserved Available 16-bit TSS LDT Busy 16-bit TSS 16-bit call gate 16-bit/32-bit task gate 16-bit interrupt gate 16-bit trap gate Reserved Available 32-bit TSS Reserved Busy 32-bit TSS 32-bit call gate Reserved 32-bit interrupt gate 32-bit trap gate</td>, <td>No Yes Yes Yes No No No No No Yes No Yes No No No No</td>, <td>Reserved Reserved LDT<sup>1</sup> Reserved Reserved Reserved Reserved Reserved Reserved 64-bit TSS<sup>1</sup> Reserved Busy 64-bit TSS<sup>1</sup> 64-bit call gate Reserved 64-bit interrupt gate 64-bit trap gate</td>, <td>No No Yes No No No No No No Yes No Yes No No No No</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and the memory operand effective address is unaligned while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>The LSL instruction cannot be executed in real-address mode.</td>, <td>#UD</td>, <td>The LSL instruction cannot be executed in virtual-8086 mode.</td>, <td>#SS(0)</td>, <td>If the memory operand effective address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory operand effective address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and the memory operand effective address is unaligned while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>C5 /<em>r</em></td>, <td>LDS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load DS:<em>r16</em> with far pointer from memory.</td>, <td>C5 /<em>r</em></td>, <td>LDS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load DS:<em>r32</em> with far pointer from memory.</td>, <td>0F B2 /<em>r</em></td>, <td>LSS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load SS:<em>r16</em> with far pointer from memory.</td>, <td>0F B2 /<em>r</em></td>, <td>LSS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load SS:<em>r32</em> with far pointer from memory.</td>, <td>REX + 0F B2 /<em>r</em></td>, <td>LSS <em>r64,m16:64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load SS:<em>r64</em> with far pointer from memory.</td>, <td>C4 /<em>r</em></td>, <td>LES <em>r16,m16:16</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load ES:<em>r16</em> with far pointer from memory.</td>, <td>C4 /<em>r</em></td>, <td>LES <em>r32,m16:32</em></td>, <td>RM</td>, <td>Invalid</td>, <td>Valid</td>, <td>Load ES:<em>r32</em> with far pointer from memory.</td>, <td>0F B4 /<em>r</em></td>, <td>LFS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load FS:<em>r16</em> with far pointer from memory.</td>, <td>0F B4 /<em>r</em></td>, <td>LFS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load FS:<em>r32</em> with far pointer from memory.</td>, <td>REX + 0F B4 /<em>r</em></td>, <td>LFS <em>r64,m16:64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load FS:<em>r64</em> with far pointer from memory.</td>, <td>0F B5 /<em>r</em></td>, <td>LGS <em>r16,m16:16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load GS:<em>r16</em> with far pointer from memory.</td>, <td>0F B5 /<em>r</em></td>, <td>LGS <em>r32,m16:32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Load GS:<em>r32</em> with far pointer from memory.</td>, <td>REX + 0F B5 /<em>r</em></td>, <td>LGS <em>r64,m16:64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load GS:<em>r64</em> with far pointer from memory.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="3">#GP(0)</td>, <td>If a NULL selector is loaded into the SS register.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td rowspan="2">#GP(selector)</td>, <td>If the SS register is being loaded and any of the following is true: the segment selector index is not within the descriptor table limits, the segment selector RPL is not equal to CPL, the segment is a non-writable data segment, or DPL is not equal to CPL.</td>, <td>If the DS, ES, FS, or GS register is being loaded with a non-NULL segment selector and any of the following is true: the segment selector index is not within descriptor table limits, the segment is neither a data nor a readable code segment, or the segment is a data or nonconforming-code segment and both RPL and CPL are greater than DPL.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#SS(selector)</td>, <td>If the SS register is being loaded and the segment is marked not present.</td>, <td>#NP(selector)</td>, <td>If DS, ES, FS, or GS register is being loaded with a non-NULL segment selector and the segment is marked not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td rowspan="4">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If a NULL selector is attempted to be loaded into the SS register in compatibility mode.</td>, <td>If a NULL selector is attempted to be loaded into the SS register in CPL3 and 64-bit mode.</td>, <td>If a NULL selector is attempted to be loaded into the SS register in non-CPL3 and 64-bit mode where its RPL is not equal to CPL.</td>, <td rowspan="2">#GP(Selector)</td>, <td>If the FS, or GS register is being loaded with a non-NULL segment selector and any of the following is true: the segment selector index is not within descriptor table limits, the memory address of the descriptor is non-canonical, the segment is neither a data nor a readable code segment, or the segment is a data or nonconforming-code segment and both RPL and CPL are greater than DPL.</td>, <td>If the SS register is being loaded and any of the following is true: the segment selector index is not within the descriptor table limits, the memory address of the descriptor is non-canonical, the segment selector RPL is not equal to CPL, the segment is a nonwritable data segment, or DPL is not equal to CPL.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is non-canonical</td>, <td>#SS(Selector)</td>, <td>If the SS register is being loaded and the segment is marked not present.</td>, <td>#NP(selector)</td>, <td>If FS, or GS register is being loaded with a non-NULL segment selector and the segment is marked not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="2">#UD</td>, <td>If source operand is not a memory location.</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 00 /3</td>, <td>LTR <em>r/m</em>16</td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Load <em>r/m</em>16 into task register.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="4">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the source operand contains a NULL segment selector.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td rowspan="2">#GP(selector)</td>, <td>If the source selector points to a segment that is not a TSS or to one for a task that is already busy.</td>, <td>If the selector points to LDT or is beyond the GDT limit.</td>, <td>#NP(selector)</td>, <td>If the TSS is marked not present.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>The LTR instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>The LTR instruction is not recognized in virtual-8086 mode.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="3">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If the source operand contains a NULL segment selector.</td>, <td rowspan="3">#GP(selector)</td>, <td>If the source selector points to a segment that is not a TSS or to one for a task that is already busy.</td>, <td>If the selector points to LDT or is beyond the GDT limit.</td>, <td>If the descriptor type of the upper 8-byte of the 16-byte descriptor is non-zero.</td>, <td>#NP(selector)</td>, <td>If the TSS is marked not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>F3 0F BD /r</td>, <td>RM</td>, <td>V/V</td>, <td>LZCNT</td>, <td rowspan="2">Count the number of leading zero bits in r/m16, return result in r16.</td>, <td>LZCNT r16, r/m16</td>, <td></td>, <td></td>, <td></td>, <td>F3 0F BD /r</td>, <td>RM</td>, <td>V/V</td>, <td>LZCNT</td>, <td rowspan="2">Count the number of leading zero bits in r/m32, return result in r32.</td>, <td>LZCNT r32, r/m32</td>, <td></td>, <td></td>, <td></td>, <td>F3 REX.W 0F BD /r</td>, <td>RM</td>, <td>V/N.E.</td>, <td>LZCNT</td>, <td rowspan="2">Count the number of leading zero bits in r/m64, return result in r64.</td>, <td>LZCNT r64, r/m64</td>, <td></td>, <td></td>, <td></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>For an illegal memory operand effective address in the CS, DS, ES, FS or GS segments.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a null segment selector.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#GP(0)</td>, <td>If any part of the operand lies outside of the effective address space from 0 to 0FFFFH.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#GP(0)</td>, <td>If any part of the operand lies outside of the effective address space from 0 to 0FFFFH.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>]

[<td>66 0F F7 /<em>r</em> MASKMOVDQU <em>xmm1</em>, <em>xmm2</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE2</td>, <td>Selectively write bytes from <em>xmm1</em> to memory location using the byte mask in <em>xmm2</em>. The default memory location is specified by DS:DI/EDI/RDI.</td>, <td>VEX.128.66.0F.WIG F7 /r VMASKMOVDQU <em>xmm1, xmm2</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Selectively write bytes from <em>xmm1</em> to memory location using the byte mask in <em>xmm2</em>. The default memory location is specified by DS:DI/EDI/RDI.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If VEX.L= 1</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>NP 0F F7 /<em>r</em> MASKMOVQ <em>mm1</em>, <em>mm2</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Selectively write bytes from <em>mm1</em> to memory location using the byte mask in <em>mm2.</em> The default memory location is specified by DS:DI/EDI/RDI.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>66 0F 5F /r MAXPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Return the maximum double-precision floating-point values between xmm1 and xmm2/m128.</td>, <td>VEX.128.66.0F.WIG 5F /r VMAXPD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the maximum double-precision floating-point values between xmm2 and xmm3/m128.</td>, <td>VEX.256.66.0F.WIG 5F /r VMAXPD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the maximum packed double-precision floating-point values between ymm2 and ymm3/m256.</td>, <td>EVEX.128.66.0F.W1 5F /r VMAXPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Return the maximum packed double-precision floating-point values between xmm2 and xmm3/m128/m64bcst and store result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F.W1 5F /r VMAXPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Return the maximum packed double-precision floating-point values between ymm2 and ymm3/m256/m64bcst and store result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F.W1 5F /r VMAXPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{sae}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Return the maximum packed double-precision floating-point values between zmm2 and zmm3/m512/m64bcst and store result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 5F /r MAXPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Return the maximum single-precision floating-point values between xmm1 and xmm2/mem.</td>, <td>VEX.128.0F.WIG 5F /r VMAXPS xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the maximum single-precision floating-point values between xmm2 and xmm3/mem.</td>, <td>VEX.256.0F.WIG 5F /r VMAXPS ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the maximum single-precision floating-point values between ymm2 and ymm3/mem.</td>, <td>EVEX.128.0F.W0 5F /r VMAXPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Return the maximum packed single-precision floating-point values between xmm2 and xmm3/m128/m32bcst and store result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.0F.W0 5F /r VMAXPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Return the maximum packed single-precision floating-point values between ymm2 and ymm3/m256/m32bcst and store result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.0F.W0 5F /r VMAXPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{sae}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Return the maximum packed single-precision floating-point values between zmm2 and zmm3/m512/m32bcst and store result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F2 0F 5F /r MAXSD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Return the maximum scalar double-precision floating-point value between xmm2/m64 and xmm1.</td>, <td>VEX.LIG.F2.0F.WIG 5F /r VMAXSD xmm1, xmm2, xmm3/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the maximum scalar double-precision floating-point value between xmm3/m64 and xmm2.</td>, <td>EVEX.LIG.F2.0F.W1 5F /r VMAXSD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Return the maximum scalar double-precision floating-point value between xmm3/m64 and xmm2.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F3 0F 5F /r MAXSS xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Return the maximum scalar single-precision floating-point value between xmm2/m32 and xmm1.</td>, <td>VEX.LIG.F3.0F.WIG 5F /r VMAXSS xmm1, xmm2, xmm3/m32</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the maximum scalar single-precision floating-point value between xmm3/m32 and xmm2.</td>, <td>EVEX.LIG.F3.0F.W0 5F /r VMAXSS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Return the maximum scalar single-precision floating-point value between xmm3/m32 and xmm2.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td><strong>Opcode Instruction Op/ 64-Bit Compat/ Description En Mode Leg Mode</strong> NP 0F AE F0 MFENCE ZO Valid Valid Serializes load and store operations.</td>, <td>Op/En Operand 1 Operand 2 Operand 3 Operand 4 ZO NA NA NA NA</td>]

[<td>66 0F 5D /r MINPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Return the minimum double-precision floating-point values between xmm1 and xmm2/mem</td>, <td>VEX.128.66.0F.WIG 5D /r VMINPD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the minimum double-precision floating-point values between xmm2 and xmm3/mem.</td>, <td>VEX.256.66.0F.WIG 5D /r VMINPD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the minimum packed double-precision floating-point values between ymm2 and ymm3/mem.</td>, <td>EVEX.128.66.0F.W1 5D /r VMINPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Return the minimum packed double-precision floating-point values between xmm2 and xmm3/m128/m64bcst and store result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F.W1 5D /r VMINPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Return the minimum packed double-precision floating-point values between ymm2 and ymm3/m256/m64bcst and store result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F.W1 5D /r VMINPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{sae}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Return the minimum packed double-precision floating-point values between zmm2 and zmm3/m512/m64bcst and store result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 5D /r MINPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Return the minimum single-precision floating-point values between xmm1 and xmm2/mem.</td>, <td>VEX.128.0F.WIG 5D /r VMINPS xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the minimum single-precision floating-point values between xmm2 and xmm3/mem.</td>, <td>VEX.256.0F.WIG 5D /r VMINPS ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the minimum single double-precision floating-point values between ymm2 and ymm3/mem.</td>, <td>EVEX.128.0F.W0 5D /r VMINPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Return the minimum packed single-precision floating-point values between xmm2 and xmm3/m128/m32bcst and store result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.0F.W0 5D /r VMINPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Return the minimum packed single-precision floating-point values between ymm2 and ymm3/m256/m32bcst and store result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.0F.W0 5D /r VMINPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{sae}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Return the minimum packed single-precision floating-point values between zmm2 and zmm3/m512/m32bcst and store result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F2 0F 5D /r MINSD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Return the minimum scalar double-precision floating-point value between xmm2/m64 and xmm1.</td>, <td>VEX.LIG.F2.0F.WIG 5D /r VMINSD xmm1, xmm2, xmm3/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the minimum scalar double-precision floating-point value between xmm3/m64 and xmm2.</td>, <td>EVEX.LIG.F2.0F.W1 5D /r VMINSD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Return the minimum scalar double-precision floating-point value between xmm3/m64 and xmm2.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F3 0F 5D /r MINSS xmm1,xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Return the minimum scalar single-precision floating-point value between xmm2/m32 and xmm1.</td>, <td>VEX.LIG.F3.0F.WIG 5D /r VMINSS xmm1,xmm2, xmm3/m32</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the minimum scalar single-precision floating-point value between xmm3/m32 and xmm2.</td>, <td>EVEX.LIG.F3.0F.W0 5D /r VMINSS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Return the minimum scalar single-precision floating-point value between xmm3/m32 and xmm2.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td><strong>Opcode Instruction Op/ 64-Bit Compat/ Description En Mode Leg Mode</strong> 0F 01 C8 MONITOR ZO Valid Valid Sets up a linear address range to be monitored by hardware and activates the monitor. The address range should be a write-back memory caching type. The address is DS:RAX/EAX/AX.</td>, <td>Op/En Operand 1 Operand 2 Operand 3 Operand 4 ZO NA NA NA NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the value in EAX is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>If ECX ≠ 0.</td>, <td>#SS(0)</td>, <td>If the value in EAX is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:ECX.MONITOR[bit 3] = 0.</td>, <td>If current privilege level is not 0.</td>, <td rowspan="2">#GP</td>, <td>If the CS, DS, ES, FS, or GS register is used to access memory and the value in EAX is outside of the effective address space from 0 to FFFFH.</td>, <td>If ECX ≠ 0.</td>, <td>#SS</td>, <td>If the SS register is used to access memory and the value in EAX is outside of the effective address space from 0 to FFFFH.</td>, <td>#UD</td>, <td>If CPUID.01H:ECX.MONITOR[bit 3] = 0.</td>, <td>#UD</td>, <td>The MONITOR instruction is not recognized in virtual-8086 mode (even if CPUID.01H:ECX.MONITOR[bit 3] = 1).</td>, <td rowspan="2">#GP(0)</td>, <td>If the linear address of the operand in the CS, DS, ES, FS, or GS segment is in a non-canonical form.</td>, <td>If RCX ≠ 0.</td>, <td>#SS(0)</td>, <td>If the SS register is used to access memory and the value in EAX is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td rowspan="2">#UD</td>, <td>If the current privilege level is not 0.</td>, <td>If CPUID.01H:ECX.MONITOR[bit 3] = 0.</td>]

[<td>88 /<em>r</em></td>, <td>MOV <em>r/m8,r8</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Move <em>r8</em> to <em>r/m8.</em></td>, <td>REX + 88 /<em>r</em></td>, <td>MOV <em>r/m8</em><sup>***,</sup><em>r8</em><sup>***</sup></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move <em>r8</em> to <em>r/m8.</em></td>, <td>89 /<em>r</em></td>, <td>MOV <em>r/m16,r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Move <em>r16</em> to <em>r/m16.</em></td>, <td>89 /<em>r</em></td>, <td>MOV <em>r/m32,r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Move <em>r32</em> to <em>r/m32.</em></td>, <td>REX.W + 89 /<em>r</em></td>, <td>MOV <em>r/m64,r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move <em>r64</em> to <em>r/m64.</em></td>, <td>8A /<em>r</em></td>, <td>MOV <em>r8,r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move <em>r/m8</em> to <em>r8.</em></td>, <td>REX + 8A /<em>r</em></td>, <td>MOV <em>r8***,r/m8***</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move <em>r/m8</em> to <em>r8.</em></td>, <td>8B /<em>r</em></td>, <td>MOV <em>r16,r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move <em>r/m16</em> to <em>r16.</em></td>, <td>8B /<em>r</em></td>, <td>MOV <em>r32,r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move <em>r/m32</em> to <em>r32.</em></td>, <td>REX.W + 8B /<em>r</em></td>, <td>MOV <em>r64,r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move <em>r/m64</em> to <em>r64.</em></td>, <td>8C /<em>r</em></td>, <td>MOV <em>r/m16,Sreg</em>**</td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Move segment register to <em>r/m16.</em></td>, <td>REX.W + 8C /<em>r</em></td>, <td>MOV <em>r16/r32/m16, Sreg</em>**</td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Move zero extended 16-bit segment register to <em>r16/r32/r64/m16.</em></td>, <td>REX.W + 8C /<em>r</em></td>, <td>MOV <em>r64/m16, Sreg</em>**</td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Move zero extended 16-bit segment register to <em>r64/m16.</em></td>, <td>8E /<em>r</em></td>, <td>MOV <em>Sreg,r/m16</em>**</td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move <em>r/m16</em> to segment register.</td>, <td>REX.W + 8E /<em>r</em></td>, <td>MOV <em>Sreg,r/m64</em>**</td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move <em>lower 16 bits of r/m64</em> to segment register.</td>, <td>A0</td>, <td>MOV AL,<em>moffs8</em>*</td>, <td>FD</td>, <td>Valid</td>, <td>Valid</td>, <td>Move byte at (<em>seg:offset</em>) to AL.</td>, <td>REX.W + A0</td>, <td>MOV AL,<em>moffs8</em>*</td>, <td>FD</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move byte at (<em>offset</em>) to AL.</td>, <td>A1</td>, <td>MOV AX,<em>moffs16</em>*</td>, <td>FD</td>, <td>Valid</td>, <td>Valid</td>, <td>Move word at (<em>seg:offset</em>) to AX.</td>, <td>A1</td>, <td>MOV EAX,<em>moffs32</em>*</td>, <td>FD</td>, <td>Valid</td>, <td>Valid</td>, <td>Move doubleword at (<em>seg:offset</em>) to EAX.</td>, <td>REX.W + A1</td>, <td>MOV RAX,<em>moffs64</em>*</td>, <td>FD</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move quadword at (<em>offset</em>) to RAX.</td>, <td>A2</td>, <td>MOV <em>moffs8</em>,AL</td>, <td>TD</td>, <td>Valid</td>, <td>Valid</td>, <td>Move AL to (<em>seg:offset</em>).</td>, <td>REX.W + A2</td>, <td>MOV <em>moffs8</em><sup>***</sup>,AL</td>, <td>TD</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move AL to (<em>offset</em>).</td>, <td>A3</td>, <td>MOV <em>moffs16</em>*,AX</td>, <td>TD</td>, <td>Valid</td>, <td>Valid</td>, <td>Move AX to (<em>seg:offset</em>).</td>, <td>A3</td>, <td>MOV <em>moffs32</em>*,EAX</td>, <td>TD</td>, <td>Valid</td>, <td>Valid</td>, <td>Move EAX to (<em>seg:offset</em>).</td>, <td>REX.W + A3</td>, <td>MOV <em>moffs64</em>*,RAX</td>, <td>TD</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move RAX to (<em>offset</em>).</td>, <td>B0+ <em>rb ib</em></td>, <td>MOV <em>r8, imm8</em></td>, <td>OI</td>, <td>Valid</td>, <td>Valid</td>, <td>Move <em>imm8</em> to <em>r8.</em></td>, <td>REX + B0+ <em>rb ib</em></td>, <td>MOV <em>r8</em><sup>***</sup><em>, imm8</em></td>, <td>OI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move <em>imm8</em> to <em>r8.</em></td>, <td>B8+ <em>rw iw</em></td>, <td>MOV <em>r16, imm16</em></td>, <td>OI</td>, <td>Valid</td>, <td>Valid</td>, <td>Move <em>imm16</em> to <em>r16.</em></td>, <td>B8+ <em>rd id</em></td>, <td>MOV <em>r32, imm32</em></td>, <td>OI</td>, <td>Valid</td>, <td>Valid</td>, <td>Move <em>imm32</em> to <em>r32.</em></td>, <td>REX.W + B8+ <em>rd io</em></td>, <td>MOV <em>r64, imm64</em></td>, <td>OI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move <em>imm64</em> to <em>r64.</em></td>, <td>C6 /<em>0 ib</em></td>, <td>MOV <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Move <em>imm8</em> to <em>r/m8.</em></td>, <td>REX + C6 /<em>0 ib</em></td>, <td>MOV <em>r/m8***, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move <em>imm8</em> to <em>r/m8.</em></td>, <td>C7 /<em>0 iw</em></td>, <td>MOV <em>r/m16, imm16</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Move <em>imm16</em> to <em>r/m16.</em></td>, <td>C7 /<em>0 id</em></td>, <td>MOV <em>r/m32, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Move <em>imm32</em> to <em>r/m32.</em></td>, <td>REX.W + C7 /<em>0 id</em></td>, <td>MOV <em>r/m64, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move <em>imm32 sign extended to 64-bits</em> to <em>r/m64.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>MR</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>FD</td>, <td>AL/AX/EAX/RAX</td>, <td>Moffs</td>, <td>NA</td>, <td>NA</td>, <td>TD</td>, <td>Moffs (w)</td>, <td>AL/AX/EAX/RAX</td>, <td>NA</td>, <td>NA</td>, <td>OI</td>, <td>opcode + rd (w)</td>, <td>imm8/16/32/64</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (w)</td>, <td>imm8/16/32/64</td>, <td>NA</td>, <td>NA</td>, <td rowspan="4">#GP(0)</td>, <td>If attempt is made to load SS register with NULL segment selector.</td>, <td>If the destination operand is in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td rowspan="5">#GP(selector)</td>, <td>If segment selector index is outside descriptor table limits.</td>, <td>If the SS register is being loaded and the segment selector's RPL and the segment descriptor’s DPL are not equal to the CPL.</td>, <td>If the SS register is being loaded and the segment pointed to is a non-writable data segment.</td>, <td>If the DS, ES, FS, or GS register is being loaded and the segment pointed to is not a data or readable code segment.</td>, <td>If the DS, ES, FS, or GS register is being loaded and the segment pointed to is a data or nonconforming code segment, and either the RPL or the CPL is greater than the DPL.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#SS(selector)</td>, <td>If the SS register is being loaded and the segment pointed to is marked not present.</td>, <td>#NP</td>, <td>If the DS, ES, FS, or GS register is being loaded and the segment pointed to is marked not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="2">#UD</td>, <td>If attempt is made to load the CS register.</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td rowspan="2">#UD</td>, <td>If attempt is made to load the CS register.</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td rowspan="2">#UD</td>, <td>If attempt is made to load the CS register.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="3">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If an attempt is made to load SS register with NULL segment selector when CPL = 3.</td>, <td>If an attempt is made to load SS register with NULL segment selector when CPL &lt; 3 and CPL ≠ RPL.</td>, <td rowspan="6">#GP(selector)</td>, <td>If segment selector index is outside descriptor table limits.</td>, <td>If the memory access to the descriptor table is non-canonical.</td>, <td>If the SS register is being loaded and the segment selector's RPL and the segment descriptor’s DPL are not equal to the CPL.</td>, <td>If the SS register is being loaded and the segment pointed to is a nonwritable data segment.</td>, <td>If the DS, ES, FS, or GS register is being loaded and the segment pointed to is not a data or readable code segment.</td>, <td>If the DS, ES, FS, or GS register is being loaded and the segment pointed to is a data or nonconforming code segment, but both the RPL and the CPL are greater than the DPL.</td>, <td>#SS(0)</td>, <td>If the stack address is in a non-canonical form.</td>, <td>#SS(selector)</td>, <td>If the SS register is being loaded and the segment pointed to is marked not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="2">#UD</td>, <td>If attempt is made to load the CS register.</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 20/<em>r</em> MOV <em>r32,</em> CR0–CR7</td>, <td>MR</td>, <td>N.E.</td>, <td>Valid</td>, <td>Move control register to <em>r32</em>.</td>, <td>0F 20/<em>r</em> MOV <em>r64,</em> CR0–CR7</td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move extended control register to <em>r64</em>.</td>, <td>REX.R + 0F 20 /0 MOV <em>r64,</em> CR8</td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move extended CR8 to <em>r64</em>.<sup>1</sup></td>, <td>0F 22 /<em>r</em> MOV CR0–CR7, <em>r32</em></td>, <td>RM</td>, <td>N.E.</td>, <td>Valid</td>, <td>Move <em>r32</em> to control register.</td>, <td>0F 22 /<em>r</em> MOV CR0–CR7, <em>r64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move <em>r64</em> to extended control register.</td>, <td>REX.R + 0F 22 /0 MOV CR8, <em>r64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move <em>r64</em> to extended CR8.<sup>1</sup></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>MR</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="5">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If an attempt is made to write invalid bit combinations in CR0 (such as setting the PG flag to 1 when the PE flag is set to 0, or setting the CD flag to 0 when the NW flag is set to 1).</td>, <td>If an attempt is made to write a 1 to any reserved bit in CR4.</td>, <td>If an attempt is made to write 1 to CR4.PCIDE.</td>, <td>If any of the reserved bits are set in the page-directory pointers table (PDPT) and the loading of a control register causes the PDPT to be loaded into the processor.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If an attempt is made to access CR1, CR5, CR6, or CR7.</td>, <td rowspan="3">#GP</td>, <td>If an attempt is made to write a 1 to any reserved bit in CR4.</td>, <td>If an attempt is made to write 1 to CR4.PCIDE.</td>, <td>If an attempt is made to write invalid bit combinations in CR0 (such as setting the PG flag to 1 when the PE flag is set to 0).</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If an attempt is made to access CR1, CR5, CR6, or CR7.</td>, <td>#GP(0)</td>, <td>These instructions cannot be executed in virtual-8086 mode.</td>, <td rowspan="6">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If an attempt is made to write invalid bit combinations in CR0 (such as setting the PG flag to 1 when the PE flag is set to 0, or setting the CD flag to 0 when the NW flag is set to 1).</td>, <td>If an attempt is made to change CR4.PCIDE from 0 to 1 while CR3[11:0] ≠ 000H.</td>, <td>If an attempt is made to clear CR0.PG[bit 31] while CR4.PCIDE = 1.</td>, <td>If an attempt is made to write a 1 to any reserved bit in CR3.</td>, <td>If an attempt is made to leave IA-32e mode by clearing CR4.PAE[bit 5].</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If an attempt is made to access CR1, CR5, CR6, or CR7.</td>, <td rowspan="8">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If an attempt is made to write invalid bit combinations in CR0 (such as setting the PG flag to 1 when the PE flag is set to 0, or setting the CD flag to 0 when the NW flag is set to 1).</td>, <td>If an attempt is made to change CR4.PCIDE from 0 to 1 while CR3[11:0] ≠ 000H.</td>, <td>If an attempt is made to clear CR0.PG[bit 31].</td>, <td>If an attempt is made to write a 1 to any reserved bit in CR4.</td>, <td>If an attempt is made to write a 1 to any reserved bit in CR8.</td>, <td>If an attempt is made to write a 1 to any reserved bit in CR3.</td>, <td>If an attempt is made to leave IA-32e mode by clearing CR4.PAE[bit 5].</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If an attempt is made to access CR1, CR5, CR6, or CR7.</td>, <td>If the REX.R prefix is used to specify a register other than CR8.</td>]

[<td>0F 21/<em>r</em> MOV <em>r32,</em> DR0–DR7</td>, <td>MR</td>, <td>N.E.</td>, <td>Valid</td>, <td>Move debug register to <em>r32</em>.</td>, <td>0F 21/<em>r</em> MOV <em>r64,</em> DR0–DR7</td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move extended debug register to <em>r64</em>.</td>, <td>0F 23 /<em>r</em> MOV DR0–DR7, <em>r32</em></td>, <td>RM</td>, <td>N.E.</td>, <td>Valid</td>, <td>Move <em>r32</em> to debug register.</td>, <td>0F 23 /<em>r</em> MOV DR0–DR7, <em>r64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move <em>r64</em> to extended debug register.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>MR</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td rowspan="2">#UD</td>, <td>If CR4.DE[bit 3] = 1 (debug extensions) and a MOV instruction is executed involving DR4 or DR5.</td>, <td>If the LOCK prefix is used.</td>, <td>#DB</td>, <td>If any debug register is accessed while the DR7.GD[bit 13] = 1.</td>, <td rowspan="2">#UD</td>, <td>If CR4.DE[bit 3] = 1 (debug extensions) and a MOV instruction is executed involving DR4 or DR5.</td>, <td>If the LOCK prefix is used.</td>, <td>#DB</td>, <td>If any debug register is accessed while the DR7.GD[bit 13] = 1.</td>, <td>#GP(0)</td>, <td>The debug registers cannot be loaded or read when in virtual-8086 mode.</td>, <td rowspan="3">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If an attempt is made to write a 1 to any of bits 63:32 in DR6.</td>, <td>If an attempt is made to write a 1 to any of bits 63:32 in DR7.</td>, <td rowspan="3">#UD</td>, <td>If CR4.DE[bit 3] = 1 (debug extensions) and a MOV instruction is executed involving DR4 or DR5.</td>, <td>If the LOCK prefix is used.</td>, <td>If the REX.R prefix is used.</td>, <td>#DB</td>, <td>If any debug register is accessed while the DR7.GD[bit 13] = 1.</td>]

[<td>66 0F 28 /r MOVAPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move aligned packed double-precision floating-point values from xmm2/mem to xmm1.</td>, <td>66 0F 29 /r MOVAPD xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move aligned packed double-precision floating-point values from xmm1 to xmm2/mem.</td>, <td>VEX.128.66.0F.WIG 28 /r VMOVAPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed double-precision floating-point values from xmm2/mem to xmm1.</td>, <td>VEX.128.66.0F.WIG 29 /r VMOVAPD xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed double-precision floating-point values from xmm1 to xmm2/mem.</td>, <td>VEX.256.66.0F.WIG 28 /r VMOVAPD ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed double-precision floating-point values from ymm2/mem to ymm1.</td>, <td>VEX.256.66.0F.WIG 29 /r VMOVAPD ymm2/m256, ymm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed double-precision floating-point values from ymm1 to ymm2/mem.</td>, <td>EVEX.128.66.0F.W1 28 /r VMOVAPD xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed double-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W1 28 /r VMOVAPD ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed double-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W1 28 /r VMOVAPD zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move aligned packed double-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.W1 29 /r VMOVAPD xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed double-precision floating-point values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.66.0F.W1 29 /r VMOVAPD ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed double-precision floating-point values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.66.0F.W1 29 /r VMOVAPD zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move aligned packed double-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B or VEX.vvvv != 1111B.</td>]

[<td>NP 0F 28 /r MOVAPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Move aligned packed single-precision floating-point values from xmm2/mem to xmm1.</td>, <td>NP 0F 29 /r MOVAPS xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>SSE</td>, <td>Move aligned packed single-precision floating-point values from xmm1 to xmm2/mem.</td>, <td>VEX.128.0F.WIG 28 /r VMOVAPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed single-precision floating-point values from xmm2/mem to xmm1.</td>, <td>VEX.128.0F.WIG 29 /r VMOVAPS xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed single-precision floating-point values from xmm1 to xmm2/mem.</td>, <td>VEX.256.0F.WIG 28 /r VMOVAPS ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed single-precision floating-point values from ymm2/mem to ymm1.</td>, <td>VEX.256.0F.WIG 29 /r VMOVAPS ymm2/m256, ymm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed single-precision floating-point values from ymm1 to ymm2/mem.</td>, <td>EVEX.128.0F.W0 28 /r VMOVAPS xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed single-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.0F.W0 28 /r VMOVAPS ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed single-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.0F.W0 28 /r VMOVAPS zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move aligned packed single-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.0F.W0 29 /r VMOVAPS xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed single-precision floating-point values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.0F.W0 29 /r VMOVAPS ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed single-precision floating-point values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.0F.W0 29 /r VMOVAPS zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move aligned packed single-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B.</td>]

[<td><strong>Opcode Instruction Op/ 64-Bit Compat/Description En Mode Leg Mode</strong> 0F38F0/<em>r</em> MOVBE <em>r16,</em> m16 RM Valid Valid Reverse byte order in <em>m16 and move to r16.</em> 0F38F0/<em>r</em> MOVBE <em>r32,</em> m32 RM Valid Valid Reverse byte order in <em>m32 and move to r32.</em> REX.W + 0F 38 F0 /<em>r</em> MOVBE <em>r64,</em> m64 RM Valid N.E. Reverse byte order in <em>m64 and move to r64</em>. 0F 38 F1 /<em>r</em> MOVBE <em>m16,</em> r16 MR Valid Valid Reverse byte order in <em>r16 and move to m16.</em> 0F 38 F1 /<em>r</em> MOVBE <em>m32,</em> r32 MR Valid Valid Reverse byte order in <em>r32 and move to m32.</em> REX.W + 0F 38 F1 /<em>r</em> MOVBE <em>m64,</em> r64 MR Valid N.E. Reverse byte order in <em>r64 and move to m64</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>MR</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination operand is in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.MOVBE[bit 22] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>If REP (F3H) prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.MOVBE[bit 22] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>If REP (F3H) prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="4">#UD</td>, <td>If CPUID.01H:ECX.MOVBE[bit 22] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>If REP (F3H) prefix is used.</td>, <td>If REPNE (F2H) prefix is used and CPUID.01H:ECX.SSE4_2[bit 20] = 0.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#SS(0)</td>, <td>If the stack address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.MOVBE[bit 22] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>If REP (F3H) prefix is used.</td>]

[<td>NP 0F 6E /<em>r</em> MOVD <em>mm, r/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Move doubleword from <em>r/m32</em> to <em>mm</em>.</td>, <td>NP REX.W + 0F 6E /<em>r</em> MOVQ <em>mm, r/m64</em></td>, <td>A</td>, <td>V/N.E.</td>, <td>MMX</td>, <td>Move quadword from <em>r/m64</em> to <em>mm</em>.</td>, <td>NP 0F 7E /<em>r</em> MOVD <em>r/m32, mm</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Move doubleword from <em>mm</em> to <em>r/m32</em>.</td>, <td>NP REX.W + 0F 7E /<em>r</em> MOVQ <em>r/m64, mm</em></td>, <td>B</td>, <td>V/N.E.</td>, <td>MMX</td>, <td>Move quadword from <em>mm</em> to <em>r/m64</em>.</td>, <td>66 0F 6E /<em>r</em> MOVD <em>xmm</em>, <em>r/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move doubleword from <em>r/m32</em> to <em>xmm</em>.</td>, <td>66 REX.W 0F 6E /<em>r</em> MOVQ <em>xmm</em>, <em>r/m64</em></td>, <td>A</td>, <td>V/N.E.</td>, <td>SSE2</td>, <td>Move quadword from <em>r/m64</em> to <em>xmm</em>.</td>, <td>66 0F 7E /<em>r</em> MOVD <em>r/m32</em>, <em>xmm</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move doubleword from <em>xmm</em> register to <em>r/m32</em>.</td>, <td>66 REX.W 0F 7E /<em>r</em> MOVQ <em>r/m64</em>, <em>xmm</em></td>, <td>B</td>, <td>V/N.E.</td>, <td>SSE2</td>, <td>Move quadword from <em>xmm</em> register to <em>r/m64</em>.</td>, <td>VEX.128.66.0F.W0 6E / VMOVD <em>xmm1, r32/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move doubleword from <em>r/m32</em> to <em>xmm1</em>.</td>, <td>VEX.128.66.0F.W1 6E /r VMOVQ <em>xmm1, r64/m64</em></td>, <td>A</td>, <td>V/N.E<sup>1</sup>.</td>, <td>AVX</td>, <td>Move quadword from <em>r/m64</em> to <em>xmm1</em>.</td>, <td>VEX.128.66.0F.W0 7E /r VMOVD <em>r32/m32, xmm1</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move doubleword from <em>xmm1</em> register to <em>r/m32</em>.</td>, <td>VEX.128.66.0F.W1 7E /r VMOVQ <em>r64/m64, xmm1</em></td>, <td>B</td>, <td>V/N.E<sup>1</sup>.</td>, <td>AVX</td>, <td>Move quadword from <em>xmm1</em> register to <em>r/m64</em>.</td>, <td>EVEX.128.66.0F.W0 6E /r VMOVD xmm1, r32/m32</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move doubleword from r/m32 to xmm1.</td>, <td>EVEX.128.66.0F.W1 6E /r VMOVQ xmm1, r64/m64</td>, <td>C</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512F</td>, <td>Move quadword from r/m64 to xmm1.</td>, <td>EVEX.128.66.0F.W0 7E /r VMOVD r32/m32, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move doubleword from xmm1 register to r/m32.</td>, <td>EVEX.128.66.0F.W1 7E /r VMOVQ r64/m64, xmm1</td>, <td>D</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512F</td>, <td>Move quadword from xmm1 register to r/m64.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Tuple1 Scalar</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 1.</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>F2 0F 12 /r MOVDDUP xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE3</td>, <td>Move double-precision floating-point value from xmm2/m64 and duplicate into xmm1.</td>, <td>VEX.128.F2.0F.WIG 12 /r VMOVDDUP xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move double-precision floating-point value from xmm2/m64 and duplicate into xmm1.</td>, <td>VEX.256.F2.0F.WIG 12 /r VMOVDDUP ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move even index double-precision floating-point values from ymm2/mem and duplicate each element into ymm1.</td>, <td>EVEX.128.F2.0F.W1 12 /r VMOVDDUP xmm1 {k1}{z}, xmm2/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move double-precision floating-point value from xmm2/m64 and duplicate each element into xmm1 subject to writemask k1.</td>, <td>EVEX.256.F2.0F.W1 12 /r VMOVDDUP ymm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move even index double-precision floating-point values from ymm2/m256 and duplicate each element into ymm1 subject to writemask k1.</td>, <td>EVEX.512.F2.0F.W1 12 /r VMOVDDUP zmm1 {k1}{z}, zmm2/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move even index double-precision floating-point values from zmm2/m512 and duplicate each element into zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>MOVDDUP</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B or VEX.vvvv != 1111B.</td>]

[<td>66 0F 38 F8 /r MOVDIR64B r16/r32/r64, m512</td>, <td>A</td>, <td>V/V</td>, <td>MOVDIR64B</td>, <td>Move 64-bytes as direct-store with guaranteed 64-byte write atomicity from the source memory operand address to destination memory address specified as offset to ES segment in the register operand.</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>For an illegal memory operand effective address in the CS, DS, ES, FS or GS segments.</td>, <td>If address in destination (register) operand is not aligned to a 64-byte boundary.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.07H.0H:ECX.MOVDIR64B[bit 28] = 0.</td>, <td>If LOCK prefix is used.</td>, <td rowspan="2">#GP</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td>If address in destination (register) operand is not aligned to a 64-byte boundary.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.07H.0H:ECX.MOVDIR64B[bit 28] = 0.</td>, <td>If LOCK prefix is used.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#SS(0)</td>, <td>If memory address referencing the SS segment is in non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the memory address is in non-canonical form.</td>, <td>If address in destination (register) operand is not aligned to a 64-byte boundary.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.07H.0H:ECX.MOVDIR64B[bit 28] = 0.</td>, <td>If LOCK prefix is used.</td>]

[<td>NP 0F 38 F9 /r MOVDIRI m32, r32</td>, <td>A</td>, <td>V/V</td>, <td>MOVDIRI</td>, <td>Move doubleword from r32 to m32 using direct store.</td>, <td>NP REX.W + 0F 38 F9 /r MOVDIRI m64, r64</td>, <td>A</td>, <td>V/N.E.</td>, <td>MOVDIRI</td>, <td>Move quadword from r64 to m64 using direct store.</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>For an illegal memory operand effective address in the CS, DS, ES, FS or GS segments.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.07H.0H:ECX.MOVDIRI[bit 27] = 0.</td>, <td>If LOCK prefix or operand-size (66H) prefix is used.</td>, <td>#AC</td>, <td>If alignment checking is enabled and an unaligned memory reference made while in current privilege level 3.</td>, <td>#GP</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.07H.0H:ECX.MOVDIRI[bit 27] = 0.</td>, <td>If LOCK prefix or operand-size (66H) prefix is used.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#AC</td>, <td>If alignment checking is enabled and an unaligned memory reference made while in current privilege level 3.</td>, <td>#SS(0)</td>, <td>If memory address referencing the SS segment is in non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in non-canonical form.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.07H.0H:ECX.MOVDIRI[bit 27] = 0.</td>, <td>If LOCK prefix or operand-size (66H) prefix is used.</td>, <td>#AC</td>, <td>If alignment checking is enabled and an unaligned memory reference made while in current privilege level 3.</td>]

[<td><strong>Opcode Instruction Op/ 64-Bit Compat/ Description En Mode Leg Mode</strong> F2 0F D6 /r MOVDQ2Q <em>mm</em>, <em>xmm</em> RM Valid Valid Move low quadword from <em>xmm</em> to <em>mmx</em> register.</td>, <td>Op/En Operand 1 Operand 2 Operand 3 Operand 4 RM ModRM:reg (w) ModRM:r/m (r) NA NA</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="4">#UD</td>, <td>If CR0.EM[bit 2] = 1.</td>, <td>If CR4.OSFXSR[bit 9] = 0.</td>, <td>If CPUID.01H:EDX.SSE2[bit 26] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>]

[<td>66 0F 6F /r MOVDQA xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move aligned packed integer values from xmm2/mem to xmm1.</td>, <td>66 0F 7F /r MOVDQA xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move aligned packed integer values from xmm1 to xmm2/mem.</td>, <td>VEX.128.66.0F.WIG 6F /r VMOVDQA xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed integer values from xmm2/mem to xmm1.</td>, <td>VEX.128.66.0F.WIG 7F /r VMOVDQA xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed integer values from xmm1 to xmm2/mem.</td>, <td>VEX.256.66.0F.WIG 6F /r VMOVDQA ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed integer values from ymm2/mem to ymm1.</td>, <td>VEX.256.66.0F.WIG 7F /r VMOVDQA ymm2/m256, ymm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed integer values from ymm1 to ymm2/mem.</td>, <td>EVEX.128.66.0F.W0 6F /r VMOVDQA32 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W0 6F /r VMOVDQA32 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 6F /r VMOVDQA32 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move aligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.W0 7F /r VMOVDQA32 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.66.0F.W0 7F /r VMOVDQA32 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 7F /r VMOVDQA32 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move aligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.66.0F.W1 6F /r VMOVDQA64 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned quadword integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W1 6F /r VMOVDQA64 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned quadword integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W1 6F /r VMOVDQA64 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move aligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.W1 7F /r VMOVDQA64 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.66.0F.W1 7F /r VMOVDQA64 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.66.0F.W1 7F /r VMOVDQA64 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move aligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B or VEX.vvvv != 1111B.</td>]

[<td>F3 0F 6F /r MOVDQU xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move unaligned packed integer values from xmm2/m128 to xmm1.</td>, <td>F3 0F 7F /r MOVDQU xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move unaligned packed integer values from xmm1 to xmm2/m128.</td>, <td>VEX.128.F3.0F.WIG 6F /r VMOVDQU xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from xmm2/m128 to xmm1.</td>, <td>VEX.128.F3.0F.WIG 7F /r VMOVDQU xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from xmm1 to xmm2/m128.</td>, <td>VEX.256.F3.0F.WIG 6F /r VMOVDQU ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from ymm2/m256 to ymm1.</td>, <td>VEX.256.F3.0F.WIG 7F /r VMOVDQU ymm2/m256, ymm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from ymm1 to ymm2/m256.</td>, <td>EVEX.128.F2.0F.W0 6F /r VMOVDQU8 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F2.0F.W0 6F /r VMOVDQU8 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F2.0F.W0 6F /r VMOVDQU8 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed byte integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F2.0F.W0 7F /r VMOVDQU8 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F2.0F.W0 7F /r VMOVDQU8 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F2.0F.W0 7F /r VMOVDQU8 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed byte integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.F2.0F.W1 6F /r VMOVDQU16 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F2.0F.W1 6F /r VMOVDQU16 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F2.0F.W1 6F /r VMOVDQU16 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed word integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F2.0F.W1 7F /r VMOVDQU16 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F2.0F.W1 7F /r VMOVDQU16 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F2.0F.W1 7F /r VMOVDQU16 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed word integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.F3.0F.W0 6F /r VMOVDQU32 xmm1 {k1}{z}, xmm2/mm128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F3.0F.W0 6F /r VMOVDQU32 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F3.0F.W0 6F /r VMOVDQU32 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F3.0F.W0 7F /r VMOVDQU32 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F3.0F.W0 7F /r VMOVDQU32 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F3.0F.W0 7F /r VMOVDQU32 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.F3.0F.W1 6F /r VMOVDQU64 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F3.0F.W1 6F /r VMOVDQU64 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F3.0F.W1 6F /r VMOVDQU64 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F3.0F.W1 7F /r VMOVDQU64 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F3.0F.W1 7F /r VMOVDQU64 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F3.0F.W1 7F /r VMOVDQU64 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B or VEX.vvvv != 1111B.</td>]

[<td>NP 0F 12 /r MOVHLPS xmm1, xmm2</td>, <td>RM</td>, <td>V/V</td>, <td>SSE</td>, <td>Move two packed single-precision floating-point values from high quadword of xmm2 to low quadword of xmm1.</td>, <td>VEX.128.0F.WIG 12 /r VMOVHLPS xmm1, xmm2, xmm3</td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Merge two packed single-precision floating-point values from high quadword of xmm3 and low quadword of xmm2.</td>, <td>EVEX.128.0F.W0 12 /r VMOVHLPS xmm1, xmm2, xmm3</td>, <td>RVM</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Merge two packed single-precision floating-point values from high quadword of xmm3 and low quadword of xmm2.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>66 0F 16 /r MOVHPD xmm1, m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move double-precision floating-point value from m64 to high quadword of xmm1.</td>, <td>VEX.128.66.0F.WIG 16 /r VMOVHPD xmm2, xmm1, m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Merge double-precision floating-point value from m64 and the low quadword of xmm1.</td>, <td>EVEX.128.66.0F.W1 16 /r VMOVHPD xmm2, xmm1, m64</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Merge double-precision floating-point value from m64 and the low quadword of xmm1.</td>, <td>66 0F 17 /r MOVHPD m64, xmm1</td>, <td>C</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move double-precision floating-point value from high quadword of xmm1 to m64.</td>, <td>VEX.128.66.0F.WIG 17 /r VMOVHPD m64, xmm1</td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Move double-precision floating-point value from high quadword of xmm1 to m64.</td>, <td>EVEX.128.66.0F.W1 17 /r VMOVHPD m64, xmm1</td>, <td>E</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move double-precision floating-point value from high quadword of xmm1 to m64.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>E</td>, <td>Tuple1 Scalar</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>NP 0F 16 /r MOVHPS xmm1, m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Move two packed single-precision floating-point values from m64 to high quadword of xmm1.</td>, <td>VEX.128.0F.WIG 16 /r VMOVHPS xmm2, xmm1, m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Merge two packed single-precision floating-point values from m64 and the low quadword of xmm1.</td>, <td>EVEX.128.0F.W0 16 /r VMOVHPS xmm2, xmm1, m64</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Merge two packed single-precision floating-point values from m64 and the low quadword of xmm1.</td>, <td>NP 0F 17 /r MOVHPS m64, xmm1</td>, <td>C</td>, <td>V/V</td>, <td>SSE</td>, <td>Move two packed single-precision floating-point values from high quadword of xmm1 to m64.</td>, <td>VEX.128.0F.WIG 17 /r VMOVHPS m64, xmm1</td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Move two packed single-precision floating-point values from high quadword of xmm1 to m64.</td>, <td>EVEX.128.0F.W0 17 /r VMOVHPS m64, xmm1</td>, <td>E</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move two packed single-precision floating-point values from high quadword of xmm1 to m64.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Tuple2</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>E</td>, <td>Tuple2</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>NP 0F 16 /r MOVLHPS xmm1, xmm2</td>, <td>RM</td>, <td>V/V</td>, <td>SSE</td>, <td>Move two packed single-precision floating-point values from low quadword of xmm2 to high quadword of xmm1.</td>, <td>VEX.128.0F.WIG 16 /r VMOVLHPS xmm1, xmm2, xmm3</td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Merge two packed single-precision floating-point values from low quadword of xmm3 and low quadword of xmm2.</td>, <td>EVEX.128.0F.W0 16 /r VMOVLHPS xmm1, xmm2, xmm3</td>, <td>RVM</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Merge two packed single-precision floating-point values from low quadword of xmm3 and low quadword of xmm2.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>66 0F 12 /r MOVLPD xmm1, m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move double-precision floating-point value from m64 to low quadword of xmm1.</td>, <td>VEX.128.66.0F.WIG 12 /r VMOVLPD xmm2, xmm1, m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Merge double-precision floating-point value from m64 and the high quadword of xmm1.</td>, <td>EVEX.128.66.0F.W1 12 /r VMOVLPD xmm2, xmm1, m64</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Merge double-precision floating-point value from m64 and the high quadword of xmm1.</td>, <td>66 0F 13/r MOVLPD m64, xmm1</td>, <td>C</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move double-precision floating-point value from low quadword of xmm1 to m64.</td>, <td>VEX.128.66.0F.WIG 13/r VMOVLPD m64, xmm1</td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Move double-precision floating-point value from low quadword of xmm1 to m64.</td>, <td>EVEX.128.66.0F.W1 13/r VMOVLPD m64, xmm1</td>, <td>E</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move double-precision floating-point value from low quadword of xmm1 to m64.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (r)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>E</td>, <td>Tuple1 Scalar</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>NP 0F 12 /r MOVLPS xmm1, m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Move two packed single-precision floating-point values from m64 to low quadword of xmm1.</td>, <td>VEX.128.0F.WIG 12 /r VMOVLPS xmm2, xmm1, m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Merge two packed single-precision floating-point values from m64 and the high quadword of xmm1.</td>, <td>EVEX.128.0F.W0 12 /r VMOVLPS xmm2, xmm1, m64</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Merge two packed single-precision floating-point values from m64 and the high quadword of xmm1.</td>, <td>0F 13/r MOVLPS m64, xmm1</td>, <td>C</td>, <td>V/V</td>, <td>SSE</td>, <td>Move two packed single-precision floating-point values from low quadword of xmm1 to m64.</td>, <td>VEX.128.0F.WIG 13/r VMOVLPS m64, xmm1</td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Move two packed single-precision floating-point values from low quadword of xmm1 to m64.</td>, <td>EVEX.128.0F.W0 13/r VMOVLPS m64, xmm1</td>, <td>E</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move two packed single-precision floating-point values from low quadword of xmm1 to m64.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Tuple2</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>E</td>, <td>Tuple2</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>66 0F 50 /<em>r</em> MOVMSKPD <em>reg</em>, <em>xmm</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE2</td>, <td>Extract 2-bit sign mask from <em>xmm</em> and store in <em>reg</em>. The upper bits of <em>r32</em> or <em>r64</em> are filled with zeros.</td>, <td>VEX.128.66.0F.WIG 50 /r VMOVMSKPD <em>reg, xmm2</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Extract 2-bit sign mask from <em>xmm2</em> and store in reg. The upper bits of <em>r32</em> or <em>r64</em> are zeroed.</td>, <td>VEX.256.66.0F.WIG 50 /r VMOVMSKPD <em>reg, ymm2</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Extract 4-bit sign mask from <em>ymm2</em> and store in reg. The upper bits of <em>r32</em> or <em>r64</em> are zeroed.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>NP 0F 50 /<em>r</em> MOVMSKPS <em>reg</em>, <em>xmm</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE</td>, <td>Extract 4-bit sign mask from <em>xmm</em> and store in <em>reg</em>. The upper bits of <em>r32</em> or <em>r64</em> are filled with zeros.</td>, <td>VEX.128.0F.WIG 50 /r VMOVMSKPS <em>reg, xmm2</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Extract 4-bit sign mask from <em>xmm2</em> and store in reg. The upper bits of <em>r32</em> or <em>r64</em> are zeroed.</td>, <td>VEX.256.0F.WIG 50 /r VMOVMSKPS <em>reg, ymm2</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Extract 8-bit sign mask from ymm2 and store in reg. The upper bits of <em>r32</em> or <em>r64</em> are zeroed.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>66 0F E7 /r MOVNTDQ m128, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move packed integer values in xmm1 to m128 using non-temporal hint.</td>, <td>VEX.128.66.0F.WIG E7 /r VMOVNTDQ m128, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move packed integer values in xmm1 to m128 using non-temporal hint.</td>, <td>VEX.256.66.0F.WIG E7 /r VMOVNTDQ m256, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move packed integer values in ymm1 to m256 using non-temporal hint.</td>, <td>EVEX.128.66.0F.W0 E7 /r VMOVNTDQ m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move packed integer values in xmm1 to m128 using non-temporal hint.</td>, <td>EVEX.256.66.0F.W0 E7 /r VMOVNTDQ m256, ymm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move packed integer values in zmm1 to m256 using non-temporal hint.</td>, <td>EVEX.512.66.0F.W0 E7 /r VMOVNTDQ m512, zmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move packed integer values in zmm1 to m512 using non-temporal hint.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>66 0F 38 2A /r MOVNTDQA xmm1, m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Move double quadword from m128 to xmm1 using non-temporal hint if WC memory type.</td>, <td>VEX.128.66.0F38.WIG 2A /r VMOVNTDQA xmm1, m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move double quadword from m128 to xmm using non-temporal hint if WC memory type.</td>, <td>VEX.256.66.0F38.WIG 2A /r VMOVNTDQA ymm1, m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Move 256-bit data from m256 to ymm using non-temporal hint if WC memory type.</td>, <td>EVEX.128.66.0F38.W0 2A /r VMOVNTDQA xmm1, m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move 128-bit data from m128 to xmm using non-temporal hint if WC memory type.</td>, <td>EVEX.256.66.0F38.W0 2A /r VMOVNTDQA ymm1, m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move 256-bit data from m256 to ymm using non-temporal hint if WC memory type.</td>, <td>EVEX.512.66.0F38.W0 2A /r VMOVNTDQA zmm1, m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move 512-bit data from m512 to zmm using non-temporal hint if WC memory type.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>NP 0F C3 /<em>r</em></td>, <td>MOVNTI <em>m32</em>, <em>r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Move doubleword from <em>r32</em> to <em>m32</em> using non-temporal hint.</td>, <td>NP REX.W + 0F C3 /<em>r</em></td>, <td>MOVNTI <em>m64, r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move quadword from <em>r64</em> to <em>m64</em> using non-temporal hint.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>MR</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>For an illegal memory operand effective address in the CS, DS, ES, FS or GS segments.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:EDX.SSE2[bit 26] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:EDX.SSE2[bit 26] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:EDX.SSE2[bit 26] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>]

[<td>66 0F 2B /r MOVNTPD m128, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move packed double-precision values in xmm1 to m128 using non-temporal hint.</td>, <td>VEX.128.66.0F.WIG 2B /r VMOVNTPD m128, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move packed double-precision values in xmm1 to m128 using non-temporal hint.</td>, <td>VEX.256.66.0F.WIG 2B /r VMOVNTPD m256, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move packed double-precision values in ymm1 to m256 using non-temporal hint.</td>, <td>EVEX.128.66.0F.W1 2B /r VMOVNTPD m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move packed double-precision values in xmm1 to m128 using non-temporal hint.</td>, <td>EVEX.256.66.0F.W1 2B /r VMOVNTPD m256, ymm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move packed double-precision values in ymm1 to m256 using non-temporal hint.</td>, <td>EVEX.512.66.0F.W1 2B /r VMOVNTPD m512, zmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move packed double-precision values in zmm1 to m512 using non-temporal hint.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>NP 0F 2B /r MOVNTPS m128, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Move packed single-precision values xmm1 to mem using non-temporal hint.</td>, <td>VEX.128.0F.WIG 2B /r VMOVNTPS m128, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move packed single-precision values xmm1 to mem using non-temporal hint.</td>, <td>VEX.256.0F.WIG 2B /r VMOVNTPS m256, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move packed single-precision values ymm1 to mem using non-temporal hint.</td>, <td>EVEX.128.0F.W0 2B /r VMOVNTPS m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move packed single-precision values in xmm1 to m128 using non-temporal hint.</td>, <td>EVEX.256.0F.W0 2B /r VMOVNTPS m256, ymm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move packed single-precision values in ymm1 to m256 using non-temporal hint.</td>, <td>EVEX.512.0F.W0 2B /r VMOVNTPS m512, zmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move packed single-precision values in zmm1 to m512 using non-temporal hint.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>NP 0F E7 /<em>r</em></td>, <td>MOVNTQ <em>m64</em>, <em>mm</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Move quadword from <em>mm</em> to <em>m64</em> using non-temporal hint.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>MR</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>NP 0F 6E /<em>r</em> MOVD <em>mm, r/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Move doubleword from <em>r/m32</em> to <em>mm</em>.</td>, <td>NP REX.W + 0F 6E /<em>r</em> MOVQ <em>mm, r/m64</em></td>, <td>A</td>, <td>V/N.E.</td>, <td>MMX</td>, <td>Move quadword from <em>r/m64</em> to <em>mm</em>.</td>, <td>NP 0F 7E /<em>r</em> MOVD <em>r/m32, mm</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Move doubleword from <em>mm</em> to <em>r/m32</em>.</td>, <td>NP REX.W + 0F 7E /<em>r</em> MOVQ <em>r/m64, mm</em></td>, <td>B</td>, <td>V/N.E.</td>, <td>MMX</td>, <td>Move quadword from <em>mm</em> to <em>r/m64</em>.</td>, <td>66 0F 6E /<em>r</em> MOVD <em>xmm</em>, <em>r/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move doubleword from <em>r/m32</em> to <em>xmm</em>.</td>, <td>66 REX.W 0F 6E /<em>r</em> MOVQ <em>xmm</em>, <em>r/m64</em></td>, <td>A</td>, <td>V/N.E.</td>, <td>SSE2</td>, <td>Move quadword from <em>r/m64</em> to <em>xmm</em>.</td>, <td>66 0F 7E /<em>r</em> MOVD <em>r/m32</em>, <em>xmm</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move doubleword from <em>xmm</em> register to <em>r/m32</em>.</td>, <td>66 REX.W 0F 7E /<em>r</em> MOVQ <em>r/m64</em>, <em>xmm</em></td>, <td>B</td>, <td>V/N.E.</td>, <td>SSE2</td>, <td>Move quadword from <em>xmm</em> register to <em>r/m64</em>.</td>, <td>VEX.128.66.0F.W0 6E / VMOVD <em>xmm1, r32/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move doubleword from <em>r/m32</em> to <em>xmm1</em>.</td>, <td>VEX.128.66.0F.W1 6E /r VMOVQ <em>xmm1, r64/m64</em></td>, <td>A</td>, <td>V/N.E<sup>1</sup>.</td>, <td>AVX</td>, <td>Move quadword from <em>r/m64</em> to <em>xmm1</em>.</td>, <td>VEX.128.66.0F.W0 7E /r VMOVD <em>r32/m32, xmm1</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move doubleword from <em>xmm1</em> register to <em>r/m32</em>.</td>, <td>VEX.128.66.0F.W1 7E /r VMOVQ <em>r64/m64, xmm1</em></td>, <td>B</td>, <td>V/N.E<sup>1</sup>.</td>, <td>AVX</td>, <td>Move quadword from <em>xmm1</em> register to <em>r/m64</em>.</td>, <td>EVEX.128.66.0F.W0 6E /r VMOVD xmm1, r32/m32</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move doubleword from r/m32 to xmm1.</td>, <td>EVEX.128.66.0F.W1 6E /r VMOVQ xmm1, r64/m64</td>, <td>C</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512F</td>, <td>Move quadword from r/m64 to xmm1.</td>, <td>EVEX.128.66.0F.W0 7E /r VMOVD r32/m32, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move doubleword from xmm1 register to r/m32.</td>, <td>EVEX.128.66.0F.W1 7E /r VMOVQ r64/m64, xmm1</td>, <td>D</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512F</td>, <td>Move quadword from xmm1 register to r/m64.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Tuple1 Scalar</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 1.</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>NP 0F 6F /<em>r</em> MOVQ <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Move quadword from <em>mm/m64</em> to <em>mm</em>.</td>, <td>NP 0F 7F /<em>r</em> MOVQ <em>mm/m64, mm</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Move quadword from <em>mm</em> to <em>mm/m64</em>.</td>, <td>F3 0F 7E /r MOVQ <em>xmm1</em>, <em>xmm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move quadword from <em>xmm2/mem64</em> to <em>xmm1</em>.</td>, <td>VEX.128.F3.0F.WIG 7E /r VMOVQ <em>xmm1, xmm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move quadword from <em>xmm2</em> to <em>xmm1</em>.</td>, <td>EVEX.128.F3.0F.W1 7E /r VMOVQ xmm1, xmm2/m64</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move quadword from xmm2/m64 to xmm1.</td>, <td>66 0F D6 /r MOVQ <em>xmm2/m64</em>, <em>xmm1</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move quadword from <em>xmm1</em> to <em>xmm2/mem64</em>.</td>, <td>VEX.128.66.0F.WIG D6 /r VMOVQ <em>xmm1/m64, xmm2</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move quadword from <em>xmm2</em> register to <em>xmm1/m64</em>.</td>, <td>EVEX.128.66.0F.W1 D6 /r VMOVQ xmm1/m64, xmm2</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move quadword from xmm2 register to xmm1/m64.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Tuple1 Scalar</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>F3 0F D6 /r</td>, <td>MOVQ2DQ <em>xmm</em>, <em>mm</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move quadword from <em>mmx</em> to low quadword of <em>xmm</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="4">#UD</td>, <td>If CR0.EM[bit 2] = 1.</td>, <td>If CR4.OSFXSR[bit 9] = 0.</td>, <td>If CPUID.01H:EDX.SSE2[bit 26] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#MF</td>, <td>If there is a pending x87 FPU exception.</td>]

[<td>A4</td>, <td>MOVS <em>m8</em>, <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI. For 64-bit mode move byte from address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVS <em>m16</em>, <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move word from address DS:(E)SI to ES:(E)DI. For 64-bit mode move word at address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVS <em>m32</em>, <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move dword from address DS:(E)SI to ES:(E)DI. For 64-bit mode move dword from address (R|E)SI to (R|E)DI.</td>, <td>REX.W + A5</td>, <td>MOVS <em>m64</em>, <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move qword from address (R|E)SI to (R|E)DI.</td>, <td>A4</td>, <td>MOVSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI. For 64-bit mode move byte from address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move word from address DS:(E)SI to ES:(E)DI. For 64-bit mode move word at address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move dword from address DS:(E)SI to ES:(E)DI. For 64-bit mode move dword from address (R|E)SI to (R|E)DI.</td>, <td>REX.W + A5</td>, <td>MOVSQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move qword from address (R|E)SI to (R|E)DI.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>A4</td>, <td>MOVS <em>m8</em>, <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI. For 64-bit mode move byte from address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVS <em>m16</em>, <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move word from address DS:(E)SI to ES:(E)DI. For 64-bit mode move word at address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVS <em>m32</em>, <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move dword from address DS:(E)SI to ES:(E)DI. For 64-bit mode move dword from address (R|E)SI to (R|E)DI.</td>, <td>REX.W + A5</td>, <td>MOVS <em>m64</em>, <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move qword from address (R|E)SI to (R|E)DI.</td>, <td>A4</td>, <td>MOVSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI. For 64-bit mode move byte from address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move word from address DS:(E)SI to ES:(E)DI. For 64-bit mode move word at address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move dword from address DS:(E)SI to ES:(E)DI. For 64-bit mode move dword from address (R|E)SI to (R|E)DI.</td>, <td>REX.W + A5</td>, <td>MOVSQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move qword from address (R|E)SI to (R|E)DI.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>A4</td>, <td>MOVS <em>m8</em>, <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI. For 64-bit mode move byte from address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVS <em>m16</em>, <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move word from address DS:(E)SI to ES:(E)DI. For 64-bit mode move word at address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVS <em>m32</em>, <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move dword from address DS:(E)SI to ES:(E)DI. For 64-bit mode move dword from address (R|E)SI to (R|E)DI.</td>, <td>REX.W + A5</td>, <td>MOVS <em>m64</em>, <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move qword from address (R|E)SI to (R|E)DI.</td>, <td>A4</td>, <td>MOVSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI. For 64-bit mode move byte from address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move word from address DS:(E)SI to ES:(E)DI. For 64-bit mode move word at address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move dword from address DS:(E)SI to ES:(E)DI. For 64-bit mode move dword from address (R|E)SI to (R|E)DI.</td>, <td>REX.W + A5</td>, <td>MOVSQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move qword from address (R|E)SI to (R|E)DI.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>F2 0F 10 /r MOVSD xmm1, xmm2</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move scalar double-precision floating-point value from xmm2 to xmm1 register.</td>, <td>F2 0F 10 /r MOVSD xmm1, m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Load scalar double-precision floating-point value from m64 to xmm1 register.</td>, <td>F2 0F 11 /r MOVSD xmm1/m64, xmm2</td>, <td>C</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move scalar double-precision floating-point value from xmm2 register to xmm1/m64.</td>, <td>VEX.LIG.F2.0F.WIG 10 /r VMOVSD xmm1, xmm2, xmm3</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Merge scalar double-precision floating-point value from xmm2 and xmm3 to xmm1 register.</td>, <td>VEX.LIG.F2.0F.WIG 10 /r VMOVSD xmm1, m64</td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Load scalar double-precision floating-point value from m64 to xmm1 register.</td>, <td>VEX.LIG.F2.0F.WIG 11 /r VMOVSD xmm1, xmm2, xmm3</td>, <td>E</td>, <td>V/V</td>, <td>AVX</td>, <td>Merge scalar double-precision floating-point value from xmm2 and xmm3 registers to xmm1.</td>, <td>VEX.LIG.F2.0F.WIG 11 /r VMOVSD m64, xmm1</td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Store scalar double-precision floating-point value from xmm1 register to m64.</td>, <td>EVEX.LIG.F2.0F.W1 10 /r VMOVSD xmm1 {k1}{z}, xmm2, xmm3</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Merge scalar double-precision floating-point value from xmm2 and xmm3 registers to xmm1 under writemask k1.</td>, <td>EVEX.LIG.F2.0F.W1 10 /r VMOVSD xmm1 {k1}{z}, m64</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Load scalar double-precision floating-point value from m64 to xmm1 register under writemask k1.</td>, <td>EVEX.LIG.F2.0F.W1 11 /r VMOVSD xmm1 {k1}{z}, xmm2, xmm3</td>, <td>E</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Merge scalar double-precision floating-point value from xmm2 and xmm3 registers to xmm1 under writemask k1.</td>, <td>EVEX.LIG.F2.0F.W1 11 /r VMOVSD m64 {k1}, xmm1</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Store scalar double-precision floating-point value from xmm1 register to m64 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>E</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>vvvv (r)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>F</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>G</td>, <td>Tuple1 Scalar</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B.</td>]

[<td>F3 0F 16 /r MOVSHDUP xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE3</td>, <td>Move odd index single-precision floating-point values from xmm2/mem and duplicate each element into xmm1.</td>, <td>VEX.128.F3.0F.WIG 16 /r VMOVSHDUP xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move odd index single-precision floating-point values from xmm2/mem and duplicate each element into xmm1.</td>, <td>VEX.256.F3.0F.WIG 16 /r VMOVSHDUP ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move odd index single-precision floating-point values from ymm2/mem and duplicate each element into ymm1.</td>, <td>EVEX.128.F3.0F.W0 16 /r VMOVSHDUP xmm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move odd index single-precision floating-point values from xmm2/m128 and duplicate each element into xmm1 under writemask.</td>, <td>EVEX.256.F3.0F.W0 16 /r VMOVSHDUP ymm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move odd index single-precision floating-point values from ymm2/m256 and duplicate each element into ymm1 under writemask.</td>, <td>EVEX.512.F3.0F.W0 16 /r VMOVSHDUP zmm1 {k1}{z}, zmm2/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move odd index single-precision floating-point values from zmm2/m512 and duplicate each element into zmm1 under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B or VEX.vvvv != 1111B.</td>]

[<td>F3 0F 12 /r MOVSLDUP xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE3</td>, <td>Move even index single-precision floating-point values from xmm2/mem and duplicate each element into xmm1.</td>, <td>VEX.128.F3.0F.WIG 12 /r VMOVSLDUP xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move even index single-precision floating-point values from xmm2/mem and duplicate each element into xmm1.</td>, <td>VEX.256.F3.0F.WIG 12 /r VMOVSLDUP ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move even index single-precision floating-point values from ymm2/mem and duplicate each element into ymm1.</td>, <td>EVEX.128.F3.0F.W0 12 /r VMOVSLDUP xmm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move even index single-precision floating-point values from xmm2/m128 and duplicate each element into xmm1 under writemask.</td>, <td>EVEX.256.F3.0F.W0 12 /r VMOVSLDUP ymm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move even index single-precision floating-point values from ymm2/m256 and duplicate each element into ymm1 under writemask.</td>, <td>EVEX.512.F3.0F.W0 12 /r VMOVSLDUP zmm1 {k1}{z}, zmm2/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move even index single-precision floating-point values from zmm2/m512 and duplicate each element into zmm1 under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B or VEX.vvvv != 1111B.</td>]

[<td>A4</td>, <td>MOVS <em>m8</em>, <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI. For 64-bit mode move byte from address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVS <em>m16</em>, <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move word from address DS:(E)SI to ES:(E)DI. For 64-bit mode move word at address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVS <em>m32</em>, <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move dword from address DS:(E)SI to ES:(E)DI. For 64-bit mode move dword from address (R|E)SI to (R|E)DI.</td>, <td>REX.W + A5</td>, <td>MOVS <em>m64</em>, <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move qword from address (R|E)SI to (R|E)DI.</td>, <td>A4</td>, <td>MOVSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI. For 64-bit mode move byte from address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move word from address DS:(E)SI to ES:(E)DI. For 64-bit mode move word at address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move dword from address DS:(E)SI to ES:(E)DI. For 64-bit mode move dword from address (R|E)SI to (R|E)DI.</td>, <td>REX.W + A5</td>, <td>MOVSQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move qword from address (R|E)SI to (R|E)DI.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>F3 0F 10 /r MOVSS xmm1, xmm2</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Merge scalar single-precision floating-point value from xmm2 to xmm1 register.</td>, <td>F3 0F 10 /r MOVSS xmm1, m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Load scalar single-precision floating-point value from m32 to xmm1 register.</td>, <td>VEX.LIG.F3.0F.WIG 10 /r VMOVSS xmm1, xmm2, xmm3</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Merge scalar single-precision floating-point value from xmm2 and xmm3 to xmm1 register</td>, <td>VEX.LIG.F3.0F.WIG 10 /r VMOVSS xmm1, m32</td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Load scalar single-precision floating-point value from m32 to xmm1 register.</td>, <td>F3 0F 11 /r MOVSS xmm2/m32, xmm1</td>, <td>C</td>, <td>V/V</td>, <td>SSE</td>, <td>Move scalar single-precision floating-point value from xmm1 register to xmm2/m32.</td>, <td>VEX.LIG.F3.0F.WIG 11 /r VMOVSS xmm1, xmm2, xmm3</td>, <td>E</td>, <td>V/V</td>, <td>AVX</td>, <td>Move scalar single-precision floating-point value from xmm2 and xmm3 to xmm1 register.</td>, <td>VEX.LIG.F3.0F.WIG 11 /r VMOVSS m32, xmm1</td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Move scalar single-precision floating-point value from xmm1 register to m32.</td>, <td>EVEX.LIG.F3.0F.W0 10 /r VMOVSS xmm1 {k1}{z}, xmm2, xmm3</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move scalar single-precision floating-point value from xmm2 and xmm3 to xmm1 register under writemask k1.</td>, <td>EVEX.LIG.F3.0F.W0 10 /r VMOVSS xmm1 {k1}{z}, m32</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move scalar single-precision floating-point values from m32 to xmm1 under writemask k1.</td>, <td>EVEX.LIG.F3.0F.W0 11 /r VMOVSS xmm1 {k1}{z}, xmm2, xmm3</td>, <td>E</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move scalar single-precision floating-point value from xmm2 and xmm3 to xmm1 register under writemask k1.</td>, <td>EVEX.LIG.F3.0F.W0 11 /r VMOVSS m32 {k1}, xmm1</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move scalar single-precision floating-point values from xmm1 to m32 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>E</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>vvvv (r)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>F</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>G</td>, <td>Tuple1 Scalar</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B.</td>]

[<td>A4</td>, <td>MOVS <em>m8</em>, <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI. For 64-bit mode move byte from address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVS <em>m16</em>, <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move word from address DS:(E)SI to ES:(E)DI. For 64-bit mode move word at address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVS <em>m32</em>, <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move dword from address DS:(E)SI to ES:(E)DI. For 64-bit mode move dword from address (R|E)SI to (R|E)DI.</td>, <td>REX.W + A5</td>, <td>MOVS <em>m64</em>, <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move qword from address (R|E)SI to (R|E)DI.</td>, <td>A4</td>, <td>MOVSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI. For 64-bit mode move byte from address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move word from address DS:(E)SI to ES:(E)DI. For 64-bit mode move word at address (R|E)SI to (R|E)DI.</td>, <td>A5</td>, <td>MOVSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, move dword from address DS:(E)SI to ES:(E)DI. For 64-bit mode move dword from address (R|E)SI to (R|E)DI.</td>, <td>REX.W + A5</td>, <td>MOVSQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move qword from address (R|E)SI to (R|E)DI.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F BE /<em>r</em></td>, <td>MOVSX <em>r16, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move byte to word with sign-extension.</td>, <td>0F BE /<em>r</em></td>, <td>MOVSX <em>r32, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move byte to doubleword with sign-extension.</td>, <td>REX.W + 0F BE /<em>r</em></td>, <td>MOVSX <em>r64, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move byte to quadword with sign-extension.</td>, <td>0F BF /<em>r</em></td>, <td>MOVSX <em>r32, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move word to doubleword, with sign-extension.</td>, <td>REX.W + 0F BF /<em>r</em></td>, <td>MOVSX <em>r64, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move word to quadword with sign-extension.</td>, <td>63 /<em>r*</em></td>, <td>MOVSXD <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move word to word with sign-extension.</td>, <td>63 /<em>r*</em></td>, <td>MOVSXD <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move doubleword to doubleword with sign-extension.</td>, <td>REX.W + 63 /<em>r</em></td>, <td>MOVSXD <em>r64, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move doubleword to quadword with sign-extension.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F BE /<em>r</em></td>, <td>MOVSX <em>r16, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move byte to word with sign-extension.</td>, <td>0F BE /<em>r</em></td>, <td>MOVSX <em>r32, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move byte to doubleword with sign-extension.</td>, <td>REX.W + 0F BE /<em>r</em></td>, <td>MOVSX <em>r64, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move byte to quadword with sign-extension.</td>, <td>0F BF /<em>r</em></td>, <td>MOVSX <em>r32, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move word to doubleword, with sign-extension.</td>, <td>REX.W + 0F BF /<em>r</em></td>, <td>MOVSX <em>r64, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move word to quadword with sign-extension.</td>, <td>63 /<em>r*</em></td>, <td>MOVSXD <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move word to word with sign-extension.</td>, <td>63 /<em>r*</em></td>, <td>MOVSXD <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move doubleword to doubleword with sign-extension.</td>, <td>REX.W + 63 /<em>r</em></td>, <td>MOVSXD <em>r64, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move doubleword to quadword with sign-extension.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>66 0F 10 /r MOVUPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move unaligned packed double-precision floating-point from xmm2/mem to xmm1.</td>, <td>66 0F 11 /r MOVUPD xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move unaligned packed double-precision floating-point from xmm1 to xmm2/mem.</td>, <td>VEX.128.66.0F.WIG 10 /r VMOVUPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed double-precision floating-point from xmm2/mem to xmm1.</td>, <td>VEX.128.66.0F.WIG 11 /r VMOVUPD xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed double-precision floating-point from xmm1 to xmm2/mem.</td>, <td>VEX.256.66.0F.WIG 10 /r VMOVUPD ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed double-precision floating-point from ymm2/mem to ymm1.</td>, <td>VEX.256.66.0F.WIG 11 /r VMOVUPD ymm2/m256, ymm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed double-precision floating-point from ymm1 to ymm2/mem.</td>, <td>EVEX.128.66.0F.W1 10 /r VMOVUPD xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed double-precision floating-point from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.W1 11 /r VMOVUPD xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed double-precision floating-point from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.66.0F.W1 10 /r VMOVUPD ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed double-precision floating-point from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W1 11 /r VMOVUPD ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed double-precision floating-point from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.66.0F.W1 10 /r VMOVUPD zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed double-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W1 11 /r VMOVUPD zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed double-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B.</td>]

[<td>NP 0F 10 /r MOVUPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Move unaligned packed single-precision floating-point from xmm2/mem to xmm1.</td>, <td>NP 0F 11 /r MOVUPS xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>SSE</td>, <td>Move unaligned packed single-precision floating-point from xmm1 to xmm2/mem.</td>, <td>VEX.128.0F.WIG 10 /r VMOVUPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed single-precision floating-point from xmm2/mem to xmm1.</td>, <td>VEX.128.0F.WIG 11 /r VMOVUPS xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed single-precision floating-point from xmm1 to xmm2/mem.</td>, <td>VEX.256.0F.WIG 10 /r VMOVUPS ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed single-precision floating-point from ymm2/mem to ymm1.</td>, <td>VEX.256.0F.WIG 11 /r VMOVUPS ymm2/m256, ymm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed single-precision floating-point from ymm1 to ymm2/mem.</td>, <td>EVEX.128.0F.W0 10 /r VMOVUPS xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed single-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.0F.W0 10 /r VMOVUPS ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed single-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.0F.W0 10 /r VMOVUPS zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed single-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.0F.W0 11 /r VMOVUPS xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed single-precision floating-point values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.0F.W0 11 /r VMOVUPS ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed single-precision floating-point values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.0F.W0 11 /r VMOVUPS zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed single-precision floating-point values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B or VEX.vvvv != 1111B.</td>]

[<td>0F B6 /<em>r</em></td>, <td>MOVZX <em>r16, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move byte to word with zero-extension.</td>, <td>0F B6 /<em>r</em></td>, <td>MOVZX <em>r32, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move byte to doubleword, zero-extension.</td>, <td>REX.W + 0F B6 /<em>r</em></td>, <td>MOVZX <em>r64, r/m8*</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move byte to quadword, zero-extension.</td>, <td>0F B7 /<em>r</em></td>, <td>MOVZX <em>r32, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Move word to doubleword, zero-extension.</td>, <td>REX.W + 0F B7 /<em>r</em></td>, <td>MOVZX <em>r64, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move word to quadword, zero-extension.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>66 0F 3A 42 /r ib MPSADBW <em>xmm1, xmm2/m128, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in <em>xmm1</em> and <em>xmm2/m128</em> and writes the results in <em>xmm1</em>. Starting offsets within <em>xmm1</em> and <em>xmm2/m128</em> are determined by <em>imm8</em>.</td>, <td>VEX.128.66.0F3A.WIG 42 /r ib VMPSADBW <em>xmm1, xmm2, xmm3/m128, imm8</em></td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in <em>xmm2</em> and <em>xmm3/m128</em> and writes the results in <em>xmm1</em>. Starting offsets within <em>xmm2</em> and <em>xmm3/m128</em> are determined by <em>imm8</em>.</td>, <td>VEX.256.66.0F3A.WIG 42 /r ib VMPSADBW <em>ymm1, ymm2, ymm3/m256, imm8</em></td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX2</td>, <td>Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in <em>xmm2</em> and <em>ymm3/m128</em> and writes the results in <em>ymm1</em>. Starting offsets within <em>ymm2</em> and <em>xmm3/m128</em> are determined by <em>imm8</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMI</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>RVMI</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>F6 /4</td>, <td>MUL <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned multiply (AX ← AL ∗ <em>r/m8</em>).</td>, <td>REX + F6 /4</td>, <td>MUL <em>r/m8</em><sup>*</sup></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned multiply (AX ← AL ∗ <em>r/m8</em>).</td>, <td>F7 /4</td>, <td>MUL <em>r/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned multiply (DX:AX ← AX ∗ <em>r/m16</em>).</td>, <td>F7 /4</td>, <td>MUL <em>r/m32</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned multiply (EDX:EAX ← EAX ∗ <em>r/m32</em>).</td>, <td>REX.W + F7 /4</td>, <td>MUL <em>r/m64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned multiply (RDX:RAX ← RAX ∗ <em>r/m64).</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>Byte</td>, <td>AL</td>, <td>r/m8</td>, <td>AX</td>, <td>Word</td>, <td>AX</td>, <td>r/m16</td>, <td>DX:AX</td>, <td>Doubleword</td>, <td>EAX</td>, <td>r/m32</td>, <td>EDX:EAX</td>, <td>Quadword</td>, <td>RAX</td>, <td>r/m64</td>, <td>RDX:RAX</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>]

[<td>66 0F 59 /r MULPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Multiply packed double-precision floating-point values in xmm2/m128 with xmm1 and store result in xmm1.</td>, <td>VEX.128.66.0F.WIG 59 /r VMULPD xmm1,xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply packed double-precision floating-point values in xmm3/m128 with xmm2 and store result in xmm1.</td>, <td>VEX.256.66.0F.WIG 59 /r VMULPD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply packed double-precision floating-point values in ymm3/m256 with ymm2 and store result in ymm1.</td>, <td>EVEX.128.66.0F.W1 59 /r VMULPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm3/m128/m64bcst to xmm2 and store result in xmm1.</td>, <td>EVEX.256.66.0F.W1 59 /r VMULPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm3/m256/m64bcst to ymm2 and store result in ymm1.</td>, <td>EVEX.512.66.0F.W1 59 /r VMULPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values in zmm3/m512/m64bcst with zmm2 and store result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 59 /r MULPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Multiply packed single-precision floating-point values in xmm2/m128 with xmm1 and store result in xmm1.</td>, <td>VEX.128.0F.WIG 59 /r VMULPS xmm1,xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply packed single-precision floating-point values in xmm3/m128 with xmm2 and store result in xmm1.</td>, <td>VEX.256.0F.WIG 59 /r VMULPS ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply packed single-precision floating-point values in ymm3/m256 with ymm2 and store result in ymm1.</td>, <td>EVEX.128.0F.W0 59 /r VMULPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm3/m128/m32bcst to xmm2 and store result in xmm1.</td>, <td>EVEX.256.0F.W0 59 /r VMULPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm3/m256/m32bcst to ymm2 and store result in ymm1.</td>, <td>EVEX.512.0F.W0 59 /r VMULPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst {er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values in zmm3/m512/m32bcst with zmm2 and store result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F2 0F 59 /r MULSD xmm1,xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Multiply the low double-precision floating-point value in xmm2/m64 by low double-precision floating-point value in xmm1.</td>, <td>VEX.LIG.F2.0F.WIG 59 /r VMULSD xmm1,xmm2, xmm3/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply the low double-precision floating-point value in xmm3/m64 by low double-precision floating-point value in xmm2.</td>, <td>EVEX.LIG.F2.0F.W1 59 /r VMULSD xmm1 {k1}{z}, xmm2, xmm3/m64 {er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply the low double-precision floating-point value in xmm3/m64 by low double-precision floating-point value in xmm2.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F3 0F 59 /r MULSS xmm1,xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Multiply the low single-precision floating-point value in xmm2/m32 by the low single-precision floating-point value in xmm1.</td>, <td>VEX.LIG.F3.0F.WIG 59 /r VMULSS xmm1,xmm2, xmm3/m32</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply the low single-precision floating-point value in xmm3/m32 by the low single-precision floating-point value in xmm2.</td>, <td>EVEX.LIG.F3.0F.W0 59 /r VMULSS xmm1 {k1}{z}, xmm2, xmm3/m32 {er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply the low single-precision floating-point value in xmm3/m32 by the low single-precision floating-point value in xmm2.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LZ.F2.0F38.W0 F6 /r MULX <em>r32a, r32b, r/m32</em></td>, <td>RVM</td>, <td>V/V</td>, <td>BMI2</td>, <td>Unsigned multiply of <em>r/m32</em> with EDX without affecting arithmetic flags.</td>, <td>VEX.LZ.F2.0F38.W1 F6 /r MULX <em>r64a, r64b, r/m64</em></td>, <td>RVM</td>, <td>V/N.E.</td>, <td>BMI2</td>, <td>Unsigned multiply of <em>r/m64</em> with RDX without affecting arithmetic flags.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (r)</td>, <td>RDX/EDX is implied 64/32 bits source</td>]

[<td>0F 01 C9</td>, <td>MWAIT</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>A hint that allows the processor to stop instruction execution and enter an implementation-dependent optimized state until occurrence of a class of events.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>0</td>, <td>Treat interrupts as break events even if masked (e.g., even if EFLAGS.IF=0). May be set only if CPUID.05H:ECX[bit 1] = 1.</td>, <td>31: 1</td>, <td>Reserved</td>, <td>3:0</td>, <td>Sub C-state within a C-state, indicated by bits [7:4]</td>, <td>7:4</td>, <td>Target C-state* Value of 0 means C1; 1 means C2 and so on Value of 01111B means C0 Note: Target C states for MWAIT extensions are processor-specific C-states, not ACPI C-states</td>, <td>31: 8</td>, <td>Reserved</td>, <td rowspan="2">#GP(0)</td>, <td>If ECX[31:1] ≠ 0.</td>, <td>If ECX[0] = 1 and CPUID.05H:ECX[bit 1] = 0.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:ECX.MONITOR[bit 3] = 0.</td>, <td>If current privilege level is not 0.</td>, <td rowspan="2">#GP</td>, <td>If ECX[31:1] ≠ 0.</td>, <td>If ECX[0] = 1 and CPUID.05H:ECX[bit 1] = 0.</td>, <td>#UD</td>, <td>If CPUID.01H:ECX.MONITOR[bit 3] = 0.</td>, <td>#UD</td>, <td>The MWAIT instruction is not recognized in virtual-8086 mode (even if CPUID.01H:ECX.MONITOR[bit 3] = 1).</td>, <td rowspan="2">#GP(0)</td>, <td>If RCX[63:1] ≠ 0.</td>, <td>If RCX[0] = 1 and CPUID.05H:ECX[bit 1] = 0.</td>, <td rowspan="2">#UD</td>, <td>If the current privilege level is not 0.</td>, <td>If CPUID.01H:ECX.MONITOR[bit 3] = 0.</td>]

[<td>F6 /3</td>, <td>NEG <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Two's complement negate <em>r/m8.</em></td>, <td>REX + F6 /3</td>, <td>NEG <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Two's complement negate <em>r/m8.</em></td>, <td>F7 /3</td>, <td>NEG <em>r/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Two's complement negate <em>r/m16.</em></td>, <td>F7 /3</td>, <td>NEG <em>r/m32</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Two's complement negate <em>r/m32.</em></td>, <td>REX.W + F7 /3</td>, <td>NEG <em>r/m64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Two's complement negate <em>r/m64.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r, w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>NP 90</td>, <td>NOP</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>One byte no-operation instruction.</td>, <td>NP 0F 1F /0</td>, <td>NOP r/m16</td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Multi-byte no-operation instruction.</td>, <td>NP 0F 1F /0</td>, <td>NOP r/m32</td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Multi-byte no-operation instruction.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>2 bytes 3 bytes 4 bytes 5 bytes 6 bytes 7 bytes 8 bytes 9 bytes</td>, <td>66 NOP NOP DWORD ptr [EAX] NOP DWORD ptr [EAX + 00H] NOP DWORD ptr [EAX + EAX*1 + 00H] 66 NOP DWORD ptr [EAX + EAX*1 + 00H] NOP DWORD ptr [EAX + 00000000H] NOP DWORD ptr [EAX + EAX*1 + 00000000H] 66 NOP DWORD ptr [EAX + EAX*1 + 00000000H]</td>, <td>66 90H 0F 1F 00H 0F 1F 40 00H 0F 1F 44 00 00H 66 0F 1F 44 00 00H 0F 1F 80 00 00 00 00H 0F 1F 84 00 00 00 00 00H 66 0F 1F 84 00 00 00 00 00H</td>]

[<td>F6 /2</td>, <td>NOT <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Reverse each bit of <em>r/m8.</em></td>, <td>REX + F6 /2</td>, <td>NOT <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Reverse each bit of <em>r/m8.</em></td>, <td>F7 /2</td>, <td>NOT <em>r/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Reverse each bit of <em>r/m16.</em></td>, <td>F7 /2</td>, <td>NOT <em>r/m32</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Reverse each bit of <em>r/m32.</em></td>, <td>REX.W + F7 /2</td>, <td>NOT <em>r/m64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Reverse each bit of <em>r/m64.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r, w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination operand points to a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>0C <em>ib</em></td>, <td>OR AL, i<em>mm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>AL OR <em>imm8.</em></td>, <td>0D <em>iw</em></td>, <td>OR AX, i<em>mm16</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>AX OR <em>imm16.</em></td>, <td>0D <em>id</em></td>, <td>OR EAX, i<em>mm32</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>EAX OR <em>imm32.</em></td>, <td>REX.W + 0D <em>id</em></td>, <td>OR RAX, i<em>mm32</em></td>, <td>I</td>, <td>Valid</td>, <td>N.E.</td>, <td>RAX OR <em>imm32 (sign-extended).</em></td>, <td>80 /1 <em>ib</em></td>, <td>OR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m8</em> OR <em>imm8.</em></td>, <td>REX + 80 /1 <em>ib</em></td>, <td>OR <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r/m8</em> OR <em>imm8.</em></td>, <td>81 /1 <em>iw</em></td>, <td>OR <em>r/m16, imm16</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m16</em> OR <em>imm16.</em></td>, <td>81 /1 <em>id</em></td>, <td>OR <em>r/m32, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m32</em> OR <em>imm32.</em></td>, <td>REX.W + 81 /1 <em>id</em></td>, <td>OR <em>r/m64, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r/m64</em> OR <em>imm32 (sign-extended).</em></td>, <td>83 /1 <em>ib</em></td>, <td>OR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m16</em> OR <em>imm8 (sign-extended).</em></td>, <td>83 /1 <em>ib</em></td>, <td>OR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m32</em> OR <em>imm8 (sign-extended).</em></td>, <td>REX.W + 83 /1 <em>ib</em></td>, <td>OR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r/m64</em> OR <em>imm8 (sign-extended).</em></td>, <td>08 /<em>r</em></td>, <td>OR <em>r/m8, r8</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m8</em> OR <em>r8.</em></td>, <td>REX + 08 /<em>r</em></td>, <td>OR <em>r/m8*, r8*</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r/m8</em> OR <em>r8.</em></td>, <td>09 /<em>r</em></td>, <td>OR <em>r/m16, r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m16</em> OR <em>r16.</em></td>, <td>09 /<em>r</em></td>, <td>OR <em>r/m32, r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m32</em> OR <em>r32.</em></td>, <td>REX.W + 09 /<em>r</em></td>, <td>OR <em>r/m64, r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r/m64</em> OR <em>r64.</em></td>, <td>0A /<em>r</em></td>, <td>OR <em>r8, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r8</em> OR <em>r/m8.</em></td>, <td>REX + 0A /<em>r</em></td>, <td>OR <em>r8*, r/m8*</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r8</em> OR <em>r/m8.</em></td>, <td>0B /<em>r</em></td>, <td>OR <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r16</em> OR <em>r/m16.</em></td>, <td>0B /<em>r</em></td>, <td>OR <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r32</em> OR <em>r/m32.</em></td>, <td>REX.W + 0B /<em>r</em></td>, <td>OR <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r64</em> OR <em>r/m64.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>I</td>, <td>AL/AX/EAX/RAX</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td>MR</td>, <td>ModRM:r/m (r, w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination operand points to a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>66 0F 56/r ORPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Return the bitwise logical OR of packed double-precision floating-point values in xmm1 and xmm2/mem.</td>, <td>VEX.128.66.0F 56 /r VORPD xmm1,xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the bitwise logical OR of packed double-precision floating-point values in xmm2 and xmm3/mem.</td>, <td>VEX.256.66.0F 56 /r VORPD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the bitwise logical OR of packed double-precision floating-point values in ymm2 and ymm3/mem.</td>, <td>EVEX.128.66.0F.W1 56 /r VORPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Return the bitwise logical OR of packed double-precision floating-point values in xmm2 and xmm3/m128/m64bcst subject to writemask k1.</td>, <td>EVEX.256.66.0F.W1 56 /r VORPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Return the bitwise logical OR of packed double-precision floating-point values in ymm2 and ymm3/m256/m64bcst subject to writemask k1.</td>, <td>EVEX.512.66.0F.W1 56 /r VORPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Return the bitwise logical OR of packed double-precision floating-point values in zmm2 and zmm3/m512/m64bcst subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 56 /r ORPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Return the bitwise logical OR of packed single-precision floating-point values in xmm1 and xmm2/mem.</td>, <td>VEX.128.0F 56 /r VORPS xmm1,xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the bitwise logical OR of packed single-precision floating-point values in xmm2 and xmm3/mem.</td>, <td>VEX.256.0F 56 /r VORPS ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the bitwise logical OR of packed single-precision floating-point values in ymm2 and ymm3/mem.</td>, <td>EVEX.128.0F.W0 56 /r VORPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Return the bitwise logical OR of packed single-precision floating-point values in xmm2 and xmm3/m128/m32bcst subject to writemask k1.</td>, <td>EVEX.256.0F.W0 56 /r VORPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Return the bitwise logical OR of packed single-precision floating-point values in ymm2 and ymm3/m256/m32bcst subject to writemask k1.</td>, <td>EVEX.512.0F.W0 56 /r VORPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Return the bitwise logical OR of packed single-precision floating-point values in zmm2 and zmm3/m512/m32bcst subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>E6 <em>ib</em></td>, <td>OUT <em>imm8</em>, AL</td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Output byte in AL to I/O port address <em>imm8</em>.</td>, <td>E7 <em>ib</em></td>, <td>OUT <em>imm8</em>, AX</td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Output word in AX to I/O port address <em>imm8.</em></td>, <td>E7 <em>ib</em></td>, <td>OUT <em>imm8</em>, EAX</td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Output doubleword in EAX to I/O port address <em>imm8</em>.</td>, <td>EE</td>, <td>OUT DX, AL</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output byte in AL to I/O port address in DX.</td>, <td>EF</td>, <td>OUT DX, AX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output word in AX to I/O port address in DX.</td>, <td>EF</td>, <td>OUT DX, EAX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output doubleword in EAX to I/O port address in DX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>I</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If any of the I/O permission bits in the TSS for the I/O port being accessed is 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>6E</td>, <td>OUTS DX, <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output byte from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6F</td>, <td>OUTS DX, <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output word from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6F</td>, <td>OUTS DX, <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output doubleword from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6E</td>, <td>OUTSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output byte from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6F</td>, <td>OUTSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output word from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6F</td>, <td>OUTSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output doubleword from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>If a memory operand effective address is outside the limit of the CS, DS, ES, FS, or GS segment.</td>, <td>If the segment register contains a NULL segment selector.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If any of the I/O permission bits in the TSS for the I/O port being accessed is 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>6E</td>, <td>OUTS DX, <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output byte from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6F</td>, <td>OUTS DX, <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output word from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6F</td>, <td>OUTS DX, <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output doubleword from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6E</td>, <td>OUTSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output byte from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6F</td>, <td>OUTSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output word from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6F</td>, <td>OUTSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output doubleword from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>If a memory operand effective address is outside the limit of the CS, DS, ES, FS, or GS segment.</td>, <td>If the segment register contains a NULL segment selector.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If any of the I/O permission bits in the TSS for the I/O port being accessed is 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>6E</td>, <td>OUTS DX, <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output byte from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6F</td>, <td>OUTS DX, <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output word from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6F</td>, <td>OUTS DX, <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output doubleword from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6E</td>, <td>OUTSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output byte from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6F</td>, <td>OUTSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output word from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6F</td>, <td>OUTSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output doubleword from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>If a memory operand effective address is outside the limit of the CS, DS, ES, FS, or GS segment.</td>, <td>If the segment register contains a NULL segment selector.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If any of the I/O permission bits in the TSS for the I/O port being accessed is 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>6E</td>, <td>OUTS DX, <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output byte from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6F</td>, <td>OUTS DX, <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output word from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6F</td>, <td>OUTS DX, <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output doubleword from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6E</td>, <td>OUTSB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output byte from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6F</td>, <td>OUTSW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output word from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>6F</td>, <td>OUTSD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output doubleword from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>If a memory operand effective address is outside the limit of the CS, DS, ES, FS, or GS segment.</td>, <td>If the segment register contains a NULL segment selector.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If any of the I/O permission bits in the TSS for the I/O port being accessed is 1.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the CPL is greater than (has less privilege) the I/O privilege level (IOPL) and any of the corresponding I/O permission bits in TSS for the I/O port being accessed is 1.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>NP 0F 38 1C /r<sup>1</sup> PABSB <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of bytes in <em>mm2/m64</em> and store UNSIGNED result in <em>mm1</em>.</td>, <td>66 0F 38 1C /r PABSB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of bytes in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>NP 0F 38 1D /r<sup>1</sup> PABSW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of 16-bit integers in <em>mm2/m64</em> and store UNSIGNED result in <em>mm1</em>.</td>, <td>66 0F 38 1D /r PABSW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of 16-bit integers in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>NP 0F 38 1E /r<sup>1</sup> PABSD <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of 32-bit integers in <em>mm2/m64</em> and store UNSIGNED result in <em>mm1</em>.</td>, <td>66 0F 38 1E /r PABSD <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of 32-bit integers in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1.</em></td>, <td>VEX.128.66.0F38.WIG 1C /r VPABSB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Compute the absolute value of bytes in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 1D /r VPABSW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Compute the absolute value of 16- bit integers in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 1E /r VPABSD <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Compute the absolute value of 32- bit integers in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.WIG 1C /r VPABSB <em>ymm1, ymm2/m256</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compute the absolute value of bytes in <em>ymm2/m256</em> and store UNSIGNED result in <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.WIG 1D /r VPABSW <em>ymm1, ymm2/m256</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compute the absolute value of 16-bit integers in <em>ymm2/m256</em> and store UNSIGNED result in <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.WIG 1E /r VPABSD <em>ymm1, ymm2/m256</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compute the absolute value of 32-bit integers in <em>ymm2/m256</em> and store UNSIGNED result in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F38.WIG 1C /r VPABSB xmm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 1C /r VPABSB ymm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute the absolute value of bytes in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 1C /r VPABSB zmm1 {k1}{z}, zmm2/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compute the absolute value of bytes in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.WIG 1D /r VPABSW xmm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 1D /r VPABSW ymm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute the absolute value of 16-bit integers in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 1D /r VPABSW zmm1 {k1}{z}, zmm2/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compute the absolute value of 16-bit integers in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 1E /r VPABSD xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compute the absolute value of 32-bit integers in xmm2/m128/m32bcst and store UNSIGNED result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 1E /r VPABSD ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compute the absolute value of 32-bit integers in ymm2/m256/m32bcst and store UNSIGNED result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 1E /r VPABSD zmm1 {k1}{z}, zmm2/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compute the absolute value of 32-bit integers in zmm2/m512/m32bcst and store UNSIGNED result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 1F /r VPABSQ xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compute the absolute value of 64-bit integers in xmm2/m128/m64bcst and store UNSIGNED result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 1F /r VPABSQ ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compute the absolute value of 64-bit integers in ymm2/m256/m64bcst and store UNSIGNED result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 1F /r VPABSQ zmm1 {k1}{z}, zmm2/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compute the absolute value of 64-bit integers in zmm2/m512/m64bcst and store UNSIGNED result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>NP 0F 38 1C /r<sup>1</sup> PABSB <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of bytes in <em>mm2/m64</em> and store UNSIGNED result in <em>mm1</em>.</td>, <td>66 0F 38 1C /r PABSB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of bytes in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>NP 0F 38 1D /r<sup>1</sup> PABSW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of 16-bit integers in <em>mm2/m64</em> and store UNSIGNED result in <em>mm1</em>.</td>, <td>66 0F 38 1D /r PABSW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of 16-bit integers in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>NP 0F 38 1E /r<sup>1</sup> PABSD <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of 32-bit integers in <em>mm2/m64</em> and store UNSIGNED result in <em>mm1</em>.</td>, <td>66 0F 38 1E /r PABSD <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of 32-bit integers in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1.</em></td>, <td>VEX.128.66.0F38.WIG 1C /r VPABSB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Compute the absolute value of bytes in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 1D /r VPABSW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Compute the absolute value of 16- bit integers in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 1E /r VPABSD <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Compute the absolute value of 32- bit integers in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.WIG 1C /r VPABSB <em>ymm1, ymm2/m256</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compute the absolute value of bytes in <em>ymm2/m256</em> and store UNSIGNED result in <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.WIG 1D /r VPABSW <em>ymm1, ymm2/m256</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compute the absolute value of 16-bit integers in <em>ymm2/m256</em> and store UNSIGNED result in <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.WIG 1E /r VPABSD <em>ymm1, ymm2/m256</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compute the absolute value of 32-bit integers in <em>ymm2/m256</em> and store UNSIGNED result in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F38.WIG 1C /r VPABSB xmm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 1C /r VPABSB ymm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute the absolute value of bytes in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 1C /r VPABSB zmm1 {k1}{z}, zmm2/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compute the absolute value of bytes in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.WIG 1D /r VPABSW xmm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 1D /r VPABSW ymm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute the absolute value of 16-bit integers in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 1D /r VPABSW zmm1 {k1}{z}, zmm2/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compute the absolute value of 16-bit integers in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 1E /r VPABSD xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compute the absolute value of 32-bit integers in xmm2/m128/m32bcst and store UNSIGNED result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 1E /r VPABSD ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compute the absolute value of 32-bit integers in ymm2/m256/m32bcst and store UNSIGNED result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 1E /r VPABSD zmm1 {k1}{z}, zmm2/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compute the absolute value of 32-bit integers in zmm2/m512/m32bcst and store UNSIGNED result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 1F /r VPABSQ xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compute the absolute value of 64-bit integers in xmm2/m128/m64bcst and store UNSIGNED result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 1F /r VPABSQ ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compute the absolute value of 64-bit integers in ymm2/m256/m64bcst and store UNSIGNED result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 1F /r VPABSQ zmm1 {k1}{z}, zmm2/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compute the absolute value of 64-bit integers in zmm2/m512/m64bcst and store UNSIGNED result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>NP 0F 38 1C /r<sup>1</sup> PABSB <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of bytes in <em>mm2/m64</em> and store UNSIGNED result in <em>mm1</em>.</td>, <td>66 0F 38 1C /r PABSB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of bytes in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>NP 0F 38 1D /r<sup>1</sup> PABSW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of 16-bit integers in <em>mm2/m64</em> and store UNSIGNED result in <em>mm1</em>.</td>, <td>66 0F 38 1D /r PABSW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of 16-bit integers in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>NP 0F 38 1E /r<sup>1</sup> PABSD <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of 32-bit integers in <em>mm2/m64</em> and store UNSIGNED result in <em>mm1</em>.</td>, <td>66 0F 38 1E /r PABSD <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of 32-bit integers in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1.</em></td>, <td>VEX.128.66.0F38.WIG 1C /r VPABSB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Compute the absolute value of bytes in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 1D /r VPABSW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Compute the absolute value of 16- bit integers in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 1E /r VPABSD <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Compute the absolute value of 32- bit integers in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.WIG 1C /r VPABSB <em>ymm1, ymm2/m256</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compute the absolute value of bytes in <em>ymm2/m256</em> and store UNSIGNED result in <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.WIG 1D /r VPABSW <em>ymm1, ymm2/m256</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compute the absolute value of 16-bit integers in <em>ymm2/m256</em> and store UNSIGNED result in <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.WIG 1E /r VPABSD <em>ymm1, ymm2/m256</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compute the absolute value of 32-bit integers in <em>ymm2/m256</em> and store UNSIGNED result in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F38.WIG 1C /r VPABSB xmm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 1C /r VPABSB ymm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute the absolute value of bytes in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 1C /r VPABSB zmm1 {k1}{z}, zmm2/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compute the absolute value of bytes in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.WIG 1D /r VPABSW xmm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 1D /r VPABSW ymm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute the absolute value of 16-bit integers in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 1D /r VPABSW zmm1 {k1}{z}, zmm2/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compute the absolute value of 16-bit integers in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 1E /r VPABSD xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compute the absolute value of 32-bit integers in xmm2/m128/m32bcst and store UNSIGNED result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 1E /r VPABSD ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compute the absolute value of 32-bit integers in ymm2/m256/m32bcst and store UNSIGNED result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 1E /r VPABSD zmm1 {k1}{z}, zmm2/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compute the absolute value of 32-bit integers in zmm2/m512/m32bcst and store UNSIGNED result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 1F /r VPABSQ xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compute the absolute value of 64-bit integers in xmm2/m128/m64bcst and store UNSIGNED result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 1F /r VPABSQ ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compute the absolute value of 64-bit integers in ymm2/m256/m64bcst and store UNSIGNED result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 1F /r VPABSQ zmm1 {k1}{z}, zmm2/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compute the absolute value of 64-bit integers in zmm2/m512/m64bcst and store UNSIGNED result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>NP 0F 38 1C /r<sup>1</sup> PABSB <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of bytes in <em>mm2/m64</em> and store UNSIGNED result in <em>mm1</em>.</td>, <td>66 0F 38 1C /r PABSB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of bytes in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>NP 0F 38 1D /r<sup>1</sup> PABSW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of 16-bit integers in <em>mm2/m64</em> and store UNSIGNED result in <em>mm1</em>.</td>, <td>66 0F 38 1D /r PABSW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of 16-bit integers in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>NP 0F 38 1E /r<sup>1</sup> PABSD <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of 32-bit integers in <em>mm2/m64</em> and store UNSIGNED result in <em>mm1</em>.</td>, <td>66 0F 38 1E /r PABSD <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Compute the absolute value of 32-bit integers in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1.</em></td>, <td>VEX.128.66.0F38.WIG 1C /r VPABSB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Compute the absolute value of bytes in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 1D /r VPABSW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Compute the absolute value of 16- bit integers in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 1E /r VPABSD <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Compute the absolute value of 32- bit integers in <em>xmm2/m128</em> and store UNSIGNED result in <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.WIG 1C /r VPABSB <em>ymm1, ymm2/m256</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compute the absolute value of bytes in <em>ymm2/m256</em> and store UNSIGNED result in <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.WIG 1D /r VPABSW <em>ymm1, ymm2/m256</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compute the absolute value of 16-bit integers in <em>ymm2/m256</em> and store UNSIGNED result in <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.WIG 1E /r VPABSD <em>ymm1, ymm2/m256</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compute the absolute value of 32-bit integers in <em>ymm2/m256</em> and store UNSIGNED result in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F38.WIG 1C /r VPABSB xmm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 1C /r VPABSB ymm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute the absolute value of bytes in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 1C /r VPABSB zmm1 {k1}{z}, zmm2/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compute the absolute value of bytes in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.WIG 1D /r VPABSW xmm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 1D /r VPABSW ymm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute the absolute value of 16-bit integers in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 1D /r VPABSW zmm1 {k1}{z}, zmm2/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compute the absolute value of 16-bit integers in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 1E /r VPABSD xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compute the absolute value of 32-bit integers in xmm2/m128/m32bcst and store UNSIGNED result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 1E /r VPABSD ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compute the absolute value of 32-bit integers in ymm2/m256/m32bcst and store UNSIGNED result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 1E /r VPABSD zmm1 {k1}{z}, zmm2/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compute the absolute value of 32-bit integers in zmm2/m512/m32bcst and store UNSIGNED result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 1F /r VPABSQ xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compute the absolute value of 64-bit integers in xmm2/m128/m64bcst and store UNSIGNED result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 1F /r VPABSQ ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compute the absolute value of 64-bit integers in ymm2/m256/m64bcst and store UNSIGNED result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 1F /r VPABSQ zmm1 {k1}{z}, zmm2/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compute the absolute value of 64-bit integers in zmm2/m512/m64bcst and store UNSIGNED result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>NP 0F 63 /r<sup>1</sup> PACKSSWB <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Converts 4 packed signed word integers from <em>mm1</em> and from <em>mm2/m64</em> into 8 packed signed byte integers in <em>mm1</em> using signed saturation<em>.</em></td>, <td>66 0F 63 /<em>r</em> PACKSSWB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Converts 8 packed signed word integers from <em>xmm1</em> and from <em>xxm2/m128</em> into 16 packed signed byte integers in <em>xxm1</em> using signed saturation.</td>, <td>NP 0F 6B /<em>r</em><sup>1</sup> PACKSSDW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Converts 2 packed signed doubleword integers from <em>mm1</em> and from <em>mm2/m64</em> into 4 packed signed word integers in <em>mm1</em> using signed saturation.</td>, <td>66 0F 6B /<em>r</em> PACKSSDW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Converts 4 packed signed doubleword integers from <em>xmm1</em> and from <em>xxm2/m128</em> into 8 packed signed word integers in <em>xxm1</em> using signed saturation.</td>, <td>VEX.128.66.0F.WIG 63 /r VPACKSSWB <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Converts 8 packed signed word integers from <em>xmm2</em> and from <em>xmm3/m128</em> into 16 packed signed byte integers in <em>xmm1</em> using signed saturation.</td>, <td>VEX.128.66.0F.WIG 6B /r VPACKSSDW <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Converts 4 packed signed doubleword integers from <em>xmm2</em> and from <em>xmm3/m128</em> into 8 packed signed word integers in <em>xmm1</em> using signed saturation.</td>, <td>VEX.256.66.0F.WIG 63 /r VPACKSSWB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Converts 16 packed signed word integers from <em>ymm2</em> and from <em>ymm3/m256</em> into 32 packed signed byte integers in <em>ymm1</em> using signed saturation.</td>, <td>VEX.256.66.0F.WIG 6B /r VPACKSSDW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Converts 8 packed signed doubleword integers from <em>ymm2</em> and from <em>ymm3/m256</em> into 16 packed signed word integers in <em>ymm1</em>using signed saturation.</td>, <td>EVEX.128.66.0F.WIG 63 /<em>r</em> VPACKSSWB <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts packed signed word integers from <em>xmm2</em> and from <em>xmm3/m128</em> into packed signed byte integers in <em>xmm1</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.66.0F.WIG 63 /<em>r</em> VPACKSSWB <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts packed signed word integers from <em>ymm2</em> and from <em>ymm3/m256</em> into packed signed byte integers in <em>ymm1</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.66.0F.WIG 63 /<em>r</em> VPACKSSWB <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Converts packed signed word integers from <em>zmm2</em> and from <em>zmm3/m512</em> into packed signed byte integers in <em>zmm1</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.66.0F.W0 6B /<em>r</em> VPACKSSDW xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts packed signed doubleword integers from <em>xmm2</em> and from xmm3/m128/m32bcst into packed signed word integers in xmm1 using signed saturation under writemask k1.</td>, <td>EVEX.256.66.0F.W0 6B /r VPACKSSDW ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts packed signed doubleword integers from <em>ymm2</em> and from ymm3/m256/m32bcst into packed signed word integers in ymm1 using signed saturation under writemask k1.</td>, <td>EVEX.512.66.0F.W0 6B /r VPACKSSDW zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Converts packed signed doubleword integers from zmm2 and from zmm3/m512/m32bcst into packed signed word integers in zmm1 using signed saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 63 /r<sup>1</sup> PACKSSWB <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Converts 4 packed signed word integers from <em>mm1</em> and from <em>mm2/m64</em> into 8 packed signed byte integers in <em>mm1</em> using signed saturation<em>.</em></td>, <td>66 0F 63 /<em>r</em> PACKSSWB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Converts 8 packed signed word integers from <em>xmm1</em> and from <em>xxm2/m128</em> into 16 packed signed byte integers in <em>xxm1</em> using signed saturation.</td>, <td>NP 0F 6B /<em>r</em><sup>1</sup> PACKSSDW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Converts 2 packed signed doubleword integers from <em>mm1</em> and from <em>mm2/m64</em> into 4 packed signed word integers in <em>mm1</em> using signed saturation.</td>, <td>66 0F 6B /<em>r</em> PACKSSDW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Converts 4 packed signed doubleword integers from <em>xmm1</em> and from <em>xxm2/m128</em> into 8 packed signed word integers in <em>xxm1</em> using signed saturation.</td>, <td>VEX.128.66.0F.WIG 63 /r VPACKSSWB <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Converts 8 packed signed word integers from <em>xmm2</em> and from <em>xmm3/m128</em> into 16 packed signed byte integers in <em>xmm1</em> using signed saturation.</td>, <td>VEX.128.66.0F.WIG 6B /r VPACKSSDW <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Converts 4 packed signed doubleword integers from <em>xmm2</em> and from <em>xmm3/m128</em> into 8 packed signed word integers in <em>xmm1</em> using signed saturation.</td>, <td>VEX.256.66.0F.WIG 63 /r VPACKSSWB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Converts 16 packed signed word integers from <em>ymm2</em> and from <em>ymm3/m256</em> into 32 packed signed byte integers in <em>ymm1</em> using signed saturation.</td>, <td>VEX.256.66.0F.WIG 6B /r VPACKSSDW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Converts 8 packed signed doubleword integers from <em>ymm2</em> and from <em>ymm3/m256</em> into 16 packed signed word integers in <em>ymm1</em>using signed saturation.</td>, <td>EVEX.128.66.0F.WIG 63 /<em>r</em> VPACKSSWB <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts packed signed word integers from <em>xmm2</em> and from <em>xmm3/m128</em> into packed signed byte integers in <em>xmm1</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.66.0F.WIG 63 /<em>r</em> VPACKSSWB <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts packed signed word integers from <em>ymm2</em> and from <em>ymm3/m256</em> into packed signed byte integers in <em>ymm1</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.66.0F.WIG 63 /<em>r</em> VPACKSSWB <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Converts packed signed word integers from <em>zmm2</em> and from <em>zmm3/m512</em> into packed signed byte integers in <em>zmm1</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.66.0F.W0 6B /<em>r</em> VPACKSSDW xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts packed signed doubleword integers from <em>xmm2</em> and from xmm3/m128/m32bcst into packed signed word integers in xmm1 using signed saturation under writemask k1.</td>, <td>EVEX.256.66.0F.W0 6B /r VPACKSSDW ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts packed signed doubleword integers from <em>ymm2</em> and from ymm3/m256/m32bcst into packed signed word integers in ymm1 using signed saturation under writemask k1.</td>, <td>EVEX.512.66.0F.W0 6B /r VPACKSSDW zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Converts packed signed doubleword integers from zmm2 and from zmm3/m512/m32bcst into packed signed word integers in zmm1 using signed saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 38 2B /r PACKUSDW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Convert 4 packed signed doubleword integers from <em>xmm1</em> and 4 packed signed doubleword integers from <em>xmm2/m128</em> into 8 packed unsigned word integers in <em>xmm1</em> using unsigned saturation.</td>, <td>VEX.128.66.0F38 2B /r VPACKUSDW <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Convert 4 packed signed doubleword integers from <em>xmm2</em> and 4 packed signed doubleword integers from <em>xmm3/m128</em> into 8 packed unsigned word integers in <em>xmm1</em> using unsigned saturation.</td>, <td>VEX.256.66.0F38 2B /r VPACKUSDW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Convert 8 packed signed doubleword integers from <em>ymm2</em> and 8 packed signed doubleword integers from <em>ymm3/m256</em> into 16 packed unsigned word integers in <em>ymm1</em> using unsigned saturation.</td>, <td>EVEX.128.66.0F38.W0 2B /r VPACKUSDW <em>xmm1{k1}{z}, xmm2, xmm3/m128/m32bcst</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Convert packed signed doubleword integers from xmm2 and packed signed doubleword integers from xmm3/m128/m32bcst into packed unsigned word integers in xmm1 using unsigned saturation under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 2B /r VPACKUSDW <em>ymm1{k1}{z}, ymm2, ymm3/m256/m32bcst</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Convert packed signed doubleword integers from ymm2 and packed signed doubleword integers from ymm3/m256/m32bcst into packed unsigned word integers in ymm1 using unsigned saturation under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 2B /r VPACKUSDW <em>zmm1{k1}{z}, zmm2, zmm3/m512/m32bcst</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Convert packed signed doubleword integers from <em>zmm2</em> and packed signed doubleword integers from <em>zmm3/m512/m32bcst</em> into packed unsigned word integers in <em>zmm1</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 67 /<em>r</em><sup>1</sup> PACKUSWB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Converts 4 signed word integers from <em>mm</em> and 4 signed word integers from <em>mm/m64</em> into 8 unsigned byte integers in <em>mm</em> using unsigned saturation.</td>, <td>66 0F 67 /<em>r</em> PACKUSWB <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Converts 8 signed word integers from <em>xmm1</em> and 8 signed word integers from <em>xmm2/m128</em> into 16 unsigned byte integers in <em>xmm1</em> using unsigned saturation.</td>, <td>VEX.128.66.0F.WIG 67 /r VPACKUSWB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Converts 8 signed word integers from <em>xmm2</em> and 8 signed word integers from <em>xmm3/m128</em> into 16 unsigned byte integers in <em>xmm1</em> using unsigned saturation.</td>, <td>VEX.256.66.0F.WIG 67 /r VPACKUSWB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Converts 16 signed word integers from <em>ymm2</em> and 16signed word integers from <em>ymm3/m256</em> into 32 unsigned byte integers in <em>ymm1</em> using unsigned saturation.</td>, <td>EVEX.128.66.0F.WIG 67 /r VPACKUSWB <em>xmm1{k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts signed word integers from <em>xmm2</em> and signed word integers from <em>xmm3/m128</em> into unsigned byte integers in <em>xmm1</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.256.66.0F.WIG 67 /r VPACKUSWB <em>ymm1{k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts signed word integers from <em>ymm2</em> and signed word integers from <em>ymm3/m256</em> into unsigned byte integers in <em>ymm1</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.512.66.0F.WIG 67 /r VPACKUSWB <em>zmm1{k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Converts signed word integers from <em>zmm2</em> and signed word integers from <em>zmm3/m512</em> into unsigned byte integers in <em>zmm1</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F FC /<em>r</em><sup>1</sup> PADDB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed byte integers from <em>mm/m64</em> and <em>mm</em>.</td>, <td>NP 0F FD /<em>r</em><sup>1</sup> PADDW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed word integers from <em>mm/m64</em> and <em>mm</em>.</td>, <td>NP 0F FE /<em>r</em><sup>1</sup> PADDD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed doubleword integers from <em>mm/m64</em> and <em>mm</em>.</td>, <td>NP 0F D4 /<em>r</em><sup>1</sup> PADDQ <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed quadword integers from <em>mm/m64</em> and <em>mm</em>.</td>, <td>66 0F FC /<em>r</em> PADDB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed byte integers from <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>66 0F FD /<em>r</em> PADDW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed word integers from <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>66 0F FE /<em>r</em> PADDD <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed doubleword integers from <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>66 0F D4 /<em>r</em> PADDQ <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed quadword integers from <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG FC /<em>r</em> VPADDB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed byte integers from <em>xmm2, and xmm3/m128</em> and store in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG FD /<em>r</em> VPADDW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed word integers from <em>xmm2, xmm3/m128</em> and <em>store in xmm1</em>.</td>, <td>VEX.128.66.0F.WIG FE /<em>r</em> VPADDD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed doubleword integers from <em>xmm2, xmm3/m128</em> and store in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG D4 /<em>r</em> VPADDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed quadword integers from <em>xmm2, xmm3/m128</em> and store in <em>xmm1</em>.</td>, <td>VEX.256.66.0F.WIG FC /<em>r</em> VPADDB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed byte integers from <em>ymm2, and ymm3/m256</em> and store in <em>ymm1</em>.</td>, <td>VEX.256.66.0F.WIG FD /<em>r</em> VPADDW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed word integers from <em>ymm2, ymm3/m256</em> and <em>store in ymm1</em>.</td>, <td>VEX.256.66.0F.WIG FE /<em>r</em> VPADDD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed doubleword integers from <em>ymm2, ymm3/m256</em> and <em>store in ymm1</em>.</td>, <td>VEX.256.66.0F.WIG D4 /<em>r</em> VPADDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed quadword integers from <em>ymm2, ymm3/m256</em> and store in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.WIG FC /r VPADDB <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed byte integers from <em>xmm2, and xmm3/m128</em> and store in <em>xmm1</em> using writemask k1.</td>, <td>EVEX.128.66.0F.WIG FD /r VPADDW <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed word integers from <em>xmm2, and xmm3/m128</em> and store in <em>xmm1</em> using writemask k1.</td>, <td>EVEX.128.66.0F.W0 FE /r VPADDD <em>xmm1 {k1}{z}, xmm2,</em> xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed doubleword integers from <em>xmm2, and xmm3/m128/m32bcst</em> and store in <em>xmm1</em> using writemask k1.</td>, <td>EVEX.128.66.0F.W1 D4 /r VPADDQ <em>xmm1 {k1}{z}, xmm2,</em> xmm3/m128/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed quadword integers from <em>xmm2, and xmm3/m128/m64bcst</em> and store in <em>xmm1</em> using writemask k1.</td>, <td>EVEX.256.66.0F.WIG FC /r VPADDB <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed byte integers from <em>ymm2, and ymm3/m256</em> and store in <em>ymm1</em> using writemask k1.</td>, <td>EVEX.256.66.0F.WIG FD /r VPADDW <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed word integers from <em>ymm2, and ymm3/m256</em> and store in <em>ymm1</em> using writemask k1.</td>, <td>EVEX.256.66.0F.W0 FE /r VPADDD <em>ymm1 {k1}{z}, ymm2,</em> ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed doubleword integers from <em>ymm2, ymm3/m256/m32bcst</em> and store in <em>ymm1</em> using writemask k1.</td>, <td>EVEX.256.66.0F.W1 D4 /r VPADDQ <em>ymm1 {k1}{z}, ymm2,</em> ymm3/m256/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed quadword integers from <em>ymm2, ymm3/m256/m64bcst</em> and store in <em>ymm1</em> using writemask k1.</td>, <td>EVEX.512.66.0F.WIG FC /r VPADDB <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add packed byte integers from <em>zmm2, and zmm3/m512</em> and store in <em>zmm1</em> using writemask k1.</td>, <td>EVEX.512.66.0F.WIG FD /r VPADDW <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add packed word integers from <em>zmm2, and zmm3/m512</em> and store in <em>zmm1</em> using writemask k1.</td>, <td>EVEX.512.66.0F.W0 FE /<em>r</em> VPADDD <em>zmm1 {k1}{z}, zmm2,</em> zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Add packed doubleword integers from <em>zmm2, zmm3/m512/m32bcst</em> and store in <em>zmm1</em> using writemask k1.</td>, <td>EVEX.512.66.0F.W1 D4 /<em>r</em> VPADDQ <em>zmm1 {k1}{z}, zmm2,</em> zmm3/m512/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Add packed quadword integers from <em>zmm2, zmm3/m512/m64bcst</em> and store in <em>zmm1</em> using writemask k1.</td>, <td colspan="5">NOTES: 1. See note in Section 2.4, “AVX and SSE Instruction Exception Specification” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 2A</em> and Section 22.25.3, “Exception Conditions of Legacy SIMD Instructions Operating on MMX Registers” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 3A</em>.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F FC /<em>r</em><sup>1</sup> PADDB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed byte integers from <em>mm/m64</em> and <em>mm</em>.</td>, <td>NP 0F FD /<em>r</em><sup>1</sup> PADDW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed word integers from <em>mm/m64</em> and <em>mm</em>.</td>, <td>NP 0F FE /<em>r</em><sup>1</sup> PADDD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed doubleword integers from <em>mm/m64</em> and <em>mm</em>.</td>, <td>NP 0F D4 /<em>r</em><sup>1</sup> PADDQ <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed quadword integers from <em>mm/m64</em> and <em>mm</em>.</td>, <td>66 0F FC /<em>r</em> PADDB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed byte integers from <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>66 0F FD /<em>r</em> PADDW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed word integers from <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>66 0F FE /<em>r</em> PADDD <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed doubleword integers from <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>66 0F D4 /<em>r</em> PADDQ <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed quadword integers from <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG FC /<em>r</em> VPADDB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed byte integers from <em>xmm2, and xmm3/m128</em> and store in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG FD /<em>r</em> VPADDW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed word integers from <em>xmm2, xmm3/m128</em> and <em>store in xmm1</em>.</td>, <td>VEX.128.66.0F.WIG FE /<em>r</em> VPADDD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed doubleword integers from <em>xmm2, xmm3/m128</em> and store in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG D4 /<em>r</em> VPADDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed quadword integers from <em>xmm2, xmm3/m128</em> and store in <em>xmm1</em>.</td>, <td>VEX.256.66.0F.WIG FC /<em>r</em> VPADDB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed byte integers from <em>ymm2, and ymm3/m256</em> and store in <em>ymm1</em>.</td>, <td>VEX.256.66.0F.WIG FD /<em>r</em> VPADDW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed word integers from <em>ymm2, ymm3/m256</em> and <em>store in ymm1</em>.</td>, <td>VEX.256.66.0F.WIG FE /<em>r</em> VPADDD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed doubleword integers from <em>ymm2, ymm3/m256</em> and <em>store in ymm1</em>.</td>, <td>VEX.256.66.0F.WIG D4 /<em>r</em> VPADDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed quadword integers from <em>ymm2, ymm3/m256</em> and store in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.WIG FC /r VPADDB <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed byte integers from <em>xmm2, and xmm3/m128</em> and store in <em>xmm1</em> using writemask k1.</td>, <td>EVEX.128.66.0F.WIG FD /r VPADDW <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed word integers from <em>xmm2, and xmm3/m128</em> and store in <em>xmm1</em> using writemask k1.</td>, <td>EVEX.128.66.0F.W0 FE /r VPADDD <em>xmm1 {k1}{z}, xmm2,</em> xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed doubleword integers from <em>xmm2, and xmm3/m128/m32bcst</em> and store in <em>xmm1</em> using writemask k1.</td>, <td>EVEX.128.66.0F.W1 D4 /r VPADDQ <em>xmm1 {k1}{z}, xmm2,</em> xmm3/m128/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed quadword integers from <em>xmm2, and xmm3/m128/m64bcst</em> and store in <em>xmm1</em> using writemask k1.</td>, <td>EVEX.256.66.0F.WIG FC /r VPADDB <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed byte integers from <em>ymm2, and ymm3/m256</em> and store in <em>ymm1</em> using writemask k1.</td>, <td>EVEX.256.66.0F.WIG FD /r VPADDW <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed word integers from <em>ymm2, and ymm3/m256</em> and store in <em>ymm1</em> using writemask k1.</td>, <td>EVEX.256.66.0F.W0 FE /r VPADDD <em>ymm1 {k1}{z}, ymm2,</em> ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed doubleword integers from <em>ymm2, ymm3/m256/m32bcst</em> and store in <em>ymm1</em> using writemask k1.</td>, <td>EVEX.256.66.0F.W1 D4 /r VPADDQ <em>ymm1 {k1}{z}, ymm2,</em> ymm3/m256/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed quadword integers from <em>ymm2, ymm3/m256/m64bcst</em> and store in <em>ymm1</em> using writemask k1.</td>, <td>EVEX.512.66.0F.WIG FC /r VPADDB <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add packed byte integers from <em>zmm2, and zmm3/m512</em> and store in <em>zmm1</em> using writemask k1.</td>, <td>EVEX.512.66.0F.WIG FD /r VPADDW <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add packed word integers from <em>zmm2, and zmm3/m512</em> and store in <em>zmm1</em> using writemask k1.</td>, <td>EVEX.512.66.0F.W0 FE /<em>r</em> VPADDD <em>zmm1 {k1}{z}, zmm2,</em> zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Add packed doubleword integers from <em>zmm2, zmm3/m512/m32bcst</em> and store in <em>zmm1</em> using writemask k1.</td>, <td>EVEX.512.66.0F.W1 D4 /<em>r</em> VPADDQ <em>zmm1 {k1}{z}, zmm2,</em> zmm3/m512/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Add packed quadword integers from <em>zmm2, zmm3/m512/m64bcst</em> and store in <em>zmm1</em> using writemask k1.</td>, <td colspan="5">NOTES: 1. See note in Section 2.4, “AVX and SSE Instruction Exception Specification” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 2A</em> and Section 22.25.3, “Exception Conditions of Legacy SIMD Instructions Operating on MMX Registers” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 3A</em>.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F FC /<em>r</em><sup>1</sup> PADDB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed byte integers from <em>mm/m64</em> and <em>mm</em>.</td>, <td>NP 0F FD /<em>r</em><sup>1</sup> PADDW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed word integers from <em>mm/m64</em> and <em>mm</em>.</td>, <td>NP 0F FE /<em>r</em><sup>1</sup> PADDD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed doubleword integers from <em>mm/m64</em> and <em>mm</em>.</td>, <td>NP 0F D4 /<em>r</em><sup>1</sup> PADDQ <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed quadword integers from <em>mm/m64</em> and <em>mm</em>.</td>, <td>66 0F FC /<em>r</em> PADDB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed byte integers from <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>66 0F FD /<em>r</em> PADDW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed word integers from <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>66 0F FE /<em>r</em> PADDD <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed doubleword integers from <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>66 0F D4 /<em>r</em> PADDQ <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed quadword integers from <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG FC /<em>r</em> VPADDB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed byte integers from <em>xmm2, and xmm3/m128</em> and store in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG FD /<em>r</em> VPADDW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed word integers from <em>xmm2, xmm3/m128</em> and <em>store in xmm1</em>.</td>, <td>VEX.128.66.0F.WIG FE /<em>r</em> VPADDD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed doubleword integers from <em>xmm2, xmm3/m128</em> and store in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG D4 /<em>r</em> VPADDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed quadword integers from <em>xmm2, xmm3/m128</em> and store in <em>xmm1</em>.</td>, <td>VEX.256.66.0F.WIG FC /<em>r</em> VPADDB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed byte integers from <em>ymm2, and ymm3/m256</em> and store in <em>ymm1</em>.</td>, <td>VEX.256.66.0F.WIG FD /<em>r</em> VPADDW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed word integers from <em>ymm2, ymm3/m256</em> and <em>store in ymm1</em>.</td>, <td>VEX.256.66.0F.WIG FE /<em>r</em> VPADDD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed doubleword integers from <em>ymm2, ymm3/m256</em> and <em>store in ymm1</em>.</td>, <td>VEX.256.66.0F.WIG D4 /<em>r</em> VPADDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed quadword integers from <em>ymm2, ymm3/m256</em> and store in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.WIG FC /r VPADDB <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed byte integers from <em>xmm2, and xmm3/m128</em> and store in <em>xmm1</em> using writemask k1.</td>, <td>EVEX.128.66.0F.WIG FD /r VPADDW <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed word integers from <em>xmm2, and xmm3/m128</em> and store in <em>xmm1</em> using writemask k1.</td>, <td>EVEX.128.66.0F.W0 FE /r VPADDD <em>xmm1 {k1}{z}, xmm2,</em> xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed doubleword integers from <em>xmm2, and xmm3/m128/m32bcst</em> and store in <em>xmm1</em> using writemask k1.</td>, <td>EVEX.128.66.0F.W1 D4 /r VPADDQ <em>xmm1 {k1}{z}, xmm2,</em> xmm3/m128/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed quadword integers from <em>xmm2, and xmm3/m128/m64bcst</em> and store in <em>xmm1</em> using writemask k1.</td>, <td>EVEX.256.66.0F.WIG FC /r VPADDB <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed byte integers from <em>ymm2, and ymm3/m256</em> and store in <em>ymm1</em> using writemask k1.</td>, <td>EVEX.256.66.0F.WIG FD /r VPADDW <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed word integers from <em>ymm2, and ymm3/m256</em> and store in <em>ymm1</em> using writemask k1.</td>, <td>EVEX.256.66.0F.W0 FE /r VPADDD <em>ymm1 {k1}{z}, ymm2,</em> ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed doubleword integers from <em>ymm2, ymm3/m256/m32bcst</em> and store in <em>ymm1</em> using writemask k1.</td>, <td>EVEX.256.66.0F.W1 D4 /r VPADDQ <em>ymm1 {k1}{z}, ymm2,</em> ymm3/m256/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed quadword integers from <em>ymm2, ymm3/m256/m64bcst</em> and store in <em>ymm1</em> using writemask k1.</td>, <td>EVEX.512.66.0F.WIG FC /r VPADDB <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add packed byte integers from <em>zmm2, and zmm3/m512</em> and store in <em>zmm1</em> using writemask k1.</td>, <td>EVEX.512.66.0F.WIG FD /r VPADDW <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add packed word integers from <em>zmm2, and zmm3/m512</em> and store in <em>zmm1</em> using writemask k1.</td>, <td>EVEX.512.66.0F.W0 FE /<em>r</em> VPADDD <em>zmm1 {k1}{z}, zmm2,</em> zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Add packed doubleword integers from <em>zmm2, zmm3/m512/m32bcst</em> and store in <em>zmm1</em> using writemask k1.</td>, <td>EVEX.512.66.0F.W1 D4 /<em>r</em> VPADDQ <em>zmm1 {k1}{z}, zmm2,</em> zmm3/m512/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Add packed quadword integers from <em>zmm2, zmm3/m512/m64bcst</em> and store in <em>zmm1</em> using writemask k1.</td>, <td colspan="5">NOTES: 1. See note in Section 2.4, “AVX and SSE Instruction Exception Specification” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 2A</em> and Section 22.25.3, “Exception Conditions of Legacy SIMD Instructions Operating on MMX Registers” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 3A</em>.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F EC /<em>r</em><sup>1</sup> PADDSB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed signed byte integers from <em>mm/m64 and mm</em> and saturate the results.</td>, <td>66 0F EC /<em>r</em> PADDSB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed signed byte integers from <em>xmm2/m128</em> and <em>xmm1</em> saturate the results.</td>, <td>NP 0F ED /<em>r</em><sup>1</sup> PADDSW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed signed word integers from <em>mm/m64 and mm</em> and saturate the results.</td>, <td>66 0F ED /<em>r</em> PADDSW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed signed word integers from <em>xmm2/m128</em> and <em>xmm1</em> and saturate the results.</td>, <td>VEX.128.66.0F.WIG EC /r VPADDSB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed signed byte integers from <em>xmm3/m128</em> and <em>xmm2</em> saturate the results.</td>, <td>VEX.128.66.0F.WIG ED /r VPADDSW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed signed word integers from <em>xmm3/m128</em> and <em>xmm2</em> and saturate the results.</td>, <td>VEX.256.66.0F.WIG EC /r VPADDSB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed signed byte integers from ymm2, and <em>ymm3/m256</em> and store the saturated results in <em>ymm1</em>.</td>, <td>VEX.256.66.0F.WIG ED /r VPADDSW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed signed word integers from ymm2, and <em>ymm3/m256</em> and store the saturated results in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.WIG EC /r VPADDSB <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed signed byte integers from xmm2, and <em>xmm3/m128</em> and store the saturated results in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG EC /r VPADDSB <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed signed byte integers from ymm2, and <em>ymm3/m256</em> and store the saturated results in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG EC /r VPADDSB <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add packed signed byte integers from zmm2, and <em>zmm3/m512</em> and store the saturated results in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.WIG ED /r VPADDSW <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed signed word integers from xmm2, and <em>xmm3/m128</em> and store the saturated results in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG ED /r VPADDSW <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed signed word integers from ymm2, and <em>ymm3/m256</em> and store the saturated results in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG ED /r VPADDSW <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add packed signed word integers from zmm2, and <em>zmm3/m512</em> and store the saturated results in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F EC /<em>r</em><sup>1</sup> PADDSB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed signed byte integers from <em>mm/m64 and mm</em> and saturate the results.</td>, <td>66 0F EC /<em>r</em> PADDSB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed signed byte integers from <em>xmm2/m128</em> and <em>xmm1</em> saturate the results.</td>, <td>NP 0F ED /<em>r</em><sup>1</sup> PADDSW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed signed word integers from <em>mm/m64 and mm</em> and saturate the results.</td>, <td>66 0F ED /<em>r</em> PADDSW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed signed word integers from <em>xmm2/m128</em> and <em>xmm1</em> and saturate the results.</td>, <td>VEX.128.66.0F.WIG EC /r VPADDSB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed signed byte integers from <em>xmm3/m128</em> and <em>xmm2</em> saturate the results.</td>, <td>VEX.128.66.0F.WIG ED /r VPADDSW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed signed word integers from <em>xmm3/m128</em> and <em>xmm2</em> and saturate the results.</td>, <td>VEX.256.66.0F.WIG EC /r VPADDSB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed signed byte integers from ymm2, and <em>ymm3/m256</em> and store the saturated results in <em>ymm1</em>.</td>, <td>VEX.256.66.0F.WIG ED /r VPADDSW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed signed word integers from ymm2, and <em>ymm3/m256</em> and store the saturated results in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.WIG EC /r VPADDSB <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed signed byte integers from xmm2, and <em>xmm3/m128</em> and store the saturated results in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG EC /r VPADDSB <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed signed byte integers from ymm2, and <em>ymm3/m256</em> and store the saturated results in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG EC /r VPADDSB <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add packed signed byte integers from zmm2, and <em>zmm3/m512</em> and store the saturated results in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.WIG ED /r VPADDSW <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed signed word integers from xmm2, and <em>xmm3/m128</em> and store the saturated results in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG ED /r VPADDSW <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed signed word integers from ymm2, and <em>ymm3/m256</em> and store the saturated results in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG ED /r VPADDSW <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add packed signed word integers from zmm2, and <em>zmm3/m512</em> and store the saturated results in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F DC /<em>r</em><sup>1</sup> PADDUSB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed unsigned byte integers from <em>mm/m64 and mm</em> and saturate the results.</td>, <td>66 0F DC /<em>r</em> PADDUSB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed unsigned byte integers from <em>xmm2/m128</em> and <em>xmm1</em> saturate the results.</td>, <td>NP 0F DD /<em>r</em><sup>1</sup> PADDUSW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed unsigned word integers from <em>mm/m64 and mm</em> and saturate the results.</td>, <td>66 0F DD /<em>r</em> PADDUSW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed unsigned word integers from <em>xmm2/m128</em> to <em>xmm1</em> and saturate the results.</td>, <td>VEX.128.660F.WIG DC /r VPADDUSB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed unsigned byte integers from <em>xmm3/m128</em> to <em>xmm2</em> and saturate the results.</td>, <td>VEX.128.66.0F.WIG DD /r VPADDUSW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed unsigned word integers from <em>xmm3/m128</em> to <em>xmm2</em> and saturate the results.</td>, <td>VEX.256.66.0F.WIG DC /r VPADDUSB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed unsigned byte integers from <em>ymm2</em>, and <em>ymm3/m256</em> and store the saturated results in <em>ymm1</em>.</td>, <td>VEX.256.66.0F.WIG DD /r VPADDUSW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed unsigned word integers from <em>ymm2</em>, and <em>ymm3/m256</em> and store the saturated results in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.WIG DC /r VPADDUSB <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed unsigned byte integers from xmm2, and <em>xmm3/m128</em> and store the saturated results in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG DC /r VPADDUSB <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed unsigned byte integers from ymm2, and <em>ymm3/m256</em> and store the saturated results in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG DC /r VPADDUSB <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add packed unsigned byte integers from zmm2, and <em>zmm3/m512</em> and store the saturated results in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.WIG DD /r VPADDUSW <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed unsigned word integers from xmm2, and <em>xmm3/m128</em> and store the saturated results in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG DD /r VPADDUSW <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed unsigned word integers from ymm2, and <em>ymm3/m256</em> and store the saturated results in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG DD /r VPADDUSW <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add packed unsigned word integers from zmm2, and <em>zmm3/m512</em> and store the saturated results in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F DC /<em>r</em><sup>1</sup> PADDUSB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed unsigned byte integers from <em>mm/m64 and mm</em> and saturate the results.</td>, <td>66 0F DC /<em>r</em> PADDUSB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed unsigned byte integers from <em>xmm2/m128</em> and <em>xmm1</em> saturate the results.</td>, <td>NP 0F DD /<em>r</em><sup>1</sup> PADDUSW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed unsigned word integers from <em>mm/m64 and mm</em> and saturate the results.</td>, <td>66 0F DD /<em>r</em> PADDUSW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed unsigned word integers from <em>xmm2/m128</em> to <em>xmm1</em> and saturate the results.</td>, <td>VEX.128.660F.WIG DC /r VPADDUSB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed unsigned byte integers from <em>xmm3/m128</em> to <em>xmm2</em> and saturate the results.</td>, <td>VEX.128.66.0F.WIG DD /r VPADDUSW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed unsigned word integers from <em>xmm3/m128</em> to <em>xmm2</em> and saturate the results.</td>, <td>VEX.256.66.0F.WIG DC /r VPADDUSB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed unsigned byte integers from <em>ymm2</em>, and <em>ymm3/m256</em> and store the saturated results in <em>ymm1</em>.</td>, <td>VEX.256.66.0F.WIG DD /r VPADDUSW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed unsigned word integers from <em>ymm2</em>, and <em>ymm3/m256</em> and store the saturated results in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.WIG DC /r VPADDUSB <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed unsigned byte integers from xmm2, and <em>xmm3/m128</em> and store the saturated results in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG DC /r VPADDUSB <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed unsigned byte integers from ymm2, and <em>ymm3/m256</em> and store the saturated results in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG DC /r VPADDUSB <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add packed unsigned byte integers from zmm2, and <em>zmm3/m512</em> and store the saturated results in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.WIG DD /r VPADDUSW <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed unsigned word integers from xmm2, and <em>xmm3/m128</em> and store the saturated results in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG DD /r VPADDUSW <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed unsigned word integers from ymm2, and <em>ymm3/m256</em> and store the saturated results in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG DD /r VPADDUSW <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add packed unsigned word integers from zmm2, and <em>zmm3/m512</em> and store the saturated results in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F FC /<em>r</em><sup>1</sup> PADDB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed byte integers from <em>mm/m64</em> and <em>mm</em>.</td>, <td>NP 0F FD /<em>r</em><sup>1</sup> PADDW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed word integers from <em>mm/m64</em> and <em>mm</em>.</td>, <td>NP 0F FE /<em>r</em><sup>1</sup> PADDD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed doubleword integers from <em>mm/m64</em> and <em>mm</em>.</td>, <td>NP 0F D4 /<em>r</em><sup>1</sup> PADDQ <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Add packed quadword integers from <em>mm/m64</em> and <em>mm</em>.</td>, <td>66 0F FC /<em>r</em> PADDB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed byte integers from <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>66 0F FD /<em>r</em> PADDW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed word integers from <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>66 0F FE /<em>r</em> PADDD <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed doubleword integers from <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>66 0F D4 /<em>r</em> PADDQ <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Add packed quadword integers from <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG FC /<em>r</em> VPADDB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed byte integers from <em>xmm2, and xmm3/m128</em> and store in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG FD /<em>r</em> VPADDW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed word integers from <em>xmm2, xmm3/m128</em> and <em>store in xmm1</em>.</td>, <td>VEX.128.66.0F.WIG FE /<em>r</em> VPADDD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed doubleword integers from <em>xmm2, xmm3/m128</em> and store in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG D4 /<em>r</em> VPADDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Add packed quadword integers from <em>xmm2, xmm3/m128</em> and store in <em>xmm1</em>.</td>, <td>VEX.256.66.0F.WIG FC /<em>r</em> VPADDB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed byte integers from <em>ymm2, and ymm3/m256</em> and store in <em>ymm1</em>.</td>, <td>VEX.256.66.0F.WIG FD /<em>r</em> VPADDW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed word integers from <em>ymm2, ymm3/m256</em> and <em>store in ymm1</em>.</td>, <td>VEX.256.66.0F.WIG FE /<em>r</em> VPADDD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed doubleword integers from <em>ymm2, ymm3/m256</em> and <em>store in ymm1</em>.</td>, <td>VEX.256.66.0F.WIG D4 /<em>r</em> VPADDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add packed quadword integers from <em>ymm2, ymm3/m256</em> and store in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.WIG FC /r VPADDB <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed byte integers from <em>xmm2, and xmm3/m128</em> and store in <em>xmm1</em> using writemask k1.</td>, <td>EVEX.128.66.0F.WIG FD /r VPADDW <em>xmm1 {k1}{z}, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed word integers from <em>xmm2, and xmm3/m128</em> and store in <em>xmm1</em> using writemask k1.</td>, <td>EVEX.128.66.0F.W0 FE /r VPADDD <em>xmm1 {k1}{z}, xmm2,</em> xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed doubleword integers from <em>xmm2, and xmm3/m128/m32bcst</em> and store in <em>xmm1</em> using writemask k1.</td>, <td>EVEX.128.66.0F.W1 D4 /r VPADDQ <em>xmm1 {k1}{z}, xmm2,</em> xmm3/m128/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed quadword integers from <em>xmm2, and xmm3/m128/m64bcst</em> and store in <em>xmm1</em> using writemask k1.</td>, <td>EVEX.256.66.0F.WIG FC /r VPADDB <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed byte integers from <em>ymm2, and ymm3/m256</em> and store in <em>ymm1</em> using writemask k1.</td>, <td>EVEX.256.66.0F.WIG FD /r VPADDW <em>ymm1 {k1}{z}, ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Add packed word integers from <em>ymm2, and ymm3/m256</em> and store in <em>ymm1</em> using writemask k1.</td>, <td>EVEX.256.66.0F.W0 FE /r VPADDD <em>ymm1 {k1}{z}, ymm2,</em> ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed doubleword integers from <em>ymm2, ymm3/m256/m32bcst</em> and store in <em>ymm1</em> using writemask k1.</td>, <td>EVEX.256.66.0F.W1 D4 /r VPADDQ <em>ymm1 {k1}{z}, ymm2,</em> ymm3/m256/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Add packed quadword integers from <em>ymm2, ymm3/m256/m64bcst</em> and store in <em>ymm1</em> using writemask k1.</td>, <td>EVEX.512.66.0F.WIG FC /r VPADDB <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add packed byte integers from <em>zmm2, and zmm3/m512</em> and store in <em>zmm1</em> using writemask k1.</td>, <td>EVEX.512.66.0F.WIG FD /r VPADDW <em>zmm1 {k1}{z}, zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Add packed word integers from <em>zmm2, and zmm3/m512</em> and store in <em>zmm1</em> using writemask k1.</td>, <td>EVEX.512.66.0F.W0 FE /<em>r</em> VPADDD <em>zmm1 {k1}{z}, zmm2,</em> zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Add packed doubleword integers from <em>zmm2, zmm3/m512/m32bcst</em> and store in <em>zmm1</em> using writemask k1.</td>, <td>EVEX.512.66.0F.W1 D4 /<em>r</em> VPADDQ <em>zmm1 {k1}{z}, zmm2,</em> zmm3/m512/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Add packed quadword integers from <em>zmm2, zmm3/m512/m64bcst</em> and store in <em>zmm1</em> using writemask k1.</td>, <td colspan="5">NOTES: 1. See note in Section 2.4, “AVX and SSE Instruction Exception Specification” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 2A</em> and Section 22.25.3, “Exception Conditions of Legacy SIMD Instructions Operating on MMX Registers” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 3A</em>.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 3A 0F /r ib<sup>1</sup> PALIGNR <em>mm1, mm2/m64, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Concatenate destination and source operands, extract byte-aligned result shifted to the right by constant value in <em>imm8</em> into <em>mm1</em>.</td>, <td>66 0F 3A 0F /r ib PALIGNR <em>xmm1, xmm2/m128, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Concatenate destination and source operands, extract byte-aligned result shifted to the right by constant value in <em>imm8</em> into <em>xmm1.</em></td>, <td>VEX.128.66.0F3A.WIG 0F /r ib VPALIGNR <em>xmm1, xmm2, xmm3/m128, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Concatenate <em>xmm2</em> and <em>xmm3/m128</em>, extract byte aligned result shifted to the right by constant value in <em>imm8</em> and result is stored in <em>xmm1</em>.</td>, <td>VEX.256.66.0F3A.WIG 0F /r ib VPALIGNR <em>ymm1, ymm2, ymm3/m256, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Concatenate pairs of 16 bytes in ymm2 and <em>ymm3/m256</em> into 32-byte intermediate result, extract byte-aligned, 16-byte result shifted to the right by constant values in <em>imm8</em> from each intermediate result, and two 16-byte results are stored in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F3A.WIG 0F /r ib VPALIGNR xmm1 {k1}{z}, xmm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Concatenate xmm2 and xmm3/m128 into a 32-byte intermediate result, extract byte aligned result shifted to the right by constant value in imm8 and result is stored in xmm1.</td>, <td>EVEX.256.66.0F3A.WIG 0F /r ib VPALIGNR ymm1 {k1}{z}, ymm2, ymm3/m256, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Concatenate pairs of 16 bytes in ymm2 and ymm3/m256 into 32-byte intermediate result, extract byte-aligned, 16-byte result shifted to the right by constant values in imm8 from each intermediate result, and two 16-byte results are stored in ymm1.</td>, <td>EVEX.512.66.0F3A.WIG 0F /r ib VPALIGNR zmm1 {k1}{z}, zmm2, zmm3/m512, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Concatenate pairs of 16 bytes in zmm2 and zmm3/m512 into 32-byte intermediate result, extract byte-aligned, 16-byte result shifted to the right by constant values in imm8 from each intermediate result, and four 16-byte results are stored in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>]

[<td>NP 0F DB /<em>r</em><sup>1</sup> PAND <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Bitwise AND <em>mm/m64</em> and <em>mm</em>.</td>, <td>66 0F DB /<em>r</em> PAND <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Bitwise AND of <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG DB /r VPAND <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Bitwise AND of <em>xmm3/m128</em> and <em>xmm</em>.</td>, <td>VEX.256.66.0F.WIG DB /r VPAND <em>ymm1, ymm2, ymm3/.m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Bitwise AND of <em>ymm2</em>, and <em>ymm3/m256</em> and store result in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.W0 DB /r VPANDD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and store result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W0 DB /r VPANDD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and store result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 DB /<em>r</em> VPANDD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.W1 DB /r VPANDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and store result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W1 DB /r VPANDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and store result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W1 DB /<em>r</em> VPANDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F DF /<em>r</em><sup>1</sup> PANDN <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Bitwise AND NOT of <em>mm/m64</em> and <em>mm</em>.</td>, <td>66 0F DF /<em>r</em> PANDN <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Bitwise AND NOT of <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG DF /r VPANDN <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Bitwise AND NOT of <em>xmm3/m128</em> and <em>xmm2</em>.</td>, <td>VEX.256.66.0F.WIG DF /r VPANDN <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Bitwise AND NOT of <em>ymm2</em>, and <em>ymm3/m256</em> and store result in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.W0 DF /r VPANDND xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND NOT of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and store result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W0 DF /r VPANDND ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND NOT of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and store result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 DF /r VPANDND zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND NOT of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.W1 DF /r VPANDNQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND NOT of packed quadword integers in xmm2 and xmm3/m128/m64bcst and store result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W1 DF /r VPANDNQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND NOT of packed quadword integers in ymm2 and ymm3/m256/m64bcst and store result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W1 DF /r VPANDNQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND NOT of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F3 90</td>, <td>PAUSE</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Gives hint to processor that improves performance of spin-wait loops.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>NP 0F E0 /<em>r</em><sup>1</sup> PAVGB <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Average packed unsigned byte integers from <em>mm2/m64</em> and <em>mm1</em> with rounding.</td>, <td>66 0F E0, /<em>r</em> PAVGB <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Average packed unsigned byte integers from <em>xmm2/m128</em> and <em>xmm1</em> with rounding.</td>, <td>NP 0F E3 /<em>r</em><sup>1</sup> PAVGW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Average packed unsigned word integers from mm2/m64 and <em>mm1</em> with rounding.</td>, <td>66 0F E3 /<em>r</em> PAVGW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Average packed unsigned word integers from <em>xmm2/m128</em> and <em>xmm1</em> with rounding.</td>, <td>VEX.128.66.0F.WIG E0 /r VPAVGB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Average packed unsigned byte integers from <em>xmm3/m128</em> and <em>xmm2</em> with rounding.</td>, <td>VEX.128.66.0F.WIG E3 /r VPAVGW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Average packed unsigned word integers from <em>xmm3/m128</em> and <em>xmm2</em> with rounding.</td>, <td>VEX.256.66.0F.WIG E0 /r VPAVGB <em>ymm1</em>, <em>ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Average packed unsigned byte integers from ymm2, and <em>ymm3/m256</em> with rounding and store to <em>ymm1</em>.</td>, <td>VEX.256.66.0F.WIG E3 /r VPAVGW <em>ymm1</em>, <em>ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Average packed unsigned word integers from <em>ymm2</em>, <em>ymm3/m256</em> with rounding to <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.WIG E0 /r VPAVGB <em>xmm1</em> {k1}{z}, <em>xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Average packed unsigned byte integers from xmm2, and <em>xmm3/m128</em> with rounding and store to xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG E0 /r VPAVGB <em>ymm1</em> {k1}{z}, <em>ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Average packed unsigned byte integers from ymm2, and <em>ymm3/m256</em> with rounding and store to ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG E0 /r VPAVGB <em>zmm1</em> {k1}{z}, <em>zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Average packed unsigned byte integers from zmm2, and <em>zmm3/m512</em> with rounding and store to zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.WIG E3 /r VPAVGW <em>xmm1</em> {k1}{z}, <em>xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Average packed unsigned word integers from xmm2, <em>xmm3/m128</em> with rounding to xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG E3 /r VPAVGW <em>ymm1</em> {k1}{z}, <em>ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Average packed unsigned word integers from ymm2, <em>ymm3/m256</em> with rounding to ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG E3 /r VPAVGW <em>zmm1</em> {k1}{z}, <em>zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Average packed unsigned word integers from zmm2, <em>zmm3/m512</em> with rounding to zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F E0 /<em>r</em><sup>1</sup> PAVGB <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Average packed unsigned byte integers from <em>mm2/m64</em> and <em>mm1</em> with rounding.</td>, <td>66 0F E0, /<em>r</em> PAVGB <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Average packed unsigned byte integers from <em>xmm2/m128</em> and <em>xmm1</em> with rounding.</td>, <td>NP 0F E3 /<em>r</em><sup>1</sup> PAVGW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Average packed unsigned word integers from mm2/m64 and <em>mm1</em> with rounding.</td>, <td>66 0F E3 /<em>r</em> PAVGW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Average packed unsigned word integers from <em>xmm2/m128</em> and <em>xmm1</em> with rounding.</td>, <td>VEX.128.66.0F.WIG E0 /r VPAVGB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Average packed unsigned byte integers from <em>xmm3/m128</em> and <em>xmm2</em> with rounding.</td>, <td>VEX.128.66.0F.WIG E3 /r VPAVGW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Average packed unsigned word integers from <em>xmm3/m128</em> and <em>xmm2</em> with rounding.</td>, <td>VEX.256.66.0F.WIG E0 /r VPAVGB <em>ymm1</em>, <em>ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Average packed unsigned byte integers from ymm2, and <em>ymm3/m256</em> with rounding and store to <em>ymm1</em>.</td>, <td>VEX.256.66.0F.WIG E3 /r VPAVGW <em>ymm1</em>, <em>ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Average packed unsigned word integers from <em>ymm2</em>, <em>ymm3/m256</em> with rounding to <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.WIG E0 /r VPAVGB <em>xmm1</em> {k1}{z}, <em>xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Average packed unsigned byte integers from xmm2, and <em>xmm3/m128</em> with rounding and store to xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG E0 /r VPAVGB <em>ymm1</em> {k1}{z}, <em>ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Average packed unsigned byte integers from ymm2, and <em>ymm3/m256</em> with rounding and store to ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG E0 /r VPAVGB <em>zmm1</em> {k1}{z}, <em>zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Average packed unsigned byte integers from zmm2, and <em>zmm3/m512</em> with rounding and store to zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.WIG E3 /r VPAVGW <em>xmm1</em> {k1}{z}, <em>xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Average packed unsigned word integers from xmm2, <em>xmm3/m128</em> with rounding to xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG E3 /r VPAVGW <em>ymm1</em> {k1}{z}, <em>ymm2, ymm3/m256</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Average packed unsigned word integers from ymm2, <em>ymm3/m256</em> with rounding to ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG E3 /r VPAVGW <em>zmm1</em> {k1}{z}, <em>zmm2, zmm3/m512</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Average packed unsigned word integers from zmm2, <em>zmm3/m512</em> with rounding to zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 38 10 /r PBLENDVB <em>xmm1, xmm2/m128, &lt;XMM0&gt;</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Select byte values from <em>xmm1</em> and <em>xmm2/m128</em> from mask specified in the high bit of each byte in <em>XMM0</em> and store the values into <em>xmm1.</em></td>, <td>VEX.128.66.0F3A.W0 4C /r /is4 VPBLENDVB <em>xmm1, xmm2, xmm3/m128, xmm4</em></td>, <td>RVMR</td>, <td>V/V</td>, <td>AVX</td>, <td>Select byte values from <em>xmm2</em> and <em>xmm3/m128</em> using mask bits in the specified mask register, <em>xmm4</em>, and store the values into <em>xmm1</em>.</td>, <td>VEX.256.66.0F3A.W0 4C /r /is4 VPBLENDVB <em>ymm1, ymm2, ymm3/m256, ymm4</em></td>, <td>RVMR</td>, <td>V/V</td>, <td>AVX2</td>, <td>Select byte values from <em>ymm2</em> and <em>ymm3/m256</em> from mask specified in the high bit of each byte in <em>ymm4</em> and store the values into <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>&lt;XMM0&gt;</td>, <td>NA</td>, <td>RVMR</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8[7:4]</td>, <td>#UD</td>, <td>If VEX.W = 1.</td>]

[<td>66 0F 3A 0E /r ib PBLENDW <em>xmm1, xmm2/m128, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Select words from <em>xmm1</em> and <em>xmm2/m128</em> from mask specified in <em>imm8</em> and store the values into <em>xmm1</em>.</td>, <td>VEX.128.66.0F3A.WIG 0E /r ib VPBLENDW <em>xmm1, xmm2, xmm3/m128, imm8</em></td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Select words from <em>xmm2</em> and <em>xmm3/m128</em> from mask specified in <em>imm8</em> and store the values into <em>xmm1</em>.</td>, <td>VEX.256.66.0F3A.WIG 0E /r ib VPBLENDW <em>ymm1, ymm2, ymm3/m256, imm8</em></td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX2</td>, <td>Select words from <em>ymm2</em> and <em>ymm3/m256</em> from mask specified in <em>imm8</em> and store the values into <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMI</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>RVMI</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>#UD</td>, <td>If VEX.L = 1 and AVX2 = 0.</td>]

[<td>66 0F 3A 44 /r ib PCLMULQDQ <em>xmm1, xmm2/m128, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>PCLMULQDQ</td>, <td>Carry-less multiplication of one quadword of xmm1 by one quadword of <em>xmm2/m128</em>, stores the 128-bit result in <em>xmm1</em>. The immediate is used to determine which quadwords of <em>xmm1</em> and <em>xmm2/m128</em> should be used.</td>, <td>VEX.128.66.0F3A.WIG 44 /r ib VPCLMULQDQ <em>xmm1, xmm2, xmm3/m128, imm8</em></td>, <td>RVMI</td>, <td>V/V</td>, <td>Both PCLMULQDQ and AVX flags</td>, <td>Carry-less multiplication of one quadword of <em>xmm2</em> by one quadword of <em>xmm3/m128</em>, stores the 128-bit result in <em>xmm1</em>. The immediate is used to determine which quadwords of <em>xmm2</em> and <em>xmm3/m128</em> should be used.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand2</td>, <td>Operand3</td>, <td>Operand4</td>, <td>RMI</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>RVMI</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>0</td>, <td>0</td>, <td>CL_MUL( SRC2<sup>1</sup>[63:0], SRC1[63:0] )</td>, <td>0</td>, <td>1</td>, <td>CL_MUL( SRC2[63:0], SRC1[127:64] )</td>, <td>1</td>, <td>0</td>, <td>CL_MUL( SRC2[127:64], SRC1[63:0] )</td>, <td>1</td>, <td>1</td>, <td>CL_MUL( SRC2[127:64], SRC1[127:64] )</td>, <td><strong>PCLMULLQLQDQ</strong> <em>xmm1, xmm2</em></td>, <td><strong>0000_0000B</strong></td>, <td><strong>PCLMULHQLQDQ</strong> <em>xmm1, xmm2</em></td>, <td><strong>0000_0001B</strong></td>, <td><strong>PCLMULLQHQDQ</strong> <em>xmm1, xmm2</em></td>, <td><strong>0001_0000B</strong></td>, <td><strong>PCLMULHQHQDQ</strong> <em>xmm1, xmm2</em></td>, <td><strong>0001_0001B</strong></td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>NP 0F 74 /<em>r</em><sup>1</sup> PCMPEQB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed bytes in <em>mm/m64</em> and <em>mm</em> for equality.</td>, <td>66 0F 74 /<em>r</em> PCMPEQB <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed bytes in <em>xmm2/m128</em> and <em>xmm1</em> for equality.</td>, <td>NP 0F 75 /<em>r</em><sup>1</sup> PCMPEQW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed words in <em>mm/m64</em> and <em>mm</em> for equality.</td>, <td>66 0F 75 /<em>r</em> PCMPEQW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed words in <em>xmm2/m128</em> and <em>xmm1</em> for equality.</td>, <td>NP 0F 76 /<em>r</em><sup>1</sup> PCMPEQD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed doublewords in <em>mm/m64</em> and <em>mm</em> for equality.</td>, <td>66 0F 76 /<em>r</em> PCMPEQD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed doublewords in <em>xmm2/m128</em> and <em>xmm1</em> for equality.</td>, <td>VEX.128.66.0F.WIG 74 /r VPCMPEQB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed bytes in <em>xmm3/m128</em> and <em>xmm2</em> for equality.</td>, <td>VEX.128.66.0F.WIG 75 /r VPCMPEQW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed words in <em>xmm3/m128</em> and <em>xmm2</em> for equality.</td>, <td>VEX.128.66.0F.WIG 76 /r VPCMPEQD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed doublewords in <em>xmm3/m128</em> and <em>xmm2</em> for equality.</td>, <td>VEX.256.66.0F.WIG 74 /r VPCMPEQB ymm1, ymm2, ymm3 /m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed bytes in ymm3/m256 and ymm2 for equality.</td>, <td>VEX.256.66.0F.WIG 75 /r VPCMPEQW <em>ymm1, ymm2, ymm3 /m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed words in <em>ymm3/m256</em> and <em>ymm2</em> for equality.</td>, <td>VEX.256.66.0F.WIG 76 /r VPCMPEQD <em>ymm1, ymm2, ymm3 /m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed doublewords in <em>ymm3/m256</em> and <em>ymm2</em> for equality.</td>, <td>EVEX.128.66.0F.W0 76 /r VPCMPEQD k1 {k2}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare Equal between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.W0 76 /r VPCMPEQD k1 {k2}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare Equal between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.W0 76 /r VPCMPEQD k1 {k2}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare Equal between int32 vectors in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask k2.</td>, <td>EVEX.128.66.0F.WIG 74 /r VPCMPEQB k1 {k2}, xmm2, xmm3 /m128</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed bytes in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.WIG 74 /r VPCMPEQB k1 {k2}, ymm2, ymm3 /m256</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed bytes in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.WIG 74 /r VPCMPEQB k1 {k2}, zmm2, zmm3 /m512</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed bytes in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.128.66.0F.WIG 75 /r VPCMPEQW k1 {k2}, xmm2, xmm3 /m128</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed words in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.WIG 75 /r VPCMPEQW k1 {k2}, ymm2, ymm3 /m256</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed words in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.WIG 75 /r VPCMPEQW k1 {k2}, zmm2, zmm3 /m512</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed words in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 74 /<em>r</em><sup>1</sup> PCMPEQB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed bytes in <em>mm/m64</em> and <em>mm</em> for equality.</td>, <td>66 0F 74 /<em>r</em> PCMPEQB <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed bytes in <em>xmm2/m128</em> and <em>xmm1</em> for equality.</td>, <td>NP 0F 75 /<em>r</em><sup>1</sup> PCMPEQW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed words in <em>mm/m64</em> and <em>mm</em> for equality.</td>, <td>66 0F 75 /<em>r</em> PCMPEQW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed words in <em>xmm2/m128</em> and <em>xmm1</em> for equality.</td>, <td>NP 0F 76 /<em>r</em><sup>1</sup> PCMPEQD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed doublewords in <em>mm/m64</em> and <em>mm</em> for equality.</td>, <td>66 0F 76 /<em>r</em> PCMPEQD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed doublewords in <em>xmm2/m128</em> and <em>xmm1</em> for equality.</td>, <td>VEX.128.66.0F.WIG 74 /r VPCMPEQB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed bytes in <em>xmm3/m128</em> and <em>xmm2</em> for equality.</td>, <td>VEX.128.66.0F.WIG 75 /r VPCMPEQW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed words in <em>xmm3/m128</em> and <em>xmm2</em> for equality.</td>, <td>VEX.128.66.0F.WIG 76 /r VPCMPEQD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed doublewords in <em>xmm3/m128</em> and <em>xmm2</em> for equality.</td>, <td>VEX.256.66.0F.WIG 74 /r VPCMPEQB ymm1, ymm2, ymm3 /m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed bytes in ymm3/m256 and ymm2 for equality.</td>, <td>VEX.256.66.0F.WIG 75 /r VPCMPEQW <em>ymm1, ymm2, ymm3 /m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed words in <em>ymm3/m256</em> and <em>ymm2</em> for equality.</td>, <td>VEX.256.66.0F.WIG 76 /r VPCMPEQD <em>ymm1, ymm2, ymm3 /m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed doublewords in <em>ymm3/m256</em> and <em>ymm2</em> for equality.</td>, <td>EVEX.128.66.0F.W0 76 /r VPCMPEQD k1 {k2}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare Equal between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.W0 76 /r VPCMPEQD k1 {k2}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare Equal between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.W0 76 /r VPCMPEQD k1 {k2}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare Equal between int32 vectors in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask k2.</td>, <td>EVEX.128.66.0F.WIG 74 /r VPCMPEQB k1 {k2}, xmm2, xmm3 /m128</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed bytes in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.WIG 74 /r VPCMPEQB k1 {k2}, ymm2, ymm3 /m256</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed bytes in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.WIG 74 /r VPCMPEQB k1 {k2}, zmm2, zmm3 /m512</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed bytes in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.128.66.0F.WIG 75 /r VPCMPEQW k1 {k2}, xmm2, xmm3 /m128</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed words in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.WIG 75 /r VPCMPEQW k1 {k2}, ymm2, ymm3 /m256</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed words in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.WIG 75 /r VPCMPEQW k1 {k2}, zmm2, zmm3 /m512</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed words in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 38 29 /r PCMPEQQ <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed qwords in <em>xmm2/m128</em> and <em>xmm1</em> for equality.</td>, <td>VEX.128.66.0F38.WIG 29 /r VPCMPEQQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed quadwords in <em>xmm3/m128</em> and <em>xmm2</em> for equality.</td>, <td>VEX.256.66.0F38.WIG 29 /r VPCMPEQQ <em>ymm1, ymm2, ymm3 /m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed quadwords in <em>ymm3/m256</em> and <em>ymm2</em> for equality.</td>, <td>EVEX.128.66.0F38.W1 29 /r VPCMPEQQ k1 {k2}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare Equal between int64 vector xmm2 and int64 vector xmm3/m128/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F38.W1 29 /r VPCMPEQQ k1 {k2}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare Equal between int64 vector ymm2 and int64 vector ymm3/m256/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F38.W1 29 /r VPCMPEQQ k1 {k2}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare Equal between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 74 /<em>r</em><sup>1</sup> PCMPEQB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed bytes in <em>mm/m64</em> and <em>mm</em> for equality.</td>, <td>66 0F 74 /<em>r</em> PCMPEQB <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed bytes in <em>xmm2/m128</em> and <em>xmm1</em> for equality.</td>, <td>NP 0F 75 /<em>r</em><sup>1</sup> PCMPEQW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed words in <em>mm/m64</em> and <em>mm</em> for equality.</td>, <td>66 0F 75 /<em>r</em> PCMPEQW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed words in <em>xmm2/m128</em> and <em>xmm1</em> for equality.</td>, <td>NP 0F 76 /<em>r</em><sup>1</sup> PCMPEQD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed doublewords in <em>mm/m64</em> and <em>mm</em> for equality.</td>, <td>66 0F 76 /<em>r</em> PCMPEQD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed doublewords in <em>xmm2/m128</em> and <em>xmm1</em> for equality.</td>, <td>VEX.128.66.0F.WIG 74 /r VPCMPEQB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed bytes in <em>xmm3/m128</em> and <em>xmm2</em> for equality.</td>, <td>VEX.128.66.0F.WIG 75 /r VPCMPEQW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed words in <em>xmm3/m128</em> and <em>xmm2</em> for equality.</td>, <td>VEX.128.66.0F.WIG 76 /r VPCMPEQD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed doublewords in <em>xmm3/m128</em> and <em>xmm2</em> for equality.</td>, <td>VEX.256.66.0F.WIG 74 /r VPCMPEQB ymm1, ymm2, ymm3 /m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed bytes in ymm3/m256 and ymm2 for equality.</td>, <td>VEX.256.66.0F.WIG 75 /r VPCMPEQW <em>ymm1, ymm2, ymm3 /m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed words in <em>ymm3/m256</em> and <em>ymm2</em> for equality.</td>, <td>VEX.256.66.0F.WIG 76 /r VPCMPEQD <em>ymm1, ymm2, ymm3 /m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed doublewords in <em>ymm3/m256</em> and <em>ymm2</em> for equality.</td>, <td>EVEX.128.66.0F.W0 76 /r VPCMPEQD k1 {k2}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare Equal between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.W0 76 /r VPCMPEQD k1 {k2}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare Equal between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.W0 76 /r VPCMPEQD k1 {k2}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare Equal between int32 vectors in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask k2.</td>, <td>EVEX.128.66.0F.WIG 74 /r VPCMPEQB k1 {k2}, xmm2, xmm3 /m128</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed bytes in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.WIG 74 /r VPCMPEQB k1 {k2}, ymm2, ymm3 /m256</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed bytes in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.WIG 74 /r VPCMPEQB k1 {k2}, zmm2, zmm3 /m512</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed bytes in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.128.66.0F.WIG 75 /r VPCMPEQW k1 {k2}, xmm2, xmm3 /m128</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed words in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.WIG 75 /r VPCMPEQW k1 {k2}, ymm2, ymm3 /m256</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed words in ymm3/m256 and ymm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.WIG 75 /r VPCMPEQW k1 {k2}, zmm2, zmm3 /m512</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed words in zmm3/m512 and zmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 3A 61 <em>/r imm8</em> PCMPESTRI <em>xmm1, xmm2/m128, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>SSE4_2</td>, <td>Perform a packed comparison of string data with explicit lengths, generating an index, and storing the result in ECX.</td>, <td>VEX.128.66.0F3A 61 /r ib VPCMPESTRI <em>xmm1, xmm2/m128, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Perform a packed comparison of string data with explicit lengths, generating an index, and storing the result in ECX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMI</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>16 bit</td>, <td>xmm</td>, <td>xmm/m128</td>, <td>EAX</td>, <td>EDX</td>, <td>ECX</td>, <td>32 bit</td>, <td>xmm</td>, <td>xmm/m128</td>, <td>EAX</td>, <td>EDX</td>, <td>ECX</td>, <td>64 bit</td>, <td>xmm</td>, <td>xmm/m128</td>, <td>EAX</td>, <td>EDX</td>, <td>ECX</td>, <td>64 bit + REX.W</td>, <td>xmm</td>, <td>xmm/m128</td>, <td>RAX</td>, <td>RDX</td>, <td>ECX</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 1.</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>66 0F 3A 60 /r imm8 PCMPESTRM <em>xmm1, xmm2/m128, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>SSE4_2</td>, <td>Perform a packed comparison of string data with explicit lengths, generating a mask, and storing the result in <em>XMM0.</em></td>, <td>VEX.128.66.0F3A 60 /r ib VPCMPESTRM <em>xmm1, xmm2/m128, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Perform a packed comparison of string data with explicit lengths, generating a mask, and storing the result in <em>XMM0</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMI</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>16 bit</td>, <td>xmm</td>, <td>xmm/m128</td>, <td>EAX</td>, <td>EDX</td>, <td>XMM0</td>, <td>32 bit</td>, <td>xmm</td>, <td>xmm/m128</td>, <td>EAX</td>, <td>EDX</td>, <td>XMM0</td>, <td>64 bit</td>, <td>xmm</td>, <td>xmm/m128</td>, <td>EAX</td>, <td>EDX</td>, <td>XMM0</td>, <td>64 bit + REX.W</td>, <td>xmm</td>, <td>xmm/m128</td>, <td>RAX</td>, <td>RDX</td>, <td>XMM0</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 1.</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>NP 0F 64 /<em>r</em><sup>1</sup> PCMPGTB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed signed byte integers in <em>mm</em> and <em>mm/m64</em> for greater than.</td>, <td>66 0F 64 /<em>r</em> PCMPGTB <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed signed byte integers in <em>xmm1</em> and <em>xmm2/m128</em> for greater than.</td>, <td>NP 0F 65 /<em>r</em><sup>1</sup> PCMPGTW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed signed word integers in <em>mm</em> and <em>mm/m64</em> for greater than.</td>, <td>66 0F 65 /<em>r</em> PCMPGTW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed signed word integers in <em>xmm1</em> and <em>xmm2/m128</em> for greater than.</td>, <td>NP 0F 66 /<em>r</em><sup>1</sup> PCMPGTD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed signed doubleword integers in <em>mm</em> and <em>mm/m64</em> for greater than.</td>, <td>66 0F 66 /<em>r</em> PCMPGTD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed signed doubleword integers in <em>xmm1</em> and <em>xmm2/m128</em> for greater than.</td>, <td>VEX.128.66.0F.WIG 64 /r VPCMPGTB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed byte integers in <em>xmm2</em> and <em>xmm3/m128</em> for greater than.</td>, <td>VEX.128.66.0F.WIG 65 /r VPCMPGTW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed word integers in <em>xmm2</em> and <em>xmm3/m128</em> for greater than.</td>, <td>VEX.128.66.0F.WIG 66 /r VPCMPGTD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed doubleword integers in <em>xmm2</em> and <em>xmm3/m128</em> for greater than.</td>, <td>VEX.256.66.0F.WIG 64 /r VPCMPGTB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed byte integers in <em>ymm2</em> and <em>ymm3/m256</em> for greater than.</td>, <td>VEX.256.66.0F.WIG 65 /r VPCMPGTW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed word integers in <em>ymm2</em> and <em>ymm3/m256</em> for greater than.</td>, <td>VEX.256.66.0F.WIG 66 /r VPCMPGTD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed doubleword integers in <em>ymm2</em> and <em>ymm3/m256</em> for greater than.</td>, <td>EVEX.128.66.0F.W0 66 /r VPCMPGTD k1 {k2}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare Greater between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.W0 66 /r VPCMPGTD k1 {k2}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare Greater between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.W0 66 /r VPCMPGTD k1 {k2}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare Greater between int32 elements in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask. k2.</td>, <td>EVEX.128.66.0F.WIG 64 /r VPCMPGTB k1 {k2}, xmm2, xmm3/m128</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in xmm2 and xmm3/m128 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.WIG 64 /r VPCMPGTB k1 {k2}, ymm2, ymm3/m256</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in ymm2 and ymm3/m256 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.WIG 64 /r VPCMPGTB k1 {k2}, zmm2, zmm3/m512</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed byte integers in zmm2 and zmm3/m512 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.128.66.0F.WIG 65 /r VPCMPGTW k1 {k2}, xmm2, xmm3/m128</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in xmm2 and xmm3/m128 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.WIG 65 /r VPCMPGTW k1 {k2}, ymm2, ymm3/m256</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in ymm2 and ymm3/m256 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.WIG 65 /r VPCMPGTW k1 {k2}, zmm2, zmm3/m512</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed word integers in zmm2 and zmm3/m512 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 64 /<em>r</em><sup>1</sup> PCMPGTB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed signed byte integers in <em>mm</em> and <em>mm/m64</em> for greater than.</td>, <td>66 0F 64 /<em>r</em> PCMPGTB <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed signed byte integers in <em>xmm1</em> and <em>xmm2/m128</em> for greater than.</td>, <td>NP 0F 65 /<em>r</em><sup>1</sup> PCMPGTW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed signed word integers in <em>mm</em> and <em>mm/m64</em> for greater than.</td>, <td>66 0F 65 /<em>r</em> PCMPGTW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed signed word integers in <em>xmm1</em> and <em>xmm2/m128</em> for greater than.</td>, <td>NP 0F 66 /<em>r</em><sup>1</sup> PCMPGTD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed signed doubleword integers in <em>mm</em> and <em>mm/m64</em> for greater than.</td>, <td>66 0F 66 /<em>r</em> PCMPGTD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed signed doubleword integers in <em>xmm1</em> and <em>xmm2/m128</em> for greater than.</td>, <td>VEX.128.66.0F.WIG 64 /r VPCMPGTB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed byte integers in <em>xmm2</em> and <em>xmm3/m128</em> for greater than.</td>, <td>VEX.128.66.0F.WIG 65 /r VPCMPGTW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed word integers in <em>xmm2</em> and <em>xmm3/m128</em> for greater than.</td>, <td>VEX.128.66.0F.WIG 66 /r VPCMPGTD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed doubleword integers in <em>xmm2</em> and <em>xmm3/m128</em> for greater than.</td>, <td>VEX.256.66.0F.WIG 64 /r VPCMPGTB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed byte integers in <em>ymm2</em> and <em>ymm3/m256</em> for greater than.</td>, <td>VEX.256.66.0F.WIG 65 /r VPCMPGTW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed word integers in <em>ymm2</em> and <em>ymm3/m256</em> for greater than.</td>, <td>VEX.256.66.0F.WIG 66 /r VPCMPGTD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed doubleword integers in <em>ymm2</em> and <em>ymm3/m256</em> for greater than.</td>, <td>EVEX.128.66.0F.W0 66 /r VPCMPGTD k1 {k2}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare Greater between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.W0 66 /r VPCMPGTD k1 {k2}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare Greater between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.W0 66 /r VPCMPGTD k1 {k2}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare Greater between int32 elements in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask. k2.</td>, <td>EVEX.128.66.0F.WIG 64 /r VPCMPGTB k1 {k2}, xmm2, xmm3/m128</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in xmm2 and xmm3/m128 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.WIG 64 /r VPCMPGTB k1 {k2}, ymm2, ymm3/m256</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in ymm2 and ymm3/m256 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.WIG 64 /r VPCMPGTB k1 {k2}, zmm2, zmm3/m512</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed byte integers in zmm2 and zmm3/m512 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.128.66.0F.WIG 65 /r VPCMPGTW k1 {k2}, xmm2, xmm3/m128</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in xmm2 and xmm3/m128 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.WIG 65 /r VPCMPGTW k1 {k2}, ymm2, ymm3/m256</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in ymm2 and ymm3/m256 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.WIG 65 /r VPCMPGTW k1 {k2}, zmm2, zmm3/m512</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed word integers in zmm2 and zmm3/m512 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 38 37 <em>/r</em> PCMPGTQ <em>xmm1,xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE4_2</td>, <td>Compare packed signed qwords in <em>xmm2/m128</em> and <em>xmm1</em> for greater than.</td>, <td>VEX.128.66.0F38.WIG 37 /r VPCMPGTQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed qwords in <em>xmm2</em> and <em>xmm3/m128</em> for greater than.</td>, <td>VEX.256.66.0F38.WIG 37 /r VPCMPGTQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed qwords in <em>ymm2</em> and <em>ymm3/m256</em> for greater than.</td>, <td>EVEX.128.66.0F38.W1 37 /r VPCMPGTQ k1 {k2}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare Greater between int64 vector xmm2 and int64 vector xmm3/m128/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F38.W1 37 /r VPCMPGTQ k1 {k2}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare Greater between int64 vector ymm2 and int64 vector ymm3/m256/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F38.W1 37 /r VPCMPGTQ k1 {k2}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare Greater between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 64 /<em>r</em><sup>1</sup> PCMPGTB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed signed byte integers in <em>mm</em> and <em>mm/m64</em> for greater than.</td>, <td>66 0F 64 /<em>r</em> PCMPGTB <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed signed byte integers in <em>xmm1</em> and <em>xmm2/m128</em> for greater than.</td>, <td>NP 0F 65 /<em>r</em><sup>1</sup> PCMPGTW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed signed word integers in <em>mm</em> and <em>mm/m64</em> for greater than.</td>, <td>66 0F 65 /<em>r</em> PCMPGTW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed signed word integers in <em>xmm1</em> and <em>xmm2/m128</em> for greater than.</td>, <td>NP 0F 66 /<em>r</em><sup>1</sup> PCMPGTD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Compare packed signed doubleword integers in <em>mm</em> and <em>mm/m64</em> for greater than.</td>, <td>66 0F 66 /<em>r</em> PCMPGTD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed signed doubleword integers in <em>xmm1</em> and <em>xmm2/m128</em> for greater than.</td>, <td>VEX.128.66.0F.WIG 64 /r VPCMPGTB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed byte integers in <em>xmm2</em> and <em>xmm3/m128</em> for greater than.</td>, <td>VEX.128.66.0F.WIG 65 /r VPCMPGTW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed word integers in <em>xmm2</em> and <em>xmm3/m128</em> for greater than.</td>, <td>VEX.128.66.0F.WIG 66 /r VPCMPGTD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed doubleword integers in <em>xmm2</em> and <em>xmm3/m128</em> for greater than.</td>, <td>VEX.256.66.0F.WIG 64 /r VPCMPGTB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed byte integers in <em>ymm2</em> and <em>ymm3/m256</em> for greater than.</td>, <td>VEX.256.66.0F.WIG 65 /r VPCMPGTW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed word integers in <em>ymm2</em> and <em>ymm3/m256</em> for greater than.</td>, <td>VEX.256.66.0F.WIG 66 /r VPCMPGTD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed doubleword integers in <em>ymm2</em> and <em>ymm3/m256</em> for greater than.</td>, <td>EVEX.128.66.0F.W0 66 /r VPCMPGTD k1 {k2}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare Greater between int32 vector xmm2 and int32 vector xmm3/m128/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.W0 66 /r VPCMPGTD k1 {k2}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare Greater between int32 vector ymm2 and int32 vector ymm3/m256/m32bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.W0 66 /r VPCMPGTD k1 {k2}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare Greater between int32 elements in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask. k2.</td>, <td>EVEX.128.66.0F.WIG 64 /r VPCMPGTB k1 {k2}, xmm2, xmm3/m128</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in xmm2 and xmm3/m128 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.WIG 64 /r VPCMPGTB k1 {k2}, ymm2, ymm3/m256</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in ymm2 and ymm3/m256 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.WIG 64 /r VPCMPGTB k1 {k2}, zmm2, zmm3/m512</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed byte integers in zmm2 and zmm3/m512 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.128.66.0F.WIG 65 /r VPCMPGTW k1 {k2}, xmm2, xmm3/m128</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in xmm2 and xmm3/m128 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.256.66.0F.WIG 65 /r VPCMPGTW k1 {k2}, ymm2, ymm3/m256</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in ymm2 and ymm3/m256 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>EVEX.512.66.0F.WIG 65 /r VPCMPGTW k1 {k2}, zmm2, zmm3/m512</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed word integers in zmm2 and zmm3/m512 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 3A 63 <em>/r imm8</em> PCMPISTRI <em>xmm1, xmm2/m128, imm8</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE4_2</td>, <td>Perform a packed comparison of string data with implicit lengths, generating an index, and storing the result in ECX.</td>, <td>VEX.128.66.0F3A.WIG 63 /r ib VPCMPISTRI <em>xmm1, xmm2/m128, imm8</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Perform a packed comparison of string data with implicit lengths, generating an index, and storing the result in ECX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>16 bit</td>, <td>xmm</td>, <td>xmm/m128</td>, <td>ECX</td>, <td>32 bit</td>, <td>xmm</td>, <td>xmm/m128</td>, <td>ECX</td>, <td>64 bit</td>, <td>xmm</td>, <td>xmm/m128</td>, <td>ECX</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 1.</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>66 0F 3A 62 <em>/r imm8</em> PCMPISTRM <em>xmm1, xmm2/m128, imm8</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE4_2</td>, <td>Perform a packed comparison of string data with implicit lengths, generating a mask, and storing the result in <em>XMM0.</em></td>, <td>VEX.128.66.0F3A.WIG 62 /r ib VPCMPISTRM <em>xmm1, xmm2/m128, imm8</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Perform a packed comparison of string data with implicit lengths, generating a Mask, and storing the result in <em>XMM0</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>16 bit</td>, <td>xmm</td>, <td>xmm/m128</td>, <td>XMM0</td>, <td>32 bit</td>, <td>xmm</td>, <td>xmm/m128</td>, <td>XMM0</td>, <td>64 bit</td>, <td>xmm</td>, <td>xmm/m128</td>, <td>XMM0</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 1.</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>VEX.LZ.F2.0F38.W0 F5 /r PDEP <em>r32a, r32b, r/m32</em></td>, <td>RVM</td>, <td>V/V</td>, <td>BMI2</td>, <td>Parallel deposit of bits from <em>r32b</em> using mask in <em>r/m32</em>, result is written to <em>r32a</em>.</td>, <td>VEX.LZ.F2.0F38.W1 F5 /r PDEP <em>r64a, r64b, r/m64</em></td>, <td>RVM</td>, <td>V/N.E.</td>, <td>BMI2</td>, <td>Parallel deposit of bits from <em>r64b</em> using mask in <em>r/m64</em>, result is written to <em>r64a.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LZ.F3.0F38.W0 F5 /r PEXT <em>r32a, r32b, r/m32</em></td>, <td>RVM</td>, <td>V/V</td>, <td>BMI2</td>, <td>Parallel extract of bits from <em>r32b</em> using mask in <em>r/m32</em>, result is written to <em>r32a</em>.</td>, <td>VEX.LZ.F3.0F38.W1 F5 /r PEXT <em>r64a, r64b, r/m64</em></td>, <td>RVM</td>, <td>V/N.E.</td>, <td>BMI2</td>, <td>Parallel extract of bits from <em>r64b</em> using mask in <em>r/m64</em>, result is written to <em>r64a</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 3A 14 /r ib PEXTRB <em>reg/m8, xmm2, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Extract a byte integer value from <em>xmm2</em> at the source byte offset specified by <em>imm8</em> into <em>reg or m8.</em> The upper bits of r32 or r64 are zeroed.</td>, <td>66 0F 3A 16 /r ib PEXTRD <em>r/m32, xmm2, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Extract a dword integer value from <em>xmm2</em> at the source dword offset specified by <em>imm8</em> into <em>r/m32</em>.</td>, <td>66 REX.W 0F 3A 16 /r ib PEXTRQ <em>r/m64, xmm2, imm8</em></td>, <td>A</td>, <td>V/N.E.</td>, <td>SSE4_1</td>, <td>Extract a qword integer value from <em>xmm2</em> at the source qword offset specified by <em>imm8</em> into <em>r/m64</em>.</td>, <td>VEX.128.66.0F3A.W0 14 /r ib VPEXTRB <em>reg/m8, xmm2, imm8</em></td>, <td>A</td>, <td>V<sup>1</sup>/V</td>, <td>AVX</td>, <td>Extract a byte integer value from <em>xmm2</em> at the source byte offset specified by <em>imm8</em> into <em>reg</em> or <em>m8</em>. The upper bits of r64/r32 is filled with zeros.</td>, <td>VEX.128.66.0F3A.W0 16 /r ib VPEXTRD <em>r32/m32, xmm2, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Extract a dword integer value from <em>xmm2</em> at the source dword offset specified by <em>imm8</em> into <em>r32/m32</em>.</td>, <td>VEX.128.66.0F3A.W1 16 /r ib VPEXTRQ <em>r64/m64, xmm2, imm8</em></td>, <td>A</td>, <td>V/I<sup>2</sup></td>, <td>AVX</td>, <td>Extract a qword integer value from <em>xmm2</em> at the source dword offset specified by <em>imm8</em> into <em>r64/m64</em>.</td>, <td>EVEX.128.66.0F3A.WIG 14 /r ib VPEXTRB reg/m8, xmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into reg or m8. The upper bits of r64/r32 is filled with zeros.</td>, <td>EVEX.128.66.0F3A.W0 16 /r ib VPEXTRD r32/m32, xmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r32/m32.</td>, <td>EVEX.128.66.0F3A.W1 16 /r ib VPEXTRQ r64/m64, xmm2, imm8</td>, <td>B</td>, <td>V/N.E.<sup>2</sup></td>, <td>AVX512DQ</td>, <td>Extract a qword integer value from xmm2 at the source dword offset specified by imm8 into r64/m64.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>imm8</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>imm8</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 1 or EVEX.L’L &gt; 0.</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>66 0F 3A 14 /r ib PEXTRB <em>reg/m8, xmm2, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Extract a byte integer value from <em>xmm2</em> at the source byte offset specified by <em>imm8</em> into <em>reg or m8.</em> The upper bits of r32 or r64 are zeroed.</td>, <td>66 0F 3A 16 /r ib PEXTRD <em>r/m32, xmm2, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Extract a dword integer value from <em>xmm2</em> at the source dword offset specified by <em>imm8</em> into <em>r/m32</em>.</td>, <td>66 REX.W 0F 3A 16 /r ib PEXTRQ <em>r/m64, xmm2, imm8</em></td>, <td>A</td>, <td>V/N.E.</td>, <td>SSE4_1</td>, <td>Extract a qword integer value from <em>xmm2</em> at the source qword offset specified by <em>imm8</em> into <em>r/m64</em>.</td>, <td>VEX.128.66.0F3A.W0 14 /r ib VPEXTRB <em>reg/m8, xmm2, imm8</em></td>, <td>A</td>, <td>V<sup>1</sup>/V</td>, <td>AVX</td>, <td>Extract a byte integer value from <em>xmm2</em> at the source byte offset specified by <em>imm8</em> into <em>reg</em> or <em>m8</em>. The upper bits of r64/r32 is filled with zeros.</td>, <td>VEX.128.66.0F3A.W0 16 /r ib VPEXTRD <em>r32/m32, xmm2, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Extract a dword integer value from <em>xmm2</em> at the source dword offset specified by <em>imm8</em> into <em>r32/m32</em>.</td>, <td>VEX.128.66.0F3A.W1 16 /r ib VPEXTRQ <em>r64/m64, xmm2, imm8</em></td>, <td>A</td>, <td>V/I<sup>2</sup></td>, <td>AVX</td>, <td>Extract a qword integer value from <em>xmm2</em> at the source dword offset specified by <em>imm8</em> into <em>r64/m64</em>.</td>, <td>EVEX.128.66.0F3A.WIG 14 /r ib VPEXTRB reg/m8, xmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into reg or m8. The upper bits of r64/r32 is filled with zeros.</td>, <td>EVEX.128.66.0F3A.W0 16 /r ib VPEXTRD r32/m32, xmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r32/m32.</td>, <td>EVEX.128.66.0F3A.W1 16 /r ib VPEXTRQ r64/m64, xmm2, imm8</td>, <td>B</td>, <td>V/N.E.<sup>2</sup></td>, <td>AVX512DQ</td>, <td>Extract a qword integer value from xmm2 at the source dword offset specified by imm8 into r64/m64.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>imm8</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>imm8</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 1 or EVEX.L’L &gt; 0.</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>66 0F 3A 14 /r ib PEXTRB <em>reg/m8, xmm2, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Extract a byte integer value from <em>xmm2</em> at the source byte offset specified by <em>imm8</em> into <em>reg or m8.</em> The upper bits of r32 or r64 are zeroed.</td>, <td>66 0F 3A 16 /r ib PEXTRD <em>r/m32, xmm2, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Extract a dword integer value from <em>xmm2</em> at the source dword offset specified by <em>imm8</em> into <em>r/m32</em>.</td>, <td>66 REX.W 0F 3A 16 /r ib PEXTRQ <em>r/m64, xmm2, imm8</em></td>, <td>A</td>, <td>V/N.E.</td>, <td>SSE4_1</td>, <td>Extract a qword integer value from <em>xmm2</em> at the source qword offset specified by <em>imm8</em> into <em>r/m64</em>.</td>, <td>VEX.128.66.0F3A.W0 14 /r ib VPEXTRB <em>reg/m8, xmm2, imm8</em></td>, <td>A</td>, <td>V<sup>1</sup>/V</td>, <td>AVX</td>, <td>Extract a byte integer value from <em>xmm2</em> at the source byte offset specified by <em>imm8</em> into <em>reg</em> or <em>m8</em>. The upper bits of r64/r32 is filled with zeros.</td>, <td>VEX.128.66.0F3A.W0 16 /r ib VPEXTRD <em>r32/m32, xmm2, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Extract a dword integer value from <em>xmm2</em> at the source dword offset specified by <em>imm8</em> into <em>r32/m32</em>.</td>, <td>VEX.128.66.0F3A.W1 16 /r ib VPEXTRQ <em>r64/m64, xmm2, imm8</em></td>, <td>A</td>, <td>V/I<sup>2</sup></td>, <td>AVX</td>, <td>Extract a qword integer value from <em>xmm2</em> at the source dword offset specified by <em>imm8</em> into <em>r64/m64</em>.</td>, <td>EVEX.128.66.0F3A.WIG 14 /r ib VPEXTRB reg/m8, xmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into reg or m8. The upper bits of r64/r32 is filled with zeros.</td>, <td>EVEX.128.66.0F3A.W0 16 /r ib VPEXTRD r32/m32, xmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r32/m32.</td>, <td>EVEX.128.66.0F3A.W1 16 /r ib VPEXTRQ r64/m64, xmm2, imm8</td>, <td>B</td>, <td>V/N.E.<sup>2</sup></td>, <td>AVX512DQ</td>, <td>Extract a qword integer value from xmm2 at the source dword offset specified by imm8 into r64/m64.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>imm8</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>imm8</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 1 or EVEX.L’L &gt; 0.</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>NP 0F C5 /<em>r</em> ib<sup>1</sup> PEXTRW <em>reg</em>, <em>mm</em>, <em>imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Extract the word specified by <em>imm8</em> from <em>mm</em> and move it to <em>reg</em>, bits 15-0. The upper bits of r32 or r64 is zeroed.</td>, <td>66 0F C5 /<em>r</em> ib PEXTRW <em>reg</em>, <em>xmm</em>, <em>imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Extract the word specified by <em>imm8</em> from <em>xmm</em> and move it to <em>reg</em>, bits 15-0. The upper bits of r32 or r64 is zeroed.</td>, <td>66 0F 3A 15 /r ib PEXTRW <em>reg/m16, xmm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Extract the word specified by <em>imm8</em> from <em>xmm</em> and copy it to lowest 16 bits of <em>reg or m16</em>. Zero-extend the result in the destination, r32 or r64.</td>, <td>VEX.128.66.0F.W0 C5 /r ib VPEXTRW <em>reg, xmm1, imm8</em></td>, <td>A</td>, <td>V<sup>2</sup>/V</td>, <td>AVX</td>, <td>Extract the word specified by <em>imm8</em> from <em>xmm1</em> and move it to reg, bits 15:0. Zero-extend the result. The upper bits of r64/r32 is filled with zeros.</td>, <td>VEX.128.66.0F3A.W0 15 /r ib VPEXTRW <em>reg/m16, xmm2, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Extract a word integer value from <em>xmm2</em> at the source word offset specified by <em>imm8</em> into <em>reg</em> or <em>m16</em>. The upper bits of r64/r32 is filled with zeros.</td>, <td>EVEX.128.66.0F.WIG C5 /r ib VPEXTRW reg, xmm1, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512B W</td>, <td>Extract the word specified by imm8 from xmm1 and move it to reg, bits 15:0. Zero-extend the result. The upper bits of r64/r32 is filled with zeros.</td>, <td>EVEX.128.66.0F3A.WIG 15 /r ib VPEXTRW reg/m16, xmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512B W</td>, <td>Extract a word integer value from xmm2 at the source word offset specified by imm8 into reg or m16. The upper bits of r64/r32 is filled with zeros.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>imm8</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>imm8</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 1 or EVEX.L’L &gt; 0.</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>NP 0F 38 01 /r<sup>1</sup> PHADDW <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Add 16-bit integers horizontally, pack to <em>mm1</em>.</td>, <td>66 0F 38 01 /r PHADDW <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Add 16-bit integers horizontally, pack to <em>xmm1</em>.</td>, <td>NP 0F 38 02 /r PHADDD <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Add 32-bit integers horizontally, pack to <em>mm1</em>.</td>, <td>66 0F 38 02 /r PHADDD <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Add 32-bit integers horizontally, pack to <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 01 /r VPHADDW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Add 16-bit integers horizontally, pack to <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 02 /r VPHADDD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Add 32-bit integers horizontally, pack to <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.WIG 01 /r VPHADDW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add 16-bit signed integers horizontally, pack to <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.WIG 02 /r VPHADDD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add 32-bit signed integers horizontally, pack to <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>NP 0F 38 03 /r<sup>1</sup> PHADDSW <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Add 16-bit signed integers horizontally, pack saturated integers to <em>mm1</em>.</td>, <td>66 0F 38 03 /r PHADDSW <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Add 16-bit signed integers horizontally, pack saturated integers to <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 03 /r VPHADDSW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Add 16-bit signed integers horizontally, pack saturated integers to <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.WIG 03 /r VPHADDSW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add 16-bit signed integers horizontally, pack saturated integers to <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>NP 0F 38 01 /r<sup>1</sup> PHADDW <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Add 16-bit integers horizontally, pack to <em>mm1</em>.</td>, <td>66 0F 38 01 /r PHADDW <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Add 16-bit integers horizontally, pack to <em>xmm1</em>.</td>, <td>NP 0F 38 02 /r PHADDD <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Add 32-bit integers horizontally, pack to <em>mm1</em>.</td>, <td>66 0F 38 02 /r PHADDD <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Add 32-bit integers horizontally, pack to <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 01 /r VPHADDW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Add 16-bit integers horizontally, pack to <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 02 /r VPHADDD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Add 32-bit integers horizontally, pack to <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.WIG 01 /r VPHADDW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add 16-bit signed integers horizontally, pack to <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.WIG 02 /r VPHADDD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Add 32-bit signed integers horizontally, pack to <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>66 0F 38 41 /r PHMINPOSUW <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Find the minimum unsigned word in <em>xmm2/m128</em> and place its value in the low word of <em>xmm1</em> and its index in the second-lowest word of <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 41 /r VPHMINPOSUW <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Find the minimum unsigned word in <em>xmm2/m128</em> and place its value in the low word of xmm1 and its index in the second-lowest word of <em>xmm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 1.</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>NP 0F 38 05 /r<sup>1</sup> PHSUBW <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Subtract 16-bit signed integers horizontally, pack to <em>mm1</em>.</td>, <td>66 0F 38 05 /r PHSUBW <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Subtract 16-bit signed integers horizontally, pack to <em>xmm1</em>.</td>, <td>NP 0F 38 06 /r PHSUBD <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Subtract 32-bit signed integers horizontally, pack to <em>mm1</em>.</td>, <td>66 0F 38 06 /r PHSUBD <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Subtract 32-bit signed integers horizontally, pack to <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 05 /r VPHSUBW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract 16-bit signed integers horizontally, pack to <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 06 /r VPHSUBD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract 32-bit signed integers horizontally, pack to <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.WIG 05 /r VPHSUBW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract 16-bit signed integers horizontally, pack to <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.WIG 06 /r VPHSUBD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract 32-bit signed integers horizontally, pack to <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>NP 0F 38 07 /r<sup>1</sup> PHSUBSW <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Subtract 16-bit signed integer horizontally, pack saturated integers to <em>mm1.</em></td>, <td>66 0F 38 07 /r PHSUBSW <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Subtract 16-bit signed integer horizontally, pack saturated integers to <em>xmm1.</em></td>, <td>VEX.128.66.0F38.WIG 07 /r VPHSUBSW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract 16-bit signed integer horizontally, pack saturated integers to <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.WIG 07 /r VPHSUBSW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract 16-bit signed integer horizontally, pack saturated integers to <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>NP 0F 38 05 /r<sup>1</sup> PHSUBW <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Subtract 16-bit signed integers horizontally, pack to <em>mm1</em>.</td>, <td>66 0F 38 05 /r PHSUBW <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Subtract 16-bit signed integers horizontally, pack to <em>xmm1</em>.</td>, <td>NP 0F 38 06 /r PHSUBD <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Subtract 32-bit signed integers horizontally, pack to <em>mm1</em>.</td>, <td>66 0F 38 06 /r PHSUBD <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Subtract 32-bit signed integers horizontally, pack to <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 05 /r VPHSUBW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract 16-bit signed integers horizontally, pack to <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 06 /r VPHSUBD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract 32-bit signed integers horizontally, pack to <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.WIG 05 /r VPHSUBW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract 16-bit signed integers horizontally, pack to <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.WIG 06 /r VPHSUBD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract 32-bit signed integers horizontally, pack to <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>66 0F 3A 20 /r ib PINSRB <em>xmm1, r32/m8, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Insert a byte integer value from <em>r32/m8</em> into <em>xmm1</em> at the destination element in <em>xmm1</em> specified by <em>imm8.</em></td>, <td>66 0F 3A 22 /r ib PINSRD <em>xmm1, r/m32, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Insert a dword integer value from <em>r/m32</em> into the <em>xmm1</em> at the destination element specified by <em>imm8.</em></td>, <td>66 REX.W 0F 3A 22 /r ib PINSRQ <em>xmm1, r/m64, imm8</em></td>, <td>A</td>, <td>V/N. E.</td>, <td>SSE4_1</td>, <td>Insert a qword integer value from <em>r/m64 i</em>nto the <em>xmm1</em> at the destination element specified by <em>imm8.</em></td>, <td>VEX.128.66.0F3A.W0 20 /r ib VPINSRB <em>xmm1, xmm2, r32/m8, imm8</em></td>, <td>B</td>, <td>V<sup>1</sup>/V</td>, <td>AVX</td>, <td>Merge a byte integer value from <em>r32/m8</em> and rest from <em>xmm2</em> into <em>xmm1</em> at the byte offset in <em>imm8</em>.</td>, <td>VEX.128.66.0F3A.W0 22 /r ib VPINSRD <em>xmm1, xmm2, r/m32, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Insert a dword integer value from <em>r32/m32</em> and rest from <em>xmm2</em> into <em>xmm1</em> at the dword offset in <em>imm8</em>.</td>, <td>VEX.128.66.0F3A.W1 22 /r ib VPINSRQ <em>xmm1, xmm2, r/m64, imm8</em></td>, <td>B</td>, <td>V/I<sup>2</sup></td>, <td>AVX</td>, <td>Insert a qword integer value from <em>r64/m64</em> and rest from <em>xmm2</em> into <em>xmm1</em> at the qword offset in <em>imm8</em>.</td>, <td>EVEX.128.66.0F3A.WIG 20 /r ib VPINSRB xmm1, xmm2, r32/m8, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Merge a byte integer value from r32/m8 and rest from xmm2 into xmm1 at the byte offset in imm8.</td>, <td>EVEX.128.66.0F3A.W0 22 /r ib VPINSRD xmm1, xmm2, r32/m32, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert a dword integer value from r32/m32 and rest from xmm2 into xmm1 at the dword offset in imm8.</td>, <td>EVEX.128.66.0F3A.W1 22 /r ib VPINSRQ xmm1, xmm2, r64/m64, imm8</td>, <td>C</td>, <td>V/N.E.<sup>2</sup></td>, <td>AVX512DQ</td>, <td>Insert a qword integer value from r64/m64 and rest from xmm2 into xmm1 at the qword offset in imm8.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>#UD</td>, <td>If VEX.L = 1 or EVEX.L’L &gt; 0.</td>]

[<td>66 0F 3A 20 /r ib PINSRB <em>xmm1, r32/m8, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Insert a byte integer value from <em>r32/m8</em> into <em>xmm1</em> at the destination element in <em>xmm1</em> specified by <em>imm8.</em></td>, <td>66 0F 3A 22 /r ib PINSRD <em>xmm1, r/m32, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Insert a dword integer value from <em>r/m32</em> into the <em>xmm1</em> at the destination element specified by <em>imm8.</em></td>, <td>66 REX.W 0F 3A 22 /r ib PINSRQ <em>xmm1, r/m64, imm8</em></td>, <td>A</td>, <td>V/N. E.</td>, <td>SSE4_1</td>, <td>Insert a qword integer value from <em>r/m64 i</em>nto the <em>xmm1</em> at the destination element specified by <em>imm8.</em></td>, <td>VEX.128.66.0F3A.W0 20 /r ib VPINSRB <em>xmm1, xmm2, r32/m8, imm8</em></td>, <td>B</td>, <td>V<sup>1</sup>/V</td>, <td>AVX</td>, <td>Merge a byte integer value from <em>r32/m8</em> and rest from <em>xmm2</em> into <em>xmm1</em> at the byte offset in <em>imm8</em>.</td>, <td>VEX.128.66.0F3A.W0 22 /r ib VPINSRD <em>xmm1, xmm2, r/m32, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Insert a dword integer value from <em>r32/m32</em> and rest from <em>xmm2</em> into <em>xmm1</em> at the dword offset in <em>imm8</em>.</td>, <td>VEX.128.66.0F3A.W1 22 /r ib VPINSRQ <em>xmm1, xmm2, r/m64, imm8</em></td>, <td>B</td>, <td>V/I<sup>2</sup></td>, <td>AVX</td>, <td>Insert a qword integer value from <em>r64/m64</em> and rest from <em>xmm2</em> into <em>xmm1</em> at the qword offset in <em>imm8</em>.</td>, <td>EVEX.128.66.0F3A.WIG 20 /r ib VPINSRB xmm1, xmm2, r32/m8, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Merge a byte integer value from r32/m8 and rest from xmm2 into xmm1 at the byte offset in imm8.</td>, <td>EVEX.128.66.0F3A.W0 22 /r ib VPINSRD xmm1, xmm2, r32/m32, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert a dword integer value from r32/m32 and rest from xmm2 into xmm1 at the dword offset in imm8.</td>, <td>EVEX.128.66.0F3A.W1 22 /r ib VPINSRQ xmm1, xmm2, r64/m64, imm8</td>, <td>C</td>, <td>V/N.E.<sup>2</sup></td>, <td>AVX512DQ</td>, <td>Insert a qword integer value from r64/m64 and rest from xmm2 into xmm1 at the qword offset in imm8.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>#UD</td>, <td>If VEX.L = 1 or EVEX.L’L &gt; 0.</td>]

[<td>66 0F 3A 20 /r ib PINSRB <em>xmm1, r32/m8, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Insert a byte integer value from <em>r32/m8</em> into <em>xmm1</em> at the destination element in <em>xmm1</em> specified by <em>imm8.</em></td>, <td>66 0F 3A 22 /r ib PINSRD <em>xmm1, r/m32, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Insert a dword integer value from <em>r/m32</em> into the <em>xmm1</em> at the destination element specified by <em>imm8.</em></td>, <td>66 REX.W 0F 3A 22 /r ib PINSRQ <em>xmm1, r/m64, imm8</em></td>, <td>A</td>, <td>V/N. E.</td>, <td>SSE4_1</td>, <td>Insert a qword integer value from <em>r/m64 i</em>nto the <em>xmm1</em> at the destination element specified by <em>imm8.</em></td>, <td>VEX.128.66.0F3A.W0 20 /r ib VPINSRB <em>xmm1, xmm2, r32/m8, imm8</em></td>, <td>B</td>, <td>V<sup>1</sup>/V</td>, <td>AVX</td>, <td>Merge a byte integer value from <em>r32/m8</em> and rest from <em>xmm2</em> into <em>xmm1</em> at the byte offset in <em>imm8</em>.</td>, <td>VEX.128.66.0F3A.W0 22 /r ib VPINSRD <em>xmm1, xmm2, r/m32, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Insert a dword integer value from <em>r32/m32</em> and rest from <em>xmm2</em> into <em>xmm1</em> at the dword offset in <em>imm8</em>.</td>, <td>VEX.128.66.0F3A.W1 22 /r ib VPINSRQ <em>xmm1, xmm2, r/m64, imm8</em></td>, <td>B</td>, <td>V/I<sup>2</sup></td>, <td>AVX</td>, <td>Insert a qword integer value from <em>r64/m64</em> and rest from <em>xmm2</em> into <em>xmm1</em> at the qword offset in <em>imm8</em>.</td>, <td>EVEX.128.66.0F3A.WIG 20 /r ib VPINSRB xmm1, xmm2, r32/m8, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Merge a byte integer value from r32/m8 and rest from xmm2 into xmm1 at the byte offset in imm8.</td>, <td>EVEX.128.66.0F3A.W0 22 /r ib VPINSRD xmm1, xmm2, r32/m32, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert a dword integer value from r32/m32 and rest from xmm2 into xmm1 at the dword offset in imm8.</td>, <td>EVEX.128.66.0F3A.W1 22 /r ib VPINSRQ xmm1, xmm2, r64/m64, imm8</td>, <td>C</td>, <td>V/N.E.<sup>2</sup></td>, <td>AVX512DQ</td>, <td>Insert a qword integer value from r64/m64 and rest from xmm2 into xmm1 at the qword offset in imm8.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>#UD</td>, <td>If VEX.L = 1 or EVEX.L’L &gt; 0.</td>]

[<td>NP 0F C4 /<em>r</em> ib<sup>1</sup> PINSRW <em>mm</em>, <em>r32/m16, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Insert the low word from <em>r32</em> or from <em>m16</em> into <em>mm</em> at the word position specified by <em>imm8.</em></td>, <td>66 0F C4 /<em>r</em> ib PINSRW <em>xmm, r32/m16, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move the low word of <em>r32</em> or from <em>m16</em> into <em>xmm</em> at the word position specified by <em>imm8</em>.</td>, <td>VEX.128.66.0F.W0 C4 /r ib VPINSRW <em>xmm1, xmm2, r32/m16, imm8</em></td>, <td>B</td>, <td>V<sup>2</sup>/V</td>, <td>AVX</td>, <td>Insert a word integer value from <em>r32/m16</em> and rest from <em>xmm2</em> into <em>xmm1</em> at the word offset in <em>imm8</em>.</td>, <td>EVEX.128.66.0F.WIG C4 /r ib VPINSRW xmm1, xmm2, r32/m16, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Insert a word integer value from r32/m16 and rest from xmm2 into xmm1 at the word offset in imm8.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>#UD</td>, <td>If VEX.L = 1 or EVEX.L’L &gt; 0.</td>]

[<td>NP 0F 38 04 /r<sup>1</sup> PMADDUBSW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to <em>mm1</em>.</td>, <td>66 0F 38 04 /r PMADDUBSW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 04 /r VPMADDUBSW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.WIG 04 /r VPMADDUBSW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to <em>ymm1.</em></td>, <td>EVEX.128.66.0F38.WIG 04 /r VPMADDUBSW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 04 /r VPMADDUBSW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 04 /r VPMADDUBSW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F F5 /<em>r</em><sup>1</sup> PMADDWD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Multiply the packed words in <em>mm</em> by the packed words in <em>mm/m64</em>, add adjacent doubleword results, and store in <em>mm</em>.</td>, <td>66 0F F5 /<em>r</em> PMADDWD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Multiply the packed word integers in <em>xmm1</em> by the packed word integers in <em>xmm2/m128</em>, add adjacent doubleword results, and store in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG F5 /r VPMADDWD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply the packed word integers in <em>xmm2</em> by the packed word integers in <em>xmm3/m128</em>, add adjacent doubleword results, and store in <em>xmm1</em>.</td>, <td>VEX.256.66.0F.WIG F5 /r VPMADDWD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Multiply the packed word integers in <em>ymm2</em> by the packed word integers in <em>ymm3/m256</em>, add adjacent doubleword results, and store in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.WIG F5 /r VPMADDWD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Multiply the packed word integers in xmm2 by the packed word integers in xmm3/m128, add adjacent doubleword results, and store in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG F5 /r VPMADDWD ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Multiply the packed word integers in ymm2 by the packed word integers in ymm3/m256, add adjacent doubleword results, and store in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG F5 /r VPMADDWD zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Multiply the packed word integers in zmm2 by the packed word integers in zmm3/m512, add adjacent doubleword results, and store in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F EE /<em>r</em><sup>1</sup> PMAXSW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Compare signed word integers in <em>mm2/m64</em> and <em>mm1</em> and return maximum values.</td>, <td>66 0F 38 3C /r PMAXSB xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.</td>, <td>66 0F EE /r PMAXSW xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed signed word integers in xmm2/m128 and xmm1 and stores maximum packed values in xmm1.</td>, <td>66 0F 38 3D /r PMAXSD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed signed dword integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.</td>, <td>VEX.128.66.0F38.WIG 3C /r VPMAXSB xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.</td>, <td>VEX.128.66.0F.WIG EE /r VPMAXSW xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed word integers in xmm3/m128 and xmm2 and store packed maximum values in xmm1.</td>, <td>VEX.128.66.0F38.WIG 3D /r VPMAXSD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.</td>, <td>VEX.256.66.0F38.WIG 3C /r VPMAXSB ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.</td>, <td>VEX.256.66.0F.WIG EE /r VPMAXSW ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed word integers in ymm3/m256 and ymm2 and store packed maximum values in ymm1.</td>, <td>VEX.256.66.0F38.WIG 3D /r VPMAXSD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed dword integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.</td>, <td>EVEX.128.66.0F38.WIG 3C /r VPMAXSB xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 3C /r VPMAXSB ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 3C /r VPMAXSB zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.WIG EE /r VPMAXSW xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG EE /r VPMAXSW ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG EE /r VPMAXSW zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F38.W0 3D /r VPMAXSD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed dword integers in xmm2 and xmm3/m128/m32bcst and store packed maximum values in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 3D /r VPMAXSD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed dword integers in ymm2 and ymm3/m256/m32bcst and store packed maximum values in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 3D /r VPMAXSD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed signed dword integers in zmm2 and zmm3/m512/m32bcst and store packed maximum values in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 3D /r VPMAXSQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed qword integers in xmm2 and xmm3/m128/m64bcst and store packed maximum values in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 3D /r VPMAXSQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed qword integers in ymm2 and ymm3/m256/m64bcst and store packed maximum values in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 3D /r VPMAXSQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed signed qword integers in zmm2 and zmm3/m512/m64bcst and store packed maximum values in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F EE /<em>r</em><sup>1</sup> PMAXSW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Compare signed word integers in <em>mm2/m64</em> and <em>mm1</em> and return maximum values.</td>, <td>66 0F 38 3C /r PMAXSB xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.</td>, <td>66 0F EE /r PMAXSW xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed signed word integers in xmm2/m128 and xmm1 and stores maximum packed values in xmm1.</td>, <td>66 0F 38 3D /r PMAXSD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed signed dword integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.</td>, <td>VEX.128.66.0F38.WIG 3C /r VPMAXSB xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.</td>, <td>VEX.128.66.0F.WIG EE /r VPMAXSW xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed word integers in xmm3/m128 and xmm2 and store packed maximum values in xmm1.</td>, <td>VEX.128.66.0F38.WIG 3D /r VPMAXSD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.</td>, <td>VEX.256.66.0F38.WIG 3C /r VPMAXSB ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.</td>, <td>VEX.256.66.0F.WIG EE /r VPMAXSW ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed word integers in ymm3/m256 and ymm2 and store packed maximum values in ymm1.</td>, <td>VEX.256.66.0F38.WIG 3D /r VPMAXSD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed dword integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.</td>, <td>EVEX.128.66.0F38.WIG 3C /r VPMAXSB xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 3C /r VPMAXSB ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 3C /r VPMAXSB zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.WIG EE /r VPMAXSW xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG EE /r VPMAXSW ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG EE /r VPMAXSW zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F38.W0 3D /r VPMAXSD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed dword integers in xmm2 and xmm3/m128/m32bcst and store packed maximum values in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 3D /r VPMAXSD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed dword integers in ymm2 and ymm3/m256/m32bcst and store packed maximum values in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 3D /r VPMAXSD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed signed dword integers in zmm2 and zmm3/m512/m32bcst and store packed maximum values in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 3D /r VPMAXSQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed qword integers in xmm2 and xmm3/m128/m64bcst and store packed maximum values in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 3D /r VPMAXSQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed qword integers in ymm2 and ymm3/m256/m64bcst and store packed maximum values in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 3D /r VPMAXSQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed signed qword integers in zmm2 and zmm3/m512/m64bcst and store packed maximum values in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F EE /<em>r</em><sup>1</sup> PMAXSW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Compare signed word integers in <em>mm2/m64</em> and <em>mm1</em> and return maximum values.</td>, <td>66 0F 38 3C /r PMAXSB xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.</td>, <td>66 0F EE /r PMAXSW xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed signed word integers in xmm2/m128 and xmm1 and stores maximum packed values in xmm1.</td>, <td>66 0F 38 3D /r PMAXSD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed signed dword integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.</td>, <td>VEX.128.66.0F38.WIG 3C /r VPMAXSB xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.</td>, <td>VEX.128.66.0F.WIG EE /r VPMAXSW xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed word integers in xmm3/m128 and xmm2 and store packed maximum values in xmm1.</td>, <td>VEX.128.66.0F38.WIG 3D /r VPMAXSD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.</td>, <td>VEX.256.66.0F38.WIG 3C /r VPMAXSB ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.</td>, <td>VEX.256.66.0F.WIG EE /r VPMAXSW ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed word integers in ymm3/m256 and ymm2 and store packed maximum values in ymm1.</td>, <td>VEX.256.66.0F38.WIG 3D /r VPMAXSD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed dword integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.</td>, <td>EVEX.128.66.0F38.WIG 3C /r VPMAXSB xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 3C /r VPMAXSB ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 3C /r VPMAXSB zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.WIG EE /r VPMAXSW xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG EE /r VPMAXSW ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG EE /r VPMAXSW zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F38.W0 3D /r VPMAXSD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed dword integers in xmm2 and xmm3/m128/m32bcst and store packed maximum values in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 3D /r VPMAXSD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed dword integers in ymm2 and ymm3/m256/m32bcst and store packed maximum values in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 3D /r VPMAXSD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed signed dword integers in zmm2 and zmm3/m512/m32bcst and store packed maximum values in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 3D /r VPMAXSQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed qword integers in xmm2 and xmm3/m128/m64bcst and store packed maximum values in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 3D /r VPMAXSQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed qword integers in ymm2 and ymm3/m256/m64bcst and store packed maximum values in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 3D /r VPMAXSQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed signed qword integers in zmm2 and zmm3/m512/m64bcst and store packed maximum values in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F EE /<em>r</em><sup>1</sup> PMAXSW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Compare signed word integers in <em>mm2/m64</em> and <em>mm1</em> and return maximum values.</td>, <td>66 0F 38 3C /r PMAXSB xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.</td>, <td>66 0F EE /r PMAXSW xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed signed word integers in xmm2/m128 and xmm1 and stores maximum packed values in xmm1.</td>, <td>66 0F 38 3D /r PMAXSD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed signed dword integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.</td>, <td>VEX.128.66.0F38.WIG 3C /r VPMAXSB xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.</td>, <td>VEX.128.66.0F.WIG EE /r VPMAXSW xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed word integers in xmm3/m128 and xmm2 and store packed maximum values in xmm1.</td>, <td>VEX.128.66.0F38.WIG 3D /r VPMAXSD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.</td>, <td>VEX.256.66.0F38.WIG 3C /r VPMAXSB ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.</td>, <td>VEX.256.66.0F.WIG EE /r VPMAXSW ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed word integers in ymm3/m256 and ymm2 and store packed maximum values in ymm1.</td>, <td>VEX.256.66.0F38.WIG 3D /r VPMAXSD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed dword integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.</td>, <td>EVEX.128.66.0F38.WIG 3C /r VPMAXSB xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 3C /r VPMAXSB ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 3C /r VPMAXSB zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.WIG EE /r VPMAXSW xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG EE /r VPMAXSW ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG EE /r VPMAXSW zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F38.W0 3D /r VPMAXSD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed dword integers in xmm2 and xmm3/m128/m32bcst and store packed maximum values in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 3D /r VPMAXSD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed dword integers in ymm2 and ymm3/m256/m32bcst and store packed maximum values in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 3D /r VPMAXSD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed signed dword integers in zmm2 and zmm3/m512/m32bcst and store packed maximum values in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 3D /r VPMAXSQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed qword integers in xmm2 and xmm3/m128/m64bcst and store packed maximum values in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 3D /r VPMAXSQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed qword integers in ymm2 and ymm3/m256/m64bcst and store packed maximum values in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 3D /r VPMAXSQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed signed qword integers in zmm2 and zmm3/m512/m64bcst and store packed maximum values in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F DE /<em>r</em><sup>1</sup> PMAXUB <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Compare unsigned byte integers in <em>mm2/m64</em> and <em>mm1</em> and returns maximum values.</td>, <td>66 0F DE /r PMAXUB xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed unsigned byte integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.</td>, <td>66 0F 38 3E/r PMAXUW xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed unsigned word integers in xmm2/m128 and xmm1 and stores maximum packed values in xmm1.</td>, <td>VEX.128.66.0F DE /r VPMAXUB xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.</td>, <td>VEX.128.66.0F38 3E/r VPMAXUW xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed unsigned word integers in xmm3/m128 and xmm2 and store maximum packed values in xmm1.</td>, <td>VEX.256.66.0F DE /r VPMAXUB ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.</td>, <td>VEX.256.66.0F38 3E/r VPMAXUW ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed unsigned word integers in ymm3/m256 and ymm2 and store maximum packed values in ymm1.</td>, <td>EVEX.128.66.0F.WIG DE /r VPMAXUB xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG DE /r VPMAXUB ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG DE /r VPMAXUB zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed unsigned byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F38.WIG 3E /r VPMAXUW xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned word integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 3E /r VPMAXUW ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned word integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 3E /r VPMAXUW zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed unsigned word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.</td>, <td colspan="5">NOTES: 1. See note in Section 2.4, “AVX and SSE Instruction Exception Specification” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 2A</em> and Section 22.25.3, “Exception Conditions of Legacy SIMD Instructions Operating on MMX Registers” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 3A</em>.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 38 3F /r PMAXUD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed unsigned dword integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.</td>, <td>VEX.128.66.0F38.WIG 3F /r VPMAXUD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed unsigned dword integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.</td>, <td>VEX.256.66.0F38.WIG 3F /r VPMAXUD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed unsigned dword integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.</td>, <td>EVEX.128.66.0F38.W0 3F /r VPMAXUD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned dword integers in xmm2 and xmm3/m128/m32bcst and store packed maximum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 3F /r VPMAXUD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned dword integers in ymm2 and ymm3/m256/m32bcst and store packed maximum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 3F /r VPMAXUD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed unsigned dword integers in zmm2 and zmm3/m512/m32bcst and store packed maximum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F38.W1 3F /r VPMAXUQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned qword integers in xmm2 and xmm3/m128/m64bcst and store packed maximum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 3F /r VPMAXUQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned qword integers in ymm2 and ymm3/m256/m64bcst and store packed maximum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 3F /r VPMAXUQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed unsigned qword integers in zmm2 and zmm3/m512/m64bcst and store packed maximum values in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 38 3F /r PMAXUD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed unsigned dword integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.</td>, <td>VEX.128.66.0F38.WIG 3F /r VPMAXUD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed unsigned dword integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.</td>, <td>VEX.256.66.0F38.WIG 3F /r VPMAXUD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed unsigned dword integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.</td>, <td>EVEX.128.66.0F38.W0 3F /r VPMAXUD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned dword integers in xmm2 and xmm3/m128/m32bcst and store packed maximum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 3F /r VPMAXUD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned dword integers in ymm2 and ymm3/m256/m32bcst and store packed maximum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 3F /r VPMAXUD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed unsigned dword integers in zmm2 and zmm3/m512/m32bcst and store packed maximum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F38.W1 3F /r VPMAXUQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned qword integers in xmm2 and xmm3/m128/m64bcst and store packed maximum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 3F /r VPMAXUQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned qword integers in ymm2 and ymm3/m256/m64bcst and store packed maximum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 3F /r VPMAXUQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed unsigned qword integers in zmm2 and zmm3/m512/m64bcst and store packed maximum values in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F DE /<em>r</em><sup>1</sup> PMAXUB <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Compare unsigned byte integers in <em>mm2/m64</em> and <em>mm1</em> and returns maximum values.</td>, <td>66 0F DE /r PMAXUB xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed unsigned byte integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1.</td>, <td>66 0F 38 3E/r PMAXUW xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed unsigned word integers in xmm2/m128 and xmm1 and stores maximum packed values in xmm1.</td>, <td>VEX.128.66.0F DE /r VPMAXUB xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1.</td>, <td>VEX.128.66.0F38 3E/r VPMAXUW xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed unsigned word integers in xmm3/m128 and xmm2 and store maximum packed values in xmm1.</td>, <td>VEX.256.66.0F DE /r VPMAXUB ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1.</td>, <td>VEX.256.66.0F38 3E/r VPMAXUW ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed unsigned word integers in ymm3/m256 and ymm2 and store maximum packed values in ymm1.</td>, <td>EVEX.128.66.0F.WIG DE /r VPMAXUB xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG DE /r VPMAXUB ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG DE /r VPMAXUB zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed unsigned byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F38.WIG 3E /r VPMAXUW xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned word integers in xmm2 and xmm3/m128 and store packed maximum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 3E /r VPMAXUW ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned word integers in ymm2 and ymm3/m256 and store packed maximum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 3E /r VPMAXUW zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed unsigned word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1.</td>, <td colspan="5">NOTES: 1. See note in Section 2.4, “AVX and SSE Instruction Exception Specification” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 2A</em> and Section 22.25.3, “Exception Conditions of Legacy SIMD Instructions Operating on MMX Registers” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 3A</em>.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F EA /<em>r</em><sup>1</sup> PMINSW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Compare signed word integers in <em>mm2/m64</em> and <em>mm1</em> and return minimum values.</td>, <td>66 0F 38 38 /r PMINSB xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.</td>, <td>66 0F EA /r PMINSW xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed signed word integers in xmm2/m128 and xmm1 and store packed minimum values in xmm1.</td>, <td>VEX.128.66.0F38 38 /r VPMINSB xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.</td>, <td>VEX.128.66.0F EA /r VPMINSW xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1.</td>, <td>VEX.256.66.0F38 38 /r VPMINSB ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.</td>, <td>VEX.256.66.0F EA /r VPMINSW ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1.</td>, <td>EVEX.128.66.0F38.WIG 38 /r VPMINSB xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 38 /r VPMINSB ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 38 /r VPMINSB zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.WIG EA /r VPMINSW xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG EA /r VPMINSW ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG EA /r VPMINSW zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed word integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.</td>, <td colspan="5">NOTES: 1. See note in Section 2.4, “AVX and SSE Instruction Exception Specification” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 2A</em> and Section 22.25.3, “Exception Conditions of Legacy SIMD Instructions Operating on MMX Registers” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 3A</em>.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#MF</td>, <td>(64-bit operations only) If there is a pending x87 FPU exception.</td>]

[<td>66 0F 38 39 /r PMINSD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed signed dword integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.</td>, <td>VEX.128.66.0F38.WIG 39 /r VPMINSD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.</td>, <td>VEX.256.66.0F38.WIG 39 /r VPMINSD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed dword integers in ymm2 and ymm3/m128 and store packed minimum values in ymm1.</td>, <td>EVEX.128.66.0F38.W0 39 /r VPMINSD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 39 /r VPMINSD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed dword integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 39 /r VPMINSD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed signed dword integers in zmm2 and zmm3/m512/m32bcst and store packed minimum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F38.W1 39 /r VPMINSQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed qword integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 39 /r VPMINSQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed qword integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 39 /r VPMINSQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed signed qword integers in zmm2 and zmm3/m512/m64bcst and store packed minimum values in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 38 39 /r PMINSD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed signed dword integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.</td>, <td>VEX.128.66.0F38.WIG 39 /r VPMINSD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.</td>, <td>VEX.256.66.0F38.WIG 39 /r VPMINSD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed dword integers in ymm2 and ymm3/m128 and store packed minimum values in ymm1.</td>, <td>EVEX.128.66.0F38.W0 39 /r VPMINSD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed dword integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 39 /r VPMINSD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed dword integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 39 /r VPMINSD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed signed dword integers in zmm2 and zmm3/m512/m32bcst and store packed minimum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F38.W1 39 /r VPMINSQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed qword integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 39 /r VPMINSQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed qword integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 39 /r VPMINSQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed signed qword integers in zmm2 and zmm3/m512/m64bcst and store packed minimum values in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F EA /<em>r</em><sup>1</sup> PMINSW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Compare signed word integers in <em>mm2/m64</em> and <em>mm1</em> and return minimum values.</td>, <td>66 0F 38 38 /r PMINSB xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.</td>, <td>66 0F EA /r PMINSW xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed signed word integers in xmm2/m128 and xmm1 and store packed minimum values in xmm1.</td>, <td>VEX.128.66.0F38 38 /r VPMINSB xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.</td>, <td>VEX.128.66.0F EA /r VPMINSW xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed signed word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1.</td>, <td>VEX.256.66.0F38 38 /r VPMINSB ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.</td>, <td>VEX.256.66.0F EA /r VPMINSW ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed signed word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1.</td>, <td>EVEX.128.66.0F38.WIG 38 /r VPMINSB xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 38 /r VPMINSB ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 38 /r VPMINSB zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.WIG EA /r VPMINSW xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG EA /r VPMINSW ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG EA /r VPMINSW zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed word integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.</td>, <td colspan="5">NOTES: 1. See note in Section 2.4, “AVX and SSE Instruction Exception Specification” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 2A</em> and Section 22.25.3, “Exception Conditions of Legacy SIMD Instructions Operating on MMX Registers” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 3A</em>.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#MF</td>, <td>(64-bit operations only) If there is a pending x87 FPU exception.</td>]

[<td>NP 0F DA /<em>r</em><sup>1</sup> PMINUB <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Compare unsigned byte integers in <em>mm2/m64</em> and <em>mm1</em> and returns minimum values.</td>, <td>66 0F DA /r PMINUB xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed unsigned byte integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.</td>, <td>66 0F 38 3A/r PMINUW xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed unsigned word integers in xmm2/m128 and xmm1 and store packed minimum values in xmm1.</td>, <td>VEX.128.66.0F DA /r VPMINUB xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.</td>, <td>VEX.128.66.0F38 3A/r VPMINUW xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed unsigned word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1.</td>, <td>VEX.256.66.0F DA /r VPMINUB ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.</td>, <td>VEX.256.66.0F38 3A/r VPMINUW ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed unsigned word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1.</td>, <td>EVEX.128.66.0F DA /r VPMINUB xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F DA /r VPMINUB ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F DA /r VPMINUB zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed unsigned byte integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F38 3A/r VPMINUW xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38 3A/r VPMINUW ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38 3A/r VPMINUW zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed unsigned word integers in zmm3/m512 and zmm2 and return packed minimum values in zmm1 under writemask k1.</td>, <td colspan="5">NOTES: 1. See note in Section 2.4, “AVX and SSE Instruction Exception Specification” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 2A</em> and Section 22.25.3, “Exception Conditions of Legacy SIMD Instructions Operating on MMX Registers” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 3A</em>.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 38 3B /r PMINUD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed unsigned dword integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.</td>, <td>VEX.128.66.0F38.WIG 3B /r VPMINUD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed unsigned dword integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.</td>, <td>VEX.256.66.0F38.WIG 3B /r VPMINUD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed unsigned dword integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.</td>, <td>EVEX.128.66.0F38.W0 3B /r VPMINUD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned dword integers in xmm2 and xmm3/m128/m32bcst and store packed minimum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 3B /r VPMINUD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned dword integers in ymm2 and ymm3/m256/m32bcst and store packed minimum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 3B /r VPMINUD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed unsigned dword integers in zmm2 and zmm3/m512/m32bcst and store packed minimum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F38.W1 3B /r VPMINUQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned qword integers in xmm2 and xmm3/m128/m64bcst and store packed minimum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 3B /r VPMINUQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned qword integers in ymm2 and ymm3/m256/m64bcst and store packed minimum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 3B /r VPMINUQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed unsigned qword integers in zmm2 and zmm3/m512/m64bcst and store packed minimum values in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 38 3B /r PMINUD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed unsigned dword integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.</td>, <td>VEX.128.66.0F38.WIG 3B /r VPMINUD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed unsigned dword integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.</td>, <td>VEX.256.66.0F38.WIG 3B /r VPMINUD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed unsigned dword integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.</td>, <td>EVEX.128.66.0F38.W0 3B /r VPMINUD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned dword integers in xmm2 and xmm3/m128/m32bcst and store packed minimum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 3B /r VPMINUD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned dword integers in ymm2 and ymm3/m256/m32bcst and store packed minimum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 3B /r VPMINUD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed unsigned dword integers in zmm2 and zmm3/m512/m32bcst and store packed minimum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F38.W1 3B /r VPMINUQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned qword integers in xmm2 and xmm3/m128/m64bcst and store packed minimum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 3B /r VPMINUQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned qword integers in ymm2 and ymm3/m256/m64bcst and store packed minimum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 3B /r VPMINUQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed unsigned qword integers in zmm2 and zmm3/m512/m64bcst and store packed minimum values in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F DA /<em>r</em><sup>1</sup> PMINUB <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Compare unsigned byte integers in <em>mm2/m64</em> and <em>mm1</em> and returns minimum values.</td>, <td>66 0F DA /r PMINUB xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare packed unsigned byte integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1.</td>, <td>66 0F 38 3A/r PMINUW xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Compare packed unsigned word integers in xmm2/m128 and xmm1 and store packed minimum values in xmm1.</td>, <td>VEX.128.66.0F DA /r VPMINUB xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1.</td>, <td>VEX.128.66.0F38 3A/r VPMINUW xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare packed unsigned word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1.</td>, <td>VEX.256.66.0F DA /r VPMINUB ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1.</td>, <td>VEX.256.66.0F38 3A/r VPMINUW ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Compare packed unsigned word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1.</td>, <td>EVEX.128.66.0F DA /r VPMINUB xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned byte integers in xmm2 and xmm3/m128 and store packed minimum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F DA /r VPMINUB ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned byte integers in ymm2 and ymm3/m256 and store packed minimum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F DA /r VPMINUB zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed unsigned byte integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F38 3A/r VPMINUW xmm1{k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned word integers in xmm3/m128 and xmm2 and return packed minimum values in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38 3A/r VPMINUW ymm1{k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned word integers in ymm3/m256 and ymm2 and return packed minimum values in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38 3A/r VPMINUW zmm1{k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed unsigned word integers in zmm3/m512 and zmm2 and return packed minimum values in zmm1 under writemask k1.</td>, <td colspan="5">NOTES: 1. See note in Section 2.4, “AVX and SSE Instruction Exception Specification” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 2A</em> and Section 22.25.3, “Exception Conditions of Legacy SIMD Instructions Operating on MMX Registers” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 3A</em>.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F D7 /<em>r</em><sup>1</sup> PMOVMSKB <em>reg</em>, <em>mm</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE</td>, <td>Move a byte mask of <em>mm</em> to <em>reg</em>. The upper bits of r32 or r64 are zeroed</td>, <td>66 0F D7 /<em>r</em> PMOVMSKB <em>reg</em>, <em>xmm</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move a byte mask of <em>xmm</em> to <em>reg</em>. The upper bits of r32 or r64 are zeroed</td>, <td>VEX.128.66.0F.WIG D7 /r VPMOVMSKB <em>reg, xmm1</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Move a byte mask of <em>xmm1</em> to <em>reg</em>. The upper bits of r32 or r64 are filled with zeros.</td>, <td>VEX.256.66.0F.WIG D7 /r VPMOVMSKB <em>reg, ymm1</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Move a 32-bit mask of <em>ymm1</em> to <em>reg</em>. The upper bits of r64 are filled with zeros.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>66 0f 38 20 /r PMOVSXBW xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.</td>, <td>66 0f 38 21 /r PMOVSXBD xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.</td>, <td>66 0f 38 22 /r PMOVSXBQ xmm1, xmm2/m16</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.</td>, <td>66 0f 38 23/r PMOVSXWD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.</td>, <td>66 0f 38 24 /r PMOVSXWQ xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.</td>, <td>66 0f 38 25 /r PMOVSXDQ xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.</td>, <td>VEX.128.66.0F38.WIG 20 /r VPMOVSXBW xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.</td>, <td>VEX.128.66.0F38.WIG 21 /r VPMOVSXBD xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.</td>, <td>VEX.128.66.0F38.WIG 22 /r VPMOVSXBQ xmm1, xmm2/m16</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.</td>, <td>VEX.128.66.0F38.WIG 23 /r VPMOVSXWD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.</td>, <td>VEX.128.66.0F38.WIG 24 /r VPMOVSXWQ xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.</td>, <td>VEX.128.66.0F38.WIG 25 /r VPMOVSXDQ xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.</td>, <td>VEX.256.66.0F38.WIG 20 /r VPMOVSXBW ymm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Sign extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.</td>, <td>VEX.256.66.0F38.WIG 21 /r VPMOVSXBD ymm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1.</td>, <td>VEX.256.66.0F38.WIG 22 /r VPMOVSXBQ ymm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1.</td>, <td>VEX.256.66.0F38.WIG 23 /r VPMOVSXWD ymm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Sign extend 8 packed 16-bit integers in the low 16 bytes of xmm2/m128 to 8 packed 32-bit integers in ymm1.</td>, <td>VEX.256.66.0F38.WIG 24 /r VPMOVSXWQ ymm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1.</td>, <td>VEX.256.66.0F38.WIG 25 /r VPMOVSXDQ ymm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Sign extend 4 packed 32-bit integers in the low 16 bytes of xmm2/m128 to 4 packed 64-bit integers in ymm1.</td>, <td>EVEX.128.66.0F38.WIG 20 /r VPMOVSXBW xmm1 {k1}{z}, xmm2/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sign extend 8 packed 8-bit integers in xmm2/m64 to 8 packed 16-bit integers in zmm1.</td>, <td>EVEX.256.66.0F38.WIG 20 /r VPMOVSXBW ymm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sign extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.</td>, <td>EVEX.512.66.0F38.WIG 20 /r VPMOVSXBW zmm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sign extend 32 packed 8-bit integers in ymm2/m256 to 32 packed 16-bit integers in zmm1.</td>, <td>EVEX.128.66.0F38.WIG 21 /r VPMOVSXBD xmm1 {k1}{z}, xmm2/m32</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 21 /r VPMOVSXBD ymm1 {k1}{z}, xmm2/m64</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 21 /r VPMOVSXBD zmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Sign extend 16 packed 8-bit integers in the low 16 bytes of xmm2/m128 to 16 packed 32-bit integers in zmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.WIG 22 /r VPMOVSXBQ xmm1 {k1}{z}, xmm2/m16</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 22 /r VPMOVSXBQ ymm1 {k1}{z}, xmm2/m32</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 22 /r VPMOVSXBQ zmm1 {k1}{z}, xmm2/m64</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 64-bit integers in zmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.WIG 23 /r VPMOVSXWD xmm1 {k1}{z}, xmm2/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Sign extend 4 packed 16-bit integers in the low 8 bytes of ymm2/mem to 4 packed 32-bit integers in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 23 /r VPMOVSXWD ymm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Sign extend 8 packed 16-bit integers in the low 16 bytes of ymm2/m128 to 8 packed 32-bit integers in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 23 /r VPMOVSXWD zmm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Sign extend 16 packed 16-bit integers in the low 32 bytes of ymm2/m256 to 16 packed 32-bit integers in zmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.WIG 24 /r VPMOVSXWQ xmm1 {k1}{z}, xmm2/m32</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 24 /r VPMOVSXWQ ymm1 {k1}{z}, xmm2/m64</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 24 /r VPMOVSXWQ zmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Sign extend 8 packed 16-bit integers in the low 16 bytes of xmm2/m128 to 8 packed 64-bit integers in zmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 25 /r VPMOVSXDQ xmm1 {k1}{z}, xmm2/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in zmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 25 /r VPMOVSXDQ ymm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Sign extend 4 packed 32-bit integers in the low 16 bytes of xmm2/m128 to 4 packed 64-bit integers in zmm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 25 /r VPMOVSXDQ zmm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Sign extend 8 packed 32-bit integers in the low 32 bytes of ymm2/m256 to 8 packed 64-bit integers in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Half Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Quarter Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Eighth Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B, or EVEX.vvvv != 1111B.</td>]

[<td>66 0f 38 30 /r PMOVZXBW xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.</td>, <td>66 0f 38 31 /r PMOVZXBD xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.</td>, <td>66 0f 38 32 /r PMOVZXBQ xmm1, xmm2/m16</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.</td>, <td>66 0f 38 33 /r PMOVZXWD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.</td>, <td>66 0f 38 34 /r PMOVZXWQ xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.</td>, <td>66 0f 38 35 /r PMOVZXDQ xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.</td>, <td>VEX.128.66.0F38.WIG 30 /r VPMOVZXBW xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.</td>, <td>VEX.128.66.0F38.WIG 31 /r VPMOVZXBD xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1.</td>, <td>VEX.128.66.0F38.WIG 32 /r VPMOVZXBQ xmm1, xmm2/m16</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1.</td>, <td>VEX.128.66.0F38.WIG 33 /r VPMOVZXWD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1.</td>, <td>VEX.128.66.0F38.WIG 34 /r VPMOVZXWQ xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1.</td>, <td>VEX.128.66.0F 38.WIG 35 /r VPMOVZXDQ xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1.</td>, <td>VEX.256.66.0F38.WIG 30 /r VPMOVZXBW ymm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.</td>, <td>VEX.256.66.0F38.WIG 31 /r VPMOVZXBD ymm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1.</td>, <td>VEX.256.66.0F38.WIG 32 /r VPMOVZXBQ ymm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1.</td>, <td>VEX.256.66.0F38.WIG 33 /r VPMOVZXWD ymm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Zero extend 8 packed 16-bit integers xmm2/m128 to 8 packed 32-bit integers in ymm1.</td>, <td>VEX.256.66.0F38.WIG 34 /r VPMOVZXWQ ymm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in xmm1.</td>, <td>VEX.256.66.0F38.WIG 35 /r VPMOVZXDQ ymm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Zero extend 4 packed 32-bit integers in xmm2/m128 to 4 packed 64-bit integers in ymm1.</td>, <td>EVEX.128.66.0F38 30.WIG /r VPMOVZXBW xmm1 {k1}{z}, xmm2/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1.</td>, <td>EVEX.256.66.0F38.WIG 30 /r VPMOVZXBW ymm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 16-bit integers in ymm1.</td>, <td>EVEX.512.66.0F38.WIG 30 /r VPMOVZXBW zmm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Zero extend 32 packed 8-bit integers in ymm2/m256 to 32 packed 16-bit integers in zmm1.</td>, <td>EVEX.128.66.0F38.WIG 31 /r VPMOVZXBD xmm1 {k1}{z}, xmm2/m32</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 31 /r VPMOVZXBD ymm1 {k1}{z}, xmm2/m64</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 32-bit integers in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 31 /r VPMOVZXBD zmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 32-bit integers in zmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.WIG 32 /r VPMOVZXBQ xmm1 {k1}{z}, xmm2/m16</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 32 /r VPMOVZXBQ ymm1 {k1}{z}, xmm2/m32</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 64-bit integers in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 32 /r VPMOVZXBQ zmm1 {k1}{z}, xmm2/m64</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 64-bit integers in zmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.WIG 33 /r VPMOVZXWD xmm1 {k1}{z}, xmm2/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 33 /r VPMOVZXWD ymm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Zero extend 8 packed 16-bit integers in xmm2/m128 to 8 packed 32-bit integers in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 33 /r VPMOVZXWD zmm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Zero extend 16 packed 16-bit integers in ymm2/m256 to 16 packed 32-bit integers in zmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.WIG 34 /r VPMOVZXWQ xmm1 {k1}{z}, xmm2/m32</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 34 /r VPMOVZXWQ ymm1 {k1}{z}, xmm2/m64</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 64-bit integers in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 34 /r VPMOVZXWQ zmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Zero extend 8 packed 16-bit integers in xmm2/m128 to 8 packed 64-bit integers in zmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 35 /r VPMOVZXDQ xmm1 {k1}{z}, xmm2/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in zmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 35 /r VPMOVZXDQ ymm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Zero extend 4 packed 32-bit integers in xmm2/m128 to 4 packed 64-bit integers in zmm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 35 /r VPMOVZXDQ zmm1 {k1}{z}, ymm2/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Zero extend 8 packed 32-bit integers in ymm2/m256 to 8 packed 64-bit integers in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Half Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Quarter Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Eighth Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B, or EVEX.vvvv != 1111B.</td>]

[<td>66 0F 38 28 /r PMULDQ xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Multiply packed signed doubleword integers in xmm1 by packed signed doubleword integers in xmm2/m128, and store the quadword results in xmm1.</td>, <td>VEX.128.66.0F38.WIG 28 /r VPMULDQ xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply packed signed doubleword integers in xmm2 by packed signed doubleword integers in xmm3/m128, and store the quadword results in xmm1.</td>, <td>VEX.256.66.0F38.WIG 28 /r VPMULDQ ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Multiply packed signed doubleword integers in ymm2 by packed signed doubleword integers in ymm3/m256, and store the quadword results in ymm1.</td>, <td>EVEX.128.66.0F38.W1 28 /r VPMULDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed signed doubleword integers in xmm2 by packed signed doubleword integers in xmm3/m128/m64bcst, and store the quadword results in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 28 /r VPMULDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed signed doubleword integers in ymm2 by packed signed doubleword integers in ymm3/m256/m64bcst, and store the quadword results in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 28 /r VPMULDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed signed doubleword integers in zmm2 by packed signed doubleword integers in zmm3/m512/m64bcst, and store the quadword results in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 38 0B /r<sup>1</sup> PMULHRSW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to <em>mm1</em>.</td>, <td>66 0F 38 0B /r PMULHRSW <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.WIG 0B /r VPMULHRSW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.WIG 0B /r VPMULHRSW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to <em>ymm1</em>.</td>, <td>EVEX.128.66.0F38.WIG 0B /r VPMULHRSW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.WIG 0B /r VPMULHRSW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.WIG 0B /r VPMULHRSW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F E4 /<em>r</em><sup>1</sup> PMULHUW <em>mm1</em>, <em>mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Multiply the packed unsigned word integers in <em>mm1</em> register and <em>mm2/m64</em>, and store the high 16 bits of the results in <em>mm1</em>.</td>, <td>66 0F E4 /<em>r</em> PMULHUW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Multiply the packed unsigned word integers in <em>xmm1</em> and <em>xmm2/m128</em>, and store the high 16 bits of the results in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG E4 /r VPMULHUW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply the packed unsigned word integers in <em>xmm2</em> and <em>xmm3/m128</em>, and store the high 16 bits of the results in <em>xmm1</em>.</td>, <td>VEX.256.66.0F.WIG E4 /r VPMULHUW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Multiply the packed unsigned word integers in <em>ymm2</em> and <em>ymm3/m256</em>, and store the high 16 bits of the results in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.WIG E4 /r VPMULHUW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Multiply the packed unsigned word integers in xmm2 and xmm3/m128, and store the high 16 bits of the results in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG E4 /r VPMULHUW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Multiply the packed unsigned word integers in ymm2 and ymm3/m256, and store the high 16 bits of the results in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG E4 /r VPMULHUW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Multiply the packed unsigned word integers in zmm2 and zmm3/m512, and store the high 16 bits of the results in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F E5 /<em>r</em><sup>1</sup> PMULHW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Multiply the packed signed word integers in <em>mm1</em> register and <em>mm2/m64</em>, and store the high 16 bits of the results in <em>mm1</em>.</td>, <td>66 0F E5 /<em>r</em> PMULHW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Multiply the packed signed word integers in <em>xmm1</em> and <em>xmm2/m128</em>, and store the high 16 bits of the results in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG E5 /r VPMULHW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply the packed signed word integers in <em>xmm2</em> and <em>xmm3/m128</em>, and store the high 16 bits of the results in <em>xmm1</em>.</td>, <td>VEX.256.66.0F.WIG E5 /r VPMULHW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Multiply the packed signed word integers in <em>ymm2</em> and <em>ymm3/m256</em>, and store the high 16 bits of the results in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.WIG E5 /r VPMULHW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Multiply the packed signed word integers in xmm2 and xmm3/m128, and store the high 16 bits of the results in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG E5 /r VPMULHW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Multiply the packed signed word integers in ymm2 and ymm3/m256, and store the high 16 bits of the results in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG E5 /r VPMULHW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Multiply the packed signed word integers in zmm2 and zmm3/m512, and store the high 16 bits of the results in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 38 40 /r PMULLD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Multiply the packed dword signed integers in xmm1 and xmm2/m128 and store the low 32 bits of each product in xmm1.</td>, <td>VEX.128.66.0F38.WIG 40 /r VPMULLD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply the packed dword signed integers in xmm2 and xmm3/m128 and store the low 32 bits of each product in xmm1.</td>, <td>VEX.256.66.0F38.WIG 40 /r VPMULLD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Multiply the packed dword signed integers in ymm2 and ymm3/m256 and store the low 32 bits of each product in ymm1.</td>, <td>EVEX.128.66.0F38.W0 40 /r VPMULLD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply the packed dword signed integers in xmm2 and xmm3/m128/m32bcst and store the low 32 bits of each product in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 40 /r VPMULLD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply the packed dword signed integers in ymm2 and ymm3/m256/m32bcst and store the low 32 bits of each product in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 40 /r VPMULLD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply the packed dword signed integers in zmm2 and zmm3/m512/m32bcst and store the low 32 bits of each product in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F38.W1 40 /r VPMULLQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Multiply the packed qword signed integers in xmm2 and xmm3/m128/m64bcst and store the low 64 bits of each product in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 40 /r VPMULLQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Multiply the packed qword signed integers in ymm2 and ymm3/m256/m64bcst and store the low 64 bits of each product in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 40 /r VPMULLQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Multiply the packed qword signed integers in zmm2 and zmm3/m512/m64bcst and store the low 64 bits of each product in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 38 40 /r PMULLD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Multiply the packed dword signed integers in xmm1 and xmm2/m128 and store the low 32 bits of each product in xmm1.</td>, <td>VEX.128.66.0F38.WIG 40 /r VPMULLD xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply the packed dword signed integers in xmm2 and xmm3/m128 and store the low 32 bits of each product in xmm1.</td>, <td>VEX.256.66.0F38.WIG 40 /r VPMULLD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Multiply the packed dword signed integers in ymm2 and ymm3/m256 and store the low 32 bits of each product in ymm1.</td>, <td>EVEX.128.66.0F38.W0 40 /r VPMULLD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply the packed dword signed integers in xmm2 and xmm3/m128/m32bcst and store the low 32 bits of each product in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 40 /r VPMULLD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply the packed dword signed integers in ymm2 and ymm3/m256/m32bcst and store the low 32 bits of each product in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 40 /r VPMULLD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply the packed dword signed integers in zmm2 and zmm3/m512/m32bcst and store the low 32 bits of each product in zmm1 under writemask k1.</td>, <td>EVEX.128.66.0F38.W1 40 /r VPMULLQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Multiply the packed qword signed integers in xmm2 and xmm3/m128/m64bcst and store the low 64 bits of each product in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 40 /r VPMULLQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Multiply the packed qword signed integers in ymm2 and ymm3/m256/m64bcst and store the low 64 bits of each product in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 40 /r VPMULLQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Multiply the packed qword signed integers in zmm2 and zmm3/m512/m64bcst and store the low 64 bits of each product in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F D5 /<em>r</em><sup>1</sup> PMULLW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Multiply the packed signed word integers in <em>mm1</em> register and <em>mm2/m64</em>, and store the low 16 bits of the results in <em>mm1</em>.</td>, <td>66 0F D5 /<em>r</em> PMULLW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Multiply the packed signed word integers in <em>xmm1</em> and <em>xmm2/m128</em>, and store the low 16 bits of the results in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG D5 /r VPMULLW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply the packed dword signed integers in <em>xmm2</em> and <em>xmm3/m128</em> and store the low 32 bits of each product in <em>xmm1</em>.</td>, <td>VEX.256.66.0F.WIG D5 /r VPMULLW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Multiply the packed signed word integers in <em>ymm2</em> and <em>ymm3/m256</em>, and store the low 16 bits of the results in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.WIG D5 /r VPMULLW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Multiply the packed signed word integers in xmm2 and xmm3/m128, and store the low 16 bits of the results in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.WIG D5 /r VPMULLW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Multiply the packed signed word integers in ymm2 and ymm3/m256, and store the low 16 bits of the results in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.WIG D5 /r VPMULLW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Multiply the packed signed word integers in zmm2 and zmm3/m512, and store the low 16 bits of the results in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F F4 /<em>r</em><sup>1</sup> PMULUDQ <em>mm1</em>, <em>mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Multiply unsigned doubleword integer in <em>mm1</em> by unsigned doubleword integer in <em>mm2/m64</em>, and store the quadword result in <em>mm1</em>.</td>, <td>66 0F F4 /<em>r</em> PMULUDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Multiply packed unsigned doubleword integers in <em>xmm1</em> by packed unsigned doubleword integers in <em>xmm2/m128</em>, and store the quadword results in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG F4 /r VPMULUDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Multiply packed unsigned doubleword integers in <em>xmm2</em> by packed unsigned doubleword integers in <em>xmm3/m128</em>, and store the quadword results in <em>xmm1</em>.</td>, <td>VEX.256.66.0F.WIG F4 /r VPMULUDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Multiply packed unsigned doubleword integers in <em>ymm2</em> by packed unsigned doubleword integers in <em>ymm3/m256</em>, and store the quadword results in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.W1 F4 /r VPMULUDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed unsigned doubleword integers in xmm2 by packed unsigned doubleword integers in xmm3/m128/m64bcst, and store the quadword results in xmm1 under writemask k1.</td>, <td>EVEX.256.66.0F.W1 F4 /r VPMULUDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed unsigned doubleword integers in ymm2 by packed unsigned doubleword integers in ymm3/m256/m64bcst, and store the quadword results in ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F.W1 F4 /r VPMULUDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed unsigned doubleword integers in zmm2 by packed unsigned doubleword integers in zmm3/m512/m64bcst, and store the quadword results in zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>8F /0</td>, <td>POP r/<em>m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Pop top of stack into <em>m16</em>; increment stack pointer.</td>, <td>8F /0</td>, <td>POP r/<em>m32</em></td>, <td>M</td>, <td>N.E.</td>, <td>Valid</td>, <td>Pop top of stack into <em>m32</em>; increment stack pointer.</td>, <td>8F /0</td>, <td>POP r/<em>m64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Pop top of stack into <em>m64</em>; increment stack pointer. Cannot encode 32-bit operand size.</td>, <td>58+ <em>rw</em></td>, <td>POP <em>r16</em></td>, <td>O</td>, <td>Valid</td>, <td>Valid</td>, <td>Pop top of stack into <em>r16</em>; increment stack pointer.</td>, <td>58+ <em>rd</em></td>, <td>POP <em>r32</em></td>, <td>O</td>, <td>N.E.</td>, <td>Valid</td>, <td>Pop top of stack into <em>r32</em>; increment stack pointer.</td>, <td>58+ <em>rd</em></td>, <td>POP <em>r64</em></td>, <td>O</td>, <td>Valid</td>, <td>N.E.</td>, <td>Pop top of stack into <em>r64</em>; increment stack pointer. Cannot encode 32-bit operand size.</td>, <td>1F</td>, <td>POP DS</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Pop top of stack into DS; increment stack pointer.</td>, <td>07</td>, <td>POP ES</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Pop top of stack into ES; increment stack pointer.</td>, <td>17</td>, <td>POP SS</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Pop top of stack into SS; increment stack pointer.</td>, <td>0F A1</td>, <td>POP FS</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Pop top of stack into FS; increment stack pointer by 16 bits.</td>, <td>0F A1</td>, <td>POP FS</td>, <td>ZO</td>, <td>N.E.</td>, <td>Valid</td>, <td>Pop top of stack into FS; increment stack pointer by 32 bits.</td>, <td>0F A1</td>, <td>POP FS</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Pop top of stack into FS; increment stack pointer by 64 bits.</td>, <td>0F A9</td>, <td>POP GS</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Pop top of stack into GS; increment stack pointer by 16 bits.</td>, <td>0F A9</td>, <td>POP GS</td>, <td>ZO</td>, <td>N.E.</td>, <td>Valid</td>, <td>Pop top of stack into GS; increment stack pointer by 32 bits.</td>, <td>0F A9</td>, <td>POP GS</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Pop top of stack into GS; increment stack pointer by 64 bits.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>O</td>, <td>opcode + rd (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="4">#GP(0)</td>, <td>If attempt is made to load SS register with NULL segment selector.</td>, <td>If the destination operand is in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td rowspan="5">#GP(selector)</td>, <td>If segment selector index is outside descriptor table limits.</td>, <td>If the SS register is being loaded and the segment selector's RPL and the segment descriptor’s DPL are not equal to the CPL.</td>, <td>If the SS register is being loaded and the segment pointed to is a non-writable data segment.</td>, <td>If the DS, ES, FS, or GS register is being loaded and the segment pointed to is not a data or readable code segment.</td>, <td>If the DS, ES, FS, or GS register is being loaded and the segment pointed to is a data or nonconforming code segment, but both the RPL and the CPL are greater than the DPL.</td>, <td rowspan="2">#SS(0)</td>, <td>If the current top of stack is not within the stack segment.</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#SS(selector)</td>, <td>If the SS register is being loaded and the segment pointed to is marked not present.</td>, <td>#NP</td>, <td>If the DS, ES, FS, or GS register is being loaded and the segment pointed to is marked not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while the current privilege level is 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#SS(0)</td>, <td>If the stack address is in a non-canonical form.</td>, <td rowspan="3">#GP(selector)</td>, <td>If the descriptor is outside the descriptor table limit.</td>, <td>If the FS or GS register is being loaded and the segment pointed to is not a data or readable code segment.</td>, <td>If the FS or GS register is being loaded and the segment pointed to is a data or nonconforming code segment, but both the RPL and the CPL are greater than the DPL.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while alignment checking is enabled.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#NP</td>, <td>If the FS or GS register is being loaded and the segment pointed to is marked not present.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>61</td>, <td>POPA</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Pop DI, SI, BP, BX, DX, CX, and AX.</td>, <td>61</td>, <td>POPAD</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Pop EDI, ESI, EBP, EBX, EDX, ECX, and EAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#SS(0)</td>, <td>If the starting or ending stack address is not within the stack segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while the current privilege level is 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS</td>, <td>If the starting or ending stack address is not within the stack segment.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If the starting or ending stack address is not within the stack segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If in 64-bit mode.</td>]

[<td>61</td>, <td>POPA</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Pop DI, SI, BP, BX, DX, CX, and AX.</td>, <td>61</td>, <td>POPAD</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Pop EDI, ESI, EBP, EBX, EDX, ECX, and EAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#SS(0)</td>, <td>If the starting or ending stack address is not within the stack segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while the current privilege level is 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS</td>, <td>If the starting or ending stack address is not within the stack segment.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If the starting or ending stack address is not within the stack segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If in 64-bit mode.</td>]

[<td>F3 0F B8 /r</td>, <td>POPCNT <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>POPCNT on <em>r/m16</em></td>, <td>F3 0F B8 /r</td>, <td>POPCNT <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>POPCNT on <em>r/m32</em></td>, <td>F3 REX.W 0F B8 <em>/r</em></td>, <td>POPCNT <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>POPCNT on <em>r/m64</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS or GS segments.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while the current privilege level is 3 and alignment checking is enabled.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:ECX.POPCNT [Bit 23] = 0.</td>, <td>If LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If any part of the operand lies outside of the effective address space from 0 to 0FFFFH.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:ECX.POPCNT [Bit 23] = 0.</td>, <td>If LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If any part of the operand lies outside of the effective address space from 0 to 0FFFFH.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while alignment checking is enabled.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:ECX.POPCNT [Bit 23] = 0.</td>, <td>If LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="2">#UD</td>, <td>If CPUID.01H:ECX.POPCNT [Bit 23] = 0.</td>, <td>If LOCK prefix is used.</td>]

[<td>9D</td>, <td>POPF</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Pop top of stack into lower 16 bits of EFLAGS.</td>, <td>9D</td>, <td>POPFD</td>, <td>ZO</td>, <td>N.E.</td>, <td>Valid</td>, <td>Pop top of stack into EFLAGS.</td>, <td>9D</td>, <td>POPFQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Pop top of stack and zero-extend into RFLAGS.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2"><strong>Real-Address Mode (CR0.PE = 0)</strong></td>, <td>16</td>, <td>0</td>, <td>0-3</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32</td>, <td>0</td>, <td>0-3</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td rowspan="6"><strong>Protected, Compatibility, and 64-Bit Modes (CR0.PE = 1 EFLAGS.VM = 0)</strong></td>, <td>16</td>, <td>0</td>, <td>0-3</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>16</td>, <td>1-3</td>, <td>&lt;CPL</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>16</td>, <td>1-3</td>, <td>≥CPL</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32, 64</td>, <td>0</td>, <td>0-3</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32, 64</td>, <td>1-3</td>, <td>&lt;CPL</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32, 64</td>, <td>1-3</td>, <td>≥CPL</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td rowspan="4"><strong>Virtual-8086 (CR0.PE = 1 EFLAGS.VM = 1 CR4.VME = 0)</strong></td>, <td>16</td>, <td>3</td>, <td>0-2</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>1</td>, <td>16</td>, <td>3</td>, <td>3</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32</td>, <td>3</td>, <td>0-2</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>1</td>, <td>32</td>, <td>3</td>, <td>3</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td rowspan="4"><strong>VME (CR0.PE = 1 EFLAGS.VM = 1 CR4.VME = 1)</strong></td>, <td>16</td>, <td>3</td>, <td>0-2</td>, <td>N/X</td>, <td>N/X</td>, <td>SV/X</td>, <td>N/X</td>, <td>N/X</td>, <td>0/X</td>, <td>S/X</td>, <td>N/X</td>, <td>S/X</td>, <td>S/X</td>, <td>N/X</td>, <td>S/X</td>, <td>S/X</td>, <td>S/X</td>, <td>S/X</td>, <td>S/X</td>, <td>S/X</td>, <td>2,3</td>, <td>16</td>, <td>3</td>, <td>3</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32</td>, <td>3</td>, <td>0-2</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>1</td>, <td>32</td>, <td>3</td>, <td>3</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td><strong>S</strong></td>, <td>Updated from stack</td>, <td><strong>SV</strong></td>, <td>Updated from IF (bit 9) in FLAGS value on stack</td>, <td><strong>N</strong></td>, <td>No change in value</td>, <td><strong>X</strong></td>, <td>No EFLAGS update</td>, <td><strong>0</strong></td>, <td>Value is cleared</td>, <td>#SS(0)</td>, <td>If the top of stack is not within the stack segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while CPL = 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS</td>, <td>If the top of stack is not within the stack segment.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="5">#GP(0)</td>, <td>If IOPL &lt; 3 and VME is not enabled.</td>, <td>If IOPL &lt; 3 and the 32-bit operand size is used.</td>, <td>If IOPL &lt; 3, EFLAGS.VIP = 1, and bit 9 (IF) is set in the FLAGS value on the stack.</td>, <td>If IOPL &lt; 3 and bit 8 (TF) is set in the FLAGS value on the stack.</td>, <td>If an attempt is made to execute the POPF/POPFD instruction with an operand-size override prefix.</td>, <td>#SS(0)</td>, <td>If the top of stack is not within the stack segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#SS(0)</td>, <td>If the stack address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>9D</td>, <td>POPF</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Pop top of stack into lower 16 bits of EFLAGS.</td>, <td>9D</td>, <td>POPFD</td>, <td>ZO</td>, <td>N.E.</td>, <td>Valid</td>, <td>Pop top of stack into EFLAGS.</td>, <td>9D</td>, <td>POPFQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Pop top of stack and zero-extend into RFLAGS.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2"><strong>Real-Address Mode (CR0.PE = 0)</strong></td>, <td>16</td>, <td>0</td>, <td>0-3</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32</td>, <td>0</td>, <td>0-3</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td rowspan="6"><strong>Protected, Compatibility, and 64-Bit Modes (CR0.PE = 1 EFLAGS.VM = 0)</strong></td>, <td>16</td>, <td>0</td>, <td>0-3</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>16</td>, <td>1-3</td>, <td>&lt;CPL</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>16</td>, <td>1-3</td>, <td>≥CPL</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32, 64</td>, <td>0</td>, <td>0-3</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32, 64</td>, <td>1-3</td>, <td>&lt;CPL</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32, 64</td>, <td>1-3</td>, <td>≥CPL</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td rowspan="4"><strong>Virtual-8086 (CR0.PE = 1 EFLAGS.VM = 1 CR4.VME = 0)</strong></td>, <td>16</td>, <td>3</td>, <td>0-2</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>1</td>, <td>16</td>, <td>3</td>, <td>3</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32</td>, <td>3</td>, <td>0-2</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>1</td>, <td>32</td>, <td>3</td>, <td>3</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td rowspan="4"><strong>VME (CR0.PE = 1 EFLAGS.VM = 1 CR4.VME = 1)</strong></td>, <td>16</td>, <td>3</td>, <td>0-2</td>, <td>N/X</td>, <td>N/X</td>, <td>SV/X</td>, <td>N/X</td>, <td>N/X</td>, <td>0/X</td>, <td>S/X</td>, <td>N/X</td>, <td>S/X</td>, <td>S/X</td>, <td>N/X</td>, <td>S/X</td>, <td>S/X</td>, <td>S/X</td>, <td>S/X</td>, <td>S/X</td>, <td>S/X</td>, <td>2,3</td>, <td>16</td>, <td>3</td>, <td>3</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32</td>, <td>3</td>, <td>0-2</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>1</td>, <td>32</td>, <td>3</td>, <td>3</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td><strong>S</strong></td>, <td>Updated from stack</td>, <td><strong>SV</strong></td>, <td>Updated from IF (bit 9) in FLAGS value on stack</td>, <td><strong>N</strong></td>, <td>No change in value</td>, <td><strong>X</strong></td>, <td>No EFLAGS update</td>, <td><strong>0</strong></td>, <td>Value is cleared</td>, <td>#SS(0)</td>, <td>If the top of stack is not within the stack segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while CPL = 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS</td>, <td>If the top of stack is not within the stack segment.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="5">#GP(0)</td>, <td>If IOPL &lt; 3 and VME is not enabled.</td>, <td>If IOPL &lt; 3 and the 32-bit operand size is used.</td>, <td>If IOPL &lt; 3, EFLAGS.VIP = 1, and bit 9 (IF) is set in the FLAGS value on the stack.</td>, <td>If IOPL &lt; 3 and bit 8 (TF) is set in the FLAGS value on the stack.</td>, <td>If an attempt is made to execute the POPF/POPFD instruction with an operand-size override prefix.</td>, <td>#SS(0)</td>, <td>If the top of stack is not within the stack segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#SS(0)</td>, <td>If the stack address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>9D</td>, <td>POPF</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Pop top of stack into lower 16 bits of EFLAGS.</td>, <td>9D</td>, <td>POPFD</td>, <td>ZO</td>, <td>N.E.</td>, <td>Valid</td>, <td>Pop top of stack into EFLAGS.</td>, <td>9D</td>, <td>POPFQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Pop top of stack and zero-extend into RFLAGS.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2"><strong>Real-Address Mode (CR0.PE = 0)</strong></td>, <td>16</td>, <td>0</td>, <td>0-3</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32</td>, <td>0</td>, <td>0-3</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td rowspan="6"><strong>Protected, Compatibility, and 64-Bit Modes (CR0.PE = 1 EFLAGS.VM = 0)</strong></td>, <td>16</td>, <td>0</td>, <td>0-3</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>16</td>, <td>1-3</td>, <td>&lt;CPL</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>16</td>, <td>1-3</td>, <td>≥CPL</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32, 64</td>, <td>0</td>, <td>0-3</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32, 64</td>, <td>1-3</td>, <td>&lt;CPL</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32, 64</td>, <td>1-3</td>, <td>≥CPL</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td rowspan="4"><strong>Virtual-8086 (CR0.PE = 1 EFLAGS.VM = 1 CR4.VME = 0)</strong></td>, <td>16</td>, <td>3</td>, <td>0-2</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>1</td>, <td>16</td>, <td>3</td>, <td>3</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32</td>, <td>3</td>, <td>0-2</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>1</td>, <td>32</td>, <td>3</td>, <td>3</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td rowspan="4"><strong>VME (CR0.PE = 1 EFLAGS.VM = 1 CR4.VME = 1)</strong></td>, <td>16</td>, <td>3</td>, <td>0-2</td>, <td>N/X</td>, <td>N/X</td>, <td>SV/X</td>, <td>N/X</td>, <td>N/X</td>, <td>0/X</td>, <td>S/X</td>, <td>N/X</td>, <td>S/X</td>, <td>S/X</td>, <td>N/X</td>, <td>S/X</td>, <td>S/X</td>, <td>S/X</td>, <td>S/X</td>, <td>S/X</td>, <td>S/X</td>, <td>2,3</td>, <td>16</td>, <td>3</td>, <td>3</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td>32</td>, <td>3</td>, <td>0-2</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>X</td>, <td>1</td>, <td>32</td>, <td>3</td>, <td>3</td>, <td>S</td>, <td>N</td>, <td>N</td>, <td>S</td>, <td>N</td>, <td>0</td>, <td>S</td>, <td>N</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td>S</td>, <td></td>, <td><strong>S</strong></td>, <td>Updated from stack</td>, <td><strong>SV</strong></td>, <td>Updated from IF (bit 9) in FLAGS value on stack</td>, <td><strong>N</strong></td>, <td>No change in value</td>, <td><strong>X</strong></td>, <td>No EFLAGS update</td>, <td><strong>0</strong></td>, <td>Value is cleared</td>, <td>#SS(0)</td>, <td>If the top of stack is not within the stack segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while CPL = 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS</td>, <td>If the top of stack is not within the stack segment.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="5">#GP(0)</td>, <td>If IOPL &lt; 3 and VME is not enabled.</td>, <td>If IOPL &lt; 3 and the 32-bit operand size is used.</td>, <td>If IOPL &lt; 3, EFLAGS.VIP = 1, and bit 9 (IF) is set in the FLAGS value on the stack.</td>, <td>If IOPL &lt; 3 and bit 8 (TF) is set in the FLAGS value on the stack.</td>, <td>If an attempt is made to execute the POPF/POPFD instruction with an operand-size override prefix.</td>, <td>#SS(0)</td>, <td>If the top of stack is not within the stack segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#SS(0)</td>, <td>If the stack address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>NP 0F EB /<em>r</em><sup>1</sup> POR <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Bitwise OR of <em>mm/m64</em> and <em>mm</em>.</td>, <td>66 0F EB /<em>r</em> POR <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Bitwise OR of <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG EB /r VPOR <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Bitwise OR of <em>xmm2/m128</em> and <em>xmm3</em>.</td>, <td>VEX.256.66.0F.WIG EB /r VPOR <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Bitwise OR of <em>ymm2/m256</em> and <em>ymm3</em>.</td>, <td>EVEX.128.66.0F.W0 EB /r VPORD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise OR of packed doubleword integers in xmm2 and xmm3/m128/m32bcst using writemask k1.</td>, <td>EVEX.256.66.0F.W0 EB /r VPORD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise OR of packed doubleword integers in ymm2 and ymm3/m256/m32bcst using writemask k1.</td>, <td>EVEX.512.66.0F.W0 EB /r VPORD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise OR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1.</td>, <td>EVEX.128.66.0F.W1 EB /r VPORQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise OR of packed quadword integers in xmm2 and xmm3/m128/m64bcst using writemask k1.</td>, <td>EVEX.256.66.0F.W1 EB /r VPORQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise OR of packed quadword integers in ymm2 and ymm3/m256/m64bcst using writemask k1.</td>, <td>EVEX.512.66.0F.W1 EB /r VPORQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise OR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>0F 0D /1 PREFETCHW m8</td>, <td>A</td>, <td>V/V</td>, <td>PREFETCHW</td>, <td>Move data from m8 closer to the processor in anticipation of a write.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 18 /1</td>, <td>PREFETCHT0 <em>m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Move data from <em>m8</em> closer to the processor using T0 hint.</td>, <td>0F 18 /2</td>, <td>PREFETCHT1 <em>m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Move data from <em>m8</em> closer to the processor using T1 hint.</td>, <td>0F 18 /3</td>, <td>PREFETCHT2 <em>m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Move data from <em>m8</em> closer to the processor using T2 hint.</td>, <td>0F 18 /0</td>, <td>PREFETCHNTA <em>m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Move data from <em>m8</em> closer to the processor using NTA hint.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>NP 0F F6 /<em>r</em><sup>1</sup> PSADBW <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Computes the absolute differences of the packed unsigned byte integers from <em>mm2 /m64</em> and <em>mm1</em>; differences are then summed to produce an unsigned word integer result.</td>, <td>66 0F F6 /<em>r</em> PSADBW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Computes the absolute differences of the packed unsigned byte integers from <em>xmm2 /m128</em> and <em>xmm1</em>; the 8 low differences and 8 high differences are then summed separately to produce two unsigned word integer results.</td>, <td>VEX.128.66.0F.WIG F6 /r VPSADBW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Computes the absolute differences of the packed unsigned byte integers from <em>xmm3 /m128</em> and <em>xmm2</em>; the 8 low differences and 8 high differences are then summed separately to produce two unsigned word integer results.</td>, <td>VEX.256.66.0F.WIG F6 /r VPSADBW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Computes the absolute differences of the packed unsigned byte integers from <em>ymm3 /m256</em> and <em>ymm2</em>; then each consecutive 8 differences are summed separately to produce four unsigned word integer results.</td>, <td>EVEX.128.66.0F.WIG F6 /r VPSADBW xmm1, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Computes the absolute differences of the packed unsigned byte integers from xmm3 /m128 and xmm2; then each consecutive 8 differences are summed separately to produce four unsigned word integer results.</td>, <td>EVEX.256.66.0F.WIG F6 /r VPSADBW ymm1, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Computes the absolute differences of the packed unsigned byte integers from ymm3 /m256 and ymm2; then each consecutive 8 differences are summed separately to produce four unsigned word integer results.</td>, <td>EVEX.512.66.0F.WIG F6 /r VPSADBW zmm1, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Computes the absolute differences of the packed unsigned byte integers from zmm3 /m512 and zmm2; then each consecutive 8 differences are summed separately to produce four unsigned word integer results.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 38 00 /r<sup>1</sup> PSHUFB <em>mm1, mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Shuffle bytes in <em>mm1</em> according to contents of <em>mm2/m64</em>.</td>, <td>66 0F 38 00 /r PSHUFB <em>xmm1, xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Shuffle bytes in <em>xmm1</em> according to contents of <em>xmm2/m128</em>.</td>, <td>VEX.128.66.0F38.WIG 00 /r VPSHUFB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Shuffle bytes in <em>xmm2</em> according to contents of <em>xmm3/m128</em>.</td>, <td>VEX.256.66.0F38.WIG 00 /r VPSHUFB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shuffle bytes in <em>ymm2</em> according to contents of <em>ymm3/m256</em>.</td>, <td>EVEX.128.66.0F38.WIG 00 /r VPSHUFB xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shuffle bytes in xmm2 according to contents of xmm3/m128 under write mask k1.</td>, <td>EVEX.256.66.0F38.WIG 00 /r VPSHUFB ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shuffle bytes in ymm2 according to contents of ymm3/m256 under write mask k1.</td>, <td>EVEX.512.66.0F38.WIG 00 /r VPSHUFB zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shuffle bytes in zmm2 according to contents of zmm3/m512 under write mask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 70 /<em>r</em> ib PSHUFD <em>xmm1</em>, <em>xmm2/m128</em>, <em>imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shuffle the doublewords in <em>xmm2/m128</em> based on the encoding in <em>imm8</em> and store the result in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 70 /r ib VPSHUFD <em>xmm1, xmm2/m128, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Shuffle the doublewords in <em>xmm2/m128</em> based on the encoding in <em>imm8</em> and store the result in <em>xmm1</em>.</td>, <td>VEX.256.66.0F.WIG 70 /r ib VPSHUFD <em>ymm1, ymm2/m256, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shuffle the doublewords in <em>ymm2/m256</em> based on the encoding in <em>imm8</em> and store the result in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.W0 70 /r ib VPSHUFD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle the doublewords in xmm2/m128/m32bcst based on the encoding in imm8 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W0 70 /r ib VPSHUFD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle the doublewords in ymm2/m256/m32bcst based on the encoding in imm8 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 70 /r ib VPSHUFD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle the doublewords in zmm2/m512/m32bcst based on the encoding in imm8 and store the result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv ≠ 1111B or EVEX.vvvv ≠ 1111B.</td>]

[<td>F3 0F 70 /<em>r</em> ib PSHUFHW <em>xmm1</em>, <em>xmm2/m128</em>, <em>imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shuffle the high words in <em>xmm2/m128</em> based on the encoding in <em>imm8</em> and store the result in <em>xmm1</em>.</td>, <td>VEX.128.F3.0F.WIG 70 /r ib VPSHUFHW <em>xmm1, xmm2/m128, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Shuffle the high words in <em>xmm2/m128</em> based on the encoding in <em>imm8</em> and store the result in <em>xmm1</em>.</td>, <td>VEX.256.F3.0F.WIG 70 /r ib VPSHUFHW <em>ymm1, ymm2/m256, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shuffle the high words in <em>ymm2/m256</em> based on the encoding in <em>imm8</em> and store the result in <em>ymm1</em>.</td>, <td>EVEX.128.F3.0F.WIG 70 /r ib VPSHUFHW xmm1 {k1}{z}, xmm2/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shuffle the high words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1 under write mask k1.</td>, <td>EVEX.256.F3.0F.WIG 70 /r ib VPSHUFHW ymm1 {k1}{z}, ymm2/m256, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shuffle the high words in ymm2/m256 based on the encoding in imm8 and store the result in ymm1 under write mask k1.</td>, <td>EVEX.512.F3.0F.WIG 70 /r ib VPSHUFHW zmm1 {k1}{z}, zmm2/m512, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shuffle the high words in zmm2/m512 based on the encoding in imm8 and store the result in zmm1 under write mask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B, or EVEX.vvvv != 1111B.</td>]

[<td>F2 0F 70 /<em>r</em> ib PSHUFLW <em>xmm1</em>, <em>xmm2/m128</em>, <em>imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shuffle the low words in <em>xmm2/m128</em> based on the encoding in <em>imm8</em> and store the result in <em>xmm1</em>.</td>, <td>VEX.128.F2.0F.WIG 70 /r ib VPSHUFLW <em>xmm1, xmm2/m128, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Shuffle the low words in <em>xmm2/m128</em> based on the encoding in <em>imm8</em> and store the result in <em>xmm1</em>.</td>, <td>VEX.256.F2.0F.WIG 70 /r ib VPSHUFLW <em>ymm1, ymm2/m256, imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shuffle the low words in <em>ymm2/m256</em> based on the encoding in <em>imm8</em> and store the result in <em>ymm1</em>.</td>, <td>EVEX.128.F2.0F.WIG 70 /r ib VPSHUFLW xmm1 {k1}{z}, xmm2/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1 under write mask k1.</td>, <td>EVEX.256.F2.0F.WIG 70 /r ib VPSHUFLW ymm1 {k1}{z}, ymm2/m256, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shuffle the low words in ymm2/m256 based on the encoding in imm8 and store the result in ymm1 under write mask k1.</td>, <td>EVEX.512.F2.0F.WIG 70 /r ib VPSHUFLW zmm1 {k1}{z}, zmm2/m512, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shuffle the low words in zmm2/m512 based on the encoding in imm8 and store the result in zmm1 under write mask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B, or EVEX.vvvv != 1111B.</td>]

[<td>NP 0F 70 /<em>r</em> ib PSHUFW <em>mm1, mm2/m64, imm8</em></td>, <td>RMI</td>, <td>Valid</td>, <td>Valid</td>, <td>Shuffle the words in <em>mm2/m64</em> based on the encoding in <em>imm8</em> and store the result in <em>mm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMI</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>]

[<td>NP 0F 38 08 /r<sup>1</sup> PSIGNB <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed byte integers in <em>mm1</em> depending on the corresponding sign in <em>mm2/m64.</em></td>, <td>66 0F 38 08 /r PSIGNB <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed byte integers in <em>xmm1</em> depending on the corresponding sign in <em>xmm2/m128</em>.</td>, <td>NP 0F 38 09 /r<sup>1</sup> PSIGNW <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed word integers in <em>mm1</em> depending on the corresponding sign in <em>mm2/m128</em>.</td>, <td>66 0F 38 09 /r PSIGNW <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed word integers in <em>xmm1</em> depending on the corresponding sign in <em>xmm2/m128</em>.</td>, <td>NP 0F 38 0A /r<sup>1</sup> PSIGND <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed doubleword integers in <em>mm1</em> depending on the corresponding sign in <em>mm2/m128</em>.</td>, <td>66 0F 38 0A /r PSIGND <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed doubleword integers in <em>xmm1</em> depending on the corresponding sign in <em>xmm2/m128</em>.</td>, <td>VEX.128.66.0F38.WIG 08 /r VPSIGNB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Negate/zero/preserve packed byte integers in <em>xmm2</em> depending on the corresponding sign in <em>xmm3/m128</em>.</td>, <td>VEX.128.66.0F38.WIG 09 /r VPSIGNW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Negate/zero/preserve packed word integers in <em>xmm2</em> depending on the corresponding sign in <em>xmm3/m128</em>.</td>, <td>VEX.128.66.0F38.WIG 0A /r VPSIGND <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Negate/zero/preserve packed doubleword integers in <em>xmm2</em> depending on the corresponding sign in <em>xmm3/m128</em>.</td>, <td>VEX.256.66.0F38.WIG 08 /r VPSIGNB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Negate packed byte integers in <em>ymm2</em> if the corresponding sign in <em>ymm3/m256</em> is less than zero.</td>, <td>VEX.256.66.0F38.WIG 09 /r VPSIGNW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Negate packed 16-bit integers in <em>ymm2</em> if the corresponding sign in <em>ymm3/m256</em> is less than zero.</td>, <td>VEX.256.66.0F38.WIG 0A /r VPSIGND <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Negate packed doubleword integers in <em>ymm2</em> if the corresponding sign in <em>ymm3/m256</em> is less than zero.</td>, <td colspan="5">NOTES: 1. See note in Section 2.4, “AVX and SSE Instruction Exception Specification” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 2A</em> and Section 22.25.3, “Exception Conditions of Legacy SIMD Instructions Operating on MMX Registers” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 3A</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>NP 0F 38 08 /r<sup>1</sup> PSIGNB <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed byte integers in <em>mm1</em> depending on the corresponding sign in <em>mm2/m64.</em></td>, <td>66 0F 38 08 /r PSIGNB <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed byte integers in <em>xmm1</em> depending on the corresponding sign in <em>xmm2/m128</em>.</td>, <td>NP 0F 38 09 /r<sup>1</sup> PSIGNW <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed word integers in <em>mm1</em> depending on the corresponding sign in <em>mm2/m128</em>.</td>, <td>66 0F 38 09 /r PSIGNW <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed word integers in <em>xmm1</em> depending on the corresponding sign in <em>xmm2/m128</em>.</td>, <td>NP 0F 38 0A /r<sup>1</sup> PSIGND <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed doubleword integers in <em>mm1</em> depending on the corresponding sign in <em>mm2/m128</em>.</td>, <td>66 0F 38 0A /r PSIGND <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed doubleword integers in <em>xmm1</em> depending on the corresponding sign in <em>xmm2/m128</em>.</td>, <td>VEX.128.66.0F38.WIG 08 /r VPSIGNB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Negate/zero/preserve packed byte integers in <em>xmm2</em> depending on the corresponding sign in <em>xmm3/m128</em>.</td>, <td>VEX.128.66.0F38.WIG 09 /r VPSIGNW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Negate/zero/preserve packed word integers in <em>xmm2</em> depending on the corresponding sign in <em>xmm3/m128</em>.</td>, <td>VEX.128.66.0F38.WIG 0A /r VPSIGND <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Negate/zero/preserve packed doubleword integers in <em>xmm2</em> depending on the corresponding sign in <em>xmm3/m128</em>.</td>, <td>VEX.256.66.0F38.WIG 08 /r VPSIGNB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Negate packed byte integers in <em>ymm2</em> if the corresponding sign in <em>ymm3/m256</em> is less than zero.</td>, <td>VEX.256.66.0F38.WIG 09 /r VPSIGNW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Negate packed 16-bit integers in <em>ymm2</em> if the corresponding sign in <em>ymm3/m256</em> is less than zero.</td>, <td>VEX.256.66.0F38.WIG 0A /r VPSIGND <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Negate packed doubleword integers in <em>ymm2</em> if the corresponding sign in <em>ymm3/m256</em> is less than zero.</td>, <td colspan="5">NOTES: 1. See note in Section 2.4, “AVX and SSE Instruction Exception Specification” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 2A</em> and Section 22.25.3, “Exception Conditions of Legacy SIMD Instructions Operating on MMX Registers” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 3A</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>NP 0F 38 08 /r<sup>1</sup> PSIGNB <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed byte integers in <em>mm1</em> depending on the corresponding sign in <em>mm2/m64.</em></td>, <td>66 0F 38 08 /r PSIGNB <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed byte integers in <em>xmm1</em> depending on the corresponding sign in <em>xmm2/m128</em>.</td>, <td>NP 0F 38 09 /r<sup>1</sup> PSIGNW <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed word integers in <em>mm1</em> depending on the corresponding sign in <em>mm2/m128</em>.</td>, <td>66 0F 38 09 /r PSIGNW <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed word integers in <em>xmm1</em> depending on the corresponding sign in <em>xmm2/m128</em>.</td>, <td>NP 0F 38 0A /r<sup>1</sup> PSIGND <em>mm1, mm2/m64</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed doubleword integers in <em>mm1</em> depending on the corresponding sign in <em>mm2/m128</em>.</td>, <td>66 0F 38 0A /r PSIGND <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSSE3</td>, <td>Negate/zero/preserve packed doubleword integers in <em>xmm1</em> depending on the corresponding sign in <em>xmm2/m128</em>.</td>, <td>VEX.128.66.0F38.WIG 08 /r VPSIGNB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Negate/zero/preserve packed byte integers in <em>xmm2</em> depending on the corresponding sign in <em>xmm3/m128</em>.</td>, <td>VEX.128.66.0F38.WIG 09 /r VPSIGNW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Negate/zero/preserve packed word integers in <em>xmm2</em> depending on the corresponding sign in <em>xmm3/m128</em>.</td>, <td>VEX.128.66.0F38.WIG 0A /r VPSIGND <em>xmm1, xmm2, xmm3/m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Negate/zero/preserve packed doubleword integers in <em>xmm2</em> depending on the corresponding sign in <em>xmm3/m128</em>.</td>, <td>VEX.256.66.0F38.WIG 08 /r VPSIGNB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Negate packed byte integers in <em>ymm2</em> if the corresponding sign in <em>ymm3/m256</em> is less than zero.</td>, <td>VEX.256.66.0F38.WIG 09 /r VPSIGNW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Negate packed 16-bit integers in <em>ymm2</em> if the corresponding sign in <em>ymm3/m256</em> is less than zero.</td>, <td>VEX.256.66.0F38.WIG 0A /r VPSIGND <em>ymm1, ymm2, ymm3/m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Negate packed doubleword integers in <em>ymm2</em> if the corresponding sign in <em>ymm3/m256</em> is less than zero.</td>, <td colspan="5">NOTES: 1. See note in Section 2.4, “AVX and SSE Instruction Exception Specification” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 2A</em> and Section 22.25.3, “Exception Conditions of Legacy SIMD Instructions Operating on MMX Registers” in the <em>Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 3A</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.L = 1.</td>]

[<td>NP 0F F1 /<em>r</em><sup>1</sup> PSLLW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> left <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F F1 /<em>r</em> PSLLW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> left by <em>xmm2/m128</em> while shifting in 0s.</td>, <td>NP 0F 71 /6 ib PSLLW <em>mm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 71 /6 ib PSLLW <em>xmm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>NP 0F F2 /<em>r</em><sup>1</sup> PSLLD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> left by <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F F2 /<em>r</em> PSLLD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doublewords in <em>xmm1</em> left by <em>xmm2/m128</em> while shifting in 0s.</td>, <td>NP 0F 72 /6 ib<sup>1</sup> PSLLD <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 72 /6 ib PSLLD <em>xmm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doublewords in <em>xmm1</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>NP 0F F3 /<em>r</em><sup>1</sup> PSLLQ <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift quadword in <em>mm</em> left by <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F F3 /<em>r</em> PSLLQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift quadwords in <em>xmm1</em> left by <em>xmm2/m128</em> while shifting in 0s.</td>, <td>NP 0F 73 /6 ib<sup>1</sup> PSLLQ <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift quadword in <em>mm</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 73 /6 ib PSLLQ <em>xmm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift quadwords in <em>xmm1</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG F1 /r VPSLLW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 71 /6 ib VPSLLW <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG F2 /r VPSLLD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 72 /6 ib VPSLLD <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG F3 /r VPSLLQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift quadwords in <em>xmm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 73 /6 ib VPSLLQ <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift quadwords in <em>xmm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG F1 /r VPSLLW <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 71 /6 ib VPSLLW <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG F2 /r VPSLLD <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 72 /6 ib VPSLLD <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG F3 /r VPSLLQ <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in <em>ymm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 73 /6 ib VPSLLQ <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in <em>ymm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>EVEX.128.66.0F.WIG F1 /r VPSLLW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.WIG F1 /r VPSLLW ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.WIG F1 /r VPSLLW zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.WIG 71 /6 ib VPSLLW xmm1 {k1}{z}, xmm2/m128, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2/m128 left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.WIG 71 /6 ib VPSLLW ymm1 {k1}{z}, ymm2/m256, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2/m256 left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.WIG 71 /6 ib VPSLLW zmm1 {k1}{z}, zmm2/m512, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2/m512 left by imm8 while shifting in 0 using writemask k1.</td>, <td>EVEX.128.66.0F.W0 F2 /r VPSLLD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.</td>, <td>EVEX.256.66.0F.W0 F2 /r VPSLLD ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.</td>, <td>EVEX.512.66.0F.W0 F2 /r VPSLLD zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /6 ib VPSLLD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2/m128/m32bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /6 ib VPSLLD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2/m256/m32bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /6 ib VPSLLD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2/m512/m32bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W1 F3 /r VPSLLQ xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W1 F3 /r VPSLLQ ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W1 F3 /r VPSLLQ zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W1 73 /6 ib VPSLLQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2/m128/m64bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W1 73 /6 ib VPSLLQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2/m256/m64bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W1 73 /6 ib VPSLLQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2/m512/m64bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>NA</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>E</td>, <td>Full Mem</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>F</td>, <td>Full</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>G</td>, <td>Mem128</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 73 /7 ib PSLLDQ <em>xmm1</em>, <em>imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift <em>xmm1</em> left by <em>imm8</em> bytes while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 73 /7 ib VPSLLDQ <em>xmm1, xmm2, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift <em>xmm2</em> left by <em>imm8</em> bytes while shifting in 0s and store result in <em>xmm1</em>.</td>, <td>VEX.256.66.0F.WIG 73 /7 ib VPSLLDQ <em>ymm1, ymm2, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift <em>ymm2</em> left by <em>imm8</em> bytes while shifting in 0s and store result in <em>ymm1</em>.</td>, <td>EVEX.128.66.0F.WIG 73 /7 ib VPSLLDQ xmm1,xmm2/ m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift xmm2/m128 left by imm8 bytes while shifting in 0s and store result in xmm1.</td>, <td>EVEX.256.66.0F.WIG 73 /7 ib VPSLLDQ ymm1, ymm2/m256, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift ymm2/m256 left by imm8 bytes while shifting in 0s and store result in ymm1.</td>, <td>EVEX.512.66.0F.WIG 73 /7 ib VPSLLDQ zmm1, zmm2/m512, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift zmm2/m512 left by imm8 bytes while shifting in 0s and store result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>]

[<td>NP 0F F1 /<em>r</em><sup>1</sup> PSLLW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> left <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F F1 /<em>r</em> PSLLW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> left by <em>xmm2/m128</em> while shifting in 0s.</td>, <td>NP 0F 71 /6 ib PSLLW <em>mm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 71 /6 ib PSLLW <em>xmm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>NP 0F F2 /<em>r</em><sup>1</sup> PSLLD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> left by <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F F2 /<em>r</em> PSLLD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doublewords in <em>xmm1</em> left by <em>xmm2/m128</em> while shifting in 0s.</td>, <td>NP 0F 72 /6 ib<sup>1</sup> PSLLD <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 72 /6 ib PSLLD <em>xmm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doublewords in <em>xmm1</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>NP 0F F3 /<em>r</em><sup>1</sup> PSLLQ <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift quadword in <em>mm</em> left by <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F F3 /<em>r</em> PSLLQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift quadwords in <em>xmm1</em> left by <em>xmm2/m128</em> while shifting in 0s.</td>, <td>NP 0F 73 /6 ib<sup>1</sup> PSLLQ <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift quadword in <em>mm</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 73 /6 ib PSLLQ <em>xmm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift quadwords in <em>xmm1</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG F1 /r VPSLLW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 71 /6 ib VPSLLW <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG F2 /r VPSLLD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 72 /6 ib VPSLLD <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG F3 /r VPSLLQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift quadwords in <em>xmm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 73 /6 ib VPSLLQ <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift quadwords in <em>xmm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG F1 /r VPSLLW <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 71 /6 ib VPSLLW <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG F2 /r VPSLLD <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 72 /6 ib VPSLLD <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG F3 /r VPSLLQ <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in <em>ymm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 73 /6 ib VPSLLQ <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in <em>ymm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>EVEX.128.66.0F.WIG F1 /r VPSLLW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.WIG F1 /r VPSLLW ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.WIG F1 /r VPSLLW zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.WIG 71 /6 ib VPSLLW xmm1 {k1}{z}, xmm2/m128, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2/m128 left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.WIG 71 /6 ib VPSLLW ymm1 {k1}{z}, ymm2/m256, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2/m256 left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.WIG 71 /6 ib VPSLLW zmm1 {k1}{z}, zmm2/m512, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2/m512 left by imm8 while shifting in 0 using writemask k1.</td>, <td>EVEX.128.66.0F.W0 F2 /r VPSLLD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.</td>, <td>EVEX.256.66.0F.W0 F2 /r VPSLLD ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.</td>, <td>EVEX.512.66.0F.W0 F2 /r VPSLLD zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /6 ib VPSLLD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2/m128/m32bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /6 ib VPSLLD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2/m256/m32bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /6 ib VPSLLD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2/m512/m32bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W1 F3 /r VPSLLQ xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W1 F3 /r VPSLLQ ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W1 F3 /r VPSLLQ zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W1 73 /6 ib VPSLLQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2/m128/m64bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W1 73 /6 ib VPSLLQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2/m256/m64bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W1 73 /6 ib VPSLLQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2/m512/m64bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>NA</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>E</td>, <td>Full Mem</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>F</td>, <td>Full</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>G</td>, <td>Mem128</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F F1 /<em>r</em><sup>1</sup> PSLLW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> left <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F F1 /<em>r</em> PSLLW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> left by <em>xmm2/m128</em> while shifting in 0s.</td>, <td>NP 0F 71 /6 ib PSLLW <em>mm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 71 /6 ib PSLLW <em>xmm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>NP 0F F2 /<em>r</em><sup>1</sup> PSLLD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> left by <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F F2 /<em>r</em> PSLLD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doublewords in <em>xmm1</em> left by <em>xmm2/m128</em> while shifting in 0s.</td>, <td>NP 0F 72 /6 ib<sup>1</sup> PSLLD <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 72 /6 ib PSLLD <em>xmm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doublewords in <em>xmm1</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>NP 0F F3 /<em>r</em><sup>1</sup> PSLLQ <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift quadword in <em>mm</em> left by <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F F3 /<em>r</em> PSLLQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift quadwords in <em>xmm1</em> left by <em>xmm2/m128</em> while shifting in 0s.</td>, <td>NP 0F 73 /6 ib<sup>1</sup> PSLLQ <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift quadword in <em>mm</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 73 /6 ib PSLLQ <em>xmm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift quadwords in <em>xmm1</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG F1 /r VPSLLW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 71 /6 ib VPSLLW <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG F2 /r VPSLLD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 72 /6 ib VPSLLD <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG F3 /r VPSLLQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift quadwords in <em>xmm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 73 /6 ib VPSLLQ <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift quadwords in <em>xmm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG F1 /r VPSLLW <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 71 /6 ib VPSLLW <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG F2 /r VPSLLD <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 72 /6 ib VPSLLD <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG F3 /r VPSLLQ <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in <em>ymm2</em> left by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 73 /6 ib VPSLLQ <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in <em>ymm2</em> left by <em>imm8</em> while shifting in 0s.</td>, <td>EVEX.128.66.0F.WIG F1 /r VPSLLW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.WIG F1 /r VPSLLW ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.WIG F1 /r VPSLLW zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.WIG 71 /6 ib VPSLLW xmm1 {k1}{z}, xmm2/m128, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2/m128 left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.WIG 71 /6 ib VPSLLW ymm1 {k1}{z}, ymm2/m256, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2/m256 left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.WIG 71 /6 ib VPSLLW zmm1 {k1}{z}, zmm2/m512, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2/m512 left by imm8 while shifting in 0 using writemask k1.</td>, <td>EVEX.128.66.0F.W0 F2 /r VPSLLD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.</td>, <td>EVEX.256.66.0F.W0 F2 /r VPSLLD ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.</td>, <td>EVEX.512.66.0F.W0 F2 /r VPSLLD zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 left by amount specified in xmm3/m128 while shifting in 0s under writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /6 ib VPSLLD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2/m128/m32bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /6 ib VPSLLD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2/m256/m32bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /6 ib VPSLLD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2/m512/m32bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W1 F3 /r VPSLLQ xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W1 F3 /r VPSLLQ ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W1 F3 /r VPSLLQ zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 left by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W1 73 /6 ib VPSLLQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2/m128/m64bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W1 73 /6 ib VPSLLQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2/m256/m64bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W1 73 /6 ib VPSLLQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2/m512/m64bcst left by imm8 while shifting in 0s using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>NA</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>E</td>, <td>Full Mem</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>F</td>, <td>Full</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>G</td>, <td>Mem128</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F E1 /<em>r</em><sup>1</sup> PSRAW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> right by <em>mm/m64</em> while shifting in sign bits.</td>, <td>66 0F E1 /<em>r</em> PSRAW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> right by <em>xmm2/m128</em> while shifting in sign bits.</td>, <td>NP 0F 71 /4 ib<sup>1</sup> PSRAW <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> right by <em>imm8</em> while shifting in sign bits</td>, <td>66 0F 71 /4 ib PSRAW <em>xmm1</em>, imm8</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> right by imm8 while shifting in sign bits</td>, <td>NP 0F E2 /<em>r</em><sup>1</sup> PSRAD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> right by <em>mm/m64</em> while shifting in sign bits.</td>, <td>66 0F E2 /<em>r</em> PSRAD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doubleword in <em>xmm1</em> right by <em>xmm2 /m128</em> while shifting in sign bits.</td>, <td>NP 0F 72 /4 ib<sup>1</sup> PSRAD <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>66 0F 72 /4 ib PSRAD <em>xmm1</em>, imm8</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doublewords in <em>xmm1</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>VEX.128.66.0F.WIG E1 /r VPSRAW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in sign bits.</td>, <td>VEX.128.66.0F.WIG 71 /4 ib VPSRAW <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>VEX.128.66.0F.WIG E2 /r VPSRAD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in sign bits.</td>, <td>VEX.128.66.0F.WIG 72 /4 ib VPSRAD <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>VEX.256.66.0F.WIG E1 /r VPSRAW <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in sign bits.</td>, <td>VEX.256.66.0F.WIG 71 /4 ib VPSRAW <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>VEX.256.66.0F.WIG E2 /r VPSRAD <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in sign bits.</td>, <td>VEX.256.66.0F.WIG 72 /4 ib VPSRAD <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>EVEX.128.66.0F.WIG E1 /r VPSRAW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.WIG E1 /r VPSRAW ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.WIG E1 /r VPSRAW zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F.WIG 71 /4 ib VPSRAW xmm1 {k1}{z}, xmm2/m128, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2/m128 right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.WIG 71 /4 ib VPSRAW ymm1 {k1}{z}, ymm2/m256, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2/m256 right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.WIG 71 /4 ib VPSRAW zmm1 {k1}{z}, zmm2/m512, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2/m512 right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F.W0 E2 /r VPSRAD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.W0 E2 /r VPSRAD ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.W0 E2 /r VPSRAD zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /4 ib VPSRAD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /4 ib VPSRAD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /4 ib VPSRAD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F.W1 E2 /r VPSRAQ xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.W1 E2 /r VPSRAQ ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.W1 E2 /r VPSRAQ zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F.W1 72 /4 ib VPSRAQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.W1 72 /4 ib VPSRAQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.W1 72 /4 ib VPSRAQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>NA</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>E</td>, <td>Full Mem</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>F</td>, <td>Full</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>G</td>, <td>Mem128</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F E1 /<em>r</em><sup>1</sup> PSRAW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> right by <em>mm/m64</em> while shifting in sign bits.</td>, <td>66 0F E1 /<em>r</em> PSRAW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> right by <em>xmm2/m128</em> while shifting in sign bits.</td>, <td>NP 0F 71 /4 ib<sup>1</sup> PSRAW <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> right by <em>imm8</em> while shifting in sign bits</td>, <td>66 0F 71 /4 ib PSRAW <em>xmm1</em>, imm8</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> right by imm8 while shifting in sign bits</td>, <td>NP 0F E2 /<em>r</em><sup>1</sup> PSRAD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> right by <em>mm/m64</em> while shifting in sign bits.</td>, <td>66 0F E2 /<em>r</em> PSRAD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doubleword in <em>xmm1</em> right by <em>xmm2 /m128</em> while shifting in sign bits.</td>, <td>NP 0F 72 /4 ib<sup>1</sup> PSRAD <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>66 0F 72 /4 ib PSRAD <em>xmm1</em>, imm8</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doublewords in <em>xmm1</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>VEX.128.66.0F.WIG E1 /r VPSRAW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in sign bits.</td>, <td>VEX.128.66.0F.WIG 71 /4 ib VPSRAW <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>VEX.128.66.0F.WIG E2 /r VPSRAD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in sign bits.</td>, <td>VEX.128.66.0F.WIG 72 /4 ib VPSRAD <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>VEX.256.66.0F.WIG E1 /r VPSRAW <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in sign bits.</td>, <td>VEX.256.66.0F.WIG 71 /4 ib VPSRAW <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>VEX.256.66.0F.WIG E2 /r VPSRAD <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in sign bits.</td>, <td>VEX.256.66.0F.WIG 72 /4 ib VPSRAD <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>EVEX.128.66.0F.WIG E1 /r VPSRAW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.WIG E1 /r VPSRAW ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.WIG E1 /r VPSRAW zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F.WIG 71 /4 ib VPSRAW xmm1 {k1}{z}, xmm2/m128, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2/m128 right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.WIG 71 /4 ib VPSRAW ymm1 {k1}{z}, ymm2/m256, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2/m256 right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.WIG 71 /4 ib VPSRAW zmm1 {k1}{z}, zmm2/m512, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2/m512 right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F.W0 E2 /r VPSRAD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.W0 E2 /r VPSRAD ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.W0 E2 /r VPSRAD zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /4 ib VPSRAD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /4 ib VPSRAD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /4 ib VPSRAD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F.W1 E2 /r VPSRAQ xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.W1 E2 /r VPSRAQ ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.W1 E2 /r VPSRAQ zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F.W1 72 /4 ib VPSRAQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.W1 72 /4 ib VPSRAQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.W1 72 /4 ib VPSRAQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>NA</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>E</td>, <td>Full Mem</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>F</td>, <td>Full</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>G</td>, <td>Mem128</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F E1 /<em>r</em><sup>1</sup> PSRAW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> right by <em>mm/m64</em> while shifting in sign bits.</td>, <td>66 0F E1 /<em>r</em> PSRAW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> right by <em>xmm2/m128</em> while shifting in sign bits.</td>, <td>NP 0F 71 /4 ib<sup>1</sup> PSRAW <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> right by <em>imm8</em> while shifting in sign bits</td>, <td>66 0F 71 /4 ib PSRAW <em>xmm1</em>, imm8</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> right by imm8 while shifting in sign bits</td>, <td>NP 0F E2 /<em>r</em><sup>1</sup> PSRAD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> right by <em>mm/m64</em> while shifting in sign bits.</td>, <td>66 0F E2 /<em>r</em> PSRAD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doubleword in <em>xmm1</em> right by <em>xmm2 /m128</em> while shifting in sign bits.</td>, <td>NP 0F 72 /4 ib<sup>1</sup> PSRAD <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>66 0F 72 /4 ib PSRAD <em>xmm1</em>, imm8</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doublewords in <em>xmm1</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>VEX.128.66.0F.WIG E1 /r VPSRAW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in sign bits.</td>, <td>VEX.128.66.0F.WIG 71 /4 ib VPSRAW <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>VEX.128.66.0F.WIG E2 /r VPSRAD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in sign bits.</td>, <td>VEX.128.66.0F.WIG 72 /4 ib VPSRAD <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>VEX.256.66.0F.WIG E1 /r VPSRAW <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in sign bits.</td>, <td>VEX.256.66.0F.WIG 71 /4 ib VPSRAW <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>VEX.256.66.0F.WIG E2 /r VPSRAD <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in sign bits.</td>, <td>VEX.256.66.0F.WIG 72 /4 ib VPSRAD <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> right by <em>imm8</em> while shifting in sign bits.</td>, <td>EVEX.128.66.0F.WIG E1 /r VPSRAW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.WIG E1 /r VPSRAW ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.WIG E1 /r VPSRAW zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F.WIG 71 /4 ib VPSRAW xmm1 {k1}{z}, xmm2/m128, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2/m128 right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.WIG 71 /4 ib VPSRAW ymm1 {k1}{z}, ymm2/m256, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2/m256 right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.WIG 71 /4 ib VPSRAW zmm1 {k1}{z}, zmm2/m512, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2/m512 right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F.W0 E2 /r VPSRAD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.W0 E2 /r VPSRAD ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.W0 E2 /r VPSRAD zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /4 ib VPSRAD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /4 ib VPSRAD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /4 ib VPSRAD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F.W1 E2 /r VPSRAQ xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.W1 E2 /r VPSRAQ ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.W1 E2 /r VPSRAQ zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F.W1 72 /4 ib VPSRAQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F.W1 72 /4 ib VPSRAQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F.W1 72 /4 ib VPSRAQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in sign bits using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>NA</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>E</td>, <td>Full Mem</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>F</td>, <td>Full</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>G</td>, <td>Mem128</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F D1 /<em>r</em><sup>1</sup> PSRLW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> right by amount specified in <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F D1 /<em>r</em> PSRLW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> right by amount specified in <em>xmm2/m128</em> while shifting in 0s.</td>, <td>NP 0F 71 /2 ib<sup>1</sup> PSRLW <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 71 /2 ib PSRLW <em>xmm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>NP 0F D2 /<em>r</em><sup>1</sup> PSRLD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> right by amount specified in <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F D2 /<em>r</em> PSRLD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doublewords in <em>xmm1</em> right by amount specified in <em>xmm2 /m128</em> while shifting in 0s.</td>, <td>NP 0F 72 /2 ib<sup>1</sup> PSRLD <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 72 /2 ib PSRLD <em>xmm1</em>, imm8</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doublewords in <em>xmm1</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>NP 0F D3 /<em>r</em><sup>1</sup> PSRLQ <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift <em>mm</em> right by amount specified in <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F D3 /<em>r</em> PSRLQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift quadwords in <em>xmm1</em> right by amount specified in <em>xmm2/m128</em> while shifting in 0s.</td>, <td>NP 0F 73 /2 ib<sup>1</sup> PSRLQ <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift <em>mm</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 73 /2 ib PSRLQ <em>xmm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift quadwords in <em>xmm1</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG D1 /r VPSRLW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 71 /2 ib VPSRLW <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG D2 /r VPSRLD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 72 /2 ib VPSRLD <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG D3 /r VPSRLQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift quadwords in <em>xmm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 73 /2 ib VPSRLQ <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift quadwords in <em>xmm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG D1 /r VPSRLW <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 71 /2 ib VPSRLW <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG D2 /r VPSRLD <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 72 /2 ib VPSRLD <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG D3 /r VPSRLQ <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in <em>ymm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 73 /2 ib VPSRLQ <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in <em>ymm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>EVEX.128.66.0F.WIG D1 /r VPSRLW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.WIG D1 /r VPSRLW ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.WIG D1 /r VPSRLW zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.WIG 71 /2 ib VPSRLW xmm1 {k1}{z}, xmm2/m128, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2/m128 right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.WIG 71 /2 ib VPSRLW ymm1 {k1}{z}, ymm2/m256, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2/m256 right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.WIG 71 /2 ib VPSRLW zmm1 {k1}{z}, zmm2/m512, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2/m512 right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W0 D2 /r VPSRLD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W0 D2 /r VPSRLD ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W0 D2 /r VPSRLD zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /2 ib VPSRLD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /2 ib VPSRLD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /2 ib VPSRLD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W1 D3 /r VPSRLQ xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W1 D3 /r VPSRLQ ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W1 D3 /r VPSRLQ zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W1 73 /2 ib VPSRLQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W1 73 /2 ib VPSRLQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W1 73 /2 ib VPSRLQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>NA</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>E</td>, <td>Full Mem</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>F</td>, <td>Full</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>G</td>, <td>Mem128</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 73 /3 ib PSRLDQ <em>xmm1</em>, <em>imm8</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift <em>xmm1</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 73 /3 ib VPSRLDQ <em>xmm1, xmm2, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift <em>xmm2</em> right by <em>imm8</em> bytes while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 73 /3 ib VPSRLDQ <em>ymm1, ymm2, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift <em>ymm1</em> right by <em>imm8</em> bytes while shifting in 0s.</td>, <td>EVEX.128.66.0F.WIG 73 /3 ib VPSRLDQ xmm1, xmm2/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift xmm2/m128 right by imm8 bytes while shifting in 0s and store result in xmm1.</td>, <td>EVEX.256.66.0F.WIG 73 /3 ib VPSRLDQ ymm1, ymm2/m256, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift ymm2/m256 right by imm8 bytes while shifting in 0s and store result in ymm1.</td>, <td>EVEX.512.66.0F.WIG 73 /3 ib VPSRLDQ zmm1, zmm2/m512, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift zmm2/m512 right by imm8 bytes while shifting in 0s and store result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>]

[<td>NP 0F D1 /<em>r</em><sup>1</sup> PSRLW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> right by amount specified in <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F D1 /<em>r</em> PSRLW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> right by amount specified in <em>xmm2/m128</em> while shifting in 0s.</td>, <td>NP 0F 71 /2 ib<sup>1</sup> PSRLW <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 71 /2 ib PSRLW <em>xmm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>NP 0F D2 /<em>r</em><sup>1</sup> PSRLD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> right by amount specified in <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F D2 /<em>r</em> PSRLD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doublewords in <em>xmm1</em> right by amount specified in <em>xmm2 /m128</em> while shifting in 0s.</td>, <td>NP 0F 72 /2 ib<sup>1</sup> PSRLD <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 72 /2 ib PSRLD <em>xmm1</em>, imm8</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doublewords in <em>xmm1</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>NP 0F D3 /<em>r</em><sup>1</sup> PSRLQ <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift <em>mm</em> right by amount specified in <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F D3 /<em>r</em> PSRLQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift quadwords in <em>xmm1</em> right by amount specified in <em>xmm2/m128</em> while shifting in 0s.</td>, <td>NP 0F 73 /2 ib<sup>1</sup> PSRLQ <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift <em>mm</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 73 /2 ib PSRLQ <em>xmm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift quadwords in <em>xmm1</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG D1 /r VPSRLW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 71 /2 ib VPSRLW <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG D2 /r VPSRLD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 72 /2 ib VPSRLD <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG D3 /r VPSRLQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift quadwords in <em>xmm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 73 /2 ib VPSRLQ <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift quadwords in <em>xmm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG D1 /r VPSRLW <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 71 /2 ib VPSRLW <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG D2 /r VPSRLD <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 72 /2 ib VPSRLD <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG D3 /r VPSRLQ <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in <em>ymm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 73 /2 ib VPSRLQ <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in <em>ymm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>EVEX.128.66.0F.WIG D1 /r VPSRLW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.WIG D1 /r VPSRLW ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.WIG D1 /r VPSRLW zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.WIG 71 /2 ib VPSRLW xmm1 {k1}{z}, xmm2/m128, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2/m128 right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.WIG 71 /2 ib VPSRLW ymm1 {k1}{z}, ymm2/m256, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2/m256 right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.WIG 71 /2 ib VPSRLW zmm1 {k1}{z}, zmm2/m512, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2/m512 right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W0 D2 /r VPSRLD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W0 D2 /r VPSRLD ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W0 D2 /r VPSRLD zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /2 ib VPSRLD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /2 ib VPSRLD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /2 ib VPSRLD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W1 D3 /r VPSRLQ xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W1 D3 /r VPSRLQ ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W1 D3 /r VPSRLQ zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W1 73 /2 ib VPSRLQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W1 73 /2 ib VPSRLQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W1 73 /2 ib VPSRLQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>NA</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>E</td>, <td>Full Mem</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>F</td>, <td>Full</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>G</td>, <td>Mem128</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F D1 /<em>r</em><sup>1</sup> PSRLW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> right by amount specified in <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F D1 /<em>r</em> PSRLW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> right by amount specified in <em>xmm2/m128</em> while shifting in 0s.</td>, <td>NP 0F 71 /2 ib<sup>1</sup> PSRLW <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift words in <em>mm</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 71 /2 ib PSRLW <em>xmm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift words in <em>xmm1</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>NP 0F D2 /<em>r</em><sup>1</sup> PSRLD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> right by amount specified in <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F D2 /<em>r</em> PSRLD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doublewords in <em>xmm1</em> right by amount specified in <em>xmm2 /m128</em> while shifting in 0s.</td>, <td>NP 0F 72 /2 ib<sup>1</sup> PSRLD <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift doublewords in <em>mm</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 72 /2 ib PSRLD <em>xmm1</em>, imm8</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift doublewords in <em>xmm1</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>NP 0F D3 /<em>r</em><sup>1</sup> PSRLQ <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift <em>mm</em> right by amount specified in <em>mm/m64</em> while shifting in 0s.</td>, <td>66 0F D3 /<em>r</em> PSRLQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift quadwords in <em>xmm1</em> right by amount specified in <em>xmm2/m128</em> while shifting in 0s.</td>, <td>NP 0F 73 /2 ib<sup>1</sup> PSRLQ <em>mm, imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>MMX</td>, <td>Shift <em>mm</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>66 0F 73 /2 ib PSRLQ <em>xmm1</em>, <em>imm8</em></td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shift quadwords in <em>xmm1</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG D1 /r VPSRLW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 71 /2 ib VPSRLW <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift words in <em>xmm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG D2 /r VPSRLD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 72 /2 ib VPSRLD <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift doublewords in <em>xmm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG D3 /r VPSRLQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift quadwords in <em>xmm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.128.66.0F.WIG 73 /2 ib VPSRLQ <em>xmm1, xmm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX</td>, <td>Shift quadwords in <em>xmm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG D1 /r VPSRLW <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 71 /2 ib VPSRLW <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift words in <em>ymm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG D2 /r VPSRLD <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 72 /2 ib VPSRLD <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in <em>ymm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG D3 /r VPSRLQ <em>ymm1, ymm2, xmm3/m128</em></td>, <td>C</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in <em>ymm2</em> right by amount specified in <em>xmm3/m128</em> while shifting in 0s.</td>, <td>VEX.256.66.0F.WIG 73 /2 ib VPSRLQ <em>ymm1, ymm2, imm8</em></td>, <td>D</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in <em>ymm2</em> right by <em>imm8</em> while shifting in 0s.</td>, <td>EVEX.128.66.0F.WIG D1 /r VPSRLW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.WIG D1 /r VPSRLW ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.WIG D1 /r VPSRLW zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.WIG 71 /2 ib VPSRLW xmm1 {k1}{z}, xmm2/m128, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2/m128 right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.WIG 71 /2 ib VPSRLW ymm1 {k1}{z}, ymm2/m256, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2/m256 right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.WIG 71 /2 ib VPSRLW zmm1 {k1}{z}, zmm2/m512, imm8</td>, <td>E</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2/m512 right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W0 D2 /r VPSRLD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W0 D2 /r VPSRLD ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W0 D2 /r VPSRLD zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /2 ib VPSRLD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2/m128/m32bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /2 ib VPSRLD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2/m256/m32bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /2 ib VPSRLD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2/m512/m32bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W1 D3 /r VPSRLQ xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W1 D3 /r VPSRLQ ymm1 {k1}{z}, ymm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W1 D3 /r VPSRLQ zmm1 {k1}{z}, zmm2, xmm3/m128</td>, <td>G</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 right by amount specified in xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F.W1 73 /2 ib VPSRLQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2/m128/m64bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F.W1 73 /2 ib VPSRLQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2/m256/m64bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F.W1 73 /2 ib VPSRLQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>F</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2/m512/m64bcst right by imm8 while shifting in 0s using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>NA</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>E</td>, <td>Full Mem</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>F</td>, <td>Full</td>, <td>EVEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>G</td>, <td>Mem128</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F F8 /<em>r</em><sup>1</sup> PSUBB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract packed byte integers in <em>mm/m64</em> from packed byte integers in <em>mm</em>.</td>, <td>66 0F F8 /<em>r</em> PSUBB <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed byte integers in <em>xmm2/m128</em> from packed byte integers in <em>xmm1</em>.</td>, <td>NP 0F F9 /<em>r</em><sup>1</sup> PSUBW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract packed word integers in <em>mm/m64</em> from packed word integers in <em>mm</em>.</td>, <td>66 0F F9 /<em>r</em> PSUBW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed word integers in <em>xmm2/m128</em> from packed word integers in <em>xmm1</em>.</td>, <td>NP 0F FA /<em>r</em><sup>1</sup> PSUBD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract packed doubleword integers in <em>mm/m64</em> from packed doubleword integers in <em>mm</em>.</td>, <td>66 0F FA /<em>r</em> PSUBD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed doubleword integers in <em>xmm2/mem128</em> from packed doubleword integers in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG F8 /r VPSUBB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed byte integers in <em>xmm3/m128</em> from <em>xmm2</em>.</td>, <td>VEX.128.66.0F.WIG F9 /r VPSUBW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed word integers in <em>xmm3/m128</em> from <em>xmm2</em>.</td>, <td>VEX.128.66.0F.WIG FA /r VPSUBD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed doubleword integers in <em>xmm3/m128</em> from <em>xmm2</em>.</td>, <td>VEX.256.66.0F.WIG F8 /r VPSUBB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed byte integers in <em>ymm3/m256</em> from <em>ymm2</em>.</td>, <td>VEX.256.66.0F.WIG F9 /r VPSUBW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed word integers in <em>ymm3/m256</em> from <em>ymm2</em>.</td>, <td>VEX.256.66.0F.WIG FA /r VPSUBD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed doubleword integers in <em>ymm3/m256</em> from <em>ymm2</em>.</td>, <td>EVEX.128.66.0F.WIG F8 /r VPSUBB xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed byte integers in xmm3/m128 from xmm2 and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.WIG F8 /r VPSUBB ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed byte integers in ymm3/m256 from ymm2 and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.WIG F8 /r VPSUBB zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Subtract packed byte integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.WIG F9 /r VPSUBW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed word integers in xmm3/m128 from xmm2 and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.WIG F9 /r VPSUBW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed word integers in ymm3/m256 from ymm2 and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.WIG F9 /r VPSUBW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Subtract packed word integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.W0 FA /r VPSUBD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Subtract packed doubleword integers in xmm3/m128/m32bcst from xmm2 and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W0 FA /r VPSUBD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Subtract packed doubleword integers in ymm3/m256/m32bcst from ymm2 and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 FA /r VPSUBD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Subtract packed doubleword integers in zmm3/m512/m32bcst from zmm2 and store in zmm1 using writemask k1</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F F8 /<em>r</em><sup>1</sup> PSUBB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract packed byte integers in <em>mm/m64</em> from packed byte integers in <em>mm</em>.</td>, <td>66 0F F8 /<em>r</em> PSUBB <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed byte integers in <em>xmm2/m128</em> from packed byte integers in <em>xmm1</em>.</td>, <td>NP 0F F9 /<em>r</em><sup>1</sup> PSUBW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract packed word integers in <em>mm/m64</em> from packed word integers in <em>mm</em>.</td>, <td>66 0F F9 /<em>r</em> PSUBW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed word integers in <em>xmm2/m128</em> from packed word integers in <em>xmm1</em>.</td>, <td>NP 0F FA /<em>r</em><sup>1</sup> PSUBD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract packed doubleword integers in <em>mm/m64</em> from packed doubleword integers in <em>mm</em>.</td>, <td>66 0F FA /<em>r</em> PSUBD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed doubleword integers in <em>xmm2/mem128</em> from packed doubleword integers in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG F8 /r VPSUBB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed byte integers in <em>xmm3/m128</em> from <em>xmm2</em>.</td>, <td>VEX.128.66.0F.WIG F9 /r VPSUBW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed word integers in <em>xmm3/m128</em> from <em>xmm2</em>.</td>, <td>VEX.128.66.0F.WIG FA /r VPSUBD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed doubleword integers in <em>xmm3/m128</em> from <em>xmm2</em>.</td>, <td>VEX.256.66.0F.WIG F8 /r VPSUBB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed byte integers in <em>ymm3/m256</em> from <em>ymm2</em>.</td>, <td>VEX.256.66.0F.WIG F9 /r VPSUBW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed word integers in <em>ymm3/m256</em> from <em>ymm2</em>.</td>, <td>VEX.256.66.0F.WIG FA /r VPSUBD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed doubleword integers in <em>ymm3/m256</em> from <em>ymm2</em>.</td>, <td>EVEX.128.66.0F.WIG F8 /r VPSUBB xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed byte integers in xmm3/m128 from xmm2 and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.WIG F8 /r VPSUBB ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed byte integers in ymm3/m256 from ymm2 and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.WIG F8 /r VPSUBB zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Subtract packed byte integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.WIG F9 /r VPSUBW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed word integers in xmm3/m128 from xmm2 and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.WIG F9 /r VPSUBW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed word integers in ymm3/m256 from ymm2 and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.WIG F9 /r VPSUBW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Subtract packed word integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.W0 FA /r VPSUBD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Subtract packed doubleword integers in xmm3/m128/m32bcst from xmm2 and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W0 FA /r VPSUBD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Subtract packed doubleword integers in ymm3/m256/m32bcst from ymm2 and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 FA /r VPSUBD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Subtract packed doubleword integers in zmm3/m512/m32bcst from zmm2 and store in zmm1 using writemask k1</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F FB /<em>r</em><sup>1</sup> PSUBQ <em>mm1</em>, <em>mm2/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract quadword integer in <em>mm1</em> from <em>mm2 /m64</em>.</td>, <td>66 0F FB /<em>r</em> PSUBQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed quadword integers in <em>xmm1</em> from <em>xmm2 /m128</em>.</td>, <td>VEX.128.66.0F.WIG FB/r VPSUBQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed quadword integers in <em>xmm3/m128</em> from <em>xmm2</em>.</td>, <td>VEX.256.66.0F.WIG FB /r VPSUBQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed quadword integers in <em>ymm3/m256</em> from <em>ymm2.</em></td>, <td>EVEX.128.66.0F.W1 FB /r VPSUBQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Subtract packed quadword integers in xmm3/m128/m64bcst from xmm2 and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W1 FB /r VPSUBQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Subtract packed quadword integers in ymm3/m256/m64bcst from ymm2 and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W1 FB/r VPSUBQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Subtract packed quadword integers in zmm3/m512/m64bcst from zmm2 and store in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F E8 /<em>r</em><sup>1</sup> PSUBSB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract signed packed bytes in <em>mm/m64</em> from signed packed bytes in <em>mm</em> and saturate results.</td>, <td>66 0F E8 /<em>r</em> PSUBSB <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed signed byte integers in <em>xmm2/m128</em> from packed signed byte integers in <em>xmm1</em> and saturate results.</td>, <td>NP 0F E9 /<em>r</em><sup>1</sup> PSUBSW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract signed packed words in <em>mm/m64</em> from signed packed words in <em>mm</em> and saturate results.</td>, <td>66 0F E9 /<em>r</em> PSUBSW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed signed word integers in <em>xmm2/m128</em> from packed signed word integers in <em>xmm1</em> and saturate results.</td>, <td>VEX.128.66.0F.WIG E8 /r VPSUBSB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed signed byte integers in <em>xmm3/m128</em> from packed signed byte integers in <em>xmm2</em> and saturate results.</td>, <td>VEX.128.66.0F.WIG E9 /r VPSUBSW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed signed word integers in <em>xmm3/m128</em> from packed signed word integers in <em>xmm2</em> and saturate results.</td>, <td>VEX.256.66.0F.WIG E8 /r VPSUBSB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed signed byte integers in <em>ymm3/m256</em> from packed signed byte integers in <em>ymm2</em> and saturate results.</td>, <td>VEX.256.66.0F.WIG E9 /r VPSUBSW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed signed word integers in <em>ymm3/m256</em> from packed signed word integers in <em>ymm2</em> and saturate results.</td>, <td>EVEX.128.66.0F.WIG E8 /r VPSUBSB xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed signed byte integers in xmm3/m128 from packed signed byte integers in xmm2 and saturate results and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.WIG E8 /r VPSUBSB ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed signed byte integers in ymm3/m256 from packed signed byte integers in ymm2 and saturate results and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.WIG E8 /r VPSUBSB zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Subtract packed signed byte integers in zmm3/m512 from packed signed byte integers in zmm2 and saturate results and store in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.WIG E9 /r VPSUBSW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed signed word integers in xmm3/m128 from packed signed word integers in xmm2 and saturate results and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.WIG E9 /r VPSUBSW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed signed word integers in ymm3/m256 from packed signed word integers in ymm2 and saturate results and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.WIG E9 /r VPSUBSW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Subtract packed signed word integers in zmm3/m512 from packed signed word integers in zmm2 and saturate results and store in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F E8 /<em>r</em><sup>1</sup> PSUBSB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract signed packed bytes in <em>mm/m64</em> from signed packed bytes in <em>mm</em> and saturate results.</td>, <td>66 0F E8 /<em>r</em> PSUBSB <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed signed byte integers in <em>xmm2/m128</em> from packed signed byte integers in <em>xmm1</em> and saturate results.</td>, <td>NP 0F E9 /<em>r</em><sup>1</sup> PSUBSW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract signed packed words in <em>mm/m64</em> from signed packed words in <em>mm</em> and saturate results.</td>, <td>66 0F E9 /<em>r</em> PSUBSW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed signed word integers in <em>xmm2/m128</em> from packed signed word integers in <em>xmm1</em> and saturate results.</td>, <td>VEX.128.66.0F.WIG E8 /r VPSUBSB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed signed byte integers in <em>xmm3/m128</em> from packed signed byte integers in <em>xmm2</em> and saturate results.</td>, <td>VEX.128.66.0F.WIG E9 /r VPSUBSW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed signed word integers in <em>xmm3/m128</em> from packed signed word integers in <em>xmm2</em> and saturate results.</td>, <td>VEX.256.66.0F.WIG E8 /r VPSUBSB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed signed byte integers in <em>ymm3/m256</em> from packed signed byte integers in <em>ymm2</em> and saturate results.</td>, <td>VEX.256.66.0F.WIG E9 /r VPSUBSW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed signed word integers in <em>ymm3/m256</em> from packed signed word integers in <em>ymm2</em> and saturate results.</td>, <td>EVEX.128.66.0F.WIG E8 /r VPSUBSB xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed signed byte integers in xmm3/m128 from packed signed byte integers in xmm2 and saturate results and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.WIG E8 /r VPSUBSB ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed signed byte integers in ymm3/m256 from packed signed byte integers in ymm2 and saturate results and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.WIG E8 /r VPSUBSB zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Subtract packed signed byte integers in zmm3/m512 from packed signed byte integers in zmm2 and saturate results and store in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.WIG E9 /r VPSUBSW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed signed word integers in xmm3/m128 from packed signed word integers in xmm2 and saturate results and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.WIG E9 /r VPSUBSW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed signed word integers in ymm3/m256 from packed signed word integers in ymm2 and saturate results and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.WIG E9 /r VPSUBSW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Subtract packed signed word integers in zmm3/m512 from packed signed word integers in zmm2 and saturate results and store in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F D8 /<em>r</em><sup>1</sup> PSUBUSB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract unsigned packed bytes in <em>mm/m64</em> from unsigned packed bytes in <em>mm</em> and saturate result.</td>, <td>66 0F D8 /<em>r</em> PSUBUSB <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed unsigned byte integers in <em>xmm2/m128</em> from packed unsigned byte integers in xmm1 and saturate result.</td>, <td>NP 0F D9 /<em>r</em><sup>1</sup> PSUBUSW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract unsigned packed words in <em>mm/m64</em> from unsigned packed words in <em>mm</em> and saturate result.</td>, <td>66 0F D9 /<em>r</em> PSUBUSW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed unsigned word integers in <em>xmm2/m128</em> from packed unsigned word integers in <em>xmm1</em> and saturate result.</td>, <td>VEX.128.66.0F.WIG D8 /r VPSUBUSB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed unsigned byte integers in <em>xmm3/m128</em> from packed unsigned byte integers in <em>xmm2</em> and saturate result.</td>, <td>VEX.128.66.0F.WIG D9 /r VPSUBUSW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed unsigned word integers in <em>xmm3/m128</em> from packed unsigned word integers in <em>xmm2</em> and saturate result.</td>, <td>VEX.256.66.0F.WIG D8 /r VPSUBUSB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed unsigned byte integers in <em>ymm3/m256</em> from packed unsigned byte integers in <em>ymm2</em> and saturate result.</td>, <td>VEX.256.66.0F.WIG D9 /r VPSUBUSW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed unsigned word integers in <em>ymm3/m256</em> from packed unsigned word integers in <em>ymm2</em> and saturate result.</td>, <td>EVEX.128.66.0F.WIG D8 /r VPSUBUSB xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed unsigned byte integers in xmm3/m128 from packed unsigned byte integers in xmm2, saturate results and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.WIG D8 /r VPSUBUSB ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed unsigned byte integers in ymm3/m256 from packed unsigned byte integers in ymm2, saturate results and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.WIG D8 /r VPSUBUSB zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Subtract packed unsigned byte integers in zmm3/m512 from packed unsigned byte integers in zmm2, saturate results and store in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.WIG D9 /r VPSUBUSW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed unsigned word integers in xmm3/m128 from packed unsigned word integers in xmm2 and saturate results and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.WIG D9 /r VPSUBUSW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed unsigned word integers in ymm3/m256 from packed unsigned word integers in ymm2, saturate results and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.WIG D9 /r VPSUBUSW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Subtract packed unsigned word integers in zmm3/m512 from packed unsigned word integers in zmm2, saturate results and store in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F D8 /<em>r</em><sup>1</sup> PSUBUSB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract unsigned packed bytes in <em>mm/m64</em> from unsigned packed bytes in <em>mm</em> and saturate result.</td>, <td>66 0F D8 /<em>r</em> PSUBUSB <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed unsigned byte integers in <em>xmm2/m128</em> from packed unsigned byte integers in xmm1 and saturate result.</td>, <td>NP 0F D9 /<em>r</em><sup>1</sup> PSUBUSW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract unsigned packed words in <em>mm/m64</em> from unsigned packed words in <em>mm</em> and saturate result.</td>, <td>66 0F D9 /<em>r</em> PSUBUSW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed unsigned word integers in <em>xmm2/m128</em> from packed unsigned word integers in <em>xmm1</em> and saturate result.</td>, <td>VEX.128.66.0F.WIG D8 /r VPSUBUSB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed unsigned byte integers in <em>xmm3/m128</em> from packed unsigned byte integers in <em>xmm2</em> and saturate result.</td>, <td>VEX.128.66.0F.WIG D9 /r VPSUBUSW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed unsigned word integers in <em>xmm3/m128</em> from packed unsigned word integers in <em>xmm2</em> and saturate result.</td>, <td>VEX.256.66.0F.WIG D8 /r VPSUBUSB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed unsigned byte integers in <em>ymm3/m256</em> from packed unsigned byte integers in <em>ymm2</em> and saturate result.</td>, <td>VEX.256.66.0F.WIG D9 /r VPSUBUSW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed unsigned word integers in <em>ymm3/m256</em> from packed unsigned word integers in <em>ymm2</em> and saturate result.</td>, <td>EVEX.128.66.0F.WIG D8 /r VPSUBUSB xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed unsigned byte integers in xmm3/m128 from packed unsigned byte integers in xmm2, saturate results and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.WIG D8 /r VPSUBUSB ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed unsigned byte integers in ymm3/m256 from packed unsigned byte integers in ymm2, saturate results and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.WIG D8 /r VPSUBUSB zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Subtract packed unsigned byte integers in zmm3/m512 from packed unsigned byte integers in zmm2, saturate results and store in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.WIG D9 /r VPSUBUSW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed unsigned word integers in xmm3/m128 from packed unsigned word integers in xmm2 and saturate results and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.WIG D9 /r VPSUBUSW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed unsigned word integers in ymm3/m256 from packed unsigned word integers in ymm2, saturate results and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.WIG D9 /r VPSUBUSW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Subtract packed unsigned word integers in zmm3/m512 from packed unsigned word integers in zmm2, saturate results and store in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F F8 /<em>r</em><sup>1</sup> PSUBB <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract packed byte integers in <em>mm/m64</em> from packed byte integers in <em>mm</em>.</td>, <td>66 0F F8 /<em>r</em> PSUBB <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed byte integers in <em>xmm2/m128</em> from packed byte integers in <em>xmm1</em>.</td>, <td>NP 0F F9 /<em>r</em><sup>1</sup> PSUBW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract packed word integers in <em>mm/m64</em> from packed word integers in <em>mm</em>.</td>, <td>66 0F F9 /<em>r</em> PSUBW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed word integers in <em>xmm2/m128</em> from packed word integers in <em>xmm1</em>.</td>, <td>NP 0F FA /<em>r</em><sup>1</sup> PSUBD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Subtract packed doubleword integers in <em>mm/m64</em> from packed doubleword integers in <em>mm</em>.</td>, <td>66 0F FA /<em>r</em> PSUBD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed doubleword integers in <em>xmm2/mem128</em> from packed doubleword integers in <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG F8 /r VPSUBB <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed byte integers in <em>xmm3/m128</em> from <em>xmm2</em>.</td>, <td>VEX.128.66.0F.WIG F9 /r VPSUBW <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed word integers in <em>xmm3/m128</em> from <em>xmm2</em>.</td>, <td>VEX.128.66.0F.WIG FA /r VPSUBD <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed doubleword integers in <em>xmm3/m128</em> from <em>xmm2</em>.</td>, <td>VEX.256.66.0F.WIG F8 /r VPSUBB <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed byte integers in <em>ymm3/m256</em> from <em>ymm2</em>.</td>, <td>VEX.256.66.0F.WIG F9 /r VPSUBW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed word integers in <em>ymm3/m256</em> from <em>ymm2</em>.</td>, <td>VEX.256.66.0F.WIG FA /r VPSUBD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Subtract packed doubleword integers in <em>ymm3/m256</em> from <em>ymm2</em>.</td>, <td>EVEX.128.66.0F.WIG F8 /r VPSUBB xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed byte integers in xmm3/m128 from xmm2 and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.WIG F8 /r VPSUBB ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed byte integers in ymm3/m256 from ymm2 and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.WIG F8 /r VPSUBB zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Subtract packed byte integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.WIG F9 /r VPSUBW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed word integers in xmm3/m128 from xmm2 and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.WIG F9 /r VPSUBW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Subtract packed word integers in ymm3/m256 from ymm2 and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.WIG F9 /r VPSUBW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Subtract packed word integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.W0 FA /r VPSUBD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Subtract packed doubleword integers in xmm3/m128/m32bcst from xmm2 and store in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W0 FA /r VPSUBD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Subtract packed doubleword integers in ymm3/m256/m32bcst from ymm2 and store in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 FA /r VPSUBD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Subtract packed doubleword integers in zmm3/m512/m32bcst from zmm2 and store in zmm1 using writemask k1</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 38 17 /r PTEST <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Set ZF if <em>xmm2/m128</em> AND <em>xmm1</em> result is all 0s. Set CF if <em>xmm2/m128</em> AND NOT <em>xmm1</em> result is all 0s.</td>, <td>VEX.128.66.0F38.WIG 17 /r VPTEST <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Set ZF and CF depending on bitwise AND and ANDN of sources.</td>, <td>VEX.256.66.0F38.WIG 17 /r VPTEST <em>ymm1, ymm2/m256</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Set ZF and CF depending on bitwise AND and ANDN of sources.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>F3 REX.W 0F AE /4 PTWRITE <em>r64/m64</em></td>, <td>RM</td>, <td>V/N.E</td>, <td></td>, <td>Reads the data from r64/m64 to encode into a PTW packet if dependencies are met (see details below).</td>, <td>F3 0F AE /4 PTWRITE <em>r32/m32</em></td>, <td>RM</td>, <td>V/V</td>, <td></td>, <td>Reads the data from r32/m32 to encode into a PTW packet if dependencies are met (see details below).</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:rm (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS or GS segments.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while the current privilege level is 3 and alignment checking is enabled.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.(EAX=14H, ECX=0):EBX.PTWRITE [Bit 4] = 0.</td>, <td>If LOCK prefix is used.</td>, <td>If 66H prefix is used.</td>, <td>#GP(0)</td>, <td>If any part of the operand lies outside of the effective address space from 0 to 0FFFFH.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.(EAX=14H, ECX=0):EBX.PTWRITE [Bit 4] = 0.</td>, <td>If LOCK prefix is used.</td>, <td>If 66H prefix is used.</td>, <td>#GP(0)</td>, <td>If any part of the operand lies outside of the effective address space from 0 to 0FFFFH.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while alignment checking is enabled.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.(EAX=14H, ECX=0):EBX.PTWRITE [Bit 4] = 0.</td>, <td>If LOCK prefix is used.</td>, <td>If 66H prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.(EAX=14H, ECX=0):EBX.PTWRITE [Bit 4] = 0.</td>, <td>If LOCK prefix is used.</td>, <td>If 66H prefix is used.</td>]

[<td>NP 0F 68 /<em>r</em><sup>1</sup> PUNPCKHBW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Unpack and interleave high-order bytes from <em>mm</em> and <em>mm/m64</em> into <em>mm</em>.</td>, <td>66 0F 68 /<em>r</em> PUNPCKHBW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpack and interleave high-order bytes from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>NP 0F 69 /<em>r</em><sup>1</sup> PUNPCKHWD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Unpack and interleave high-order words from <em>mm</em> and <em>mm/m64</em> into <em>mm</em>.</td>, <td>66 0F 69 /<em>r</em> PUNPCKHWD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpack and interleave high-order words from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>NP 0F 6A /<em>r</em><sup>1</sup> PUNPCKHDQ <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Unpack and interleave high-order doublewords from <em>mm</em> and <em>mm/m64</em> into <em>mm</em>.</td>, <td>66 0F 6A /<em>r</em> PUNPCKHDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpack and interleave high-order doublewords from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>66 0F 6D /<em>r</em> PUNPCKHQDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpack and interleave high-order quadwords from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1.</em></td>, <td>VEX.128.66.0F.WIG 68/r VPUNPCKHBW <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave high-order bytes from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 69/r VPUNPCKHWD <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave high-order words from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 6A/r VPUNPCKHDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave high-order doublewords from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 6D/r VPUNPCKHQDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave high-order quadword from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em> register.</td>, <td>VEX.256.66.0F.WIG 68 /r VPUNPCKHBW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave high-order bytes from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 69 /r VPUNPCKHWD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave high-order words from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 6A /r VPUNPCKHDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave high-order doublewords from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 6D /r VPUNPCKHQDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave high-order quadword from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>EVEX.128.66.0F.WIG 68 /r VPUNPCKHBW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave high-order bytes from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.</td>, <td>EVEX.128.66.0F.WIG 69 /r VPUNPCKHWD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave high-order words from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.</td>, <td>EVEX.128.66.0F.W0 6A /r VPUNPCKHDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave high-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register using k1 write mask.</td>, <td>EVEX.128.66.0F.W1 6D /r VPUNPCKHQDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave high-order quadword from xmm2 and xmm3/m128/m64bcst into xmm1 register using k1 write mask.</td>, <td>EVEX.256.66.0F.WIG 68 /r VPUNPCKHBW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave high-order bytes from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.</td>, <td>EVEX.256.66.0F.WIG 69 /r VPUNPCKHWD ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave high-order words from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.</td>, <td>EVEX.256.66.0F.W0 6A /r VPUNPCKHDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave high-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register using k1 write mask.</td>, <td>EVEX.256.66.0F.W1 6D /r VPUNPCKHQDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave high-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register using k1 write mask.</td>, <td>EVEX.512.66.0F.WIG 68/r VPUNPCKHBW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Interleave high-order bytes from zmm2 and zmm3/m512 into zmm1 register.</td>, <td>EVEX.512.66.0F.WIG 69/r VPUNPCKHWD zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Interleave high-order words from zmm2 and zmm3/m512 into zmm1 register.</td>, <td>EVEX.512.66.0F.W0 6A /r VPUNPCKHDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Interleave high-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register using k1 write mask.</td>, <td>EVEX.512.66.0F.W1 6D /r VPUNPCKHQDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Interleave high-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register using k1 write mask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 68 /<em>r</em><sup>1</sup> PUNPCKHBW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Unpack and interleave high-order bytes from <em>mm</em> and <em>mm/m64</em> into <em>mm</em>.</td>, <td>66 0F 68 /<em>r</em> PUNPCKHBW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpack and interleave high-order bytes from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>NP 0F 69 /<em>r</em><sup>1</sup> PUNPCKHWD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Unpack and interleave high-order words from <em>mm</em> and <em>mm/m64</em> into <em>mm</em>.</td>, <td>66 0F 69 /<em>r</em> PUNPCKHWD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpack and interleave high-order words from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>NP 0F 6A /<em>r</em><sup>1</sup> PUNPCKHDQ <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Unpack and interleave high-order doublewords from <em>mm</em> and <em>mm/m64</em> into <em>mm</em>.</td>, <td>66 0F 6A /<em>r</em> PUNPCKHDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpack and interleave high-order doublewords from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>66 0F 6D /<em>r</em> PUNPCKHQDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpack and interleave high-order quadwords from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1.</em></td>, <td>VEX.128.66.0F.WIG 68/r VPUNPCKHBW <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave high-order bytes from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 69/r VPUNPCKHWD <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave high-order words from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 6A/r VPUNPCKHDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave high-order doublewords from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 6D/r VPUNPCKHQDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave high-order quadword from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em> register.</td>, <td>VEX.256.66.0F.WIG 68 /r VPUNPCKHBW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave high-order bytes from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 69 /r VPUNPCKHWD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave high-order words from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 6A /r VPUNPCKHDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave high-order doublewords from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 6D /r VPUNPCKHQDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave high-order quadword from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>EVEX.128.66.0F.WIG 68 /r VPUNPCKHBW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave high-order bytes from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.</td>, <td>EVEX.128.66.0F.WIG 69 /r VPUNPCKHWD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave high-order words from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.</td>, <td>EVEX.128.66.0F.W0 6A /r VPUNPCKHDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave high-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register using k1 write mask.</td>, <td>EVEX.128.66.0F.W1 6D /r VPUNPCKHQDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave high-order quadword from xmm2 and xmm3/m128/m64bcst into xmm1 register using k1 write mask.</td>, <td>EVEX.256.66.0F.WIG 68 /r VPUNPCKHBW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave high-order bytes from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.</td>, <td>EVEX.256.66.0F.WIG 69 /r VPUNPCKHWD ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave high-order words from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.</td>, <td>EVEX.256.66.0F.W0 6A /r VPUNPCKHDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave high-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register using k1 write mask.</td>, <td>EVEX.256.66.0F.W1 6D /r VPUNPCKHQDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave high-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register using k1 write mask.</td>, <td>EVEX.512.66.0F.WIG 68/r VPUNPCKHBW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Interleave high-order bytes from zmm2 and zmm3/m512 into zmm1 register.</td>, <td>EVEX.512.66.0F.WIG 69/r VPUNPCKHWD zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Interleave high-order words from zmm2 and zmm3/m512 into zmm1 register.</td>, <td>EVEX.512.66.0F.W0 6A /r VPUNPCKHDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Interleave high-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register using k1 write mask.</td>, <td>EVEX.512.66.0F.W1 6D /r VPUNPCKHQDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Interleave high-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register using k1 write mask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 68 /<em>r</em><sup>1</sup> PUNPCKHBW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Unpack and interleave high-order bytes from <em>mm</em> and <em>mm/m64</em> into <em>mm</em>.</td>, <td>66 0F 68 /<em>r</em> PUNPCKHBW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpack and interleave high-order bytes from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>NP 0F 69 /<em>r</em><sup>1</sup> PUNPCKHWD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Unpack and interleave high-order words from <em>mm</em> and <em>mm/m64</em> into <em>mm</em>.</td>, <td>66 0F 69 /<em>r</em> PUNPCKHWD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpack and interleave high-order words from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>NP 0F 6A /<em>r</em><sup>1</sup> PUNPCKHDQ <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Unpack and interleave high-order doublewords from <em>mm</em> and <em>mm/m64</em> into <em>mm</em>.</td>, <td>66 0F 6A /<em>r</em> PUNPCKHDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpack and interleave high-order doublewords from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>66 0F 6D /<em>r</em> PUNPCKHQDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpack and interleave high-order quadwords from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1.</em></td>, <td>VEX.128.66.0F.WIG 68/r VPUNPCKHBW <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave high-order bytes from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 69/r VPUNPCKHWD <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave high-order words from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 6A/r VPUNPCKHDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave high-order doublewords from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 6D/r VPUNPCKHQDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave high-order quadword from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em> register.</td>, <td>VEX.256.66.0F.WIG 68 /r VPUNPCKHBW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave high-order bytes from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 69 /r VPUNPCKHWD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave high-order words from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 6A /r VPUNPCKHDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave high-order doublewords from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 6D /r VPUNPCKHQDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave high-order quadword from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>EVEX.128.66.0F.WIG 68 /r VPUNPCKHBW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave high-order bytes from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.</td>, <td>EVEX.128.66.0F.WIG 69 /r VPUNPCKHWD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave high-order words from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.</td>, <td>EVEX.128.66.0F.W0 6A /r VPUNPCKHDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave high-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register using k1 write mask.</td>, <td>EVEX.128.66.0F.W1 6D /r VPUNPCKHQDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave high-order quadword from xmm2 and xmm3/m128/m64bcst into xmm1 register using k1 write mask.</td>, <td>EVEX.256.66.0F.WIG 68 /r VPUNPCKHBW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave high-order bytes from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.</td>, <td>EVEX.256.66.0F.WIG 69 /r VPUNPCKHWD ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave high-order words from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.</td>, <td>EVEX.256.66.0F.W0 6A /r VPUNPCKHDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave high-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register using k1 write mask.</td>, <td>EVEX.256.66.0F.W1 6D /r VPUNPCKHQDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave high-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register using k1 write mask.</td>, <td>EVEX.512.66.0F.WIG 68/r VPUNPCKHBW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Interleave high-order bytes from zmm2 and zmm3/m512 into zmm1 register.</td>, <td>EVEX.512.66.0F.WIG 69/r VPUNPCKHWD zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Interleave high-order words from zmm2 and zmm3/m512 into zmm1 register.</td>, <td>EVEX.512.66.0F.W0 6A /r VPUNPCKHDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Interleave high-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register using k1 write mask.</td>, <td>EVEX.512.66.0F.W1 6D /r VPUNPCKHQDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Interleave high-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register using k1 write mask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 68 /<em>r</em><sup>1</sup> PUNPCKHBW <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Unpack and interleave high-order bytes from <em>mm</em> and <em>mm/m64</em> into <em>mm</em>.</td>, <td>66 0F 68 /<em>r</em> PUNPCKHBW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpack and interleave high-order bytes from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>NP 0F 69 /<em>r</em><sup>1</sup> PUNPCKHWD <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Unpack and interleave high-order words from <em>mm</em> and <em>mm/m64</em> into <em>mm</em>.</td>, <td>66 0F 69 /<em>r</em> PUNPCKHWD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpack and interleave high-order words from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>NP 0F 6A /<em>r</em><sup>1</sup> PUNPCKHDQ <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Unpack and interleave high-order doublewords from <em>mm</em> and <em>mm/m64</em> into <em>mm</em>.</td>, <td>66 0F 6A /<em>r</em> PUNPCKHDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpack and interleave high-order doublewords from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>66 0F 6D /<em>r</em> PUNPCKHQDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpack and interleave high-order quadwords from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1.</em></td>, <td>VEX.128.66.0F.WIG 68/r VPUNPCKHBW <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave high-order bytes from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 69/r VPUNPCKHWD <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave high-order words from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 6A/r VPUNPCKHDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave high-order doublewords from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 6D/r VPUNPCKHQDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave high-order quadword from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em> register.</td>, <td>VEX.256.66.0F.WIG 68 /r VPUNPCKHBW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave high-order bytes from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 69 /r VPUNPCKHWD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave high-order words from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 6A /r VPUNPCKHDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave high-order doublewords from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 6D /r VPUNPCKHQDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave high-order quadword from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>EVEX.128.66.0F.WIG 68 /r VPUNPCKHBW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave high-order bytes from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.</td>, <td>EVEX.128.66.0F.WIG 69 /r VPUNPCKHWD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave high-order words from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.</td>, <td>EVEX.128.66.0F.W0 6A /r VPUNPCKHDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave high-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register using k1 write mask.</td>, <td>EVEX.128.66.0F.W1 6D /r VPUNPCKHQDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave high-order quadword from xmm2 and xmm3/m128/m64bcst into xmm1 register using k1 write mask.</td>, <td>EVEX.256.66.0F.WIG 68 /r VPUNPCKHBW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave high-order bytes from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.</td>, <td>EVEX.256.66.0F.WIG 69 /r VPUNPCKHWD ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave high-order words from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.</td>, <td>EVEX.256.66.0F.W0 6A /r VPUNPCKHDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave high-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register using k1 write mask.</td>, <td>EVEX.256.66.0F.W1 6D /r VPUNPCKHQDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave high-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register using k1 write mask.</td>, <td>EVEX.512.66.0F.WIG 68/r VPUNPCKHBW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Interleave high-order bytes from zmm2 and zmm3/m512 into zmm1 register.</td>, <td>EVEX.512.66.0F.WIG 69/r VPUNPCKHWD zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Interleave high-order words from zmm2 and zmm3/m512 into zmm1 register.</td>, <td>EVEX.512.66.0F.W0 6A /r VPUNPCKHDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Interleave high-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register using k1 write mask.</td>, <td>EVEX.512.66.0F.W1 6D /r VPUNPCKHQDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Interleave high-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register using k1 write mask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 60 /<em>r</em><sup>1</sup> PUNPCKLBW <em>mm, mm/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Interleave low-order bytes from <em>mm</em> and <em>mm/m32</em> into <em>mm</em>.</td>, <td>66 0F 60 /<em>r</em> PUNPCKLBW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Interleave low-order bytes from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>NP 0F 61 /<em>r</em><sup>1</sup> PUNPCKLWD <em>mm, mm/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Interleave low-order words from <em>mm</em> and <em>mm/m32</em> into <em>mm</em>.</td>, <td>66 0F 61 /<em>r</em> PUNPCKLWD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Interleave low-order words from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>NP 0F 62 /<em>r</em><sup>1</sup> PUNPCKLDQ <em>mm, mm/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Interleave low-order doublewords from <em>mm</em> and <em>mm/m32</em> into <em>mm</em>.</td>, <td>66 0F 62 /<em>r</em> PUNPCKLDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Interleave low-order doublewords from <em>xmm1</em> and <em>xmm2/m128</em> into xmm1.</td>, <td>66 0F 6C /<em>r</em> PUNPCKLQDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Interleave low-order quadword from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em> register.</td>, <td>VEX.128.66.0F.WIG 60/r VPUNPCKLBW <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave low-order bytes from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 61/r VPUNPCKLWD <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave low-order words from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 62/r VPUNPCKLDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave low-order doublewords from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 6C/r VPUNPCKLQDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave low-order quadword from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em> register.</td>, <td>VEX.256.66.0F.WIG 60 /r VPUNPCKLBW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave low-order bytes from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 61 /r VPUNPCKLWD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave low-order words from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 62 /r VPUNPCKLDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave low-order doublewords from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 6C /r VPUNPCKLQDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave low-order quadword from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>EVEX.128.66.0F.WIG 60 /r VPUNPCKLBW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave low-order bytes from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.</td>, <td>EVEX.128.66.0F.WIG 61 /r VPUNPCKLWD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave low-order words from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.</td>, <td>EVEX.128.66.0F.W0 62 /r VPUNPCKLDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave low-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register subject to write mask k1.</td>, <td>EVEX.128.66.0F.W1 6C /r VPUNPCKLQDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.</td>, <td>EVEX.256.66.0F.WIG 60 /r VPUNPCKLBW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave low-order bytes from ymm2 and ymm3/m256 into ymm1 register subject to write mask k1.</td>, <td>EVEX.256.66.0F.WIG 61 /r VPUNPCKLWD ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave low-order words from ymm2 and ymm3/m256 into ymm1 register subject to write mask k1.</td>, <td>EVEX.256.66.0F.W0 62 /r VPUNPCKLDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave low-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register subject to write mask k1.</td>, <td>EVEX.256.66.0F.W1 6C /r VPUNPCKLQDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave low-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register subject to write mask k1.</td>, <td>EVEX.512.66.0F.WIG 60/r VPUNPCKLBW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Interleave low-order bytes from zmm2 and zmm3/m512 into zmm1 register subject to write mask k1.</td>, <td>EVEX.512.66.0F.WIG 61/r VPUNPCKLWD zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Interleave low-order words from zmm2 and zmm3/m512 into zmm1 register subject to write mask k1.</td>, <td>EVEX.512.66.0F.W0 62 /r VPUNPCKLDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Interleave low-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register subject to write mask k1.</td>, <td>EVEX.512.66.0F.W1 6C /r VPUNPCKLQDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 60 /<em>r</em><sup>1</sup> PUNPCKLBW <em>mm, mm/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Interleave low-order bytes from <em>mm</em> and <em>mm/m32</em> into <em>mm</em>.</td>, <td>66 0F 60 /<em>r</em> PUNPCKLBW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Interleave low-order bytes from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>NP 0F 61 /<em>r</em><sup>1</sup> PUNPCKLWD <em>mm, mm/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Interleave low-order words from <em>mm</em> and <em>mm/m32</em> into <em>mm</em>.</td>, <td>66 0F 61 /<em>r</em> PUNPCKLWD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Interleave low-order words from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>NP 0F 62 /<em>r</em><sup>1</sup> PUNPCKLDQ <em>mm, mm/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Interleave low-order doublewords from <em>mm</em> and <em>mm/m32</em> into <em>mm</em>.</td>, <td>66 0F 62 /<em>r</em> PUNPCKLDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Interleave low-order doublewords from <em>xmm1</em> and <em>xmm2/m128</em> into xmm1.</td>, <td>66 0F 6C /<em>r</em> PUNPCKLQDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Interleave low-order quadword from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em> register.</td>, <td>VEX.128.66.0F.WIG 60/r VPUNPCKLBW <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave low-order bytes from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 61/r VPUNPCKLWD <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave low-order words from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 62/r VPUNPCKLDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave low-order doublewords from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 6C/r VPUNPCKLQDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave low-order quadword from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em> register.</td>, <td>VEX.256.66.0F.WIG 60 /r VPUNPCKLBW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave low-order bytes from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 61 /r VPUNPCKLWD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave low-order words from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 62 /r VPUNPCKLDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave low-order doublewords from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 6C /r VPUNPCKLQDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave low-order quadword from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>EVEX.128.66.0F.WIG 60 /r VPUNPCKLBW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave low-order bytes from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.</td>, <td>EVEX.128.66.0F.WIG 61 /r VPUNPCKLWD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave low-order words from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.</td>, <td>EVEX.128.66.0F.W0 62 /r VPUNPCKLDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave low-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register subject to write mask k1.</td>, <td>EVEX.128.66.0F.W1 6C /r VPUNPCKLQDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.</td>, <td>EVEX.256.66.0F.WIG 60 /r VPUNPCKLBW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave low-order bytes from ymm2 and ymm3/m256 into ymm1 register subject to write mask k1.</td>, <td>EVEX.256.66.0F.WIG 61 /r VPUNPCKLWD ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave low-order words from ymm2 and ymm3/m256 into ymm1 register subject to write mask k1.</td>, <td>EVEX.256.66.0F.W0 62 /r VPUNPCKLDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave low-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register subject to write mask k1.</td>, <td>EVEX.256.66.0F.W1 6C /r VPUNPCKLQDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave low-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register subject to write mask k1.</td>, <td>EVEX.512.66.0F.WIG 60/r VPUNPCKLBW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Interleave low-order bytes from zmm2 and zmm3/m512 into zmm1 register subject to write mask k1.</td>, <td>EVEX.512.66.0F.WIG 61/r VPUNPCKLWD zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Interleave low-order words from zmm2 and zmm3/m512 into zmm1 register subject to write mask k1.</td>, <td>EVEX.512.66.0F.W0 62 /r VPUNPCKLDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Interleave low-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register subject to write mask k1.</td>, <td>EVEX.512.66.0F.W1 6C /r VPUNPCKLQDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 60 /<em>r</em><sup>1</sup> PUNPCKLBW <em>mm, mm/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Interleave low-order bytes from <em>mm</em> and <em>mm/m32</em> into <em>mm</em>.</td>, <td>66 0F 60 /<em>r</em> PUNPCKLBW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Interleave low-order bytes from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>NP 0F 61 /<em>r</em><sup>1</sup> PUNPCKLWD <em>mm, mm/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Interleave low-order words from <em>mm</em> and <em>mm/m32</em> into <em>mm</em>.</td>, <td>66 0F 61 /<em>r</em> PUNPCKLWD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Interleave low-order words from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>NP 0F 62 /<em>r</em><sup>1</sup> PUNPCKLDQ <em>mm, mm/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Interleave low-order doublewords from <em>mm</em> and <em>mm/m32</em> into <em>mm</em>.</td>, <td>66 0F 62 /<em>r</em> PUNPCKLDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Interleave low-order doublewords from <em>xmm1</em> and <em>xmm2/m128</em> into xmm1.</td>, <td>66 0F 6C /<em>r</em> PUNPCKLQDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Interleave low-order quadword from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em> register.</td>, <td>VEX.128.66.0F.WIG 60/r VPUNPCKLBW <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave low-order bytes from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 61/r VPUNPCKLWD <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave low-order words from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 62/r VPUNPCKLDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave low-order doublewords from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 6C/r VPUNPCKLQDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave low-order quadword from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em> register.</td>, <td>VEX.256.66.0F.WIG 60 /r VPUNPCKLBW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave low-order bytes from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 61 /r VPUNPCKLWD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave low-order words from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 62 /r VPUNPCKLDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave low-order doublewords from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 6C /r VPUNPCKLQDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave low-order quadword from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>EVEX.128.66.0F.WIG 60 /r VPUNPCKLBW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave low-order bytes from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.</td>, <td>EVEX.128.66.0F.WIG 61 /r VPUNPCKLWD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave low-order words from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.</td>, <td>EVEX.128.66.0F.W0 62 /r VPUNPCKLDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave low-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register subject to write mask k1.</td>, <td>EVEX.128.66.0F.W1 6C /r VPUNPCKLQDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.</td>, <td>EVEX.256.66.0F.WIG 60 /r VPUNPCKLBW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave low-order bytes from ymm2 and ymm3/m256 into ymm1 register subject to write mask k1.</td>, <td>EVEX.256.66.0F.WIG 61 /r VPUNPCKLWD ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave low-order words from ymm2 and ymm3/m256 into ymm1 register subject to write mask k1.</td>, <td>EVEX.256.66.0F.W0 62 /r VPUNPCKLDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave low-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register subject to write mask k1.</td>, <td>EVEX.256.66.0F.W1 6C /r VPUNPCKLQDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave low-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register subject to write mask k1.</td>, <td>EVEX.512.66.0F.WIG 60/r VPUNPCKLBW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Interleave low-order bytes from zmm2 and zmm3/m512 into zmm1 register subject to write mask k1.</td>, <td>EVEX.512.66.0F.WIG 61/r VPUNPCKLWD zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Interleave low-order words from zmm2 and zmm3/m512 into zmm1 register subject to write mask k1.</td>, <td>EVEX.512.66.0F.W0 62 /r VPUNPCKLDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Interleave low-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register subject to write mask k1.</td>, <td>EVEX.512.66.0F.W1 6C /r VPUNPCKLQDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 60 /<em>r</em><sup>1</sup> PUNPCKLBW <em>mm, mm/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Interleave low-order bytes from <em>mm</em> and <em>mm/m32</em> into <em>mm</em>.</td>, <td>66 0F 60 /<em>r</em> PUNPCKLBW <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Interleave low-order bytes from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>NP 0F 61 /<em>r</em><sup>1</sup> PUNPCKLWD <em>mm, mm/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Interleave low-order words from <em>mm</em> and <em>mm/m32</em> into <em>mm</em>.</td>, <td>66 0F 61 /<em>r</em> PUNPCKLWD <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Interleave low-order words from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em>.</td>, <td>NP 0F 62 /<em>r</em><sup>1</sup> PUNPCKLDQ <em>mm, mm/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Interleave low-order doublewords from <em>mm</em> and <em>mm/m32</em> into <em>mm</em>.</td>, <td>66 0F 62 /<em>r</em> PUNPCKLDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Interleave low-order doublewords from <em>xmm1</em> and <em>xmm2/m128</em> into xmm1.</td>, <td>66 0F 6C /<em>r</em> PUNPCKLQDQ <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Interleave low-order quadword from <em>xmm1</em> and <em>xmm2/m128</em> into <em>xmm1</em> register.</td>, <td>VEX.128.66.0F.WIG 60/r VPUNPCKLBW <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave low-order bytes from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 61/r VPUNPCKLWD <em>xmm1,xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave low-order words from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 62/r VPUNPCKLDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave low-order doublewords from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG 6C/r VPUNPCKLQDQ <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Interleave low-order quadword from <em>xmm2</em> and <em>xmm3/m128</em> into <em>xmm1</em> register.</td>, <td>VEX.256.66.0F.WIG 60 /r VPUNPCKLBW <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave low-order bytes from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 61 /r VPUNPCKLWD <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave low-order words from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 62 /r VPUNPCKLDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave low-order doublewords from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>VEX.256.66.0F.WIG 6C /r VPUNPCKLQDQ <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Interleave low-order quadword from <em>ymm2</em> and <em>ymm3/m256</em> into <em>ymm1</em> register.</td>, <td>EVEX.128.66.0F.WIG 60 /r VPUNPCKLBW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave low-order bytes from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.</td>, <td>EVEX.128.66.0F.WIG 61 /r VPUNPCKLWD xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave low-order words from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1.</td>, <td>EVEX.128.66.0F.W0 62 /r VPUNPCKLDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave low-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register subject to write mask k1.</td>, <td>EVEX.128.66.0F.W1 6C /r VPUNPCKLQDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.</td>, <td>EVEX.256.66.0F.WIG 60 /r VPUNPCKLBW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave low-order bytes from ymm2 and ymm3/m256 into ymm1 register subject to write mask k1.</td>, <td>EVEX.256.66.0F.WIG 61 /r VPUNPCKLWD ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Interleave low-order words from ymm2 and ymm3/m256 into ymm1 register subject to write mask k1.</td>, <td>EVEX.256.66.0F.W0 62 /r VPUNPCKLDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave low-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register subject to write mask k1.</td>, <td>EVEX.256.66.0F.W1 6C /r VPUNPCKLQDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Interleave low-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register subject to write mask k1.</td>, <td>EVEX.512.66.0F.WIG 60/r VPUNPCKLBW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Interleave low-order bytes from zmm2 and zmm3/m512 into zmm1 register subject to write mask k1.</td>, <td>EVEX.512.66.0F.WIG 61/r VPUNPCKLWD zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Interleave low-order words from zmm2 and zmm3/m512 into zmm1 register subject to write mask k1.</td>, <td>EVEX.512.66.0F.W0 62 /r VPUNPCKLDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Interleave low-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register subject to write mask k1.</td>, <td>EVEX.512.66.0F.W1 6C /r VPUNPCKLQDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>FF /6</td>, <td>PUSH <em>r/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Push <em>r/m16.</em></td>, <td>FF /6</td>, <td>PUSH <em>r/m32</em></td>, <td>M</td>, <td>N.E.</td>, <td>Valid</td>, <td>Push <em>r/m32.</em></td>, <td>FF /6</td>, <td>PUSH <em>r/m64</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Push <em>r/m64.</em></td>, <td>50+<em>rw</em></td>, <td>PUSH <em>r16</em></td>, <td>O</td>, <td>Valid</td>, <td>Valid</td>, <td>Push <em>r16.</em></td>, <td>50+<em>rd</em></td>, <td>PUSH <em>r32</em></td>, <td>O</td>, <td>N.E.</td>, <td>Valid</td>, <td>Push <em>r32.</em></td>, <td>50+<em>rd</em></td>, <td>PUSH <em>r64</em></td>, <td>O</td>, <td>Valid</td>, <td>N.E.</td>, <td>Push <em>r64.</em></td>, <td>6A ib</td>, <td>PUSH <em>imm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Push <em>imm8.</em></td>, <td>68 iw</td>, <td>PUSH <em>imm16</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Push <em>imm16.</em></td>, <td>68 id</td>, <td>PUSH <em>imm32</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Push <em>imm32.</em></td>, <td>0E</td>, <td>PUSH CS</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Push CS.</td>, <td>16</td>, <td>PUSH SS</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Push SS.</td>, <td>1E</td>, <td>PUSH DS</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Push DS.</td>, <td>06</td>, <td>PUSH ES</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Push ES.</td>, <td>0F A0</td>, <td>PUSH FS</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Push FS.</td>, <td>0F A8</td>, <td>PUSH GS</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Push GS.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>O</td>, <td>opcode + rd (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>I</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td rowspan="2">#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>If the new value of the SP or ESP register is outside the stack segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#SS(0)</td>, <td>If the stack address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If the PUSH is of CS, SS, DS, or ES.</td>]

[<td>60</td>, <td>PUSHA</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Push AX, CX, DX, BX, original SP, BP, SI, and DI.</td>, <td>60</td>, <td>PUSHAD</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Push EAX, ECX, EDX, EBX, original ESP, EBP, ESI, and EDI.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#SS(0)</td>, <td>If the starting or ending stack address is outside the stack segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while the current privilege level is 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If the ESP or SP register contains 7, 9, 11, 13, or 15.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the ESP or SP register contains 7, 9, 11, 13, or 15.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If in 64-bit mode.</td>]

[<td>60</td>, <td>PUSHA</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Push AX, CX, DX, BX, original SP, BP, SI, and DI.</td>, <td>60</td>, <td>PUSHAD</td>, <td>ZO</td>, <td>Invalid</td>, <td>Valid</td>, <td>Push EAX, ECX, EDX, EBX, original ESP, EBP, ESI, and EDI.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#SS(0)</td>, <td>If the starting or ending stack address is outside the stack segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while the current privilege level is 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If the ESP or SP register contains 7, 9, 11, 13, or 15.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the ESP or SP register contains 7, 9, 11, 13, or 15.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If in 64-bit mode.</td>]

[<td>9C</td>, <td>PUSHF</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Push lower 16 bits of EFLAGS.</td>, <td>9C</td>, <td>PUSHFD</td>, <td>ZO</td>, <td>N.E.</td>, <td>Valid</td>, <td>Push EFLAGS.</td>, <td>9C</td>, <td>PUSHFQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Push RFLAGS.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#SS(0)</td>, <td>If the new value of the ESP register is outside the stack segment boundary.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while CPL = 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the I/O privilege level is less than 3.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#SS(0)</td>, <td>If the stack address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while CPL = 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>9C</td>, <td>PUSHF</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Push lower 16 bits of EFLAGS.</td>, <td>9C</td>, <td>PUSHFD</td>, <td>ZO</td>, <td>N.E.</td>, <td>Valid</td>, <td>Push EFLAGS.</td>, <td>9C</td>, <td>PUSHFQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Push RFLAGS.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#SS(0)</td>, <td>If the new value of the ESP register is outside the stack segment boundary.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while CPL = 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the I/O privilege level is less than 3.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#SS(0)</td>, <td>If the stack address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while CPL = 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>9C</td>, <td>PUSHF</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Push lower 16 bits of EFLAGS.</td>, <td>9C</td>, <td>PUSHFD</td>, <td>ZO</td>, <td>N.E.</td>, <td>Valid</td>, <td>Push EFLAGS.</td>, <td>9C</td>, <td>PUSHFQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Push RFLAGS.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#SS(0)</td>, <td>If the new value of the ESP register is outside the stack segment boundary.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while CPL = 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the I/O privilege level is less than 3.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#SS(0)</td>, <td>If the stack address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory reference is made while CPL = 3 and alignment checking is enabled.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>NP 0F EF /<em>r</em><sup>1</sup> PXOR <em>mm, mm/m64</em></td>, <td>A</td>, <td>V/V</td>, <td>MMX</td>, <td>Bitwise XOR of <em>mm/m64</em> and <em>mm</em>.</td>, <td>66 0F EF /<em>r</em> PXOR <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Bitwise XOR of <em>xmm2/m128</em> and <em>xmm1</em>.</td>, <td>VEX.128.66.0F.WIG EF /r VPXOR <em>xmm1, xmm2, xmm3/m128</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Bitwise XOR of <em>xmm3/m128</em> and <em>xmm2</em>.</td>, <td>VEX.256.66.0F.WIG EF /r VPXOR <em>ymm1, ymm2, ymm3/m256</em></td>, <td>B</td>, <td>V/V</td>, <td>AVX2</td>, <td>Bitwise XOR of <em>ymm3/m256</em> and <em>ymm2.</em></td>, <td>EVEX.128.66.0F.W0 EF /r VPXORD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise XOR of packed doubleword integers in xmm2 and xmm3/m128 using writemask k1.</td>, <td>EVEX.256.66.0F.W0 EF /r VPXORD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise XOR of packed doubleword integers in ymm2 and ymm3/m256 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 EF /r VPXORD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise XOR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1.</td>, <td>EVEX.128.66.0F.W1 EF /r VPXORQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise XOR of packed quadword integers in xmm2 and xmm3/m128 using writemask k1.</td>, <td>EVEX.256.66.0F.W1 EF /r VPXORQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise XOR of packed quadword integers in ymm2 and ymm3/m256 using writemask k1.</td>, <td>EVEX.512.66.0F.W1 EF /r VPXORQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise XOR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>D0 /2</td>, <td>RCL <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left once.</td>, <td>REX + D0 /2</td>, <td>RCL <em>r/m8*</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left once.</td>, <td>D2 /2</td>, <td>RCL <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left CL times.</td>, <td>REX + D2 /2</td>, <td>RCL <em>r/m8*</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left CL times.</td>, <td>C0 /2 <em>ib</em></td>, <td>RCL <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left <em>imm8</em> times.</td>, <td>REX + C0 /2 <em>ib</em></td>, <td>RCL <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left <em>imm8</em> times.</td>, <td>D1 /2</td>, <td>RCL <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) left once.</td>, <td>D3 /2</td>, <td>RCL <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) left CL times.</td>, <td>C1 /2 <em>ib</em></td>, <td>RCL <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) left <em>imm8</em> times.</td>, <td>D1 /2</td>, <td>RCL <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) left once.</td>, <td>REX.W + D1 /2</td>, <td>RCL <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) left once. Uses a 6 bit count.</td>, <td>D3 /2</td>, <td>RCL <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) left CL times.</td>, <td>REX.W + D3 /2</td>, <td>RCL <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) left CL times. Uses a 6 bit count.</td>, <td>C1 /2 <em>ib</em></td>, <td>RCL <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) left <em>imm8</em> times.</td>, <td>REX.W + C1 /2 <em>ib</em></td>, <td>RCL <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) left <em>imm8</em> times. Uses a 6 bit count.</td>, <td>D0 /3</td>, <td>RCR <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right once.</td>, <td>REX + D0 /3</td>, <td>RCR <em>r/m8*</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right once.</td>, <td>D2 /3</td>, <td>RCR <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right CL times.</td>, <td>REX + D2 /3</td>, <td>RCR <em>r/m8*</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right CL times.</td>, <td>C0 /3 <em>ib</em></td>, <td>RCR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right <em>imm8</em> times.</td>, <td>REX + C0 /3 <em>ib</em></td>, <td>RCR <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right <em>imm8</em> times.</td>, <td>D1 /3</td>, <td>RCR <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) right once.</td>, <td>D3 /3</td>, <td>RCR <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) right CL times.</td>, <td>C1 /3 <em>ib</em></td>, <td>RCR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) right <em>imm8</em> times.</td>, <td>D1 /3</td>, <td>RCR <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) right once. Uses a 6 bit count.</td>, <td>REX.W + D1 /3</td>, <td>RCR <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) right once. Uses a 6 bit count.</td>, <td>D3 /3</td>, <td>RCR <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) right CL times.</td>, <td>REX.W + D3 /3</td>, <td>RCR <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) right CL times. Uses a 6 bit count.</td>, <td>C1 /3 <em>ib</em></td>, <td>RCR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) right <em>imm8</em> times.</td>, <td>REX.W + C1 /3 <em>ib</em></td>, <td>RCR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) right <em>imm8</em> times. Uses a 6 bit count.</td>, <td>D0 /0</td>, <td>ROL <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> left once.</td>, <td>REX + D0 /0</td>, <td>ROL <em>r/m8*</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> left once</td>, <td>D2 /0</td>, <td>ROL <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> left CL times.</td>, <td>REX + D2 /0</td>, <td>ROL <em>r/m8*</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> left CL times.</td>, <td>C0 /0 <em>ib</em></td>, <td>ROL <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> left <em>imm8</em> times.</td>, <td>REX + C0 /0 <em>ib</em></td>, <td>ROL <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> left <em>imm8</em> times.</td>, <td>D1 /0</td>, <td>ROL <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> left once.</td>, <td>D3 /0</td>, <td>ROL <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> left CL times.</td>, <td>C1 /0 <em>ib</em></td>, <td>ROL <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> left <em>imm8</em> times.</td>, <td>D1 /0</td>, <td>ROL <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> left once.</td>, <td>REX.W + D1 /0</td>, <td>ROL <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> left once. Uses a 6 bit count.</td>, <td>D3 /0</td>, <td>ROL <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> left CL times.</td>, <td>REX.W + D3 /0</td>, <td>ROL <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> left CL times. Uses a 6 bit count.</td>, <td>C1 /0 <em>ib</em></td>, <td>ROL <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> left <em>imm8</em> times.</td>, <td>REX.W + C1 /0 <em>ib</em></td>, <td>ROL <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> left <em>imm8</em> times. Uses a 6 bit count.</td>, <td>D0 /1</td>, <td>ROR <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> right once.</td>, <td>REX + D0 /1</td>, <td>ROR <em>r/m8*</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> right once.</td>, <td>D2 /1</td>, <td>ROR <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> right CL times.</td>, <td>REX + D2 /1</td>, <td>ROR <em>r/m8*</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> right CL times.</td>, <td>C0 /1 <em>ib</em></td>, <td>ROR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m16</em> right <em>imm8</em> times.</td>, <td>REX + C0 /1 <em>ib</em></td>, <td>ROR <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m16</em> right <em>imm8</em> times.</td>, <td>D1 /1</td>, <td>ROR <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> right once.</td>, <td>D3 /1</td>, <td>ROR <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> right CL times.</td>, <td>C1 /1 <em>ib</em></td>, <td>ROR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> right <em>imm8</em> times.</td>, <td>D1 /1</td>, <td>ROR <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> right once.</td>, <td>REX.W + D1 /1</td>, <td>ROR <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> right once. Uses a 6 bit count.</td>, <td>D3 /1</td>, <td>ROR <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> right CL times.</td>, <td>REX.W + D3 /1</td>, <td>ROR <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> right CL times. Uses a 6 bit count.</td>, <td>C1 /1 <em>ib</em></td>, <td>ROR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> right <em>imm8</em> times.</td>, <td>REX.W + C1 /1 <em>ib</em></td>, <td>ROR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> right <em>imm8</em> times. Uses a 6 bit count.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M1</td>, <td>ModRM:r/m (w)</td>, <td>1</td>, <td>NA</td>, <td>NA</td>, <td>MC</td>, <td>ModRM:r/m (w)</td>, <td>CL</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the source operand is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the source operand is located in a nonwritable segment.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>NP 0F 53 /<em>r</em> RCPPS <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE</td>, <td>Computes the approximate reciprocals of the packed single-precision floating-point values in <em>xmm2/m128</em> and stores the results in <em>xmm1</em>.</td>, <td>VEX.128.0F.WIG 53 /r VRCPPS <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Computes the approximate reciprocals of packed single-precision values in <em>xmm2/mem</em> and stores the results in <em>xmm1</em>.</td>, <td>VEX.256.0F.WIG 53 /r VRCPPS <em>ymm1, ymm2/m256</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Computes the approximate reciprocals of packed single-precision values in <em>ymm2/mem</em> and stores the results in <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>F3 0F 53 /<em>r</em> RCPSS <em>xmm1</em>, xmm2/m32</td>, <td>RM</td>, <td>V/V</td>, <td>SSE</td>, <td>Computes the approximate reciprocal of the scalar single-precision floating-point value in <em>xmm2/m32</em> and stores the result in <em>xmm1</em>.</td>, <td>VEX.LIG.F3.0F.WIG 53 /r VRCPSS <em>xmm1, xmm2, xmm3/m32</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Computes the approximate reciprocal of the scalar single-precision floating-point value in <em>xmm3/m32</em> and stores the result in <em>xmm1</em>. Also, upper single precision floating-point values (bits[127:32]) from <em>xmm2</em> are copied to <em>xmm1</em>[127:32].</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>D0 /2</td>, <td>RCL <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left once.</td>, <td>REX + D0 /2</td>, <td>RCL <em>r/m8*</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left once.</td>, <td>D2 /2</td>, <td>RCL <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left CL times.</td>, <td>REX + D2 /2</td>, <td>RCL <em>r/m8*</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left CL times.</td>, <td>C0 /2 <em>ib</em></td>, <td>RCL <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left <em>imm8</em> times.</td>, <td>REX + C0 /2 <em>ib</em></td>, <td>RCL <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left <em>imm8</em> times.</td>, <td>D1 /2</td>, <td>RCL <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) left once.</td>, <td>D3 /2</td>, <td>RCL <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) left CL times.</td>, <td>C1 /2 <em>ib</em></td>, <td>RCL <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) left <em>imm8</em> times.</td>, <td>D1 /2</td>, <td>RCL <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) left once.</td>, <td>REX.W + D1 /2</td>, <td>RCL <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) left once. Uses a 6 bit count.</td>, <td>D3 /2</td>, <td>RCL <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) left CL times.</td>, <td>REX.W + D3 /2</td>, <td>RCL <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) left CL times. Uses a 6 bit count.</td>, <td>C1 /2 <em>ib</em></td>, <td>RCL <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) left <em>imm8</em> times.</td>, <td>REX.W + C1 /2 <em>ib</em></td>, <td>RCL <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) left <em>imm8</em> times. Uses a 6 bit count.</td>, <td>D0 /3</td>, <td>RCR <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right once.</td>, <td>REX + D0 /3</td>, <td>RCR <em>r/m8*</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right once.</td>, <td>D2 /3</td>, <td>RCR <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right CL times.</td>, <td>REX + D2 /3</td>, <td>RCR <em>r/m8*</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right CL times.</td>, <td>C0 /3 <em>ib</em></td>, <td>RCR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right <em>imm8</em> times.</td>, <td>REX + C0 /3 <em>ib</em></td>, <td>RCR <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right <em>imm8</em> times.</td>, <td>D1 /3</td>, <td>RCR <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) right once.</td>, <td>D3 /3</td>, <td>RCR <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) right CL times.</td>, <td>C1 /3 <em>ib</em></td>, <td>RCR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) right <em>imm8</em> times.</td>, <td>D1 /3</td>, <td>RCR <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) right once. Uses a 6 bit count.</td>, <td>REX.W + D1 /3</td>, <td>RCR <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) right once. Uses a 6 bit count.</td>, <td>D3 /3</td>, <td>RCR <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) right CL times.</td>, <td>REX.W + D3 /3</td>, <td>RCR <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) right CL times. Uses a 6 bit count.</td>, <td>C1 /3 <em>ib</em></td>, <td>RCR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) right <em>imm8</em> times.</td>, <td>REX.W + C1 /3 <em>ib</em></td>, <td>RCR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) right <em>imm8</em> times. Uses a 6 bit count.</td>, <td>D0 /0</td>, <td>ROL <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> left once.</td>, <td>REX + D0 /0</td>, <td>ROL <em>r/m8*</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> left once</td>, <td>D2 /0</td>, <td>ROL <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> left CL times.</td>, <td>REX + D2 /0</td>, <td>ROL <em>r/m8*</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> left CL times.</td>, <td>C0 /0 <em>ib</em></td>, <td>ROL <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> left <em>imm8</em> times.</td>, <td>REX + C0 /0 <em>ib</em></td>, <td>ROL <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> left <em>imm8</em> times.</td>, <td>D1 /0</td>, <td>ROL <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> left once.</td>, <td>D3 /0</td>, <td>ROL <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> left CL times.</td>, <td>C1 /0 <em>ib</em></td>, <td>ROL <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> left <em>imm8</em> times.</td>, <td>D1 /0</td>, <td>ROL <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> left once.</td>, <td>REX.W + D1 /0</td>, <td>ROL <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> left once. Uses a 6 bit count.</td>, <td>D3 /0</td>, <td>ROL <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> left CL times.</td>, <td>REX.W + D3 /0</td>, <td>ROL <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> left CL times. Uses a 6 bit count.</td>, <td>C1 /0 <em>ib</em></td>, <td>ROL <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> left <em>imm8</em> times.</td>, <td>REX.W + C1 /0 <em>ib</em></td>, <td>ROL <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> left <em>imm8</em> times. Uses a 6 bit count.</td>, <td>D0 /1</td>, <td>ROR <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> right once.</td>, <td>REX + D0 /1</td>, <td>ROR <em>r/m8*</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> right once.</td>, <td>D2 /1</td>, <td>ROR <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> right CL times.</td>, <td>REX + D2 /1</td>, <td>ROR <em>r/m8*</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> right CL times.</td>, <td>C0 /1 <em>ib</em></td>, <td>ROR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m16</em> right <em>imm8</em> times.</td>, <td>REX + C0 /1 <em>ib</em></td>, <td>ROR <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m16</em> right <em>imm8</em> times.</td>, <td>D1 /1</td>, <td>ROR <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> right once.</td>, <td>D3 /1</td>, <td>ROR <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> right CL times.</td>, <td>C1 /1 <em>ib</em></td>, <td>ROR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> right <em>imm8</em> times.</td>, <td>D1 /1</td>, <td>ROR <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> right once.</td>, <td>REX.W + D1 /1</td>, <td>ROR <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> right once. Uses a 6 bit count.</td>, <td>D3 /1</td>, <td>ROR <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> right CL times.</td>, <td>REX.W + D3 /1</td>, <td>ROR <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> right CL times. Uses a 6 bit count.</td>, <td>C1 /1 <em>ib</em></td>, <td>ROR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> right <em>imm8</em> times.</td>, <td>REX.W + C1 /1 <em>ib</em></td>, <td>ROR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> right <em>imm8</em> times. Uses a 6 bit count.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M1</td>, <td>ModRM:r/m (w)</td>, <td>1</td>, <td>NA</td>, <td>NA</td>, <td>MC</td>, <td>ModRM:r/m (w)</td>, <td>CL</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the source operand is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the source operand is located in a nonwritable segment.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td colspan="2">F3 0F AE /0 RDFSBASE r32</td>, <td>M</td>, <td>V/I</td>, <td>FSGSBASE</td>, <td>Load the 32-bit destination register with the FS base address.</td>, <td colspan="2">F3 REX.W 0F AE /0 RDFSBASE r64</td>, <td>M</td>, <td>V/I</td>, <td>FSGSBASE</td>, <td>Load the 64-bit destination register with the FS base address.</td>, <td colspan="2">F3 0F AE /1 RDGSBASE <em>r32</em></td>, <td>M</td>, <td>V/I</td>, <td>FSGSBASE</td>, <td>Load the 32-bit destination register with the GS base address.</td>, <td>F3 REX.W 0F AE /1 RDGSBASE <em>r64</em></td>, <td></td>, <td>M</td>, <td>V/I</td>, <td>FSGSBASE</td>, <td>Load the 64-bit destination register with the GS base address.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>The RDFSBASE and RDGSBASE instructions are not recognized in protected mode.</td>, <td>#UD</td>, <td>The RDFSBASE and RDGSBASE instructions are not recognized in real-address mode.</td>, <td>#UD</td>, <td>The RDFSBASE and RDGSBASE instructions are not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The RDFSBASE and RDGSBASE instructions are not recognized in compatibility mode.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CR4.FSGSBASE[bit 16] = 0.</td>, <td>If CPUID.07H.0H:EBX.FSGSBASE[bit 0] = 0.</td>]

[<td colspan="2">F3 0F AE /0 RDFSBASE r32</td>, <td>M</td>, <td>V/I</td>, <td>FSGSBASE</td>, <td>Load the 32-bit destination register with the FS base address.</td>, <td colspan="2">F3 REX.W 0F AE /0 RDFSBASE r64</td>, <td>M</td>, <td>V/I</td>, <td>FSGSBASE</td>, <td>Load the 64-bit destination register with the FS base address.</td>, <td colspan="2">F3 0F AE /1 RDGSBASE <em>r32</em></td>, <td>M</td>, <td>V/I</td>, <td>FSGSBASE</td>, <td>Load the 32-bit destination register with the GS base address.</td>, <td>F3 REX.W 0F AE /1 RDGSBASE <em>r64</em></td>, <td></td>, <td>M</td>, <td>V/I</td>, <td>FSGSBASE</td>, <td>Load the 64-bit destination register with the GS base address.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>The RDFSBASE and RDGSBASE instructions are not recognized in protected mode.</td>, <td>#UD</td>, <td>The RDFSBASE and RDGSBASE instructions are not recognized in real-address mode.</td>, <td>#UD</td>, <td>The RDFSBASE and RDGSBASE instructions are not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The RDFSBASE and RDGSBASE instructions are not recognized in compatibility mode.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CR4.FSGSBASE[bit 16] = 0.</td>, <td>If CPUID.07H.0H:EBX.FSGSBASE[bit 0] = 0.</td>]

[<td></td>, <td></td>, <td></td>, <td>Valid</td>, <td>Valid</td>, <td>Read MSR specified by ECX into EDX:EAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the value in ECX specifies a reserved or unimplemented MSR address.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If the value in ECX specifies a reserved or unimplemented MSR address.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>The RDMSR instruction is not recognized in virtual-8086 mode.</td>]

[<td>F3 0F C7 /7 RDPID r32</td>, <td>R</td>, <td>N.E./V</td>, <td>RDPID</td>, <td>Read IA32_TSC_AUX into r32.</td>, <td>F3 0F C7 /7 RDPID r64</td>, <td>R</td>, <td>V/N.E.</td>, <td>RDPID</td>, <td>Read IA32_TSC_AUX into r64.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>R</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.7H.0:ECX.RDPID[bit 22] = 0.</td>]

[<td>NP 0F 01 EE</td>, <td>RDPKRU</td>, <td>ZO</td>, <td>V/V</td>, <td>OSPKE</td>, <td>Reads PKRU into EAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If ECX ≠ 0.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CR4.PKE = 0.</td>]

[<td>0F 33</td>, <td>RDPMC</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Read performance-monitoring counter specified by ECX into EDX:EAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If the current privilege level is not 0 and the PCE flag in the CR4 register is clear.</td>, <td>If an invalid performance counter index is specified.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If an invalid performance counter index is specified.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP(0)</td>, <td>If the PCE flag in the CR4 register is clear.</td>, <td>If an invalid performance counter index is specified.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP(0)</td>, <td>If the current privilege level is not 0 and the PCE flag in the CR4 register is clear.</td>, <td>If an invalid performance counter index is specified.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>NFx 0F C7 /6 RDRAND r16</td>, <td>M</td>, <td>V/V</td>, <td>RDRAND</td>, <td>Read a 16-bit random number and store in the destination register.</td>, <td>NFx 0F C7 /6 RDRAND r32</td>, <td>M</td>, <td>V/V</td>, <td>RDRAND</td>, <td>Read a 32-bit random number and store in the destination register.</td>, <td>NFx REX.W + 0F C7 /6 RDRAND r64</td>, <td>M</td>, <td>V/I</td>, <td>RDRAND</td>, <td>Read a 64-bit random number and store in the destination register.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.01H:ECX.RDRAND[bit 30] = 0.</td>]

[<td>NFx 0F C7 /7 RDSEED r16</td>, <td>M</td>, <td>V/V</td>, <td>RDSEED</td>, <td>Read a 16-bit NIST SP800-90B &amp; C compliant random value and store in the destination register.</td>, <td>NFx 0F C7 /7 RDSEED r32</td>, <td>M</td>, <td>V/V</td>, <td>RDSEED</td>, <td>Read a 32-bit NIST SP800-90B &amp; C compliant random value and store in the destination register.</td>, <td>NFx REX.W + 0F C7 /7 RDSEED r64</td>, <td>M</td>, <td>V/I</td>, <td>RDSEED</td>, <td>Read a 64-bit NIST SP800-90B &amp; C compliant random value and store in the destination register.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.RDSEED[bit 18] = 0.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.RDSEED[bit 18] = 0.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.RDSEED[bit 18] = 0.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.RDSEED[bit 18] = 0.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.RDSEED[bit 18] = 0.</td>]

[<td>0F 31</td>, <td>RDTSC</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Read time-stamp counter into EDX:EAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If the TSD flag in register CR4 is set and the CPL is greater than 0.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the TSD flag in register CR4 is set.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 01 F9</td>, <td>RDTSCP</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Read 64-bit time-stamp counter and IA32_TSC_AUX value into EDX:EAX and ECX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If the TSD flag in register CR4 is set and the CPL is greater than 0.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.80000001H:EDX.RDTSCP[bit 27] = 0.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.80000001H:EDX.RDTSCP[bit 27] = 0.</td>, <td>#GP(0)</td>, <td>If the TSD flag in register CR4 is set.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.80000001H:EDX.RDTSCP[bit 27] = 0.</td>]

[<td>F3 6C</td>, <td>REP INS <em>m8</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input (E)CX bytes from port DX into ES:[(E)DI].</td>, <td>F3 6C</td>, <td>REP INS <em>m8</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Input RCX bytes from port DX into [RDI].</td>, <td>F3 6D</td>, <td>REP INS <em>m16</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input (E)CX words from port DX into ES:[(E)DI.]</td>, <td>F3 6D</td>, <td>REP INS <em>m32</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input (E)CX doublewords from port DX into ES:[(E)DI].</td>, <td>F3 6D</td>, <td>REP INS <em>r/m32</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Input RCX default size from port DX into [RDI].</td>, <td>F3 A4</td>, <td>REP MOVS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Move (E)CX bytes from DS:[(E)SI] to ES:[(E)DI].</td>, <td>F3 REX.W A4</td>, <td>REP MOVS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move RCX bytes from [RSI] to [RDI].</td>, <td>F3 A5</td>, <td>REP MOVS <em>m16, m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Move (E)CX words from DS:[(E)SI] to ES:[(E)DI].</td>, <td>F3 A5</td>, <td>REP MOVS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Move (E)CX doublewords from DS:[(E)SI] to ES:[(E)DI].</td>, <td>F3 REX.W A5</td>, <td>REP MOVS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move RCX quadwords from [RSI] to [RDI].</td>, <td>F3 6E</td>, <td>REP OUTS DX, <em>r/m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output (E)CX bytes from DS:[(E)SI] to port DX.</td>, <td>F3 REX.W 6E</td>, <td>REP OUTS DX, <em>r/m8*</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Output RCX bytes from [RSI] to port DX.</td>, <td>F3 6F</td>, <td>REP OUTS DX, <em>r/m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output (E)CX words from DS:[(E)SI] to port DX.</td>, <td>F3 6F</td>, <td>REP OUTS DX, <em>r/m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output (E)CX doublewords from DS:[(E)SI] to port DX.</td>, <td>F3 REX.W 6F</td>, <td>REP OUTS DX, <em>r/m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Output RCX default size from [RSI] to port DX.</td>, <td>F3 AC</td>, <td>REP LODS AL</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Load (E)CX bytes from DS:[(E)SI] to AL.</td>, <td>F3 REX.W AC</td>, <td>REP LODS AL</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load RCX bytes from [RSI] to AL.</td>, <td>F3 AD</td>, <td>REP LODS AX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Load (E)CX words from DS:[(E)SI] to AX.</td>, <td>F3 AD</td>, <td>REP LODS EAX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Load (E)CX doublewords from DS:[(E)SI] to EAX.</td>, <td>F3 REX.W AD</td>, <td>REP LODS RAX</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load RCX quadwords from [RSI] to RAX.</td>, <td>F3 AA</td>, <td>REP STOS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fill (E)CX bytes at ES:[(E)DI] with AL.</td>, <td>F3 REX.W AA</td>, <td>REP STOS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Fill RCX bytes at [RDI] with AL.</td>, <td>F3 AB</td>, <td>REP STOS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fill (E)CX words at ES:[(E)DI] with AX.</td>, <td>F3 AB</td>, <td>REP STOS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fill (E)CX doublewords at ES:[(E)DI] with EAX.</td>, <td>F3 REX.W AB</td>, <td>REP STOS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Fill RCX quadwords at [RDI] with RAX.</td>, <td>F3 A6</td>, <td>REPE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find nonmatching bytes in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F3 REX.W A6</td>, <td>REPE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-matching bytes in [RDI] and [RSI].</td>, <td>F3 A7</td>, <td>REPE CMPS <em>m16, m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find nonmatching words in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F3 A7</td>, <td>REPE CMPS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find nonmatching doublewords in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F3 REX.W A7</td>, <td>REPE CMPS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-matching quadwords in [RDI] and [RSI].</td>, <td>F3 AE</td>, <td>REPE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find non-AL byte starting at ES:[(E)DI].</td>, <td>F3 REX.W AE</td>, <td>REPE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-AL byte starting at [RDI].</td>, <td>F3 AF</td>, <td>REPE SCAS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find non-AX word starting at ES:[(E)DI].</td>, <td>F3 AF</td>, <td>REPE SCAS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find non-EAX doubleword starting at ES:[(E)DI].</td>, <td>F3 REX.W AF</td>, <td>REPE SCAS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-RAX quadword starting at [RDI].</td>, <td>F2 A6</td>, <td>REPNE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find matching bytes in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F2 REX.W A6</td>, <td>REPNE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find matching bytes in [RDI] and [RSI].</td>, <td>F2 A7</td>, <td>REPNE CMPS <em>m16, m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find matching words in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F2 A7</td>, <td>REPNE CMPS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find matching doublewords in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F2 REX.W A7</td>, <td>REPNE CMPS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find matching doublewords in [RDI] and [RSI].</td>, <td>F2 AE</td>, <td>REPNE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find AL, starting at ES:[(E)DI].</td>, <td>F2 REX.W AE</td>, <td>REPNE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find AL, starting at [RDI].</td>, <td>F2 AF</td>, <td>REPNE SCAS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find AX, starting at ES:[(E)DI].</td>, <td>F2 AF</td>, <td>REPNE SCAS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find EAX, starting at ES:[(E)DI].</td>, <td>F2 REX.W AF</td>, <td>REPNE SCAS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find RAX, starting at [RDI].</td>, <td colspan="6"><strong>NOTES:</strong> * In64-bitmode,r/m8cannotbeencodedtoaccessthefollowingbyteregistersifaREXprefixisused:AH,BH,CH,DH.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>REP</td>, <td>RCX or (E)CX = 0</td>, <td>None</td>, <td>REPE/REPZ</td>, <td>RCX or (E)CX = 0</td>, <td>ZF = 0</td>, <td>REPNE/REPNZ</td>, <td>RCX or (E)CX = 0</td>, <td>ZF = 1</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>]

[<td>F3 6C</td>, <td>REP INS <em>m8</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input (E)CX bytes from port DX into ES:[(E)DI].</td>, <td>F3 6C</td>, <td>REP INS <em>m8</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Input RCX bytes from port DX into [RDI].</td>, <td>F3 6D</td>, <td>REP INS <em>m16</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input (E)CX words from port DX into ES:[(E)DI.]</td>, <td>F3 6D</td>, <td>REP INS <em>m32</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input (E)CX doublewords from port DX into ES:[(E)DI].</td>, <td>F3 6D</td>, <td>REP INS <em>r/m32</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Input RCX default size from port DX into [RDI].</td>, <td>F3 A4</td>, <td>REP MOVS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Move (E)CX bytes from DS:[(E)SI] to ES:[(E)DI].</td>, <td>F3 REX.W A4</td>, <td>REP MOVS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move RCX bytes from [RSI] to [RDI].</td>, <td>F3 A5</td>, <td>REP MOVS <em>m16, m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Move (E)CX words from DS:[(E)SI] to ES:[(E)DI].</td>, <td>F3 A5</td>, <td>REP MOVS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Move (E)CX doublewords from DS:[(E)SI] to ES:[(E)DI].</td>, <td>F3 REX.W A5</td>, <td>REP MOVS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move RCX quadwords from [RSI] to [RDI].</td>, <td>F3 6E</td>, <td>REP OUTS DX, <em>r/m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output (E)CX bytes from DS:[(E)SI] to port DX.</td>, <td>F3 REX.W 6E</td>, <td>REP OUTS DX, <em>r/m8*</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Output RCX bytes from [RSI] to port DX.</td>, <td>F3 6F</td>, <td>REP OUTS DX, <em>r/m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output (E)CX words from DS:[(E)SI] to port DX.</td>, <td>F3 6F</td>, <td>REP OUTS DX, <em>r/m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output (E)CX doublewords from DS:[(E)SI] to port DX.</td>, <td>F3 REX.W 6F</td>, <td>REP OUTS DX, <em>r/m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Output RCX default size from [RSI] to port DX.</td>, <td>F3 AC</td>, <td>REP LODS AL</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Load (E)CX bytes from DS:[(E)SI] to AL.</td>, <td>F3 REX.W AC</td>, <td>REP LODS AL</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load RCX bytes from [RSI] to AL.</td>, <td>F3 AD</td>, <td>REP LODS AX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Load (E)CX words from DS:[(E)SI] to AX.</td>, <td>F3 AD</td>, <td>REP LODS EAX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Load (E)CX doublewords from DS:[(E)SI] to EAX.</td>, <td>F3 REX.W AD</td>, <td>REP LODS RAX</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load RCX quadwords from [RSI] to RAX.</td>, <td>F3 AA</td>, <td>REP STOS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fill (E)CX bytes at ES:[(E)DI] with AL.</td>, <td>F3 REX.W AA</td>, <td>REP STOS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Fill RCX bytes at [RDI] with AL.</td>, <td>F3 AB</td>, <td>REP STOS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fill (E)CX words at ES:[(E)DI] with AX.</td>, <td>F3 AB</td>, <td>REP STOS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fill (E)CX doublewords at ES:[(E)DI] with EAX.</td>, <td>F3 REX.W AB</td>, <td>REP STOS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Fill RCX quadwords at [RDI] with RAX.</td>, <td>F3 A6</td>, <td>REPE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find nonmatching bytes in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F3 REX.W A6</td>, <td>REPE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-matching bytes in [RDI] and [RSI].</td>, <td>F3 A7</td>, <td>REPE CMPS <em>m16, m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find nonmatching words in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F3 A7</td>, <td>REPE CMPS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find nonmatching doublewords in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F3 REX.W A7</td>, <td>REPE CMPS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-matching quadwords in [RDI] and [RSI].</td>, <td>F3 AE</td>, <td>REPE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find non-AL byte starting at ES:[(E)DI].</td>, <td>F3 REX.W AE</td>, <td>REPE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-AL byte starting at [RDI].</td>, <td>F3 AF</td>, <td>REPE SCAS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find non-AX word starting at ES:[(E)DI].</td>, <td>F3 AF</td>, <td>REPE SCAS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find non-EAX doubleword starting at ES:[(E)DI].</td>, <td>F3 REX.W AF</td>, <td>REPE SCAS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-RAX quadword starting at [RDI].</td>, <td>F2 A6</td>, <td>REPNE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find matching bytes in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F2 REX.W A6</td>, <td>REPNE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find matching bytes in [RDI] and [RSI].</td>, <td>F2 A7</td>, <td>REPNE CMPS <em>m16, m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find matching words in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F2 A7</td>, <td>REPNE CMPS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find matching doublewords in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F2 REX.W A7</td>, <td>REPNE CMPS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find matching doublewords in [RDI] and [RSI].</td>, <td>F2 AE</td>, <td>REPNE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find AL, starting at ES:[(E)DI].</td>, <td>F2 REX.W AE</td>, <td>REPNE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find AL, starting at [RDI].</td>, <td>F2 AF</td>, <td>REPNE SCAS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find AX, starting at ES:[(E)DI].</td>, <td>F2 AF</td>, <td>REPNE SCAS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find EAX, starting at ES:[(E)DI].</td>, <td>F2 REX.W AF</td>, <td>REPNE SCAS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find RAX, starting at [RDI].</td>, <td colspan="6"><strong>NOTES:</strong> * In64-bitmode,r/m8cannotbeencodedtoaccessthefollowingbyteregistersifaREXprefixisused:AH,BH,CH,DH.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>REP</td>, <td>RCX or (E)CX = 0</td>, <td>None</td>, <td>REPE/REPZ</td>, <td>RCX or (E)CX = 0</td>, <td>ZF = 0</td>, <td>REPNE/REPNZ</td>, <td>RCX or (E)CX = 0</td>, <td>ZF = 1</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>]

[<td>F3 6C</td>, <td>REP INS <em>m8</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input (E)CX bytes from port DX into ES:[(E)DI].</td>, <td>F3 6C</td>, <td>REP INS <em>m8</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Input RCX bytes from port DX into [RDI].</td>, <td>F3 6D</td>, <td>REP INS <em>m16</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input (E)CX words from port DX into ES:[(E)DI.]</td>, <td>F3 6D</td>, <td>REP INS <em>m32</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input (E)CX doublewords from port DX into ES:[(E)DI].</td>, <td>F3 6D</td>, <td>REP INS <em>r/m32</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Input RCX default size from port DX into [RDI].</td>, <td>F3 A4</td>, <td>REP MOVS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Move (E)CX bytes from DS:[(E)SI] to ES:[(E)DI].</td>, <td>F3 REX.W A4</td>, <td>REP MOVS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move RCX bytes from [RSI] to [RDI].</td>, <td>F3 A5</td>, <td>REP MOVS <em>m16, m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Move (E)CX words from DS:[(E)SI] to ES:[(E)DI].</td>, <td>F3 A5</td>, <td>REP MOVS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Move (E)CX doublewords from DS:[(E)SI] to ES:[(E)DI].</td>, <td>F3 REX.W A5</td>, <td>REP MOVS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move RCX quadwords from [RSI] to [RDI].</td>, <td>F3 6E</td>, <td>REP OUTS DX, <em>r/m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output (E)CX bytes from DS:[(E)SI] to port DX.</td>, <td>F3 REX.W 6E</td>, <td>REP OUTS DX, <em>r/m8*</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Output RCX bytes from [RSI] to port DX.</td>, <td>F3 6F</td>, <td>REP OUTS DX, <em>r/m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output (E)CX words from DS:[(E)SI] to port DX.</td>, <td>F3 6F</td>, <td>REP OUTS DX, <em>r/m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output (E)CX doublewords from DS:[(E)SI] to port DX.</td>, <td>F3 REX.W 6F</td>, <td>REP OUTS DX, <em>r/m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Output RCX default size from [RSI] to port DX.</td>, <td>F3 AC</td>, <td>REP LODS AL</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Load (E)CX bytes from DS:[(E)SI] to AL.</td>, <td>F3 REX.W AC</td>, <td>REP LODS AL</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load RCX bytes from [RSI] to AL.</td>, <td>F3 AD</td>, <td>REP LODS AX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Load (E)CX words from DS:[(E)SI] to AX.</td>, <td>F3 AD</td>, <td>REP LODS EAX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Load (E)CX doublewords from DS:[(E)SI] to EAX.</td>, <td>F3 REX.W AD</td>, <td>REP LODS RAX</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load RCX quadwords from [RSI] to RAX.</td>, <td>F3 AA</td>, <td>REP STOS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fill (E)CX bytes at ES:[(E)DI] with AL.</td>, <td>F3 REX.W AA</td>, <td>REP STOS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Fill RCX bytes at [RDI] with AL.</td>, <td>F3 AB</td>, <td>REP STOS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fill (E)CX words at ES:[(E)DI] with AX.</td>, <td>F3 AB</td>, <td>REP STOS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fill (E)CX doublewords at ES:[(E)DI] with EAX.</td>, <td>F3 REX.W AB</td>, <td>REP STOS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Fill RCX quadwords at [RDI] with RAX.</td>, <td>F3 A6</td>, <td>REPE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find nonmatching bytes in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F3 REX.W A6</td>, <td>REPE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-matching bytes in [RDI] and [RSI].</td>, <td>F3 A7</td>, <td>REPE CMPS <em>m16, m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find nonmatching words in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F3 A7</td>, <td>REPE CMPS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find nonmatching doublewords in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F3 REX.W A7</td>, <td>REPE CMPS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-matching quadwords in [RDI] and [RSI].</td>, <td>F3 AE</td>, <td>REPE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find non-AL byte starting at ES:[(E)DI].</td>, <td>F3 REX.W AE</td>, <td>REPE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-AL byte starting at [RDI].</td>, <td>F3 AF</td>, <td>REPE SCAS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find non-AX word starting at ES:[(E)DI].</td>, <td>F3 AF</td>, <td>REPE SCAS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find non-EAX doubleword starting at ES:[(E)DI].</td>, <td>F3 REX.W AF</td>, <td>REPE SCAS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-RAX quadword starting at [RDI].</td>, <td>F2 A6</td>, <td>REPNE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find matching bytes in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F2 REX.W A6</td>, <td>REPNE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find matching bytes in [RDI] and [RSI].</td>, <td>F2 A7</td>, <td>REPNE CMPS <em>m16, m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find matching words in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F2 A7</td>, <td>REPNE CMPS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find matching doublewords in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F2 REX.W A7</td>, <td>REPNE CMPS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find matching doublewords in [RDI] and [RSI].</td>, <td>F2 AE</td>, <td>REPNE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find AL, starting at ES:[(E)DI].</td>, <td>F2 REX.W AE</td>, <td>REPNE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find AL, starting at [RDI].</td>, <td>F2 AF</td>, <td>REPNE SCAS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find AX, starting at ES:[(E)DI].</td>, <td>F2 AF</td>, <td>REPNE SCAS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find EAX, starting at ES:[(E)DI].</td>, <td>F2 REX.W AF</td>, <td>REPNE SCAS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find RAX, starting at [RDI].</td>, <td colspan="6"><strong>NOTES:</strong> * In64-bitmode,r/m8cannotbeencodedtoaccessthefollowingbyteregistersifaREXprefixisused:AH,BH,CH,DH.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>REP</td>, <td>RCX or (E)CX = 0</td>, <td>None</td>, <td>REPE/REPZ</td>, <td>RCX or (E)CX = 0</td>, <td>ZF = 0</td>, <td>REPNE/REPNZ</td>, <td>RCX or (E)CX = 0</td>, <td>ZF = 1</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>]

[<td>F3 6C</td>, <td>REP INS <em>m8</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input (E)CX bytes from port DX into ES:[(E)DI].</td>, <td>F3 6C</td>, <td>REP INS <em>m8</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Input RCX bytes from port DX into [RDI].</td>, <td>F3 6D</td>, <td>REP INS <em>m16</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input (E)CX words from port DX into ES:[(E)DI.]</td>, <td>F3 6D</td>, <td>REP INS <em>m32</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input (E)CX doublewords from port DX into ES:[(E)DI].</td>, <td>F3 6D</td>, <td>REP INS <em>r/m32</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Input RCX default size from port DX into [RDI].</td>, <td>F3 A4</td>, <td>REP MOVS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Move (E)CX bytes from DS:[(E)SI] to ES:[(E)DI].</td>, <td>F3 REX.W A4</td>, <td>REP MOVS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move RCX bytes from [RSI] to [RDI].</td>, <td>F3 A5</td>, <td>REP MOVS <em>m16, m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Move (E)CX words from DS:[(E)SI] to ES:[(E)DI].</td>, <td>F3 A5</td>, <td>REP MOVS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Move (E)CX doublewords from DS:[(E)SI] to ES:[(E)DI].</td>, <td>F3 REX.W A5</td>, <td>REP MOVS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move RCX quadwords from [RSI] to [RDI].</td>, <td>F3 6E</td>, <td>REP OUTS DX, <em>r/m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output (E)CX bytes from DS:[(E)SI] to port DX.</td>, <td>F3 REX.W 6E</td>, <td>REP OUTS DX, <em>r/m8*</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Output RCX bytes from [RSI] to port DX.</td>, <td>F3 6F</td>, <td>REP OUTS DX, <em>r/m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output (E)CX words from DS:[(E)SI] to port DX.</td>, <td>F3 6F</td>, <td>REP OUTS DX, <em>r/m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output (E)CX doublewords from DS:[(E)SI] to port DX.</td>, <td>F3 REX.W 6F</td>, <td>REP OUTS DX, <em>r/m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Output RCX default size from [RSI] to port DX.</td>, <td>F3 AC</td>, <td>REP LODS AL</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Load (E)CX bytes from DS:[(E)SI] to AL.</td>, <td>F3 REX.W AC</td>, <td>REP LODS AL</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load RCX bytes from [RSI] to AL.</td>, <td>F3 AD</td>, <td>REP LODS AX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Load (E)CX words from DS:[(E)SI] to AX.</td>, <td>F3 AD</td>, <td>REP LODS EAX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Load (E)CX doublewords from DS:[(E)SI] to EAX.</td>, <td>F3 REX.W AD</td>, <td>REP LODS RAX</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load RCX quadwords from [RSI] to RAX.</td>, <td>F3 AA</td>, <td>REP STOS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fill (E)CX bytes at ES:[(E)DI] with AL.</td>, <td>F3 REX.W AA</td>, <td>REP STOS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Fill RCX bytes at [RDI] with AL.</td>, <td>F3 AB</td>, <td>REP STOS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fill (E)CX words at ES:[(E)DI] with AX.</td>, <td>F3 AB</td>, <td>REP STOS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fill (E)CX doublewords at ES:[(E)DI] with EAX.</td>, <td>F3 REX.W AB</td>, <td>REP STOS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Fill RCX quadwords at [RDI] with RAX.</td>, <td>F3 A6</td>, <td>REPE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find nonmatching bytes in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F3 REX.W A6</td>, <td>REPE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-matching bytes in [RDI] and [RSI].</td>, <td>F3 A7</td>, <td>REPE CMPS <em>m16, m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find nonmatching words in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F3 A7</td>, <td>REPE CMPS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find nonmatching doublewords in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F3 REX.W A7</td>, <td>REPE CMPS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-matching quadwords in [RDI] and [RSI].</td>, <td>F3 AE</td>, <td>REPE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find non-AL byte starting at ES:[(E)DI].</td>, <td>F3 REX.W AE</td>, <td>REPE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-AL byte starting at [RDI].</td>, <td>F3 AF</td>, <td>REPE SCAS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find non-AX word starting at ES:[(E)DI].</td>, <td>F3 AF</td>, <td>REPE SCAS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find non-EAX doubleword starting at ES:[(E)DI].</td>, <td>F3 REX.W AF</td>, <td>REPE SCAS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-RAX quadword starting at [RDI].</td>, <td>F2 A6</td>, <td>REPNE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find matching bytes in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F2 REX.W A6</td>, <td>REPNE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find matching bytes in [RDI] and [RSI].</td>, <td>F2 A7</td>, <td>REPNE CMPS <em>m16, m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find matching words in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F2 A7</td>, <td>REPNE CMPS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find matching doublewords in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F2 REX.W A7</td>, <td>REPNE CMPS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find matching doublewords in [RDI] and [RSI].</td>, <td>F2 AE</td>, <td>REPNE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find AL, starting at ES:[(E)DI].</td>, <td>F2 REX.W AE</td>, <td>REPNE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find AL, starting at [RDI].</td>, <td>F2 AF</td>, <td>REPNE SCAS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find AX, starting at ES:[(E)DI].</td>, <td>F2 AF</td>, <td>REPNE SCAS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find EAX, starting at ES:[(E)DI].</td>, <td>F2 REX.W AF</td>, <td>REPNE SCAS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find RAX, starting at [RDI].</td>, <td colspan="6"><strong>NOTES:</strong> * In64-bitmode,r/m8cannotbeencodedtoaccessthefollowingbyteregistersifaREXprefixisused:AH,BH,CH,DH.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>REP</td>, <td>RCX or (E)CX = 0</td>, <td>None</td>, <td>REPE/REPZ</td>, <td>RCX or (E)CX = 0</td>, <td>ZF = 0</td>, <td>REPNE/REPNZ</td>, <td>RCX or (E)CX = 0</td>, <td>ZF = 1</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>]

[<td>F3 6C</td>, <td>REP INS <em>m8</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input (E)CX bytes from port DX into ES:[(E)DI].</td>, <td>F3 6C</td>, <td>REP INS <em>m8</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Input RCX bytes from port DX into [RDI].</td>, <td>F3 6D</td>, <td>REP INS <em>m16</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input (E)CX words from port DX into ES:[(E)DI.]</td>, <td>F3 6D</td>, <td>REP INS <em>m32</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Input (E)CX doublewords from port DX into ES:[(E)DI].</td>, <td>F3 6D</td>, <td>REP INS <em>r/m32</em>, DX</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Input RCX default size from port DX into [RDI].</td>, <td>F3 A4</td>, <td>REP MOVS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Move (E)CX bytes from DS:[(E)SI] to ES:[(E)DI].</td>, <td>F3 REX.W A4</td>, <td>REP MOVS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move RCX bytes from [RSI] to [RDI].</td>, <td>F3 A5</td>, <td>REP MOVS <em>m16, m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Move (E)CX words from DS:[(E)SI] to ES:[(E)DI].</td>, <td>F3 A5</td>, <td>REP MOVS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Move (E)CX doublewords from DS:[(E)SI] to ES:[(E)DI].</td>, <td>F3 REX.W A5</td>, <td>REP MOVS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Move RCX quadwords from [RSI] to [RDI].</td>, <td>F3 6E</td>, <td>REP OUTS DX, <em>r/m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output (E)CX bytes from DS:[(E)SI] to port DX.</td>, <td>F3 REX.W 6E</td>, <td>REP OUTS DX, <em>r/m8*</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Output RCX bytes from [RSI] to port DX.</td>, <td>F3 6F</td>, <td>REP OUTS DX, <em>r/m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output (E)CX words from DS:[(E)SI] to port DX.</td>, <td>F3 6F</td>, <td>REP OUTS DX, <em>r/m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Output (E)CX doublewords from DS:[(E)SI] to port DX.</td>, <td>F3 REX.W 6F</td>, <td>REP OUTS DX, <em>r/m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Output RCX default size from [RSI] to port DX.</td>, <td>F3 AC</td>, <td>REP LODS AL</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Load (E)CX bytes from DS:[(E)SI] to AL.</td>, <td>F3 REX.W AC</td>, <td>REP LODS AL</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load RCX bytes from [RSI] to AL.</td>, <td>F3 AD</td>, <td>REP LODS AX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Load (E)CX words from DS:[(E)SI] to AX.</td>, <td>F3 AD</td>, <td>REP LODS EAX</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Load (E)CX doublewords from DS:[(E)SI] to EAX.</td>, <td>F3 REX.W AD</td>, <td>REP LODS RAX</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Load RCX quadwords from [RSI] to RAX.</td>, <td>F3 AA</td>, <td>REP STOS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fill (E)CX bytes at ES:[(E)DI] with AL.</td>, <td>F3 REX.W AA</td>, <td>REP STOS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Fill RCX bytes at [RDI] with AL.</td>, <td>F3 AB</td>, <td>REP STOS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fill (E)CX words at ES:[(E)DI] with AX.</td>, <td>F3 AB</td>, <td>REP STOS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fill (E)CX doublewords at ES:[(E)DI] with EAX.</td>, <td>F3 REX.W AB</td>, <td>REP STOS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Fill RCX quadwords at [RDI] with RAX.</td>, <td>F3 A6</td>, <td>REPE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find nonmatching bytes in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F3 REX.W A6</td>, <td>REPE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-matching bytes in [RDI] and [RSI].</td>, <td>F3 A7</td>, <td>REPE CMPS <em>m16, m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find nonmatching words in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F3 A7</td>, <td>REPE CMPS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find nonmatching doublewords in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F3 REX.W A7</td>, <td>REPE CMPS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-matching quadwords in [RDI] and [RSI].</td>, <td>F3 AE</td>, <td>REPE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find non-AL byte starting at ES:[(E)DI].</td>, <td>F3 REX.W AE</td>, <td>REPE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-AL byte starting at [RDI].</td>, <td>F3 AF</td>, <td>REPE SCAS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find non-AX word starting at ES:[(E)DI].</td>, <td>F3 AF</td>, <td>REPE SCAS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find non-EAX doubleword starting at ES:[(E)DI].</td>, <td>F3 REX.W AF</td>, <td>REPE SCAS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find non-RAX quadword starting at [RDI].</td>, <td>F2 A6</td>, <td>REPNE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find matching bytes in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F2 REX.W A6</td>, <td>REPNE CMPS <em>m8, m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find matching bytes in [RDI] and [RSI].</td>, <td>F2 A7</td>, <td>REPNE CMPS <em>m16, m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find matching words in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F2 A7</td>, <td>REPNE CMPS <em>m32, m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find matching doublewords in ES:[(E)DI] and DS:[(E)SI].</td>, <td>F2 REX.W A7</td>, <td>REPNE CMPS <em>m64, m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find matching doublewords in [RDI] and [RSI].</td>, <td>F2 AE</td>, <td>REPNE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find AL, starting at ES:[(E)DI].</td>, <td>F2 REX.W AE</td>, <td>REPNE SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find AL, starting at [RDI].</td>, <td>F2 AF</td>, <td>REPNE SCAS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find AX, starting at ES:[(E)DI].</td>, <td>F2 AF</td>, <td>REPNE SCAS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Find EAX, starting at ES:[(E)DI].</td>, <td>F2 REX.W AF</td>, <td>REPNE SCAS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Find RAX, starting at [RDI].</td>, <td colspan="6"><strong>NOTES:</strong> * In64-bitmode,r/m8cannotbeencodedtoaccessthefollowingbyteregistersifaREXprefixisused:AH,BH,CH,DH.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>REP</td>, <td>RCX or (E)CX = 0</td>, <td>None</td>, <td>REPE/REPZ</td>, <td>RCX or (E)CX = 0</td>, <td>ZF = 0</td>, <td>REPNE/REPNZ</td>, <td>RCX or (E)CX = 0</td>, <td>ZF = 1</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>]

[<td>C3</td>, <td>RET</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Near return to calling procedure.</td>, <td>CB</td>, <td>RET</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Far return to calling procedure.</td>, <td>C2 <em>iw</em></td>, <td>RET <em>imm16</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Near return to calling procedure and pop <em>imm16</em> bytes from stack.</td>, <td>CA <em>iw</em></td>, <td>RET <em>imm16</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Far return to calling procedure and pop <em>imm16</em> bytes from stack.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>I</td>, <td>imm16</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If the return code or stack segment selector is NULL.</td>, <td>If the return instruction pointer is not within the return code segment limit</td>, <td rowspan="8">#GP(selector)</td>, <td>If the RPL of the return code segment selector is less then the CPL.</td>, <td>If the return code or stack segment selector index is not within its descriptor table limits.</td>, <td>If the return code segment descriptor does not indicate a code segment.</td>, <td>If the return code segment is non-conforming and the segment selector’s DPL is not equal to the RPL of the code segment’s segment selector</td>, <td>If the return code segment is conforming and the segment selector’s DPL greater than the RPL of the code segment’s segment selector</td>, <td>If the stack segment is not a writable data segment.</td>, <td>If the stack segment selector RPL is not equal to the RPL of the return code segment selector.</td>, <td>If the stack segment descriptor DPL is not equal to the RPL of the return code segment selector.</td>, <td rowspan="2">#SS(0)</td>, <td>If the top bytes of stack are not within stack limits.</td>, <td>If the return stack segment is not present.</td>, <td>#NP(selector)</td>, <td>If the return code segment is not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory access occurs when the CPL is 3 and alignment checking is enabled.</td>, <td>#GP</td>, <td>If the return instruction pointer is not within the return code segment limit</td>, <td>#SS</td>, <td>If the top bytes of stack are not within stack limits.</td>, <td>#GP(0)</td>, <td>If the return instruction pointer is not within the return code segment limit</td>, <td>#SS(0)</td>, <td>If the top bytes of stack are not within stack limits.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If an unaligned memory access occurs when alignment checking is enabled.</td>, <td rowspan="6">#GP(0)</td>, <td>If the return instruction pointer is non-canonical.</td>, <td>If the return instruction pointer is not within the return code segment limit.</td>, <td>If the stack segment selector is NULL going back to compatibility mode.</td>, <td>If the stack segment selector is NULL going back to CPL3 64-bit mode.</td>, <td>If a NULL stack segment selector RPL is not equal to CPL going back to non-CPL3 64-bit mode.</td>, <td>If the return code segment selector is NULL.</td>, <td rowspan="10">#GP(selector)</td>, <td>If the proposed segment descriptor for a code segment does not indicate it is a code segment.</td>, <td>If the proposed new code segment descriptor has both the D-bit and L-bit set.</td>, <td>If the DPL for a nonconforming-code segment is not equal to the RPL of the code segment selector.</td>, <td>If CPL is greater than the RPL of the code segment selector.</td>, <td>If the DPL of a conforming-code segment is greater than the return code segment selector RPL.</td>, <td>If a segment selector index is outside its descriptor table limits.</td>, <td>If a segment descriptor memory address is non-canonical.</td>, <td>If the stack segment is not a writable data segment.</td>, <td>If the stack segment descriptor DPL is not equal to the RPL of the return code segment selector.</td>, <td>If the stack segment selector RPL is not equal to the RPL of the return code segment selector.</td>, <td rowspan="2">#SS(0)</td>, <td>If an attempt to pop a value off the stack violates the SS limit.</td>, <td>If an attempt to pop a value off the stack causes a non-canonical address to be referenced.</td>, <td>#NP(selector)</td>, <td>If the return code or stack segment is not present.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>]

[<td>D0 /2</td>, <td>RCL <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left once.</td>, <td>REX + D0 /2</td>, <td>RCL <em>r/m8*</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left once.</td>, <td>D2 /2</td>, <td>RCL <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left CL times.</td>, <td>REX + D2 /2</td>, <td>RCL <em>r/m8*</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left CL times.</td>, <td>C0 /2 <em>ib</em></td>, <td>RCL <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left <em>imm8</em> times.</td>, <td>REX + C0 /2 <em>ib</em></td>, <td>RCL <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left <em>imm8</em> times.</td>, <td>D1 /2</td>, <td>RCL <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) left once.</td>, <td>D3 /2</td>, <td>RCL <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) left CL times.</td>, <td>C1 /2 <em>ib</em></td>, <td>RCL <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) left <em>imm8</em> times.</td>, <td>D1 /2</td>, <td>RCL <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) left once.</td>, <td>REX.W + D1 /2</td>, <td>RCL <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) left once. Uses a 6 bit count.</td>, <td>D3 /2</td>, <td>RCL <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) left CL times.</td>, <td>REX.W + D3 /2</td>, <td>RCL <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) left CL times. Uses a 6 bit count.</td>, <td>C1 /2 <em>ib</em></td>, <td>RCL <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) left <em>imm8</em> times.</td>, <td>REX.W + C1 /2 <em>ib</em></td>, <td>RCL <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) left <em>imm8</em> times. Uses a 6 bit count.</td>, <td>D0 /3</td>, <td>RCR <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right once.</td>, <td>REX + D0 /3</td>, <td>RCR <em>r/m8*</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right once.</td>, <td>D2 /3</td>, <td>RCR <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right CL times.</td>, <td>REX + D2 /3</td>, <td>RCR <em>r/m8*</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right CL times.</td>, <td>C0 /3 <em>ib</em></td>, <td>RCR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right <em>imm8</em> times.</td>, <td>REX + C0 /3 <em>ib</em></td>, <td>RCR <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right <em>imm8</em> times.</td>, <td>D1 /3</td>, <td>RCR <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) right once.</td>, <td>D3 /3</td>, <td>RCR <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) right CL times.</td>, <td>C1 /3 <em>ib</em></td>, <td>RCR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) right <em>imm8</em> times.</td>, <td>D1 /3</td>, <td>RCR <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) right once. Uses a 6 bit count.</td>, <td>REX.W + D1 /3</td>, <td>RCR <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) right once. Uses a 6 bit count.</td>, <td>D3 /3</td>, <td>RCR <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) right CL times.</td>, <td>REX.W + D3 /3</td>, <td>RCR <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) right CL times. Uses a 6 bit count.</td>, <td>C1 /3 <em>ib</em></td>, <td>RCR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) right <em>imm8</em> times.</td>, <td>REX.W + C1 /3 <em>ib</em></td>, <td>RCR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) right <em>imm8</em> times. Uses a 6 bit count.</td>, <td>D0 /0</td>, <td>ROL <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> left once.</td>, <td>REX + D0 /0</td>, <td>ROL <em>r/m8*</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> left once</td>, <td>D2 /0</td>, <td>ROL <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> left CL times.</td>, <td>REX + D2 /0</td>, <td>ROL <em>r/m8*</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> left CL times.</td>, <td>C0 /0 <em>ib</em></td>, <td>ROL <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> left <em>imm8</em> times.</td>, <td>REX + C0 /0 <em>ib</em></td>, <td>ROL <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> left <em>imm8</em> times.</td>, <td>D1 /0</td>, <td>ROL <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> left once.</td>, <td>D3 /0</td>, <td>ROL <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> left CL times.</td>, <td>C1 /0 <em>ib</em></td>, <td>ROL <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> left <em>imm8</em> times.</td>, <td>D1 /0</td>, <td>ROL <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> left once.</td>, <td>REX.W + D1 /0</td>, <td>ROL <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> left once. Uses a 6 bit count.</td>, <td>D3 /0</td>, <td>ROL <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> left CL times.</td>, <td>REX.W + D3 /0</td>, <td>ROL <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> left CL times. Uses a 6 bit count.</td>, <td>C1 /0 <em>ib</em></td>, <td>ROL <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> left <em>imm8</em> times.</td>, <td>REX.W + C1 /0 <em>ib</em></td>, <td>ROL <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> left <em>imm8</em> times. Uses a 6 bit count.</td>, <td>D0 /1</td>, <td>ROR <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> right once.</td>, <td>REX + D0 /1</td>, <td>ROR <em>r/m8*</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> right once.</td>, <td>D2 /1</td>, <td>ROR <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> right CL times.</td>, <td>REX + D2 /1</td>, <td>ROR <em>r/m8*</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> right CL times.</td>, <td>C0 /1 <em>ib</em></td>, <td>ROR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m16</em> right <em>imm8</em> times.</td>, <td>REX + C0 /1 <em>ib</em></td>, <td>ROR <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m16</em> right <em>imm8</em> times.</td>, <td>D1 /1</td>, <td>ROR <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> right once.</td>, <td>D3 /1</td>, <td>ROR <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> right CL times.</td>, <td>C1 /1 <em>ib</em></td>, <td>ROR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> right <em>imm8</em> times.</td>, <td>D1 /1</td>, <td>ROR <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> right once.</td>, <td>REX.W + D1 /1</td>, <td>ROR <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> right once. Uses a 6 bit count.</td>, <td>D3 /1</td>, <td>ROR <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> right CL times.</td>, <td>REX.W + D3 /1</td>, <td>ROR <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> right CL times. Uses a 6 bit count.</td>, <td>C1 /1 <em>ib</em></td>, <td>ROR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> right <em>imm8</em> times.</td>, <td>REX.W + C1 /1 <em>ib</em></td>, <td>ROR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> right <em>imm8</em> times. Uses a 6 bit count.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M1</td>, <td>ModRM:r/m (w)</td>, <td>1</td>, <td>NA</td>, <td>NA</td>, <td>MC</td>, <td>ModRM:r/m (w)</td>, <td>CL</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the source operand is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the source operand is located in a nonwritable segment.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D0 /2</td>, <td>RCL <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left once.</td>, <td>REX + D0 /2</td>, <td>RCL <em>r/m8*</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left once.</td>, <td>D2 /2</td>, <td>RCL <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left CL times.</td>, <td>REX + D2 /2</td>, <td>RCL <em>r/m8*</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left CL times.</td>, <td>C0 /2 <em>ib</em></td>, <td>RCL <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left <em>imm8</em> times.</td>, <td>REX + C0 /2 <em>ib</em></td>, <td>RCL <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) left <em>imm8</em> times.</td>, <td>D1 /2</td>, <td>RCL <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) left once.</td>, <td>D3 /2</td>, <td>RCL <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) left CL times.</td>, <td>C1 /2 <em>ib</em></td>, <td>RCL <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) left <em>imm8</em> times.</td>, <td>D1 /2</td>, <td>RCL <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) left once.</td>, <td>REX.W + D1 /2</td>, <td>RCL <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) left once. Uses a 6 bit count.</td>, <td>D3 /2</td>, <td>RCL <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) left CL times.</td>, <td>REX.W + D3 /2</td>, <td>RCL <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) left CL times. Uses a 6 bit count.</td>, <td>C1 /2 <em>ib</em></td>, <td>RCL <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) left <em>imm8</em> times.</td>, <td>REX.W + C1 /2 <em>ib</em></td>, <td>RCL <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) left <em>imm8</em> times. Uses a 6 bit count.</td>, <td>D0 /3</td>, <td>RCR <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right once.</td>, <td>REX + D0 /3</td>, <td>RCR <em>r/m8*</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right once.</td>, <td>D2 /3</td>, <td>RCR <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right CL times.</td>, <td>REX + D2 /3</td>, <td>RCR <em>r/m8*</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right CL times.</td>, <td>C0 /3 <em>ib</em></td>, <td>RCR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right <em>imm8</em> times.</td>, <td>REX + C0 /3 <em>ib</em></td>, <td>RCR <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 9 bits (CF, <em>r/m8</em>) right <em>imm8</em> times.</td>, <td>D1 /3</td>, <td>RCR <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) right once.</td>, <td>D3 /3</td>, <td>RCR <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) right CL times.</td>, <td>C1 /3 <em>ib</em></td>, <td>RCR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 17 bits (CF, <em>r/m16</em>) right <em>imm8</em> times.</td>, <td>D1 /3</td>, <td>RCR <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) right once. Uses a 6 bit count.</td>, <td>REX.W + D1 /3</td>, <td>RCR <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) right once. Uses a 6 bit count.</td>, <td>D3 /3</td>, <td>RCR <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) right CL times.</td>, <td>REX.W + D3 /3</td>, <td>RCR <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) right CL times. Uses a 6 bit count.</td>, <td>C1 /3 <em>ib</em></td>, <td>RCR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 33 bits (CF, <em>r/m32</em>) right <em>imm8</em> times.</td>, <td>REX.W + C1 /3 <em>ib</em></td>, <td>RCR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 65 bits (CF, <em>r/m64</em>) right <em>imm8</em> times. Uses a 6 bit count.</td>, <td>D0 /0</td>, <td>ROL <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> left once.</td>, <td>REX + D0 /0</td>, <td>ROL <em>r/m8*</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> left once</td>, <td>D2 /0</td>, <td>ROL <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> left CL times.</td>, <td>REX + D2 /0</td>, <td>ROL <em>r/m8*</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> left CL times.</td>, <td>C0 /0 <em>ib</em></td>, <td>ROL <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> left <em>imm8</em> times.</td>, <td>REX + C0 /0 <em>ib</em></td>, <td>ROL <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> left <em>imm8</em> times.</td>, <td>D1 /0</td>, <td>ROL <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> left once.</td>, <td>D3 /0</td>, <td>ROL <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> left CL times.</td>, <td>C1 /0 <em>ib</em></td>, <td>ROL <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> left <em>imm8</em> times.</td>, <td>D1 /0</td>, <td>ROL <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> left once.</td>, <td>REX.W + D1 /0</td>, <td>ROL <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> left once. Uses a 6 bit count.</td>, <td>D3 /0</td>, <td>ROL <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> left CL times.</td>, <td>REX.W + D3 /0</td>, <td>ROL <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> left CL times. Uses a 6 bit count.</td>, <td>C1 /0 <em>ib</em></td>, <td>ROL <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> left <em>imm8</em> times.</td>, <td>REX.W + C1 /0 <em>ib</em></td>, <td>ROL <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> left <em>imm8</em> times. Uses a 6 bit count.</td>, <td>D0 /1</td>, <td>ROR <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> right once.</td>, <td>REX + D0 /1</td>, <td>ROR <em>r/m8*</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> right once.</td>, <td>D2 /1</td>, <td>ROR <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m8</em> right CL times.</td>, <td>REX + D2 /1</td>, <td>ROR <em>r/m8*</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m8</em> right CL times.</td>, <td>C0 /1 <em>ib</em></td>, <td>ROR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 8 bits <em>r/m16</em> right <em>imm8</em> times.</td>, <td>REX + C0 /1 <em>ib</em></td>, <td>ROR <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 8 bits <em>r/m16</em> right <em>imm8</em> times.</td>, <td>D1 /1</td>, <td>ROR <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> right once.</td>, <td>D3 /1</td>, <td>ROR <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> right CL times.</td>, <td>C1 /1 <em>ib</em></td>, <td>ROR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 16 bits <em>r/m16</em> right <em>imm8</em> times.</td>, <td>D1 /1</td>, <td>ROR <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> right once.</td>, <td>REX.W + D1 /1</td>, <td>ROR <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> right once. Uses a 6 bit count.</td>, <td>D3 /1</td>, <td>ROR <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> right CL times.</td>, <td>REX.W + D3 /1</td>, <td>ROR <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> right CL times. Uses a 6 bit count.</td>, <td>C1 /1 <em>ib</em></td>, <td>ROR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Rotate 32 bits <em>r/m32</em> right <em>imm8</em> times.</td>, <td>REX.W + C1 /1 <em>ib</em></td>, <td>ROR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Rotate 64 bits <em>r/m64</em> right <em>imm8</em> times. Uses a 6 bit count.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M1</td>, <td>ModRM:r/m (w)</td>, <td>1</td>, <td>NA</td>, <td>NA</td>, <td>MC</td>, <td>ModRM:r/m (w)</td>, <td>CL</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the source operand is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the source operand is located in a nonwritable segment.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>VEX.LZ.F2.0F3A.W0 F0 /r ib RORX r32, <em>r/m32, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>BMI2</td>, <td>Rotate 32-bit <em>r/m32</em> right <em>imm8</em> times without affecting arithmetic flags.</td>, <td>VEX.LZ.F2.0F3A.W1 F0 /r ib RORX r64, <em>r/m64, imm8</em></td>, <td>RMI</td>, <td>V/N.E.</td>, <td>BMI2</td>, <td>Rotate 64-bit <em>r/m64</em> right <em>imm8</em> times without affecting arithmetic flags.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMI</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>]

[<td>66 0F 3A 09 /r ib ROUNDPD <em>xmm1, xmm2/m128, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Round packed double precision floating-point values in <em>xmm2/m128</em> and place the result in <em>xmm1</em>. The rounding mode is determined by <em>imm8.</em></td>, <td>VEX.128.66.0F3A.WIG 09 /r ib VROUNDPD <em>xmm1, xmm2/m128, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Round packed double-precision floating-point values in <em>xmm2/m128</em> and place the result in <em>xmm1</em>. The rounding mode is determined by <em>imm8</em>.</td>, <td>VEX.256.66.0F3A.WIG 09 /r ib VROUNDPD <em>ymm1, ymm2/m256, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Round packed double-precision floating-point values in <em>ymm2/m256</em> and place the result in <em>ymm1</em>. The rounding mode is determined by <em>imm8</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMI</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td></td>, <td>8 3210</td>, <td></td>, <td></td>, <td>Reserved</td>, <td></td>, <td></td>, <td>P — Precision Mask; 0: normal, 1: inexact</td>, <td></td>, <td></td>, <td>RS — Rounding select; 1: MXCSR.RC, 0: Imm8.RC</td>, <td></td>, <td></td>, <td>RC — Rounding mode</td>, <td></td>, <td>#UD</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>66 0F 3A 08 /r ib ROUNDPS <em>xmm1, xmm2/m128, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Round packed single precision floating-point values in <em>xmm2/m128</em> and place the result in <em>xmm1</em>. The rounding mode is determined by <em>imm8</em>.</td>, <td>VEX.128.66.0F3A.WIG 08 /r ib VROUNDPS <em>xmm1, xmm2/m128, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Round packed single-precision floating-point values in <em>xmm2/m128</em> and place the result in xmm1. The rounding mode is determined by <em>imm8</em>.</td>, <td>VEX.256.66.0F3A.WIG 08 /r ib VROUNDPS <em>ymm1, ymm2/m256, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Round packed single-precision floating-point values in <em>ymm2/m256</em> and place the result in ymm1. The rounding mode is determined by <em>imm8</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMI</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>66 0F 3A 0B /r ib ROUNDSD <em>xmm1, xmm2/m64, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Round the low packed double precision floating-point value in <em>xmm2/m64</em> and place the result in <em>xmm1.</em> The rounding mode is determined by <em>imm8</em>.</td>, <td>VEX.LIG.66.0F3A.WIG 0B /r ib VROUNDSD <em>xmm1, xmm2, xmm3/m64, imm8</em></td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Round the low packed double precision floating-point value in <em>xmm3/m64</em> and place the result in <em>xmm1</em>. The rounding mode is determined by <em>imm8</em>. Upper packed double precision floating-point value (bits[127:64]) from <em>xmm2</em> is copied to <em>xmm1</em>[127:64].</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMI</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>RVMI</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>]

[<td>66 0F 3A 0A /r ib ROUNDSS <em>xmm1, xmm2/m32, imm8</em></td>, <td>RMI</td>, <td>V/V</td>, <td>SSE4_1</td>, <td>Round the low packed single precision floating-point value in <em>xmm2/m32</em> and place the result in <em>xmm1</em>. The rounding mode is determined by <em>imm8</em>.</td>, <td>VEX.LIG.66.0F3A.WIG 0A /r ib VROUNDSS <em>xmm1, xmm2, xmm3/m32, imm8</em></td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Round the low packed single precision floating-point value in <em>xmm3/m32</em> and place the result in <em>xmm1</em>. The rounding mode is determined by <em>imm8</em>. Also, upper packed single precision floating-point values (bits[127:32]) from <em>xmm2</em> are copied to <em>xmm1</em>[127:32].</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMI</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td>NA</td>, <td>RVMI</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>]

[<td>0F AA</td>, <td>RSM</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Resume operation of interrupted program.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If an attempt is made to execute this instruction when the processor is not in SMM.</td>, <td>If the LOCK prefix is used.</td>]

[<td>NP 0F 52 /<em>r</em> RSQRTPS <em>xmm1</em>, <em>xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE</td>, <td>Computes the approximate reciprocals of the square roots of the packed single-precision floating-point values in <em>xmm2/m128</em> and stores the results in <em>xmm1</em>.</td>, <td>VEX.128.0F.WIG 52 /r VRSQRTPS <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Computes the approximate reciprocals of the square roots of packed single-precision values in <em>xmm2/mem</em> and stores the results in <em>xmm1</em>.</td>, <td>VEX.256.0F.WIG 52 /r VRSQRTPS <em>ymm1, ymm2/m256</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Computes the approximate reciprocals of the square roots of packed single-precision values in <em>ymm2/mem</em> and stores the results in <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>F3 0F 52 /<em>r</em> RSQRTSS <em>xmm1</em>, <em>xmm2/m32</em></td>, <td>RM</td>, <td>V/V</td>, <td>SSE</td>, <td>Computes the approximate reciprocal of the square root of the low single-precision floating-point value in <em>xmm2/m32</em> and stores the results in <em>xmm1</em>.</td>, <td>VEX.LIG.F3.0F.WIG 52 /r VRSQRTSS <em>xmm1, xmm2, xmm3/m32</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Computes the approximate reciprocal of the square root of the low single precision floating-point value in <em>xmm3/m32</em> and stores the results in <em>xmm1</em>. Also, upper single precision floating-point values (bits[127:32]) from <em>xmm2</em> are copied to <em>xmm1</em>[127:32].</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>9E</td>, <td>SAHF</td>, <td>ZO</td>, <td>Invalid*</td>, <td>Valid</td>, <td>Loads SF, ZF, AF, PF, and CF from AH into EFLAGS register.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If CPUID.80000001H.ECX[0] = 0.</td>, <td>If the LOCK prefix is used.</td>]

[<td>D0 /4</td>, <td>SAL <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, once.</td>, <td>REX + D0 /4</td>, <td>SAL <em>r/m8**</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, once.</td>, <td>D2 /4</td>, <td>SAL <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, CL times.</td>, <td>REX + D2 /4</td>, <td>SAL <em>r/m8**</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, CL times.</td>, <td>C0 /4 <em>ib</em></td>, <td>SAL <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>REX + C0 /4 <em>ib</em></td>, <td>SAL <em>r/m8**, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>D1 /4</td>, <td>SAL <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, once.</td>, <td>D3 /4</td>, <td>SAL <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, CL times.</td>, <td>C1 /4 <em>ib</em></td>, <td>SAL <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, <em>imm8</em> times.</td>, <td>D1 /4</td>, <td>SAL <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, once.</td>, <td>REX.W + D1 /4</td>, <td>SAL <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, once.</td>, <td>D3 /4</td>, <td>SAL <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, CL times.</td>, <td>REX.W + D3 /4</td>, <td>SAL <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, CL times.</td>, <td>C1 /4 <em>ib</em></td>, <td>SAL <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, <em>imm8</em> times.</td>, <td>REX.W + C1 /4 <em>ib</em></td>, <td>SAL <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, <em>imm8</em> times.</td>, <td>D0 /7</td>, <td>SAR <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m8</em> by 2, once.</td>, <td>REX + D0 /7</td>, <td>SAR <em>r/m8**</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m8</em> by 2, once.</td>, <td>D2 /7</td>, <td>SAR <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m8</em> by 2, CL times.</td>, <td>REX + D2 /7</td>, <td>SAR <em>r/m8**</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m8</em> by 2, CL times.</td>, <td>C0 /7 <em>ib</em></td>, <td>SAR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m8</em> by 2, <em>imm8</em> time.</td>, <td>REX + C0 /7 <em>ib</em></td>, <td>SAR <em>r/m8**, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>D1 /7</td>, <td>SAR <em>r/m16</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m16</em> by 2, once.</td>, <td>D3 /7</td>, <td>SAR <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m16</em> by 2, CL times.</td>, <td>C1 /7 <em>ib</em></td>, <td>SAR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m16</em> by 2, <em>imm8</em> times.</td>, <td>D1 /7</td>, <td>SAR <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m32</em> by 2, once.</td>, <td>REX.W + D1 /7</td>, <td>SAR <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m64</em> by 2, once.</td>, <td>D3 /7</td>, <td>SAR <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m32</em> by 2, CL times.</td>, <td>REX.W + D3 /7</td>, <td>SAR <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m64</em> by 2, CL times.</td>, <td>C1 /7 <em>ib</em></td>, <td>SAR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m32</em> by 2, <em>imm8</em> times.</td>, <td>REX.W + C1 /7 <em>ib</em></td>, <td>SAR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m64</em> by 2, <em>imm8</em> times</td>, <td>D0 /4</td>, <td>SHL <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, once.</td>, <td>REX + D0 /4</td>, <td>SHL <em>r/m8**</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, once.</td>, <td>D2 /4</td>, <td>SHL <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, CL times.</td>, <td>REX + D2 /4</td>, <td>SHL <em>r/m8**</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, CL times.</td>, <td>C0 /4 <em>ib</em></td>, <td>SHL <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>REX + C0 /4 <em>ib</em></td>, <td>SHL <em>r/m8**, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>D1 /4</td>, <td>SHL <em>r/m16</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, once.</td>, <td>D3 /4</td>, <td>SHL <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, CL times.</td>, <td>C1 /4 <em>ib</em></td>, <td>SHL <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, <em>imm8</em> times.</td>, <td>D1 /4</td>, <td>SHL <em>r/m32</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, once.</td>, <td>REX.W + D1 /4</td>, <td>SHL <em>r/m64</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, once.</td>, <td>D3 /4</td>, <td>SHL <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, CL times.</td>, <td>REX.W + D3 /4</td>, <td>SHL <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, CL times.</td>, <td>C1 /4 <em>ib</em></td>, <td>SHL <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, <em>imm8</em> times.</td>, <td>REX.W + C1 /4 <em>ib</em></td>, <td>SHL <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, <em>imm8</em> times.</td>, <td>D0 /5</td>, <td>SHR <em>r/m8</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m8</em> by 2, once.</td>, <td>REX + D0 /5</td>, <td>SHR <em>r/m8**</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m8</em> by 2, once.</td>, <td>D2 /5</td>, <td>SHR <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m8</em> by 2, CL times.</td>, <td>REX + D2 /5</td>, <td>SHR <em>r/m8**</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m8</em> by 2, CL times.</td>, <td>C0 /5 <em>ib</em></td>, <td>SHR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>REX + C0 /5 <em>ib</em></td>, <td>SHR <em>r/m8**, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>D1 /5</td>, <td>SHR <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m16</em> by 2, once.</td>, <td>D3 /5</td>, <td>SHR <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m16</em> by 2, CL times</td>, <td>C1 /5 <em>ib</em></td>, <td>SHR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m16</em> by 2, <em>imm8</em> times.</td>, <td>D1 /5</td>, <td>SHR <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m32</em> by 2, once.</td>, <td>REX.W + D1 /5</td>, <td>SHR <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m64</em> by 2, once.</td>, <td>D3 /5</td>, <td>SHR <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m32</em> by 2, CL times.</td>, <td>REX.W + D3 /5</td>, <td>SHR <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m64</em> by 2, CL times.</td>, <td>C1 /5 <em>ib</em></td>, <td>SHR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m32</em> by 2, <em>imm8</em> times.</td>, <td>REX.W + C1 /5 <em>ib</em></td>, <td>SHR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m64</em> by 2, <em>imm8</em> times.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M1</td>, <td>ModRM:r/m (r, w)</td>, <td>1</td>, <td>NA</td>, <td>NA</td>, <td>MC</td>, <td>ModRM:r/m (r, w)</td>, <td>CL</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D0 /4</td>, <td>SAL <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, once.</td>, <td>REX + D0 /4</td>, <td>SAL <em>r/m8**</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, once.</td>, <td>D2 /4</td>, <td>SAL <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, CL times.</td>, <td>REX + D2 /4</td>, <td>SAL <em>r/m8**</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, CL times.</td>, <td>C0 /4 <em>ib</em></td>, <td>SAL <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>REX + C0 /4 <em>ib</em></td>, <td>SAL <em>r/m8**, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>D1 /4</td>, <td>SAL <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, once.</td>, <td>D3 /4</td>, <td>SAL <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, CL times.</td>, <td>C1 /4 <em>ib</em></td>, <td>SAL <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, <em>imm8</em> times.</td>, <td>D1 /4</td>, <td>SAL <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, once.</td>, <td>REX.W + D1 /4</td>, <td>SAL <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, once.</td>, <td>D3 /4</td>, <td>SAL <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, CL times.</td>, <td>REX.W + D3 /4</td>, <td>SAL <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, CL times.</td>, <td>C1 /4 <em>ib</em></td>, <td>SAL <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, <em>imm8</em> times.</td>, <td>REX.W + C1 /4 <em>ib</em></td>, <td>SAL <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, <em>imm8</em> times.</td>, <td>D0 /7</td>, <td>SAR <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m8</em> by 2, once.</td>, <td>REX + D0 /7</td>, <td>SAR <em>r/m8**</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m8</em> by 2, once.</td>, <td>D2 /7</td>, <td>SAR <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m8</em> by 2, CL times.</td>, <td>REX + D2 /7</td>, <td>SAR <em>r/m8**</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m8</em> by 2, CL times.</td>, <td>C0 /7 <em>ib</em></td>, <td>SAR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m8</em> by 2, <em>imm8</em> time.</td>, <td>REX + C0 /7 <em>ib</em></td>, <td>SAR <em>r/m8**, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>D1 /7</td>, <td>SAR <em>r/m16</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m16</em> by 2, once.</td>, <td>D3 /7</td>, <td>SAR <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m16</em> by 2, CL times.</td>, <td>C1 /7 <em>ib</em></td>, <td>SAR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m16</em> by 2, <em>imm8</em> times.</td>, <td>D1 /7</td>, <td>SAR <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m32</em> by 2, once.</td>, <td>REX.W + D1 /7</td>, <td>SAR <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m64</em> by 2, once.</td>, <td>D3 /7</td>, <td>SAR <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m32</em> by 2, CL times.</td>, <td>REX.W + D3 /7</td>, <td>SAR <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m64</em> by 2, CL times.</td>, <td>C1 /7 <em>ib</em></td>, <td>SAR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m32</em> by 2, <em>imm8</em> times.</td>, <td>REX.W + C1 /7 <em>ib</em></td>, <td>SAR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m64</em> by 2, <em>imm8</em> times</td>, <td>D0 /4</td>, <td>SHL <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, once.</td>, <td>REX + D0 /4</td>, <td>SHL <em>r/m8**</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, once.</td>, <td>D2 /4</td>, <td>SHL <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, CL times.</td>, <td>REX + D2 /4</td>, <td>SHL <em>r/m8**</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, CL times.</td>, <td>C0 /4 <em>ib</em></td>, <td>SHL <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>REX + C0 /4 <em>ib</em></td>, <td>SHL <em>r/m8**, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>D1 /4</td>, <td>SHL <em>r/m16</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, once.</td>, <td>D3 /4</td>, <td>SHL <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, CL times.</td>, <td>C1 /4 <em>ib</em></td>, <td>SHL <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, <em>imm8</em> times.</td>, <td>D1 /4</td>, <td>SHL <em>r/m32</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, once.</td>, <td>REX.W + D1 /4</td>, <td>SHL <em>r/m64</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, once.</td>, <td>D3 /4</td>, <td>SHL <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, CL times.</td>, <td>REX.W + D3 /4</td>, <td>SHL <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, CL times.</td>, <td>C1 /4 <em>ib</em></td>, <td>SHL <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, <em>imm8</em> times.</td>, <td>REX.W + C1 /4 <em>ib</em></td>, <td>SHL <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, <em>imm8</em> times.</td>, <td>D0 /5</td>, <td>SHR <em>r/m8</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m8</em> by 2, once.</td>, <td>REX + D0 /5</td>, <td>SHR <em>r/m8**</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m8</em> by 2, once.</td>, <td>D2 /5</td>, <td>SHR <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m8</em> by 2, CL times.</td>, <td>REX + D2 /5</td>, <td>SHR <em>r/m8**</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m8</em> by 2, CL times.</td>, <td>C0 /5 <em>ib</em></td>, <td>SHR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>REX + C0 /5 <em>ib</em></td>, <td>SHR <em>r/m8**, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>D1 /5</td>, <td>SHR <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m16</em> by 2, once.</td>, <td>D3 /5</td>, <td>SHR <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m16</em> by 2, CL times</td>, <td>C1 /5 <em>ib</em></td>, <td>SHR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m16</em> by 2, <em>imm8</em> times.</td>, <td>D1 /5</td>, <td>SHR <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m32</em> by 2, once.</td>, <td>REX.W + D1 /5</td>, <td>SHR <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m64</em> by 2, once.</td>, <td>D3 /5</td>, <td>SHR <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m32</em> by 2, CL times.</td>, <td>REX.W + D3 /5</td>, <td>SHR <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m64</em> by 2, CL times.</td>, <td>C1 /5 <em>ib</em></td>, <td>SHR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m32</em> by 2, <em>imm8</em> times.</td>, <td>REX.W + C1 /5 <em>ib</em></td>, <td>SHR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m64</em> by 2, <em>imm8</em> times.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M1</td>, <td>ModRM:r/m (r, w)</td>, <td>1</td>, <td>NA</td>, <td>NA</td>, <td>MC</td>, <td>ModRM:r/m (r, w)</td>, <td>CL</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>VEX.LZ.F3.0F38.W0 F7 /r SARX <em>r32a, r/m32, r32b</em></td>, <td>RMV</td>, <td>V/V</td>, <td>BMI2</td>, <td>Shift <em>r/m32</em> arithmetically right with count specified in <em>r32b.</em></td>, <td>VEX.LZ.66.0F38.W0 F7 /r SHLX <em>r32a, r/m32, r32b</em></td>, <td>RMV</td>, <td>V/V</td>, <td>BMI2</td>, <td>Shift <em>r/m32</em> logically left with count specified in <em>r32b</em>.</td>, <td>VEX.LZ.F2.0F38.W0 F7 /r SHRX <em>r32a, r/m32, r32b</em></td>, <td>RMV</td>, <td>V/V</td>, <td>BMI2</td>, <td>Shift <em>r/m32</em> logically right with count specified in <em>r32b</em>.</td>, <td>VEX.LZ.F3.0F38.W1 F7 /r SARX <em>r64a, r/m64, r64b</em></td>, <td>RMV</td>, <td>V/N.E.</td>, <td>BMI2</td>, <td>Shift <em>r/m64</em> arithmetically right with count specified in <em>r64b</em>.</td>, <td>VEX.LZ.66.0F38.W1 F7 /r SHLX <em>r64a, r/m64, r64b</em></td>, <td>RMV</td>, <td>V/N.E.</td>, <td>BMI2</td>, <td>Shift <em>r/m64</em> logically left with count specified in <em>r64b</em>.</td>, <td>VEX.LZ.F2.0F38.W1 F7 /r SHRX <em>r64a, r/m64, r64b</em></td>, <td>RMV</td>, <td>V/N.E.</td>, <td>BMI2</td>, <td>Shift <em>r/m64</em> logically right with count specified in <em>r64b</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMV</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>VEX.vvvv (r)</td>, <td>NA</td>]

[<td>1C <em>ib</em></td>, <td>SBB AL, <em>imm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract with borrow <em>imm8</em> from AL.</td>, <td>1D <em>iw</em></td>, <td>SBB AX, <em>imm16</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract with borrow <em>imm16</em> from AX.</td>, <td>1D <em>id</em></td>, <td>SBB EAX, <em>imm32</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract with borrow <em>imm32</em> from EAX.</td>, <td>REX.W + 1D <em>id</em></td>, <td>SBB RAX, <em>imm32</em></td>, <td>I</td>, <td>Valid</td>, <td>N.E.</td>, <td>Subtract with borrow sign-extended <em>imm.32 to 64-bits</em> from RAX.</td>, <td>80 /3 <em>ib</em></td>, <td>SBB <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract with borrow <em>imm8</em> from <em>r/m8.</em></td>, <td>REX + 80 /3 <em>ib</em></td>, <td>SBB <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Subtract with borrow <em>imm8</em> from <em>r/m8.</em></td>, <td>81 /3 <em>iw</em></td>, <td>SBB <em>r/m16, imm16</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract with borrow <em>imm16</em> from <em>r/m16.</em></td>, <td>81 /3 <em>id</em></td>, <td>SBB <em>r/m32, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract with borrow <em>imm32</em> from <em>r/m32.</em></td>, <td>REX.W + 81 /3 <em>id</em></td>, <td>SBB <em>r/m64, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Subtract with borrow sign-extended <em>imm32 to 64-bits</em> from <em>r/m64.</em></td>, <td>83 /3 <em>ib</em></td>, <td>SBB <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract with borrow sign-extended <em>imm8</em> from <em>r/m16.</em></td>, <td>83 /3 <em>ib</em></td>, <td>SBB <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract with borrow sign-extended <em>imm8</em> from <em>r/m32.</em></td>, <td>REX.W + 83 /3 <em>ib</em></td>, <td>SBB <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Subtract with borrow sign-extended <em>imm8</em> from <em>r/m64.</em></td>, <td>18 /<em>r</em></td>, <td>SBB <em>r/m8, r8</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract with borrow <em>r8</em> from <em>r/m8.</em></td>, <td>REX + 18 /<em>r</em></td>, <td>SBB <em>r/m8*, r8</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Subtract with borrow <em>r8</em> from <em>r/m8.</em></td>, <td>19 /<em>r</em></td>, <td>SBB <em>r/m16, r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract with borrow <em>r16</em> from <em>r/m16.</em></td>, <td>19 /<em>r</em></td>, <td>SBB <em>r/m32, r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract with borrow <em>r32</em> from <em>r/m32.</em></td>, <td>REX.W + 19 /<em>r</em></td>, <td>SBB <em>r/m64, r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Subtract with borrow <em>r64</em> from <em>r/m64.</em></td>, <td>1A /<em>r</em></td>, <td>SBB <em>r8, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract with borrow <em>r/m8</em> from <em>r8.</em></td>, <td>REX + 1A /<em>r</em></td>, <td>SBB <em>r8*, r/m8*</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Subtract with borrow <em>r/m8</em> from <em>r8.</em></td>, <td>1B /<em>r</em></td>, <td>SBB <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract with borrow <em>r/m16</em> from <em>r16.</em></td>, <td>1B /<em>r</em></td>, <td>SBB <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract with borrow <em>r/m32</em> from <em>r32.</em></td>, <td>REX.W + 1B /<em>r</em></td>, <td>SBB <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Subtract with borrow <em>r/m64</em> from <em>r64.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>I</td>, <td>AL/AX/EAX/RAX</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (w)</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td>MR</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>AE</td>, <td>SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare AL with byte at ES:(E)DI or RDI, then set status flags.*</td>, <td>AF</td>, <td>SCAS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare AX with word at ES:(E)DI or RDI, then set status flags.*</td>, <td>AF</td>, <td>SCAS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare EAX with doubleword at ES(E)DI or RDI then set status flags.*</td>, <td>REX.W + AF</td>, <td>SCAS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare RAX with quadword at RDI or EDI then set status flags.</td>, <td>AE</td>, <td>SCASB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare AL with byte at ES:(E)DI or RDI then set status flags.*</td>, <td>AF</td>, <td>SCASW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare AX with word at ES:(E)DI or RDI then set status flags.*</td>, <td>AF</td>, <td>SCASD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare EAX with doubleword at ES:(E)DI or RDI then set status flags.*</td>, <td>REX.W + AF</td>, <td>SCASQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare RAX with quadword at RDI or EDI then set status flags.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory operand effective address is outside the limit of the ES segment.</td>, <td>If the ES register contains a NULL segment selector.</td>, <td>If an illegal memory operand effective address in the ES segment is given.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>AE</td>, <td>SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare AL with byte at ES:(E)DI or RDI, then set status flags.*</td>, <td>AF</td>, <td>SCAS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare AX with word at ES:(E)DI or RDI, then set status flags.*</td>, <td>AF</td>, <td>SCAS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare EAX with doubleword at ES(E)DI or RDI then set status flags.*</td>, <td>REX.W + AF</td>, <td>SCAS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare RAX with quadword at RDI or EDI then set status flags.</td>, <td>AE</td>, <td>SCASB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare AL with byte at ES:(E)DI or RDI then set status flags.*</td>, <td>AF</td>, <td>SCASW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare AX with word at ES:(E)DI or RDI then set status flags.*</td>, <td>AF</td>, <td>SCASD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare EAX with doubleword at ES:(E)DI or RDI then set status flags.*</td>, <td>REX.W + AF</td>, <td>SCASQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare RAX with quadword at RDI or EDI then set status flags.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory operand effective address is outside the limit of the ES segment.</td>, <td>If the ES register contains a NULL segment selector.</td>, <td>If an illegal memory operand effective address in the ES segment is given.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>AE</td>, <td>SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare AL with byte at ES:(E)DI or RDI, then set status flags.*</td>, <td>AF</td>, <td>SCAS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare AX with word at ES:(E)DI or RDI, then set status flags.*</td>, <td>AF</td>, <td>SCAS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare EAX with doubleword at ES(E)DI or RDI then set status flags.*</td>, <td>REX.W + AF</td>, <td>SCAS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare RAX with quadword at RDI or EDI then set status flags.</td>, <td>AE</td>, <td>SCASB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare AL with byte at ES:(E)DI or RDI then set status flags.*</td>, <td>AF</td>, <td>SCASW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare AX with word at ES:(E)DI or RDI then set status flags.*</td>, <td>AF</td>, <td>SCASD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare EAX with doubleword at ES:(E)DI or RDI then set status flags.*</td>, <td>REX.W + AF</td>, <td>SCASQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare RAX with quadword at RDI or EDI then set status flags.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory operand effective address is outside the limit of the ES segment.</td>, <td>If the ES register contains a NULL segment selector.</td>, <td>If an illegal memory operand effective address in the ES segment is given.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>AE</td>, <td>SCAS <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare AL with byte at ES:(E)DI or RDI, then set status flags.*</td>, <td>AF</td>, <td>SCAS <em>m16</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare AX with word at ES:(E)DI or RDI, then set status flags.*</td>, <td>AF</td>, <td>SCAS <em>m32</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare EAX with doubleword at ES(E)DI or RDI then set status flags.*</td>, <td>REX.W + AF</td>, <td>SCAS <em>m64</em></td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare RAX with quadword at RDI or EDI then set status flags.</td>, <td>AE</td>, <td>SCASB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare AL with byte at ES:(E)DI or RDI then set status flags.*</td>, <td>AF</td>, <td>SCASW</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare AX with word at ES:(E)DI or RDI then set status flags.*</td>, <td>AF</td>, <td>SCASD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Compare EAX with doubleword at ES:(E)DI or RDI then set status flags.*</td>, <td>REX.W + AF</td>, <td>SCASQ</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Compare RAX with quadword at RDI or EDI then set status flags.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory operand effective address is outside the limit of the ES segment.</td>, <td>If the ES register contains a NULL segment selector.</td>, <td>If an illegal memory operand effective address in the ES segment is given.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 97</td>, <td>SETA <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if above (CF=0 and ZF=0).</td>, <td>REX + 0F 97</td>, <td>SETA <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if above (CF=0 and ZF=0).</td>, <td>0F 93</td>, <td>SETAE <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if above or equal (CF=0).</td>, <td>REX + 0F 93</td>, <td>SETAE <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if above or equal (CF=0).</td>, <td>0F 92</td>, <td>SETB <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if below (CF=1).</td>, <td>REX + 0F 92</td>, <td>SETB <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if below (CF=1).</td>, <td>0F 96</td>, <td>SETBE <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if below or equal (CF=1 or ZF=1).</td>, <td>REX + 0F 96</td>, <td>SETBE <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if below or equal (CF=1 or ZF=1).</td>, <td>0F 92</td>, <td>SETC <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if carry (CF=1).</td>, <td>REX + 0F 92</td>, <td>SETC <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if carry (CF=1).</td>, <td>0F 94</td>, <td>SETE <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if equal (ZF=1).</td>, <td>REX + 0F 94</td>, <td>SETE <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if equal (ZF=1).</td>, <td>0F 9F</td>, <td>SETG <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if greater (ZF=0 and SF=OF).</td>, <td>REX + 0F 9F</td>, <td>SETG <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if greater (ZF=0 and SF=OF).</td>, <td>0F 9D</td>, <td>SETGE <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if greater or equal (SF=OF).</td>, <td>REX + 0F 9D</td>, <td>SETGE <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if greater or equal (SF=OF).</td>, <td>0F 9C</td>, <td>SETL <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if less (SF≠ OF).</td>, <td>REX + 0F 9C</td>, <td>SETL <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if less (SF≠ OF).</td>, <td>0F 9E</td>, <td>SETLE <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if less or equal (ZF=1 or SF≠ OF).</td>, <td>REX + 0F 9E</td>, <td>SETLE <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if less or equal (ZF=1 or SF≠ OF).</td>, <td>0F 96</td>, <td>SETNA <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if not above (CF=1 or ZF=1).</td>, <td>REX + 0F 96</td>, <td>SETNA <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if not above (CF=1 or ZF=1).</td>, <td>0F 92</td>, <td>SETNAE <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if not above or equal (CF=1).</td>, <td>REX + 0F 92</td>, <td>SETNAE <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if not above or equal (CF=1).</td>, <td>0F 93</td>, <td>SETNB <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if not below (CF=0).</td>, <td>REX + 0F 93</td>, <td>SETNB <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if not below (CF=0).</td>, <td>0F 97</td>, <td>SETNBE <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if not below or equal (CF=0 and ZF=0).</td>, <td>REX + 0F 97</td>, <td>SETNBE <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if not below or equal (CF=0 and ZF=0).</td>, <td>0F 93</td>, <td>SETNC <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if not carry (CF=0).</td>, <td>REX + 0F 93</td>, <td>SETNC <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if not carry (CF=0).</td>, <td>0F 95</td>, <td>SETNE <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if not equal (ZF=0).</td>, <td>REX + 0F 95</td>, <td>SETNE <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if not equal (ZF=0).</td>, <td>0F 9E</td>, <td>SETNG <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if not greater (ZF=1 or SF≠ OF)</td>, <td>REX + 0F 9E</td>, <td>SETNG <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if not greater (ZF=1 or SF≠ OF).</td>, <td>0F 9C</td>, <td>SETNGE <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if not greater or equal (SF≠ OF).</td>, <td>REX + 0F 9C</td>, <td>SETNGE <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if not greater or equal (SF≠ OF).</td>, <td>0F 9D</td>, <td>SETNL <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if not less (SF=OF).</td>, <td>REX + 0F 9D</td>, <td>SETNL <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if not less (SF=OF).</td>, <td>0F 9F</td>, <td>SETNLE <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if not less or equal (ZF=0 and SF=OF).</td>, <td>REX + 0F 9F</td>, <td>SETNLE <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if not less or equal (ZF=0 and SF=OF).</td>, <td>0F 91</td>, <td>SETNO <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if not overflow (OF=0).</td>, <td>REX + 0F 91</td>, <td>SETNO <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if not overflow (OF=0).</td>, <td>0F 9B</td>, <td>SETNP <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if not parity (PF=0).</td>, <td>REX + 0F 9B</td>, <td>SETNP <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if not parity (PF=0).</td>, <td>0F 99</td>, <td>SETNS <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if not sign (SF=0).</td>, <td>REX + 0F 99</td>, <td>SETNS <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if not sign (SF=0).</td>, <td>0F 95</td>, <td>SETNZ <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if not zero (ZF=0).</td>, <td>REX + 0F 95</td>, <td>SETNZ <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if not zero (ZF=0).</td>, <td>0F 90</td>, <td>SETO <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if overflow (OF=1)</td>, <td>REX + 0F 90</td>, <td>SETO <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if overflow (OF=1).</td>, <td>0F 9A</td>, <td>SETP <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if parity (PF=1).</td>, <td>REX + 0F 9A</td>, <td>SETP <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if parity (PF=1).</td>, <td>0F 9A</td>, <td>SETPE <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if parity even (PF=1).</td>, <td>REX + 0F 9A</td>, <td>SETPE <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if parity even (PF=1).</td>, <td>0F 9B</td>, <td>SETPO <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if parity odd (PF=0).</td>, <td>REX + 0F 9B</td>, <td>SETPO <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if parity odd (PF=0).</td>, <td>0F 98</td>, <td>SETS <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if sign (SF=1).</td>, <td>REX + 0F 98</td>, <td>SETS <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if sign (SF=1).</td>, <td>0F 94</td>, <td>SETZ <em>r/m8</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set byte if zero (ZF=1).</td>, <td>REX + 0F 94</td>, <td>SETZ <em>r/m8*</em></td>, <td>M</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set byte if zero (ZF=1).</td>, <td colspan="6"><strong>NOTES:</strong> * In64-bitmode,r/m8cannotbeencodedtoaccessthefollowingbyteregistersifaREXprefixisused:AH,BH,CH,DH.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>NP 0F AE F8</td>, <td>SFENCE</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Serializes store operations.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td></td>, <td></td>, <td></td>, <td></td>, <td>Valid</td>, <td>Store GDTR to <em>m.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="4">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>If CR4.UMIP = 1 and CPL &gt; 0.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while CPL = 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If CR4.UMIP = 1.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If CR4.UMIP = 1 and CPL &gt; 0.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while CPL = 3.</td>]

[<td>NP 0F 38 C9 /r SHA1MSG1 xmm1, xmm2/m128</td>, <td>RM</td>, <td>V/V</td>, <td>SHA</td>, <td>Performs an intermediate calculation for the next four SHA1 message dwords using previous message dwords from xmm1 and xmm2/m128, storing the result in xmm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 38 CA /r SHA1MSG2 xmm1, xmm2/m128</td>, <td>RM</td>, <td>V/V</td>, <td>SHA</td>, <td>Performs the final calculation for the next four SHA1 message dwords using intermediate results from xmm1 and the previous message dwords from xmm2/m128, storing the result in xmm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 38 C8 /r SHA1NEXTE xmm1, xmm2/m128</td>, <td>RM</td>, <td>V/V</td>, <td>SHA</td>, <td>Calculates SHA1 state variable E after four rounds of operation from the current SHA1 state variable A in xmm1. The calculated value of the SHA1 state variable E is added to the scheduled dwords in xmm2/m128, and stored with some of the scheduled dwords in xmm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 3A CC /r ib SHA1RNDS4 xmm1, xmm2/m128, imm8</td>, <td>RMI</td>, <td>V/V</td>, <td>SHA</td>, <td>Performs four rounds of SHA1 operation operating on SHA1 state (A,B,C,D) from xmm1, with a pre-computed sum of the next 4 round message dwords and state variable E from xmm2/m128. The immediate byte controls logic functions and round constants.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RMI</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>]

[<td>NP 0F 38 CC /r SHA256MSG1 xmm1, xmm2/m128</td>, <td>RM</td>, <td>V/V</td>, <td>SHA</td>, <td>Performs an intermediate calculation for the next four SHA256 message dwords using previous message dwords from xmm1 and xmm2/m128, storing the result in xmm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 38 CD /r SHA256MSG2 xmm1, xmm2/m128</td>, <td>RM</td>, <td>V/V</td>, <td>SHA</td>, <td>Performs the final calculation for the next four SHA256 message dwords using previous message dwords from xmm1 and xmm2/m128, storing the result in xmm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 38 CB /r SHA256RNDS2 xmm1, xmm2/m128, &lt;XMM0&gt;</td>, <td>RM0</td>, <td>V/V</td>, <td>SHA</td>, <td>Perform 2 rounds of SHA256 operation using an initial SHA256 state (C,D,G,H) from xmm1, an initial SHA256 state (A,B,E,F) from xmm2/m128, and a pre-computed sum of the next 2 round message dwords and the corresponding round constants from the implicit operand XMM0, storing the updated SHA256 state (A,B,E,F) result in xmm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>RMI</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>Implicit XMM0 (r)</td>]

[<td>D0 /4</td>, <td>SAL <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, once.</td>, <td>REX + D0 /4</td>, <td>SAL <em>r/m8**</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, once.</td>, <td>D2 /4</td>, <td>SAL <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, CL times.</td>, <td>REX + D2 /4</td>, <td>SAL <em>r/m8**</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, CL times.</td>, <td>C0 /4 <em>ib</em></td>, <td>SAL <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>REX + C0 /4 <em>ib</em></td>, <td>SAL <em>r/m8**, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>D1 /4</td>, <td>SAL <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, once.</td>, <td>D3 /4</td>, <td>SAL <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, CL times.</td>, <td>C1 /4 <em>ib</em></td>, <td>SAL <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, <em>imm8</em> times.</td>, <td>D1 /4</td>, <td>SAL <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, once.</td>, <td>REX.W + D1 /4</td>, <td>SAL <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, once.</td>, <td>D3 /4</td>, <td>SAL <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, CL times.</td>, <td>REX.W + D3 /4</td>, <td>SAL <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, CL times.</td>, <td>C1 /4 <em>ib</em></td>, <td>SAL <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, <em>imm8</em> times.</td>, <td>REX.W + C1 /4 <em>ib</em></td>, <td>SAL <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, <em>imm8</em> times.</td>, <td>D0 /7</td>, <td>SAR <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m8</em> by 2, once.</td>, <td>REX + D0 /7</td>, <td>SAR <em>r/m8**</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m8</em> by 2, once.</td>, <td>D2 /7</td>, <td>SAR <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m8</em> by 2, CL times.</td>, <td>REX + D2 /7</td>, <td>SAR <em>r/m8**</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m8</em> by 2, CL times.</td>, <td>C0 /7 <em>ib</em></td>, <td>SAR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m8</em> by 2, <em>imm8</em> time.</td>, <td>REX + C0 /7 <em>ib</em></td>, <td>SAR <em>r/m8**, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>D1 /7</td>, <td>SAR <em>r/m16</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m16</em> by 2, once.</td>, <td>D3 /7</td>, <td>SAR <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m16</em> by 2, CL times.</td>, <td>C1 /7 <em>ib</em></td>, <td>SAR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m16</em> by 2, <em>imm8</em> times.</td>, <td>D1 /7</td>, <td>SAR <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m32</em> by 2, once.</td>, <td>REX.W + D1 /7</td>, <td>SAR <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m64</em> by 2, once.</td>, <td>D3 /7</td>, <td>SAR <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m32</em> by 2, CL times.</td>, <td>REX.W + D3 /7</td>, <td>SAR <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m64</em> by 2, CL times.</td>, <td>C1 /7 <em>ib</em></td>, <td>SAR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m32</em> by 2, <em>imm8</em> times.</td>, <td>REX.W + C1 /7 <em>ib</em></td>, <td>SAR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m64</em> by 2, <em>imm8</em> times</td>, <td>D0 /4</td>, <td>SHL <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, once.</td>, <td>REX + D0 /4</td>, <td>SHL <em>r/m8**</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, once.</td>, <td>D2 /4</td>, <td>SHL <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, CL times.</td>, <td>REX + D2 /4</td>, <td>SHL <em>r/m8**</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, CL times.</td>, <td>C0 /4 <em>ib</em></td>, <td>SHL <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>REX + C0 /4 <em>ib</em></td>, <td>SHL <em>r/m8**, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>D1 /4</td>, <td>SHL <em>r/m16</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, once.</td>, <td>D3 /4</td>, <td>SHL <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, CL times.</td>, <td>C1 /4 <em>ib</em></td>, <td>SHL <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, <em>imm8</em> times.</td>, <td>D1 /4</td>, <td>SHL <em>r/m32</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, once.</td>, <td>REX.W + D1 /4</td>, <td>SHL <em>r/m64</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, once.</td>, <td>D3 /4</td>, <td>SHL <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, CL times.</td>, <td>REX.W + D3 /4</td>, <td>SHL <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, CL times.</td>, <td>C1 /4 <em>ib</em></td>, <td>SHL <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, <em>imm8</em> times.</td>, <td>REX.W + C1 /4 <em>ib</em></td>, <td>SHL <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, <em>imm8</em> times.</td>, <td>D0 /5</td>, <td>SHR <em>r/m8</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m8</em> by 2, once.</td>, <td>REX + D0 /5</td>, <td>SHR <em>r/m8**</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m8</em> by 2, once.</td>, <td>D2 /5</td>, <td>SHR <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m8</em> by 2, CL times.</td>, <td>REX + D2 /5</td>, <td>SHR <em>r/m8**</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m8</em> by 2, CL times.</td>, <td>C0 /5 <em>ib</em></td>, <td>SHR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>REX + C0 /5 <em>ib</em></td>, <td>SHR <em>r/m8**, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>D1 /5</td>, <td>SHR <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m16</em> by 2, once.</td>, <td>D3 /5</td>, <td>SHR <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m16</em> by 2, CL times</td>, <td>C1 /5 <em>ib</em></td>, <td>SHR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m16</em> by 2, <em>imm8</em> times.</td>, <td>D1 /5</td>, <td>SHR <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m32</em> by 2, once.</td>, <td>REX.W + D1 /5</td>, <td>SHR <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m64</em> by 2, once.</td>, <td>D3 /5</td>, <td>SHR <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m32</em> by 2, CL times.</td>, <td>REX.W + D3 /5</td>, <td>SHR <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m64</em> by 2, CL times.</td>, <td>C1 /5 <em>ib</em></td>, <td>SHR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m32</em> by 2, <em>imm8</em> times.</td>, <td>REX.W + C1 /5 <em>ib</em></td>, <td>SHR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m64</em> by 2, <em>imm8</em> times.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M1</td>, <td>ModRM:r/m (r, w)</td>, <td>1</td>, <td>NA</td>, <td>NA</td>, <td>MC</td>, <td>ModRM:r/m (r, w)</td>, <td>CL</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F A4 /r ib</td>, <td>SHLD <em>r/m16, r16, imm8</em></td>, <td>MRI</td>, <td>Valid</td>, <td>Valid</td>, <td>Shift <em>r/m16</em> to left <em>imm8</em> places while shifting bits from <em>r16</em> in from the right.</td>, <td>0F A5 /r</td>, <td>SHLD <em>r/m16, r16</em>, CL</td>, <td>MRC</td>, <td>Valid</td>, <td>Valid</td>, <td>Shift <em>r/m16</em> to left CL places while shifting bits from <em>r16</em> in from the right.</td>, <td>0F A4 /r ib</td>, <td>SHLD <em>r/m32, r32, imm8</em></td>, <td>MRI</td>, <td>Valid</td>, <td>Valid</td>, <td>Shift <em>r/m32</em> to left <em>imm8</em> places while shifting bits from <em>r32</em> in from the right.</td>, <td>REX.W + 0F A4 /r ib</td>, <td>SHLD <em>r/m64, r64, imm8</em></td>, <td>MRI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Shift <em>r/m64</em> to left <em>imm8</em> places while shifting bits from <em>r64</em> in from the right.</td>, <td>0F A5 /r</td>, <td>SHLD <em>r/m32, r32</em>, CL</td>, <td>MRC</td>, <td>Valid</td>, <td>Valid</td>, <td>Shift <em>r/m32</em> to left CL places while shifting bits from <em>r32</em> in from the right.</td>, <td>REX.W + 0F A5 /r</td>, <td>SHLD <em>r/m64, r64</em>, CL</td>, <td>MRC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Shift <em>r/m64</em> to left CL places while shifting bits from <em>r64</em> in from the right.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>MRI</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>imm8</td>, <td>NA</td>, <td>MRC</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>CL</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>VEX.LZ.F3.0F38.W0 F7 /r SARX <em>r32a, r/m32, r32b</em></td>, <td>RMV</td>, <td>V/V</td>, <td>BMI2</td>, <td>Shift <em>r/m32</em> arithmetically right with count specified in <em>r32b.</em></td>, <td>VEX.LZ.66.0F38.W0 F7 /r SHLX <em>r32a, r/m32, r32b</em></td>, <td>RMV</td>, <td>V/V</td>, <td>BMI2</td>, <td>Shift <em>r/m32</em> logically left with count specified in <em>r32b</em>.</td>, <td>VEX.LZ.F2.0F38.W0 F7 /r SHRX <em>r32a, r/m32, r32b</em></td>, <td>RMV</td>, <td>V/V</td>, <td>BMI2</td>, <td>Shift <em>r/m32</em> logically right with count specified in <em>r32b</em>.</td>, <td>VEX.LZ.F3.0F38.W1 F7 /r SARX <em>r64a, r/m64, r64b</em></td>, <td>RMV</td>, <td>V/N.E.</td>, <td>BMI2</td>, <td>Shift <em>r/m64</em> arithmetically right with count specified in <em>r64b</em>.</td>, <td>VEX.LZ.66.0F38.W1 F7 /r SHLX <em>r64a, r/m64, r64b</em></td>, <td>RMV</td>, <td>V/N.E.</td>, <td>BMI2</td>, <td>Shift <em>r/m64</em> logically left with count specified in <em>r64b</em>.</td>, <td>VEX.LZ.F2.0F38.W1 F7 /r SHRX <em>r64a, r/m64, r64b</em></td>, <td>RMV</td>, <td>V/N.E.</td>, <td>BMI2</td>, <td>Shift <em>r/m64</em> logically right with count specified in <em>r64b</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMV</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>VEX.vvvv (r)</td>, <td>NA</td>]

[<td>D0 /4</td>, <td>SAL <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, once.</td>, <td>REX + D0 /4</td>, <td>SAL <em>r/m8**</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, once.</td>, <td>D2 /4</td>, <td>SAL <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, CL times.</td>, <td>REX + D2 /4</td>, <td>SAL <em>r/m8**</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, CL times.</td>, <td>C0 /4 <em>ib</em></td>, <td>SAL <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>REX + C0 /4 <em>ib</em></td>, <td>SAL <em>r/m8**, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>D1 /4</td>, <td>SAL <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, once.</td>, <td>D3 /4</td>, <td>SAL <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, CL times.</td>, <td>C1 /4 <em>ib</em></td>, <td>SAL <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, <em>imm8</em> times.</td>, <td>D1 /4</td>, <td>SAL <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, once.</td>, <td>REX.W + D1 /4</td>, <td>SAL <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, once.</td>, <td>D3 /4</td>, <td>SAL <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, CL times.</td>, <td>REX.W + D3 /4</td>, <td>SAL <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, CL times.</td>, <td>C1 /4 <em>ib</em></td>, <td>SAL <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, <em>imm8</em> times.</td>, <td>REX.W + C1 /4 <em>ib</em></td>, <td>SAL <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, <em>imm8</em> times.</td>, <td>D0 /7</td>, <td>SAR <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m8</em> by 2, once.</td>, <td>REX + D0 /7</td>, <td>SAR <em>r/m8**</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m8</em> by 2, once.</td>, <td>D2 /7</td>, <td>SAR <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m8</em> by 2, CL times.</td>, <td>REX + D2 /7</td>, <td>SAR <em>r/m8**</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m8</em> by 2, CL times.</td>, <td>C0 /7 <em>ib</em></td>, <td>SAR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m8</em> by 2, <em>imm8</em> time.</td>, <td>REX + C0 /7 <em>ib</em></td>, <td>SAR <em>r/m8**, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>D1 /7</td>, <td>SAR <em>r/m16</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m16</em> by 2, once.</td>, <td>D3 /7</td>, <td>SAR <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m16</em> by 2, CL times.</td>, <td>C1 /7 <em>ib</em></td>, <td>SAR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m16</em> by 2, <em>imm8</em> times.</td>, <td>D1 /7</td>, <td>SAR <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m32</em> by 2, once.</td>, <td>REX.W + D1 /7</td>, <td>SAR <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m64</em> by 2, once.</td>, <td>D3 /7</td>, <td>SAR <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m32</em> by 2, CL times.</td>, <td>REX.W + D3 /7</td>, <td>SAR <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m64</em> by 2, CL times.</td>, <td>C1 /7 <em>ib</em></td>, <td>SAR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Signed divide* <em>r/m32</em> by 2, <em>imm8</em> times.</td>, <td>REX.W + C1 /7 <em>ib</em></td>, <td>SAR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Signed divide* <em>r/m64</em> by 2, <em>imm8</em> times</td>, <td>D0 /4</td>, <td>SHL <em>r/m8</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, once.</td>, <td>REX + D0 /4</td>, <td>SHL <em>r/m8**</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, once.</td>, <td>D2 /4</td>, <td>SHL <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, CL times.</td>, <td>REX + D2 /4</td>, <td>SHL <em>r/m8**</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, CL times.</td>, <td>C0 /4 <em>ib</em></td>, <td>SHL <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>REX + C0 /4 <em>ib</em></td>, <td>SHL <em>r/m8**, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>D1 /4</td>, <td>SHL <em>r/m16</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, once.</td>, <td>D3 /4</td>, <td>SHL <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, CL times.</td>, <td>C1 /4 <em>ib</em></td>, <td>SHL <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m16</em> by 2, <em>imm8</em> times.</td>, <td>D1 /4</td>, <td>SHL <em>r/m32</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, once.</td>, <td>REX.W + D1 /4</td>, <td>SHL <em>r/m64</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, once.</td>, <td>D3 /4</td>, <td>SHL <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, CL times.</td>, <td>REX.W + D3 /4</td>, <td>SHL <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, CL times.</td>, <td>C1 /4 <em>ib</em></td>, <td>SHL <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Multiply <em>r/m32</em> by 2, <em>imm8</em> times.</td>, <td>REX.W + C1 /4 <em>ib</em></td>, <td>SHL <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Multiply <em>r/m64</em> by 2, <em>imm8</em> times.</td>, <td>D0 /5</td>, <td>SHR <em>r/m8</em>,1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m8</em> by 2, once.</td>, <td>REX + D0 /5</td>, <td>SHR <em>r/m8**</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m8</em> by 2, once.</td>, <td>D2 /5</td>, <td>SHR <em>r/m8</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m8</em> by 2, CL times.</td>, <td>REX + D2 /5</td>, <td>SHR <em>r/m8**</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m8</em> by 2, CL times.</td>, <td>C0 /5 <em>ib</em></td>, <td>SHR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>REX + C0 /5 <em>ib</em></td>, <td>SHR <em>r/m8**, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m8</em> by 2, <em>imm8</em> times.</td>, <td>D1 /5</td>, <td>SHR <em>r/m16</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m16</em> by 2, once.</td>, <td>D3 /5</td>, <td>SHR <em>r/m16</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m16</em> by 2, CL times</td>, <td>C1 /5 <em>ib</em></td>, <td>SHR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m16</em> by 2, <em>imm8</em> times.</td>, <td>D1 /5</td>, <td>SHR <em>r/m32</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m32</em> by 2, once.</td>, <td>REX.W + D1 /5</td>, <td>SHR <em>r/m64</em>, 1</td>, <td>M1</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m64</em> by 2, once.</td>, <td>D3 /5</td>, <td>SHR <em>r/m32</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m32</em> by 2, CL times.</td>, <td>REX.W + D3 /5</td>, <td>SHR <em>r/m64</em>, CL</td>, <td>MC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m64</em> by 2, CL times.</td>, <td>C1 /5 <em>ib</em></td>, <td>SHR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Unsigned divide <em>r/m32</em> by 2, <em>imm8</em> times.</td>, <td>REX.W + C1 /5 <em>ib</em></td>, <td>SHR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Unsigned divide <em>r/m64</em> by 2, <em>imm8</em> times.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M1</td>, <td>ModRM:r/m (r, w)</td>, <td>1</td>, <td>NA</td>, <td>NA</td>, <td>MC</td>, <td>ModRM:r/m (r, w)</td>, <td>CL</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F AC /r ib</td>, <td>SHRD <em>r/m16, r16, imm8</em></td>, <td>MRI</td>, <td>Valid</td>, <td>Valid</td>, <td>Shift <em>r/m16</em> to right <em>imm8</em> places while shifting bits from <em>r16</em> in from the left.</td>, <td>0F AD /r</td>, <td>SHRD <em>r/m16, r16</em>, CL</td>, <td>MRC</td>, <td>Valid</td>, <td>Valid</td>, <td>Shift <em>r/m16</em> to right CL places while shifting bits from <em>r16</em> in from the left.</td>, <td>0F AC /r ib</td>, <td>SHRD <em>r/m32, r32, imm8</em></td>, <td>MRI</td>, <td>Valid</td>, <td>Valid</td>, <td>Shift <em>r/m32</em> to right <em>imm8</em> places while shifting bits from <em>r32</em> in from the left.</td>, <td>REX.W + 0F AC /r ib</td>, <td>SHRD <em>r/m64, r64, imm8</em></td>, <td>MRI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Shift <em>r/m64</em> to right <em>imm8</em> places while shifting bits from <em>r64</em> in from the left.</td>, <td>0F AD /r</td>, <td>SHRD <em>r/m32, r32</em>, CL</td>, <td>MRC</td>, <td>Valid</td>, <td>Valid</td>, <td>Shift <em>r/m32</em> to right CL places while shifting bits from <em>r32</em> in from the left.</td>, <td>REX.W + 0F AD /r</td>, <td>SHRD <em>r/m64, r64</em>, CL</td>, <td>MRC</td>, <td>Valid</td>, <td>N.E.</td>, <td>Shift <em>r/m64</em> to right CL places while shifting bits from <em>r64</em> in from the left.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>MRI</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>imm8</td>, <td>NA</td>, <td>MRC</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>CL</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>VEX.LZ.F3.0F38.W0 F7 /r SARX <em>r32a, r/m32, r32b</em></td>, <td>RMV</td>, <td>V/V</td>, <td>BMI2</td>, <td>Shift <em>r/m32</em> arithmetically right with count specified in <em>r32b.</em></td>, <td>VEX.LZ.66.0F38.W0 F7 /r SHLX <em>r32a, r/m32, r32b</em></td>, <td>RMV</td>, <td>V/V</td>, <td>BMI2</td>, <td>Shift <em>r/m32</em> logically left with count specified in <em>r32b</em>.</td>, <td>VEX.LZ.F2.0F38.W0 F7 /r SHRX <em>r32a, r/m32, r32b</em></td>, <td>RMV</td>, <td>V/V</td>, <td>BMI2</td>, <td>Shift <em>r/m32</em> logically right with count specified in <em>r32b</em>.</td>, <td>VEX.LZ.F3.0F38.W1 F7 /r SARX <em>r64a, r/m64, r64b</em></td>, <td>RMV</td>, <td>V/N.E.</td>, <td>BMI2</td>, <td>Shift <em>r/m64</em> arithmetically right with count specified in <em>r64b</em>.</td>, <td>VEX.LZ.66.0F38.W1 F7 /r SHLX <em>r64a, r/m64, r64b</em></td>, <td>RMV</td>, <td>V/N.E.</td>, <td>BMI2</td>, <td>Shift <em>r/m64</em> logically left with count specified in <em>r64b</em>.</td>, <td>VEX.LZ.F2.0F38.W1 F7 /r SHRX <em>r64a, r/m64, r64b</em></td>, <td>RMV</td>, <td>V/N.E.</td>, <td>BMI2</td>, <td>Shift <em>r/m64</em> logically right with count specified in <em>r64b</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMV</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>VEX.vvvv (r)</td>, <td>NA</td>]

[<td>66 0F C6 /r ib SHUFPD xmm1, xmm2/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Shuffle two pairs of double-precision floating-point values from xmm1 and xmm2/m128 using imm8 to select from each pair, interleaved result is stored in xmm1.</td>, <td>VEX.128.66.0F.WIG C6 /r ib VSHUFPD xmm1, xmm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Shuffle two pairs of double-precision floating-point values from xmm2 and xmm3/m128 using imm8 to select from each pair, interleaved result is stored in xmm1.</td>, <td>VEX.256.66.0F.WIG C6 /r ib VSHUFPD ymm1, ymm2, ymm3/m256, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Shuffle four pairs of double-precision floating-point values from ymm2 and ymm3/m256 using imm8 to select from each pair, interleaved result is stored in xmm1.</td>, <td>EVEX.128.66.0F.W1 C6 /r ib VSHUFPD xmm1{k1}{z}, xmm2, xmm3/m128/m64bcst, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle two paris of double-precision floating-point values from xmm2 and xmm3/m128/m64bcst using imm8 to select from each pair. store interleaved results in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F.W1 C6 /r ib VSHUFPD ymm1{k1}{z}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle four paris of double-precision floating-point values from ymm2 and ymm3/m256/m64bcst using imm8 to select from each pair. store interleaved results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F.W1 C6 /r ib VSHUFPD zmm1{k1}{z}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle eight paris of double-precision floating-point values from zmm2 and zmm3/m512/m64bcst using imm8 to select from each pair. store interleaved results in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>]

[<td>NP 0F C6 /r ib SHUFPS xmm1, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Select from quadruplet of single-precision floating-point values in xmm1 and xmm2/m128 using imm8, interleaved result pairs are stored in xmm1.</td>, <td>VEX.128.0F.WIG C6 /r ib VSHUFPS xmm1, xmm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Select from quadruplet of single-precision floating-point values in xmm1 and xmm2/m128 using imm8, interleaved result pairs are stored in xmm1.</td>, <td>VEX.256.0F.WIG C6 /r ib VSHUFPS ymm1, ymm2, ymm3/m256, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Select from quadruplet of single-precision floating-point values in ymm2 and ymm3/m256 using imm8, interleaved result pairs are stored in ymm1.</td>, <td>EVEX.128.0F.W0 C6 /r ib VSHUFPS xmm1{k1}{z}, xmm2, xmm3/m128/m32bcst, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Select from quadruplet of single-precision floating-point values in xmm1 and xmm2/m128 using imm8, interleaved result pairs are stored in xmm1, subject to writemask k1.</td>, <td>EVEX.256.0F.W0 C6 /r ib VSHUFPS ymm1{k1}{z}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Select from quadruplet of single-precision floating-point values in ymm2 and ymm3/m256 using imm8, interleaved result pairs are stored in ymm1, subject to writemask k1.</td>, <td>EVEX.512.0F.W0 C6 /r ib VSHUFPS zmm1{k1}{z}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Select from quadruplet of single-precision floating-point values in zmm2 and zmm3/m512 using imm8, interleaved result pairs are stored in zmm1, subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>]

[<td>0F 01 /1</td>, <td>SIDT <em>m</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Store IDTR to <em>m.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="4">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>If CR4.UMIP = 1 and CPL &gt; 0.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while CPL = 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If CR4.UMIP = 1.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If CR4.UMIP = 1 and CPL &gt; 0.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while CPL = 3.</td>]

[<td>0F 00 /0</td>, <td>SLDT <em>r/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Stores segment selector from LDTR in <em>r/m16</em>.</td>, <td>REX.W + 0F 00 /0</td>, <td>SLDT <em>r64/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Stores segment selector from LDTR in <em>r64/m16</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="4">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>If CR4.UMIP = 1 and CPL &gt; 0.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while CPL = 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>The SLDT instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>The SLDT instruction is not recognized in virtual-8086 mode.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If CR4.UMIP = 1 and CPL &gt; 0.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while CPL = 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 01 /4</td>, <td>SMSW <em>r/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Store machine status word to <em>r/m16</em>.</td>, <td>0F 01 /4</td>, <td>SMSW <em>r32/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Store machine status word in low-order 16 bits of <em>r32/m16</em>; high-order 16 bits of <em>r32</em> are undefined.</td>, <td>REX.W + 0F 01 /4</td>, <td>SMSW <em>r64/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Store machine status word in low-order 16 bits of <em>r64/m16</em>; high-order 16 bits of <em>r32</em> are undefined.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="4">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>If CR4.UMIP = 1 and CPL &gt; 0.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while CPL = 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If CR4.UMIP = 1.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If CR4.UMIP = 1 and CPL &gt; 0.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while CPL = 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>66 0F 51 /r SQRTPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Computes Square Roots of the packed double-precision floating-point values in xmm2/m128 and stores the result in xmm1.</td>, <td>VEX.128.66.0F.WIG 51 /r VSQRTPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Computes Square Roots of the packed double-precision floating-point values in xmm2/m128 and stores the result in xmm1.</td>, <td>VEX.256.66.0F.WIG 51 /r VSQRTPD ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Computes Square Roots of the packed double-precision floating-point values in ymm2/m256 and stores the result in ymm1.</td>, <td>EVEX.128.66.0F.W1 51 /r VSQRTPD xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Computes Square Roots of the packed double-precision floating-point values in xmm2/m128/m64bcst and stores the result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F.W1 51 /r VSQRTPD ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Computes Square Roots of the packed double-precision floating-point values in ymm2/m256/m64bcst and stores the result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F.W1 51 /r VSQRTPD zmm1 {k1}{z}, zmm2/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Computes Square Roots of the packed double-precision floating-point values in zmm2/m512/m64bcst and stores the result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B.</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>NP 0F 51 /r SQRTPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Computes Square Roots of the packed single-precision floating-point values in xmm2/m128 and stores the result in xmm1.</td>, <td>VEX.128.0F.WIG 51 /r VSQRTPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Computes Square Roots of the packed single-precision floating-point values in xmm2/m128 and stores the result in xmm1.</td>, <td>VEX.256.0F.WIG 51/r VSQRTPS ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Computes Square Roots of the packed single-precision floating-point values in ymm2/m256 and stores the result in ymm1.</td>, <td>EVEX.128.0F.W0 51 /r VSQRTPS xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Computes Square Roots of the packed single-precision floating-point values in xmm2/m128/m32bcst and stores the result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.0F.W0 51 /r VSQRTPS ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Computes Square Roots of the packed single-precision floating-point values in ymm2/m256/m32bcst and stores the result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.0F.W0 51/r VSQRTPS zmm1 {k1}{z}, zmm2/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Computes Square Roots of the packed single-precision floating-point values in zmm2/m512/m32bcst and stores the result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B.</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>F2 0F 51/r SQRTSD xmm1,xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Computes square root of the low double-precision floating-point value in xmm2/m64 and stores the results in xmm1.</td>, <td>VEX.LIG.F2.0F.WIG 51/r VSQRTSD xmm1,xmm2, xmm3/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Computes square root of the low double-precision floating-point value in xmm3/m64 and stores the results in xmm1. Also, upper double-precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64].</td>, <td>EVEX.LIG.F2.0F.W1 51/r VSQRTSD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Computes square root of the low double-precision floating-point value in xmm3/m64 and stores the results in xmm1 under writemask k1. Also, upper double-precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64].</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F3 0F 51 /r SQRTSS xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Computes square root of the low single-precision floating-point value in xmm2/m32 and stores the results in xmm1.</td>, <td>VEX.LIG.F3.0F.WIG 51 /r VSQRTSS xmm1, xmm2, xmm3/m32</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Computes square root of the low single-precision floating-point value in xmm3/m32 and stores the results in xmm1. Also, upper single-precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32].</td>, <td>EVEX.LIG.F3.0F.W0 51 /r VSQRTSS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Computes square root of the low single-precision floating-point value in xmm3/m32 and stores the results in xmm1 under writemask k1. Also, upper single-precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32].</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 01 CB STAC</td>, <td>ZO</td>, <td>V/V</td>, <td>SMAP</td>, <td>Set the AC flag in the EFLAGS register.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If the CPL &gt; 0.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.SMAP[bit 20] = 0.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.SMAP[bit 20] = 0.</td>, <td>#UD</td>, <td>The STAC instruction is not recognized in virtual-8086 mode.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If the CPL &gt; 0.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.SMAP[bit 20] = 0.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If the CPL &gt; 0.</td>, <td>If CPUID.(EAX=07H, ECX=0H):EBX.SMAP[bit 20] = 0.</td>]

[<td>F9</td>, <td>STC</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Set CF flag.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>FD</td>, <td>STD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Set DF flag.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>FB</td>, <td>STI</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Set interrupt flag; external, maskable interrupts enabled at the end of the next instruction.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>Real-address</td>, <td><sub>X</sub><sup>1</sup></td>, <td>X</td>, <td>IF = 1</td>, <td rowspan="2">Protected, not PVI<sup>2</sup></td>, <td>≥ CPL</td>, <td>X</td>, <td>IF = 1</td>, <td>&lt; CPL</td>, <td>X</td>, <td>#GP fault</td>, <td rowspan="3">Protected, PVI<sup>3</sup></td>, <td>3</td>, <td>X</td>, <td>IF = 1</td>, <td rowspan="2">0–2</td>, <td>0</td>, <td>VIF = 1</td>, <td>1</td>, <td>#GP fault</td>, <td rowspan="2">Virtual-8086, not VME<sup>3</sup></td>, <td>3</td>, <td>X</td>, <td>IF = 1</td>, <td>0–2</td>, <td>X</td>, <td>#GP fault</td>, <td rowspan="3">Virtual-8086, VME<sup>3</sup></td>, <td>3</td>, <td>X</td>, <td>IF = 1</td>, <td rowspan="2">0–2</td>, <td>0</td>, <td>VIF = 1</td>, <td>1</td>, <td>#GP fault</td>, <td rowspan="2">#GP(0)</td>, <td>If CPL is greater than IOPL and PVI mode is not active.</td>, <td>If CPL is greater than IOPL and EFLAGS.VIP = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP(0)</td>, <td>If IOPL is less than 3 and VME mode is not active.</td>, <td>If IOPL is less than 3 and EFLAGS.VIP = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>NP 0F AE /3 STMXCSR <em>m32</em></td>, <td>M</td>, <td>V/V</td>, <td>SSE</td>, <td>Store contents of MXCSR register to <em>m32</em>.</td>, <td>VEX.LZ.0F.WIG AE /3 VSTMXCSR <em>m32</em></td>, <td>M</td>, <td>V/V</td>, <td>AVX</td>, <td>Store contents of MXCSR register to <em>m32</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If VEX.L= 1,</td>, <td>If VEX.vvvv ≠ 1111B.</td>]

[<td>AA</td>, <td>STOS <em>m8</em></td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI.</td>, <td>AB</td>, <td>STOS <em>m16</em></td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI.</td>, <td>AB</td>, <td>STOS <em>m32</em></td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI.</td>, <td>REX.W + AB</td>, <td>STOS <em>m64</em></td>, <td>NA</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store RAX at address RDI or EDI.</td>, <td>AA</td>, <td>STOSB</td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI.</td>, <td>AB</td>, <td>STOSW</td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI.</td>, <td>AB</td>, <td>STOSD</td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI.</td>, <td>REX.W + AB</td>, <td>STOSQ</td>, <td>NA</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store RAX at address RDI or EDI.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the limit of the ES segment.</td>, <td>If the ES register contains a NULL segment selector.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the ES segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the ES segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>AA</td>, <td>STOS <em>m8</em></td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI.</td>, <td>AB</td>, <td>STOS <em>m16</em></td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI.</td>, <td>AB</td>, <td>STOS <em>m32</em></td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI.</td>, <td>REX.W + AB</td>, <td>STOS <em>m64</em></td>, <td>NA</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store RAX at address RDI or EDI.</td>, <td>AA</td>, <td>STOSB</td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI.</td>, <td>AB</td>, <td>STOSW</td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI.</td>, <td>AB</td>, <td>STOSD</td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI.</td>, <td>REX.W + AB</td>, <td>STOSQ</td>, <td>NA</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store RAX at address RDI or EDI.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the limit of the ES segment.</td>, <td>If the ES register contains a NULL segment selector.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the ES segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the ES segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>AA</td>, <td>STOS <em>m8</em></td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI.</td>, <td>AB</td>, <td>STOS <em>m16</em></td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI.</td>, <td>AB</td>, <td>STOS <em>m32</em></td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI.</td>, <td>REX.W + AB</td>, <td>STOS <em>m64</em></td>, <td>NA</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store RAX at address RDI or EDI.</td>, <td>AA</td>, <td>STOSB</td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI.</td>, <td>AB</td>, <td>STOSW</td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI.</td>, <td>AB</td>, <td>STOSD</td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI.</td>, <td>REX.W + AB</td>, <td>STOSQ</td>, <td>NA</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store RAX at address RDI or EDI.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the limit of the ES segment.</td>, <td>If the ES register contains a NULL segment selector.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the ES segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the ES segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>AA</td>, <td>STOS <em>m8</em></td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI.</td>, <td>AB</td>, <td>STOS <em>m16</em></td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI.</td>, <td>AB</td>, <td>STOS <em>m32</em></td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI.</td>, <td>REX.W + AB</td>, <td>STOS <em>m64</em></td>, <td>NA</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store RAX at address RDI or EDI.</td>, <td>AA</td>, <td>STOSB</td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI.</td>, <td>AB</td>, <td>STOSW</td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI.</td>, <td>AB</td>, <td>STOSD</td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI.</td>, <td>REX.W + AB</td>, <td>STOSQ</td>, <td>NA</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store RAX at address RDI or EDI.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the limit of the ES segment.</td>, <td>If the ES register contains a NULL segment selector.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the ES segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the ES segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>AA</td>, <td>STOS <em>m8</em></td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI.</td>, <td>AB</td>, <td>STOS <em>m16</em></td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI.</td>, <td>AB</td>, <td>STOS <em>m32</em></td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI.</td>, <td>REX.W + AB</td>, <td>STOS <em>m64</em></td>, <td>NA</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store RAX at address RDI or EDI.</td>, <td>AA</td>, <td>STOSB</td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI.</td>, <td>AB</td>, <td>STOSW</td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI.</td>, <td>AB</td>, <td>STOSD</td>, <td>NA</td>, <td>Valid</td>, <td>Valid</td>, <td>For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI.</td>, <td>REX.W + AB</td>, <td>STOSQ</td>, <td>NA</td>, <td>Valid</td>, <td>N.E.</td>, <td>Store RAX at address RDI or EDI.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the limit of the ES segment.</td>, <td>If the ES register contains a NULL segment selector.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the ES segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the ES segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 00 /1</td>, <td>STR <em>r/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Stores segment selector from TR in <em>r/m16</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is a memory operand that is located in a non-writable segment or if the effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>If CR4.UMIP = 1 and CPL &gt; 0.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>The STR instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>The STR instruction is not recognized in virtual-8086 mode.</td>, <td rowspan="2">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If CR4.UMIP = 1 and CPL &gt; 0.</td>, <td>#SS(0)</td>, <td>If the stack address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>2C <em>ib</em></td>, <td>SUB AL, i<em>mm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>imm8</em> from AL.</td>, <td>2D <em>iw</em></td>, <td>SUB AX, i<em>mm16</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>imm16</em> from AX.</td>, <td>2D <em>id</em></td>, <td>SUB EAX, i<em>mm32</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>imm32</em> from EAX.</td>, <td>REX.W + 2D <em>id</em></td>, <td>SUB RAX, i<em>mm32</em></td>, <td>I</td>, <td>Valid</td>, <td>N.E.</td>, <td>Subtract <em>imm32</em> sign-extended to 64-bits from RAX.</td>, <td>80 /5 <em>ib</em></td>, <td>SUB <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>imm8</em> from <em>r/m8.</em></td>, <td>REX + 80 /5 <em>ib</em></td>, <td>SUB <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Subtract <em>imm8</em> from <em>r/m8.</em></td>, <td>81 /5 <em>iw</em></td>, <td>SUB <em>r/m16, imm16</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>imm16</em> from <em>r/m16.</em></td>, <td>81 /5 <em>id</em></td>, <td>SUB <em>r/m32, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>imm32</em> from <em>r/m32.</em></td>, <td>REX.W + 81 /5 <em>id</em></td>, <td>SUB <em>r/m64, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Subtract <em>imm32</em> sign-extended to 64-bits from <em>r/m64.</em></td>, <td>83 /5 <em>ib</em></td>, <td>SUB <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract sign-extended <em>imm8</em> from <em>r/m16.</em></td>, <td>83 /5 <em>ib</em></td>, <td>SUB <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract sign-extended <em>imm8</em> from <em>r/m32.</em></td>, <td>REX.W + 83 /5 <em>ib</em></td>, <td>SUB <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>Subtract sign-extended <em>imm8</em> from <em>r/m64.</em></td>, <td>28 /<em>r</em></td>, <td>SUB <em>r/m8, r8</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>r8</em> from <em>r/m8.</em></td>, <td>REX + 28 /<em>r</em></td>, <td>SUB <em>r/m8*, r8*</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Subtract <em>r8</em> from <em>r/m8.</em></td>, <td>29 /<em>r</em></td>, <td>SUB <em>r/m16, r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>r16</em> from <em>r/m16.</em></td>, <td>29 /<em>r</em></td>, <td>SUB <em>r/m32, r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>r32</em> from <em>r/m32.</em></td>, <td>REX.W + 29 /<em>r</em></td>, <td>SUB <em>r/m64, r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Subtract <em>r64</em> from <em>r/m64.</em></td>, <td>2A /<em>r</em></td>, <td>SUB <em>r8, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>r/m8</em> from <em>r8.</em></td>, <td>REX + 2A /<em>r</em></td>, <td>SUB <em>r8*, r/m8*</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Subtract <em>r/m8</em> from <em>r8.</em></td>, <td>2B /<em>r</em></td>, <td>SUB <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>r/m16</em> from <em>r16.</em></td>, <td>2B /<em>r</em></td>, <td>SUB <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Subtract <em>r/m32</em> from <em>r32.</em></td>, <td>REX.W + 2B /<em>r</em></td>, <td>SUB <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Subtract <em>r/m64</em> from <em>r64.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>I</td>, <td>AL/AX/EAX/RAX</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td>MR</td>, <td>ModRM:r/m (r, w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>66 0F 5C /r SUBPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract packed double-precision floating-point values in xmm2/mem from xmm1 and store result in xmm1.</td>, <td>VEX.128.66.0F.WIG 5C /r VSUBPD xmm1,xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed double-precision floating-point values in xmm3/mem from xmm2 and store result in xmm1.</td>, <td>VEX.256.66.0F.WIG 5C /r VSUBPD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed double-precision floating-point values in ymm3/mem from ymm2 and store result in ymm1.</td>, <td>EVEX.128.66.0F.W1 5C /r VSUBPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Subtract packed double-precision floating-point values from xmm3/m128/m64bcst to xmm2 and store result in xmm1 with writemask k1.</td>, <td>EVEX.256.66.0F.W1 5C /r VSUBPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Subtract packed double-precision floating-point values from ymm3/m256/m64bcst to ymm2 and store result in ymm1 with writemask k1.</td>, <td>EVEX.512.66.0F.W1 5C /r VSUBPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Subtract packed double-precision floating-point values from zmm3/m512/m64bcst to zmm2 and store result in zmm1 with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 5C /r SUBPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Subtract packed single-precision floating-point values in xmm2/mem from xmm1 and store result in xmm1.</td>, <td>VEX.128.0F.WIG 5C /r VSUBPS xmm1,xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed single-precision floating-point values in xmm3/mem from xmm2 and stores result in xmm1.</td>, <td>VEX.256.0F.WIG 5C /r VSUBPS ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract packed single-precision floating-point values in ymm3/mem from ymm2 and stores result in ymm1.</td>, <td>EVEX.128.0F.W0 5C /r VSUBPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Subtract packed single-precision floating-point values from xmm3/m128/m32bcst to xmm2 and stores result in xmm1 with writemask k1.</td>, <td>EVEX.256.0F.W0 5C /r VSUBPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Subtract packed single-precision floating-point values from ymm3/m256/m32bcst to ymm2 and stores result in ymm1 with writemask k1.</td>, <td>EVEX.512.0F.W0 5C /r VSUBPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Subtract packed single-precision floating-point values in zmm3/m512/m32bcst from zmm2 and stores result in zmm1 with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F2 0F 5C /r SUBSD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Subtract the low double-precision floating-point value in xmm2/m64 from xmm1 and store the result in xmm1.</td>, <td>VEX.LIG.F2.0F.WIG 5C /r VSUBSD xmm1,xmm2, xmm3/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract the low double-precision floating-point value in xmm3/m64 from xmm2 and store the result in xmm1.</td>, <td>EVEX.LIG.F2.0F.W1 5C /r VSUBSD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Subtract the low double-precision floating-point value in xmm3/m64 from xmm2 and store the result in xmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F3 0F 5C /r SUBSS xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Subtract the low single-precision floating-point value in xmm2/m32 from xmm1 and store the result in xmm1.</td>, <td>VEX.LIG.F3.0F.WIG 5C /r VSUBSS xmm1,xmm2, xmm3/m32</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Subtract the low single-precision floating-point value in xmm3/m32 from xmm2 and store the result in xmm1.</td>, <td>EVEX.LIG.F3.0F.W0 5C /r VSUBSS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Subtract the low single-precision floating-point value in xmm3/m32 from xmm2 and store the result in xmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>0F 01 F8</td>, <td>SWAPGS</td>, <td>ZO</td>, <td>Valid</td>, <td>Invalid</td>, <td>Exchanges the current GS base register value with the value contained in MSR address C0000102H.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If Mode ≠ 64-Bit.</td>, <td>#UD</td>, <td>If Mode ≠ 64-Bit.</td>, <td>#UD</td>, <td>If Mode ≠ 64-Bit.</td>, <td>#UD</td>, <td>If Mode ≠ 64-Bit.</td>, <td>#GP(0)</td>, <td>If CPL ≠ 0.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 05</td>, <td>SYSCALL</td>, <td>ZO</td>, <td>Valid</td>, <td>Invalid</td>, <td>Fast call to privilege level 0 system procedures.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>The SYSCALL instruction is not recognized in protected mode.</td>, <td>#UD</td>, <td>The SYSCALL instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>The SYSCALL instruction is not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The SYSCALL instruction is not recognized in compatibility mode.</td>, <td rowspan="2">#UD</td>, <td>If IA32_EFER.SCE = 0.</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 34</td>, <td>SYSENTER</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fast call to privilege level 0 system procedures.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If IA32_SYSENTER_CS[15:2] = 0.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>The SYSENTER instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 35</td>, <td>SYSEXIT</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fast return to privilege level 3 user code.</td>, <td>REX.W + 0F 35</td>, <td>SYSEXIT</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Fast return to 64-bit mode privilege level 3 user code.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If IA32_SYSENTER_CS[15:2] = 0.</td>, <td>If CPL ≠ 0.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>The SYSEXIT instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>The SYSEXIT instruction is not recognized in virtual-8086 mode.</td>, <td rowspan="3">#GP(0)</td>, <td>If IA32_SYSENTER_CS = 0.</td>, <td>If CPL ≠ 0.</td>, <td>If RCX or RDX contains a non-canonical address.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 07</td>, <td>SYSRET</td>, <td>ZO</td>, <td>Valid</td>, <td>Invalid</td>, <td>Return to compatibility mode from fast system call</td>, <td>REX.W + 0F 07</td>, <td>SYSRET</td>, <td>ZO</td>, <td>Valid</td>, <td>Invalid</td>, <td>Return to 64-bit mode from fast system call</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>The SYSRET instruction is not recognized in protected mode.</td>, <td>#UD</td>, <td>The SYSRET instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>The SYSRET instruction is not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The SYSRET instruction is not recognized in compatibility mode.</td>, <td rowspan="2">#UD</td>, <td>If IA32_EFER.SCE = 0.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP(0)</td>, <td>If CPL ≠ 0.</td>, <td>If the return is to 64-bit mode and RCX contains a non-canonical address.</td>]

[<td>A8 <em>ib</em></td>, <td>TEST AL, i<em>mm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>AND <em>imm8</em> with AL; set SF, ZF, PF according to result.</td>, <td>A9 <em>iw</em></td>, <td>TEST AX, i<em>mm16</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>AND <em>imm16</em> with AX; set SF, ZF, PF according to result.</td>, <td>A9 <em>id</em></td>, <td>TEST EAX, i<em>mm32</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>AND <em>imm32</em> with EAX; set SF, ZF, PF according to result.</td>, <td>REX.W + A9 <em>id</em></td>, <td>TEST RAX, i<em>mm32</em></td>, <td>I</td>, <td>Valid</td>, <td>N.E.</td>, <td>AND <em>imm32</em> sign-extended to 64-bits with RAX; set SF, ZF, PF according to result.</td>, <td>F6 /0 <em>ib</em></td>, <td>TEST <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>AND <em>imm8</em> with <em>r/m8</em>; set SF, ZF, PF according to result.</td>, <td>REX + F6 /0 <em>ib</em></td>, <td>TEST <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>AND <em>imm8</em> with <em>r/m8</em>; set SF, ZF, PF according to result.</td>, <td>F7 /0 <em>iw</em></td>, <td>TEST <em>r/m16, imm16</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>AND <em>imm16</em> with <em>r/m16</em>; set SF, ZF, PF according to result.</td>, <td>F7 /0 <em>id</em></td>, <td>TEST <em>r/m32, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td>AND <em>imm32</em> with <em>r/m32</em>; set SF, ZF, PF according to result.</td>, <td>REX.W + F7 /0 <em>id</em></td>, <td>TEST <em>r/m64, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td>AND <em>imm32</em> sign-extended to 64-bits with <em>r/m64</em>; set SF, ZF, PF according to result.</td>, <td>84 /<em>r</em></td>, <td>TEST <em>r/m8, r8</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>AND <em>r8</em> with <em>r/m8</em>; set SF, ZF, PF according to result.</td>, <td>REX + 84 /<em>r</em></td>, <td>TEST <em>r/m8*, r8*</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>AND <em>r8</em> with <em>r/m8</em>; set SF, ZF, PF according to result.</td>, <td>85 /<em>r</em></td>, <td>TEST <em>r/m16, r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>AND <em>r16</em> with <em>r/m16</em>; set SF, ZF, PF according to result.</td>, <td>85 /<em>r</em></td>, <td>TEST <em>r/m32, r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>AND <em>r32</em> with <em>r/m32</em>; set SF, ZF, PF according to result.</td>, <td>REX.W + 85 /<em>r</em></td>, <td>TEST <em>r/m64, r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>AND <em>r64</em> with <em>r/m64</em>; set SF, ZF, PF according to result.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>I</td>, <td>AL/AX/EAX/RAX</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (r)</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td>MR</td>, <td>ModRM:r/m (r)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>66 0F AE /6 TPAUSE r32, &lt;edx&gt;, &lt;eax&gt;</td>, <td>A</td>, <td>V/V</td>, <td>WAITPKG</td>, <td>Directs the processor to enter an implementation-dependent optimized state until the TSC reaches the value in EDX:EAX.</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>bit[0] = 0</td>, <td>C0.2</td>, <td>Slower</td>, <td>Larger</td>, <td>Improves performance of the other SMT thread(s) on the same core.</td>, <td>bit[0] = 1</td>, <td>C0.1</td>, <td>Faster</td>, <td>Smaller</td>, <td>NA</td>, <td>bits[31:1]</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>Reserved</td>]

[<td>F3 0F BC /r TZCNT <em>r16, r/m16</em></td>, <td>A</td>, <td>V/V</td>, <td>BMI1</td>, <td>Count the number of trailing zero bits in <em>r/m16</em>, return result in <em>r16</em>.</td>, <td>F3 0F BC /r TZCNT <em>r32, r/m32</em></td>, <td>A</td>, <td>V/V</td>, <td>BMI1</td>, <td>Count the number of trailing zero bits in <em>r/m32</em>, return result in <em>r32.</em></td>, <td>F3 REX.W 0F BC /r TZCNT <em>r64, r/m64</em></td>, <td>A</td>, <td>V/N.E.</td>, <td>BMI1</td>, <td>Count the number of trailing zero bits in <em>r/m64</em>, return result in <em>r64</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>For an illegal memory operand effective address in the CS, DS, ES, FS or GS segments.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a null segment selector.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#GP(0)</td>, <td>If any part of the operand lies outside of the effective address space from 0 to 0FFFFH.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#GP(0)</td>, <td>If any part of the operand lies outside of the effective address space from 0 to 0FFFFH.</td>, <td>#SS(0)</td>, <td>For an illegal address in the SS segment.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#PF</td>, <td>(fault-code) For a page fault.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>]

[<td>66 0F 2E /r UCOMISD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Compare low double-precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly.</td>, <td>VEX.LIG.66.0F.WIG 2E /r VUCOMISD xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare low double-precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly.</td>, <td>EVEX.LIG.66.0F.W1 2E /r VUCOMISD xmm1, xmm2/m64{sae}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare low double-precision floating-point values in xmm1 and xmm2/m64 and set the EFLAGS flags accordingly.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B.</td>]

[<td>NP 0F 2E /r UCOMISS xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.</td>, <td>VEX.LIG.0F.WIG 2E /r VUCOMISS xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.</td>, <td>EVEX.LIG.0F.W0 2E /r VUCOMISS xmm1, xmm2/m32{sae}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B.</td>]

[<td>0F FF /r</td>, <td>UD0<sup>1</sup> <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Raise invalid opcode exception.</td>, <td>0F B9 /r</td>, <td>UD1 <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Raise invalid opcode exception.</td>, <td>0F 0B</td>, <td>UD2</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Raise invalid opcode exception.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>RM</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>F3 0F AE /6 UMONITOR r16/r32/r64</td>, <td>A</td>, <td>V/V</td>, <td>WAITPKG</td>, <td>Sets up a linear address range to be monitored by hardware and activates the monitor. The address range should be a write-back memory caching type. The address is contained in r16/r32/r64.</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If the specified segment is not SS and the source register is outside the specified segment limit.</td>, <td>If the specified segment register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If the specified segment is SS and the source register is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#UD</td>, <td>If CPUID.7.0:ECX.WAITPKG[bit 5]=0.</td>, <td>#GP</td>, <td>If the specified segment is not SS and the source register is outside of the effective address space from 0 to FFFFH.</td>, <td>#SS</td>, <td>If the specified segment is SS and the source register is outside of the effective address space from 0 to FFFFH.</td>, <td>#UD</td>, <td>If CPUID.7.0:ECX.WAITPKG[bit 5]=0.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#GP(0)</td>, <td>If the specified segment is not SS and the linear address is in non-canonical form.</td>, <td>#SS(0)</td>, <td>If the specified segment is SS and the source register is in non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>For a page fault.</td>, <td>#UD</td>, <td>If CPUID.7.0:ECX.WAITPKG[bit 5]=0.</td>]

[<td>F2 0F AE /6 UMWAIT r32, &lt;edx&gt;, &lt;eax&gt;</td>, <td>A</td>, <td>V/V</td>, <td>WAITPKG</td>, <td>A hint that allows the processor to stop instruction execution and enter an implementation-dependent optimized state until occurrence of a class of events.</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>bit[0] = 0</td>, <td>C0.2</td>, <td>Slower</td>, <td>Larger</td>, <td>Improves performance of the other SMT thread(s) on the same core.</td>, <td>bit[0] = 1</td>, <td>C0.1</td>, <td>Faster</td>, <td>Smaller</td>, <td>NA</td>, <td>bits[31:1]</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>Reserved</td>]

[<td>66 0F 15 /r UNPCKHPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpacks and Interleaves double-precision floating-point values from high quadwords of xmm1 and xmm2/m128.</td>, <td>VEX.128.66.0F.WIG 15 /r VUNPCKHPD xmm1,xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Unpacks and Interleaves double-precision floating-point values from high quadwords of xmm2 and xmm3/m128.</td>, <td>VEX.256.66.0F.WIG 15 /r VUNPCKHPD ymm1,ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Unpacks and Interleaves double-precision floating-point values from high quadwords of ymm2 and ymm3/m256.</td>, <td>EVEX.128.66.0F.W1 15 /r VUNPCKHPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Unpacks and Interleaves double precision floating-point values from high quadwords of xmm2 and xmm3/m128/m64bcst subject to writemask k1.</td>, <td>EVEX.256.66.0F.W1 15 /r VUNPCKHPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Unpacks and Interleaves double precision floating-point values from high quadwords of ymm2 and ymm3/m256/m64bcst subject to writemask k1.</td>, <td>EVEX.512.66.0F.W1 15 /r VUNPCKHPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Unpacks and Interleaves double-precision floating-point values from high quadwords of zmm2 and zmm3/m512/m64bcst subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 15 /r UNPCKHPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Unpacks and Interleaves single-precision floating-point values from high quadwords of xmm1 and xmm2/m128.</td>, <td>VEX.128.0F.WIG 15 /r VUNPCKHPS xmm1, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Unpacks and Interleaves single-precision floating-point values from high quadwords of xmm2 and xmm3/m128.</td>, <td>VEX.256.0F.WIG 15 /r VUNPCKHPS ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Unpacks and Interleaves single-precision floating-point values from high quadwords of ymm2 and ymm3/m256.</td>, <td>EVEX.128.0F.W0 15 /r VUNPCKHPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Unpacks and Interleaves single-precision floating-point values from high quadwords of xmm2 and xmm3/m128/m32bcst and write result to xmm1 subject to writemask k1.</td>, <td>EVEX.256.0F.W0 15 /r VUNPCKHPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Unpacks and Interleaves single-precision floating-point values from high quadwords of ymm2 and ymm3/m256/m32bcst and write result to ymm1 subject to writemask k1.</td>, <td>EVEX.512.0F.W0 15 /r VUNPCKHPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Unpacks and Interleaves single-precision floating-point values from high quadwords of zmm2 and zmm3/m512/m32bcst and write result to zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>66 0F 14 /r UNPCKLPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Unpacks and Interleaves double-precision floating-point values from low quadwords of xmm1 and xmm2/m128.</td>, <td>VEX.128.66.0F.WIG 14 /r VUNPCKLPD xmm1,xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Unpacks and Interleaves double-precision floating-point values from low quadwords of xmm2 and xmm3/m128.</td>, <td>VEX.256.66.0F.WIG 14 /r VUNPCKLPD ymm1,ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Unpacks and Interleaves double-precision floating-point values from low quadwords of ymm2 and ymm3/m256.</td>, <td>EVEX.128.66.0F.W1 14 /r VUNPCKLPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Unpacks and Interleaves double precision floating-point values from low quadwords of xmm2 and xmm3/m128/m64bcst subject to write mask k1.</td>, <td>EVEX.256.66.0F.W1 14 /r VUNPCKLPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Unpacks and Interleaves double precision floating-point values from low quadwords of ymm2 and ymm3/m256/m64bcst subject to write mask k1.</td>, <td>EVEX.512.66.0F.W1 14 /r VUNPCKLPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Unpacks and Interleaves double-precision floating-point values from low quadwords of zmm2 and zmm3/m512/m64bcst subject to write mask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 14 /r UNPCKLPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Unpacks and Interleaves single-precision floating-point values from low quadwords of xmm1 and xmm2/m128.</td>, <td>VEX.128.0F.WIG 14 /r VUNPCKLPS xmm1,xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Unpacks and Interleaves single-precision floating-point values from low quadwords of xmm2 and xmm3/m128.</td>, <td>VEX.256.0F.WIG 14 /r VUNPCKLPS ymm1,ymm2,ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Unpacks and Interleaves single-precision floating-point values from low quadwords of ymm2 and ymm3/m256.</td>, <td>EVEX.128.0F.W0 14 /r VUNPCKLPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Unpacks and Interleaves single-precision floating-point values from low quadwords of xmm2 and xmm3/mem and write result to xmm1 subject to write mask k1.</td>, <td>EVEX.256.0F.W0 14 /r VUNPCKLPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Unpacks and Interleaves single-precision floating-point values from low quadwords of ymm2 and ymm3/mem and write result to ymm1 subject to write mask k1.</td>, <td>EVEX.512.0F.W0 14 /r VUNPCKLPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Unpacks and Interleaves single-precision floating-point values from low quadwords of zmm2 and zmm3/m512/m32bcst and write result to zmm1 subject to write mask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F3A.W0 03 /r ib VALIGND xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift right and merge vectors xmm2 and xmm3/m128/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.</td>, <td>EVEX.128.66.0F3A.W1 03 /r ib VALIGNQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift right and merge vectors xmm2 and xmm3/m128/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.</td>, <td>EVEX.256.66.0F3A.W0 03 /r ib VALIGND ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift right and merge vectors ymm2 and ymm3/m256/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.</td>, <td>EVEX.256.66.0F3A.W1 03 /r ib VALIGNQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift right and merge vectors ymm2 and ymm3/m256/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.</td>, <td>EVEX.512.66.0F3A.W0 03 /r ib VALIGND zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift right and merge vectors zmm2 and zmm3/m512/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.</td>, <td>EVEX.512.66.0F3A.W1 03 /r ib VALIGNQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift right and merge vectors zmm2 and zmm3/m512/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F3A.W0 03 /r ib VALIGND xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift right and merge vectors xmm2 and xmm3/m128/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.</td>, <td>EVEX.128.66.0F3A.W1 03 /r ib VALIGNQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift right and merge vectors xmm2 and xmm3/m128/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in xmm1, under writemask.</td>, <td>EVEX.256.66.0F3A.W0 03 /r ib VALIGND ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift right and merge vectors ymm2 and ymm3/m256/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.</td>, <td>EVEX.256.66.0F3A.W1 03 /r ib VALIGNQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift right and merge vectors ymm2 and ymm3/m256/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in ymm1, under writemask.</td>, <td>EVEX.512.66.0F3A.W0 03 /r ib VALIGND zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift right and merge vectors zmm2 and zmm3/m512/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.</td>, <td>EVEX.512.66.0F3A.W1 03 /r ib VALIGNQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift right and merge vectors zmm2 and zmm3/m512/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 65 /r VBLENDMPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Blend double-precision vector xmm2 and double-precision vector xmm3/m128/m64bcst and store the result in xmm1, under control mask.</td>, <td>EVEX.256.66.0F38.W1 65 /r VBLENDMPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Blend double-precision vector ymm2 and double-precision vector ymm3/m256/m64bcst and store the result in ymm1, under control mask.</td>, <td>EVEX.512.66.0F38.W1 65 /r VBLENDMPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Blend double-precision vector zmm2 and double-precision vector zmm3/m512/m64bcst and store the result in zmm1, under control mask.</td>, <td>EVEX.128.66.0F38.W0 65 /r VBLENDMPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Blend single-precision vector xmm2 and single-precision vector xmm3/m128/m32bcst and store the result in xmm1, under control mask.</td>, <td>EVEX.256.66.0F38.W0 65 /r VBLENDMPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Blend single-precision vector ymm2 and single-precision vector ymm3/m256/m32bcst and store the result in ymm1, under control mask.</td>, <td>EVEX.512.66.0F38.W0 65 /r VBLENDMPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Blend single-precision vector zmm2 and single-precision vector zmm3/m512/m32bcst using k1 as select control and store the result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 65 /r VBLENDMPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Blend double-precision vector xmm2 and double-precision vector xmm3/m128/m64bcst and store the result in xmm1, under control mask.</td>, <td>EVEX.256.66.0F38.W1 65 /r VBLENDMPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Blend double-precision vector ymm2 and double-precision vector ymm3/m256/m64bcst and store the result in ymm1, under control mask.</td>, <td>EVEX.512.66.0F38.W1 65 /r VBLENDMPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Blend double-precision vector zmm2 and double-precision vector zmm3/m512/m64bcst and store the result in zmm1, under control mask.</td>, <td>EVEX.128.66.0F38.W0 65 /r VBLENDMPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Blend single-precision vector xmm2 and single-precision vector xmm3/m128/m32bcst and store the result in xmm1, under control mask.</td>, <td>EVEX.256.66.0F38.W0 65 /r VBLENDMPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Blend single-precision vector ymm2 and single-precision vector ymm3/m256/m32bcst and store the result in ymm1, under control mask.</td>, <td>EVEX.512.66.0F38.W0 65 /r VBLENDMPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Blend single-precision vector zmm2 and single-precision vector zmm3/m512/m32bcst using k1 as select control and store the result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 18 /r VBROADCASTSS xmm1, m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Broadcast single-precision floating-point element in mem to four locations in xmm1.</td>, <td>VEX.256.66.0F38.W0 18 /r VBROADCASTSS ymm1, m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Broadcast single-precision floating-point element in mem to eight locations in ymm1.</td>, <td>VEX.256.66.0F38.W0 19 /r VBROADCASTSD ymm1, m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Broadcast double-precision floating-point element in mem to four locations in ymm1.</td>, <td>VEX.256.66.0F38.W0 1A /r VBROADCASTF128 ymm1, m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Broadcast 128 bits of floating-point data in mem to low and high 128-bits in ymm1.</td>, <td>VEX.128.66.0F38.W0 18/r VBROADCASTSS <em>xmm1, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Broadcast the low single-precision floating-point element in the source operand to four locations in xmm1.</td>, <td>VEX.256.66.0F38.W0 18 /r VBROADCASTSS <em>ymm1, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Broadcast low single-precision floating-point element in the source operand to eight locations in ymm1.</td>, <td>VEX.256.66.0F38.W0 19 /r VBROADCASTSD <em>ymm1, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Broadcast low double-precision floating-point element in the source operand to four locations in ymm1.</td>, <td>EVEX.256.66.0F38.W1 19 /r VBROADCASTSD ymm1 {k1}{z}, xmm2/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast low double-precision floating-point element in xmm2/m64 to four locations in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 19 /r VBROADCASTSD zmm1 {k1}{z}, xmm2/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Broadcast low double-precision floating-point element in xmm2/m64 to eight locations in zmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 19 /r VBROADCASTF32X2 ymm1 {k1}{z}, xmm2/m64</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Broadcast two single-precision floating-point elements in xmm2/m64 to locations in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 19 /r VBROADCASTF32X2 zmm1 {k1}{z}, xmm2/m64</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Broadcast two single-precision floating-point elements in xmm2/m64 to locations in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 18 /r VBROADCASTSS xmm1 {k1}{z}, xmm2/m32</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast low single-precision floating-point element in xmm2/m32 to all locations in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 18 /r VBROADCASTSS ymm1 {k1}{z}, xmm2/m32</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast low single-precision floating-point element in xmm2/m32 to all locations in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 18 /r VBROADCASTSS zmm1 {k1}{z}, xmm2/m32</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Broadcast low single-precision floating-point element in xmm2/m32 to all locations in zmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 1A /r VBROADCASTF32X4 ymm1 {k1}{z}, m128</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast 128 bits of 4 single-precision floating-point data in mem to locations in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 1A /r VBROADCASTF32X4 zmm1 {k1}{z}, m128</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Broadcast 128 bits of 4 single-precision floating-point data in mem to locations in zmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 1A /r VBROADCASTF64X2 ymm1 {k1}{z}, m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Broadcast 128 bits of 2 double-precision floating-point data in mem to locations in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 1A /r VBROADCASTF64X2 zmm1 {k1}{z}, m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Broadcast 128 bits of 2 double-precision floating-point data in mem to locations in zmm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 1B /r VBROADCASTF32X8 zmm1 {k1}{z}, m256</td>, <td>E</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Broadcast 256 bits of 8 single-precision floating-point data in mem to locations in zmm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 1B /r VBROADCASTF64X4 zmm1 {k1}{z}, m256</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Broadcast 256 bits of 4 double-precision floating-point data in mem to locations in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Tuple2</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Tuple4</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>E</td>, <td>Tuple8</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#UD</td>, <td>If VEX.L = 0 for VBROADCASTSD or VBROADCASTF128.</td>, <td>If EVEX.L’L = 0 for VBROADCASTSD/VBROADCASTF32X2/VBROADCASTF32X4/VBROADCASTF64X2.</td>, <td>If EVEX.L’L &lt; 10b for VBROADCASTF32X8/VBROADCASTF64X4.</td>]

[<td>EVEX.128.66.0F38.W1 8A /r VCOMPRESSPD xmm1/m128 {k1}{z}, xmm2</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compress packed double-precision floating-point values from xmm2 to xmm1/m128 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 8A /r VCOMPRESSPD ymm1/m256 {k1}{z}, ymm2</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compress packed double-precision floating-point values from ymm2 to ymm1/m256 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 8A /r VCOMPRESSPD zmm1/m512 {k1}{z}, zmm2</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compress packed double-precision floating-point values from zmm2 using control mask k1 to zmm1/m512.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F38.W0 8A /r VCOMPRESSPS xmm1/m128 {k1}{z}, xmm2</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compress packed single-precision floating-point values from xmm2 to xmm1/m128 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 8A /r VCOMPRESSPS ymm1/m256 {k1}{z}, ymm2</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compress packed single-precision floating-point values from ymm2 to ymm1/m256 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 8A /r VCOMPRESSPS zmm1/m512 {k1}{z}, zmm2</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compress packed single-precision floating-point values from zmm2 using control mask k1 to zmm1/m512.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F.W1 7B /r VCVTPD2QQ xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert two packed double-precision floating-point values from xmm2/m128/m64bcst to two packed quadword integers in xmm1 with writemask k1.</td>, <td>EVEX.256.66.0F.W1 7B /r VCVTPD2QQ ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert four packed double-precision floating-point values from ymm2/m256/m64bcst to four packed quadword integers in ymm1 with writemask k1.</td>, <td>EVEX.512.66.0F.W1 7B /r VCVTPD2QQ zmm1 {k1}{z}, zmm2/m512/m64bcst{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Convert eight packed double-precision floating-point values from zmm2/m512/m64bcst to eight packed quadword integers in zmm1 with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.0F.W1 79 /r VCVTPD2UDQ xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert two packed double-precision floating-point values in xmm2/m128/m64bcst to two unsigned doubleword integers in xmm1 subject to writemask k1.</td>, <td>EVEX.256.0F.W1 79 /r VCVTPD2UDQ xmm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert four packed double-precision floating-point values in ymm2/m256/m64bcst to four unsigned doubleword integers in xmm1 subject to writemask k1.</td>, <td>EVEX.512.0F.W1 79 /r VCVTPD2UDQ ymm1 {k1}{z}, zmm2/m512/m64bcst{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert eight packed double-precision floating-point values in zmm2/m512/m64bcst to eight unsigned doubleword integers in ymm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F.W1 79 /r VCVTPD2UQQ xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert two packed double-precision floating-point values from xmm2/mem to two packed unsigned quadword integers in xmm1 with writemask k1.</td>, <td>EVEX.256.66.0F.W1 79 /r VCVTPD2UQQ ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert fourth packed double-precision floating-point values from ymm2/mem to four packed unsigned quadword integers in ymm1 with writemask k1.</td>, <td>EVEX.512.66.0F.W1 79 /r VCVTPD2UQQ zmm1 {k1}{z}, zmm2/m512/m64bcst{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Convert eight packed double-precision floating-point values from zmm2/mem to eight packed unsigned quadword integers in zmm1 with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>VEX.128.66.0F38.W0 13 /r VCVTPH2PS xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>F16C</td>, <td>Convert four packed half precision (16-bit) floating-point values in xmm2/m64 to packed single-precision floating-point value in xmm1.</td>, <td>VEX.256.66.0F38.W0 13 /r VCVTPH2PS ymm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>F16C</td>, <td>Convert eight packed half precision (16-bit) floating-point values in xmm2/m128 to packed single-precision floating-point value in ymm1.</td>, <td>EVEX.128.66.0F38.W0 13 /r VCVTPH2PS xmm1 {k1}{z}, xmm2/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert four packed half precision (16-bit) floating-point values in xmm2/m64 to packed single-precision floating-point values in xmm1.</td>, <td>EVEX.256.66.0F38.W0 13 /r VCVTPH2PS ymm1 {k1}{z}, xmm2/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert eight packed half precision (16-bit) floating-point values in xmm2/m128 to packed single-precision floating-point values in ymm1.</td>, <td>EVEX.512.66.0F38.W0 13 /r VCVTPH2PS zmm1 {k1}{z}, ymm2/m256 {sae}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert sixteen packed half precision (16-bit) floating-point values in ymm2/m256 to packed single-precision floating-point values in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Half Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>VCVTPH2PS<em>xmm1,xmm2/mem64, imm8</em> 127 96 95 64 63 48 47 32 31 16 15 0</td>, <td>xmm2/mem64 VH3 VH2 VH1 VH0</td>, <td rowspan="4">convert convert convert convert 127 96 95 64 63 32 31 0</td>, <td>VS3 VS2 VS1 VS0 xmm1</td>, <td>#UD</td>, <td>If VEX.W=1.</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>VEX.128.66.0F3A.W0 1D /r ib VCVTPS2PH xmm1/m64, xmm2, imm8</td>, <td>A</td>, <td>V/V</td>, <td>F16C</td>, <td>Convert four packed single-precision floating-point values in xmm2 to packed half-precision (16-bit) floating-point values in xmm1/m64. Imm8 provides rounding controls.</td>, <td>VEX.256.66.0F3A.W0 1D /r ib VCVTPS2PH xmm1/m128, ymm2, imm8</td>, <td>A</td>, <td>V/V</td>, <td>F16C</td>, <td>Convert eight packed single-precision floating-point values in ymm2 to packed half-precision (16-bit) floating-point values in xmm1/m128. Imm8 provides rounding controls.</td>, <td>EVEX.128.66.0F3A.W0 1D /r ib VCVTPS2PH xmm1/m64 {k1}{z}, xmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert four packed single-precision floating-point values in xmm2 to packed half-precision (16-bit) floating-point values in xmm1/m64. Imm8 provides rounding controls.</td>, <td>EVEX.256.66.0F3A.W0 1D /r ib VCVTPS2PH xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert eight packed single-precision floating-point values in ymm2 to packed half-precision (16-bit) floating-point values in xmm1/m128. Imm8 provides rounding controls.</td>, <td>EVEX.512.66.0F3A.W0 1D /r ib VCVTPS2PH ymm1/m256 {k1}{z}, zmm2{sae}, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert sixteen packed single-precision floating-point values in zmm2 to packed half-precision (16-bit) floating-point values in ymm1/m256. Imm8 provides rounding controls.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Half Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td rowspan="4">Imm[1:0]</td>, <td>RC=00B</td>, <td>Round to nearest even</td>, <td rowspan="4">If Imm[2] = 0</td>, <td>RC=01B</td>, <td>Round down</td>, <td>RC=10B</td>, <td>Round up</td>, <td>RC=11B</td>, <td>Truncate</td>, <td rowspan="2">Imm[2]</td>, <td>MS1=0</td>, <td>Use imm[1:0] for rounding</td>, <td>Ignore MXCSR.RC</td>, <td>MS1=1</td>, <td>Use MXCSR.RC for rounding</td>, <td></td>, <td>Imm[7:3]</td>, <td>Ignored</td>, <td>Ignored by processor</td>, <td></td>, <td>#UD</td>, <td>If VEX.W=1.</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F.W0 7B /r VCVTPS2QQ xmm1 {k1}{z}, xmm2/m64/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert two packed single precision floating-point values from xmm2/m64/m32bcst to two packed signed quadword values in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F.W0 7B /r VCVTPS2QQ ymm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed signed quadword values in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F.W0 7B /r VCVTPS2QQ zmm1 {k1}{z}, ymm2/m256/m32bcst{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed signed quadword values in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Half</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.0F.W0 79 /r VCVTPS2UDQ xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed unsigned doubleword values in xmm1 subject to writemask k1.</td>, <td>EVEX.256.0F.W0 79 /r VCVTPS2UDQ ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed unsigned doubleword values in ymm1 subject to writemask k1.</td>, <td>EVEX.512.0F.W0 79 /r VCVTPS2UDQ zmm1 {k1}{z}, zmm2/m512/m32bcst{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert sixteen packed single-precision floating-point values from zmm2/m512/m32bcst to sixteen packed unsigned doubleword values in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F.W0 79 /r VCVTPS2UQQ xmm1 {k1}{z}, xmm2/m64/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert two packed single precision floating-point values from zmm2/m64/m32bcst to two packed unsigned quadword values in zmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F.W0 79 /r VCVTPS2UQQ ymm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed unsigned quadword values in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F.W0 79 /r VCVTPS2UQQ zmm1 {k1}{z}, ymm2/m256/m32bcst{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed unsigned quadword values in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Half</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F.W1 E6 /r VCVTQQ2PD xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert two packed quadword integers from xmm2/m128/m64bcst to packed double-precision floating-point values in xmm1 with writemask k1.</td>, <td>EVEX.256.F3.0F.W1 E6 /r VCVTQQ2PD ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert four packed quadword integers from ymm2/m256/m64bcst to packed double-precision floating-point values in ymm1 with writemask k1.</td>, <td>EVEX.512.F3.0F.W1 E6 /r VCVTQQ2PD zmm1 {k1}{z}, zmm2/m512/m64bcst{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Convert eight packed quadword integers from zmm2/m512/m64bcst to eight packed double-precision floating-point values in zmm1 with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.0F.W1 5B /r VCVTQQ2PS xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert two packed quadword integers from xmm2/mem to packed single-precision floating-point values in xmm1 with writemask k1.</td>, <td>EVEX.256.0F.W1 5B /r VCVTQQ2PS xmm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert four packed quadword integers from ymm2/mem to packed single-precision floating-point values in xmm1 with writemask k1.</td>, <td>EVEX.512.0F.W1 5B /r VCVTQQ2PS ymm1 {k1}{z}, zmm2/m512/m64bcst{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Convert eight packed quadword integers from zmm2/mem to eight packed single-precision floating-point values in ymm1 with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.LIG.F2.0F.W0 79 /r VCVTSD2USI r32, xmm1/m64{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert one double-precision floating-point value from xmm1/m64 to one unsigned doubleword integer r32.</td>, <td>EVEX.LIG.F2.0F.W1 79 /r VCVTSD2USI r64, xmm1/m64{er}</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512F</td>, <td>Convert one double-precision floating-point value from xmm1/m64 to one unsigned quadword integer zero-extended into r64.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Fixed</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.LIG.F3.0F.W0 79 /r VCVTSS2USI r32, xmm1/m32{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert one single-precision floating-point value from xmm1/m32 to one unsigned doubleword integer in r32.</td>, <td>EVEX.LIG.F3.0F.W1 79 /r VCVTSS2USI r64, xmm1/m32{er}</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512F</td>, <td>Convert one single-precision floating-point value from xmm1/m32 to one unsigned quadword integer in r64.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Fixed</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.66.0F.W1 7A /r VCVTTPD2QQ xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert two packed double-precision floating-point values from zmm2/m128/m64bcst to two packed quadword integers in zmm1 using truncation with writemask k1.</td>, <td>EVEX.256.66.0F.W1 7A /r VCVTTPD2QQ ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert four packed double-precision floating-point values from ymm2/m256/m64bcst to four packed quadword integers in ymm1 using truncation with writemask k1.</td>, <td>EVEX.512.66.0F.W1 7A /r VCVTTPD2QQ zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Convert eight packed double-precision floating-point values from zmm2/m512 to eight packed quadword integers in zmm1 using truncation with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.0F.W1 78 /r VCVTTPD2UDQ xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert two packed double-precision floating-point values in xmm2/m128/m64bcst to two unsigned doubleword integers in xmm1 using truncation subject to writemask k1.</td>, <td>EVEX.256.0F.W1 78 02 /r VCVTTPD2UDQ xmm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert four packed double-precision floating-point values in ymm2/m256/m64bcst to four unsigned doubleword integers in xmm1 using truncation subject to writemask k1.</td>, <td>EVEX.512.0F.W1 78 /r VCVTTPD2UDQ ymm1 {k1}{z}, zmm2/m512/m64bcst{sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert eight packed double-precision floating-point values in zmm2/m512/m64bcst to eight unsigned doubleword integers in ymm1 using truncation subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F.W1 78 /r VCVTTPD2UQQ xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert two packed double-precision floating-point values from xmm2/m128/m64bcst to two packed unsigned quadword integers in xmm1 using truncation with writemask k1.</td>, <td>EVEX.256.66.0F.W1 78 /r VCVTTPD2UQQ ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert four packed double-precision floating-point values from ymm2/m256/m64bcst to four packed unsigned quadword integers in ymm1 using truncation with writemask k1.</td>, <td>EVEX.512.66.0F.W1 78 /r VCVTTPD2UQQ zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Convert eight packed double-precision floating-point values from zmm2/mem to eight packed unsigned quadword integers in zmm1 using truncation with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F.W0 7A /r VCVTTPS2QQ xmm1 {k1}{z}, xmm2/m64/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert two packed single precision floating-point values from xmm2/m64/m32bcst to two packed signed quadword values in xmm1 using truncation subject to writemask k1.</td>, <td>EVEX.256.66.0F.W0 7A /r VCVTTPS2QQ ymm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed signed quadword values in ymm1 using truncation subject to writemask k1.</td>, <td>EVEX.512.66.0F.W0 7A /r VCVTTPS2QQ zmm1 {k1}{z}, ymm2/m256/m32bcst{sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed signed quadword values in zmm1 using truncation subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Half</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.0F.W0 78 /r VCVTTPS2UDQ xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed unsigned doubleword values in xmm1 using truncation subject to writemask k1.</td>, <td>EVEX.256.0F.W0 78 /r VCVTTPS2UDQ ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed unsigned doubleword values in ymm1 using truncation subject to writemask k1.</td>, <td>EVEX.512.0F.W0 78 /r VCVTTPS2UDQ zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert sixteen packed single-precision floating-point values from zmm2/m512/m32bcst to sixteen packed unsigned doubleword values in zmm1 using truncation subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F.W0 78 /r VCVTTPS2UQQ xmm1 {k1}{z}, xmm2/m64/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert two packed single precision floating-point values from xmm2/m64/m32bcst to two packed unsigned quadword values in xmm1 using truncation subject to writemask k1.</td>, <td>EVEX.256.66.0F.W0 78 /r VCVTTPS2UQQ ymm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed unsigned quadword values in ymm1 using truncation subject to writemask k1.</td>, <td>EVEX.512.66.0F.W0 78 /r VCVTTPS2UQQ zmm1 {k1}{z}, ymm2/m256/m32bcst{sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed unsigned quadword values in zmm1 using truncation subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Half</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.LIG.F2.0F.W0 78 /r VCVTTSD2USI r32, xmm1/m64{sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert one double-precision floating-point value from xmm1/m64 to one unsigned doubleword integer r32 using truncation.</td>, <td>EVEX.LIG.F2.0F.W1 78 /r VCVTTSD2USI r64, xmm1/m64{sae}</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512F</td>, <td>Convert one double-precision floating-point value from xmm1/m64 to one unsigned quadword integer zero-extended into r64 using truncation.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Fixed</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.LIG.F3.0F.W0 78 /r VCVTTSS2USI r32, xmm1/m32{sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert one single-precision floating-point value from xmm1/m32 to one unsigned doubleword integer in r32 using truncation.</td>, <td>EVEX.LIG.F3.0F.W1 78 /r VCVTTSS2USI r64, xmm1/m32{sae}</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512F</td>, <td>Convert one single-precision floating-point value from xmm1/m32 to one unsigned quadword integer in r64 using truncation.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Fixed</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.F3.0F.W0 7A /r VCVTUDQ2PD xmm1 {k1}{z}, xmm2/m64/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert two packed unsigned doubleword integers from ymm2/m64/m32bcst to packed double-precision floating-point values in zmm1 with writemask k1.</td>, <td>EVEX.256.F3.0F.W0 7A /r VCVTUDQ2PD ymm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert four packed unsigned doubleword integers from xmm2/m128/m32bcst to packed double-precision floating-point values in zmm1 with writemask k1.</td>, <td>EVEX.512.F3.0F.W0 7A /r VCVTUDQ2PD zmm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert eight packed unsigned doubleword integers from ymm2/m256/m32bcst to eight packed double-precision floating-point values in zmm1 with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Half</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F2.0F.W0 7A /r VCVTUDQ2PS xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert four packed unsigned doubleword integers from xmm2/m128/m32bcst to packed single-precision floating-point values in xmm1 with writemask k1.</td>, <td>EVEX.256.F2.0F.W0 7A /r VCVTUDQ2PS ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert eight packed unsigned doubleword integers from ymm2/m256/m32bcst to packed single-precision floating-point values in zmm1 with writemask k1.</td>, <td>EVEX.512.F2.0F.W0 7A /r VCVTUDQ2PS zmm1 {k1}{z}, zmm2/m512/m32bcst{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert sixteen packed unsigned doubleword integers from zmm2/m512/m32bcst to sixteen packed single-precision floating-point values in zmm1 with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F.W1 7A /r VCVTUQQ2PD xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert two packed unsigned quadword integers from xmm2/m128/m64bcst to two packed double-precision floating-point values in xmm1 with writemask k1.</td>, <td>EVEX.256.F3.0F.W1 7A /r VCVTUQQ2PD ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert four packed unsigned quadword integers from ymm2/m256/m64bcst to packed double-precision floating-point values in ymm1 with writemask k1.</td>, <td>EVEX.512.F3.0F.W1 7A /r VCVTUQQ2PD zmm1 {k1}{z}, zmm2/m512/m64bcst{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Convert eight packed unsigned quadword integers from zmm2/m512/m64bcst to eight packed double-precision floating-point values in zmm1 with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F2.0F.W1 7A /r VCVTUQQ2PS xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert two packed unsigned quadword integers from xmm2/m128/m64bcst to packed single-precision floating-point values in zmm1 with writemask k1.</td>, <td>EVEX.256.F2.0F.W1 7A /r VCVTUQQ2PS xmm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Convert four packed unsigned quadword integers from ymm2/m256/m64bcst to packed single-precision floating-point values in xmm1 with writemask k1.</td>, <td>EVEX.512.F2.0F.W1 7A /r VCVTUQQ2PS ymm1 {k1}{z}, zmm2/m512/m64bcst{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Convert eight packed unsigned quadword integers from zmm2/m512/m64bcst to eight packed single-precision floating-point values in zmm1 with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.LIG.F2.0F.W0 7B /r VCVTUSI2SD xmm1, xmm2, r/m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert one unsigned doubleword integer from r/m32 to one double-precision floating-point value in xmm1.</td>, <td>EVEX.LIG.F2.0F.W1 7B /r VCVTUSI2SD xmm1, xmm2, r/m64{er}</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512F</td>, <td>Convert one unsigned quadword integer from r/m64 to one double-precision floating-point value in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.LIG.F3.0F.W0 7B /r VCVTUSI2SS xmm1, xmm2, r/m32{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert one signed doubleword integer from r/m32 to one single-precision floating-point value in xmm1.</td>, <td>EVEX.LIG.F3.0F.W1 7B /r VCVTUSI2SS xmm1, xmm2, r/m64{er}</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512F</td>, <td>Convert one signed quadword integer from r/m64 to one single-precision floating-point value in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F3A.W0 42 /r ib VDBPSADBW xmm1 {k1}{z}, xmm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute packed SAD word results of unsigned bytes in dword block from xmm2 with unsigned bytes of dword blocks transformed from xmm3/m128 using the shuffle controls in imm8. Results are written to xmm1 under the writemask k1.</td>, <td>EVEX.256.66.0F3A.W0 42 /r ib VDBPSADBW ymm1 {k1}{z}, ymm2, ymm3/m256, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compute packed SAD word results of unsigned bytes in dword block from ymm2 with unsigned bytes of dword blocks transformed from ymm3/m256 using the shuffle controls in imm8. Results are written to ymm1 under the writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 42 /r ib VDBPSADBW zmm1 {k1}{z}, zmm2, zmm3/m512, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compute packed SAD word results of unsigned bytes in dword block from zmm2 with unsigned bytes of dword blocks transformed from zmm3/m512 using the shuffle controls in imm8. Results are written to zmm1 under the writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>]

[<td>0F 00 /4</td>, <td>VERR <em>r/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set ZF=1 if segment specified with <em>r/m16</em> can be read.</td>, <td>0F 00 /5</td>, <td>VERW <em>r/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set ZF=1 if segment specified with <em>r/m16</em> can be written.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#UD</td>, <td>The VERR and VERW instructions are not recognized in real-address mode.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#UD</td>, <td>The VERR and VERW instructions are not recognized in virtual-8086 mode.</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 00 /4</td>, <td>VERR <em>r/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set ZF=1 if segment specified with <em>r/m16</em> can be read.</td>, <td>0F 00 /5</td>, <td>VERW <em>r/m16</em></td>, <td>M</td>, <td>Valid</td>, <td>Valid</td>, <td>Set ZF=1 if segment specified with <em>r/m16</em> can be written.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register is used to access memory and it contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#UD</td>, <td>The VERR and VERW instructions are not recognized in real-address mode.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#UD</td>, <td>The VERR and VERW instructions are not recognized in virtual-8086 mode.</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>EVEX.128.66.0F38.W1 88 /r VEXPANDPD xmm1 {k1}{z}, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Expand packed double-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 88 /r VEXPANDPD ymm1 {k1}{z}, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Expand packed double-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 88 /r VEXPANDPD zmm1 {k1}{z}, zmm2/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Expand packed double-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F38.W0 88 /r VEXPANDPS xmm1 {k1}{z}, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Expand packed single-precision floating-point values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 88 /r VEXPANDPS ymm1 {k1}{z}, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Expand packed single-precision floating-point values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 88 /r VEXPANDPS zmm1 {k1}{z}, zmm2/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Expand packed single-precision floating-point values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>VEX.256.66.0F3A.W0 19 /r ib VEXTRACTF128 xmm1/m128, ymm2, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Extract 128 bits of packed floating-point values from ymm2 and store results in xmm1/m128.</td>, <td>EVEX.256.66.0F3A.W0 19 /r ib VEXTRACTF32X4 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Extract 128 bits of packed single-precision floating-point values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 19 /r ib VEXTRACTF32x4 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 128 bits of packed single-precision floating-point values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 19 /r ib VEXTRACTF64X2 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Extract 128 bits of packed double-precision floating-point values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 19 /r ib VEXTRACTF64X2 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 128 bits of packed double-precision floating-point values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 1B /r ib VEXTRACTF32X8 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 256 bits of packed single-precision floating-point values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 1B /r ib VEXTRACTF64x4 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 256 bits of packed double-precision floating-point values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>#UD</td>, <td>IF VEX.L = 0.</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>VEX.256.66.0F3A.W0 19 /r ib VEXTRACTF128 xmm1/m128, ymm2, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Extract 128 bits of packed floating-point values from ymm2 and store results in xmm1/m128.</td>, <td>EVEX.256.66.0F3A.W0 19 /r ib VEXTRACTF32X4 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Extract 128 bits of packed single-precision floating-point values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 19 /r ib VEXTRACTF32x4 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 128 bits of packed single-precision floating-point values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 19 /r ib VEXTRACTF64X2 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Extract 128 bits of packed double-precision floating-point values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 19 /r ib VEXTRACTF64X2 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 128 bits of packed double-precision floating-point values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 1B /r ib VEXTRACTF32X8 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 256 bits of packed single-precision floating-point values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 1B /r ib VEXTRACTF64x4 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 256 bits of packed double-precision floating-point values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>#UD</td>, <td>IF VEX.L = 0.</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>VEX.256.66.0F3A.W0 19 /r ib VEXTRACTF128 xmm1/m128, ymm2, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Extract 128 bits of packed floating-point values from ymm2 and store results in xmm1/m128.</td>, <td>EVEX.256.66.0F3A.W0 19 /r ib VEXTRACTF32X4 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Extract 128 bits of packed single-precision floating-point values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 19 /r ib VEXTRACTF32x4 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 128 bits of packed single-precision floating-point values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 19 /r ib VEXTRACTF64X2 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Extract 128 bits of packed double-precision floating-point values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 19 /r ib VEXTRACTF64X2 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 128 bits of packed double-precision floating-point values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 1B /r ib VEXTRACTF32X8 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 256 bits of packed single-precision floating-point values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 1B /r ib VEXTRACTF64x4 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 256 bits of packed double-precision floating-point values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>#UD</td>, <td>IF VEX.L = 0.</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>VEX.256.66.0F3A.W0 19 /r ib VEXTRACTF128 xmm1/m128, ymm2, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Extract 128 bits of packed floating-point values from ymm2 and store results in xmm1/m128.</td>, <td>EVEX.256.66.0F3A.W0 19 /r ib VEXTRACTF32X4 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Extract 128 bits of packed single-precision floating-point values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 19 /r ib VEXTRACTF32x4 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 128 bits of packed single-precision floating-point values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 19 /r ib VEXTRACTF64X2 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Extract 128 bits of packed double-precision floating-point values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 19 /r ib VEXTRACTF64X2 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 128 bits of packed double-precision floating-point values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 1B /r ib VEXTRACTF32X8 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 256 bits of packed single-precision floating-point values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 1B /r ib VEXTRACTF64x4 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 256 bits of packed double-precision floating-point values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>#UD</td>, <td>IF VEX.L = 0.</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>VEX.256.66.0F3A.W0 19 /r ib VEXTRACTF128 xmm1/m128, ymm2, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Extract 128 bits of packed floating-point values from ymm2 and store results in xmm1/m128.</td>, <td>EVEX.256.66.0F3A.W0 19 /r ib VEXTRACTF32X4 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Extract 128 bits of packed single-precision floating-point values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 19 /r ib VEXTRACTF32x4 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 128 bits of packed single-precision floating-point values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 19 /r ib VEXTRACTF64X2 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Extract 128 bits of packed double-precision floating-point values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 19 /r ib VEXTRACTF64X2 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 128 bits of packed double-precision floating-point values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 1B /r ib VEXTRACTF32X8 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 256 bits of packed single-precision floating-point values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 1B /r ib VEXTRACTF64x4 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 256 bits of packed double-precision floating-point values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>#UD</td>, <td>IF VEX.L = 0.</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>VEX.256.66.0F3A.W0 39 /r ib VEXTRACTI128 xmm1/m128, ymm2, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Extract 128 bits of integer data from ymm2 and store results in xmm1/m128.</td>, <td>EVEX.256.66.0F3A.W0 39 /r ib VEXTRACTI32X4 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Extract 128 bits of double-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 39 /r ib VEXTRACTI32x4 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 128 bits of double-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 39 /r ib VEXTRACTI64X2 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Extract 128 bits of quad-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 39 /r ib VEXTRACTI64X2 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 128 bits of quad-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 3B /r ib VEXTRACTI32X8 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 256 bits of double-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 3B /r ib VEXTRACTI64x4 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 256 bits of quad-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>#UD</td>, <td>IF VEX.L = 0.</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>VEX.256.66.0F3A.W0 39 /r ib VEXTRACTI128 xmm1/m128, ymm2, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Extract 128 bits of integer data from ymm2 and store results in xmm1/m128.</td>, <td>EVEX.256.66.0F3A.W0 39 /r ib VEXTRACTI32X4 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Extract 128 bits of double-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 39 /r ib VEXTRACTI32x4 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 128 bits of double-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 39 /r ib VEXTRACTI64X2 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Extract 128 bits of quad-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 39 /r ib VEXTRACTI64X2 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 128 bits of quad-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 3B /r ib VEXTRACTI32X8 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 256 bits of double-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 3B /r ib VEXTRACTI64x4 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 256 bits of quad-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>#UD</td>, <td>IF VEX.L = 0.</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>VEX.256.66.0F3A.W0 39 /r ib VEXTRACTI128 xmm1/m128, ymm2, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Extract 128 bits of integer data from ymm2 and store results in xmm1/m128.</td>, <td>EVEX.256.66.0F3A.W0 39 /r ib VEXTRACTI32X4 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Extract 128 bits of double-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 39 /r ib VEXTRACTI32x4 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 128 bits of double-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 39 /r ib VEXTRACTI64X2 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Extract 128 bits of quad-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 39 /r ib VEXTRACTI64X2 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 128 bits of quad-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 3B /r ib VEXTRACTI32X8 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 256 bits of double-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 3B /r ib VEXTRACTI64x4 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 256 bits of quad-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>#UD</td>, <td>IF VEX.L = 0.</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>VEX.256.66.0F3A.W0 39 /r ib VEXTRACTI128 xmm1/m128, ymm2, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Extract 128 bits of integer data from ymm2 and store results in xmm1/m128.</td>, <td>EVEX.256.66.0F3A.W0 39 /r ib VEXTRACTI32X4 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Extract 128 bits of double-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 39 /r ib VEXTRACTI32x4 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 128 bits of double-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 39 /r ib VEXTRACTI64X2 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Extract 128 bits of quad-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 39 /r ib VEXTRACTI64X2 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 128 bits of quad-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 3B /r ib VEXTRACTI32X8 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 256 bits of double-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 3B /r ib VEXTRACTI64x4 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 256 bits of quad-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>#UD</td>, <td>IF VEX.L = 0.</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>VEX.256.66.0F3A.W0 39 /r ib VEXTRACTI128 xmm1/m128, ymm2, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Extract 128 bits of integer data from ymm2 and store results in xmm1/m128.</td>, <td>EVEX.256.66.0F3A.W0 39 /r ib VEXTRACTI32X4 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Extract 128 bits of double-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 39 /r ib VEXTRACTI32x4 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 128 bits of double-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 39 /r ib VEXTRACTI64X2 xmm1/m128 {k1}{z}, ymm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Extract 128 bits of quad-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 39 /r ib VEXTRACTI64X2 xmm1/m128 {k1}{z}, zmm2, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 128 bits of quad-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 3B /r ib VEXTRACTI32X8 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Extract 256 bits of double-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 3B /r ib VEXTRACTI64x4 ymm1/m256 {k1}{z}, zmm2, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract 256 bits of quad-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>#UD</td>, <td>IF VEX.L = 0.</td>, <td>#UD</td>, <td>If VEX.vvvv != 1111B or EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F3A.W1 54 /r ib VFIXUPIMMPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Fix up special numbers in float64 vector xmm1, float64 vector xmm2 and int64 vector xmm3/m128/m64bcst and store the result in xmm1, under writemask.</td>, <td>EVEX.256.66.0F3A.W1 54 /r ib VFIXUPIMMPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Fix up special numbers in float64 vector ymm1, float64 vector ymm2 and int64 vector ymm3/m256/m64bcst and store the result in ymm1, under writemask.</td>, <td>EVEX.512.66.0F3A.W1 54 /r ib VFIXUPIMMPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Fix up elements of float64 vector in zmm2 using int64 vector table in zmm3/m512/m64bcst, combine with preserved elements from zmm1, and store the result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>]

[<td>EVEX.128.66.0F3A.W0 54 /r VFIXUPIMMPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Fix up special numbers in float32 vector xmm1, float32 vector xmm2 and int32 vector xmm3/m128/m32bcst and store the result in xmm1, under writemask.</td>, <td>EVEX.256.66.0F3A.W0 54 /r VFIXUPIMMPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Fix up special numbers in float32 vector ymm1, float32 vector ymm2 and int32 vector ymm3/m256/m32bcst and store the result in ymm1, under writemask.</td>, <td>EVEX.512.66.0F3A.W0 54 /r ib VFIXUPIMMPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Fix up elements of float32 vector in zmm2 using int32 vector table in zmm3/m512/m32bcst, combine with preserved elements from zmm1, and store the result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>]

[<td>EVEX.LIG.66.0F3A.W1 55 /r ib VFIXUPIMMSD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Fix up a float64 number in the low quadword element of xmm2 using scalar int32 table in xmm3/m64 and store the result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>]

[<td>EVEX.LIG.66.0F3A.W0 55 /r ib VFIXUPIMMSS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Fix up a float32 number in the low doubleword element in xmm2 using scalar int32 table in xmm3/m32 and store the result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>]

[<td>VEX.128.66.0F38.W1 98 /r VFMADD132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, add to xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 A8 /r VFMADD213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, add to xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 B8 /r VFMADD231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, add to xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 98 /r VFMADD132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, add to ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 A8 /r VFMADD213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, add to ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 B8 /r VFMADD231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, add to ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W1 98 /r VFMADD132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, add to xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 A8 /r VFMADD213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, add to xmm3/m128/m64bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 B8 /r VFMADD231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, add to xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W1 98 /r VFMADD132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, add to ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 A8 /r VFMADD213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, add to ymm3/m256/m64bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 B8 /r VFMADD231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, add to ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W1 98 /r VFMADD132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, add to zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 A8 /r VFMADD213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm2, add to zmm3/m512/m64bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 B8 /r VFMADD231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, add to zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 98 /r VFMADD132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, add to xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 A8 /r VFMADD213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, add to xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 B8 /r VFMADD231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, add to xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 98 /r VFMADD132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, add to ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 A8 /r VFMADD213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, add to ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.0 B8 /r VFMADD231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, add to ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 98 /r VFMADD132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, add to xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 A8 /r VFMADD213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, add to xmm3/m128/m32bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 B8 /r VFMADD231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, add to xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W0 98 /r VFMADD132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, add to ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 A8 /r VFMADD213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, add to ymm3/m256/m32bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 B8 /r VFMADD231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, add to ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W0 98 /r VFMADD132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, add to zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 A8 /r VFMADD213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, add to zmm3/m512/m32bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 B8 /r VFMADD231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, add to zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W1 99 /r VFMADD132SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, add to xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 A9 /r VFMADD213SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, add to xmm3/m64 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 B9 /r VFMADD231SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, add to xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 99 /r VFMADD132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, add to xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 A9 /r VFMADD213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, add to xmm3/m64 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 B9 /r VFMADD231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, add to xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W0 99 /r VFMADD132SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, add to xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 A9 /r VFMADD213SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, add to xmm3/m32 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 B9 /r VFMADD231SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, add to xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 99 /r VFMADD132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, add to xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 A9 /r VFMADD213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, add to xmm3/m32 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 B9 /r VFMADD231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, add to xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 98 /r VFMADD132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, add to xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 A8 /r VFMADD213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, add to xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 B8 /r VFMADD231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, add to xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 98 /r VFMADD132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, add to ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 A8 /r VFMADD213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, add to ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 B8 /r VFMADD231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, add to ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W1 98 /r VFMADD132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, add to xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 A8 /r VFMADD213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, add to xmm3/m128/m64bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 B8 /r VFMADD231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, add to xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W1 98 /r VFMADD132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, add to ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 A8 /r VFMADD213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, add to ymm3/m256/m64bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 B8 /r VFMADD231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, add to ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W1 98 /r VFMADD132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, add to zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 A8 /r VFMADD213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm2, add to zmm3/m512/m64bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 B8 /r VFMADD231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, add to zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 98 /r VFMADD132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, add to xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 A8 /r VFMADD213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, add to xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 B8 /r VFMADD231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, add to xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 98 /r VFMADD132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, add to ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 A8 /r VFMADD213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, add to ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.0 B8 /r VFMADD231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, add to ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 98 /r VFMADD132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, add to xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 A8 /r VFMADD213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, add to xmm3/m128/m32bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 B8 /r VFMADD231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, add to xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W0 98 /r VFMADD132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, add to ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 A8 /r VFMADD213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, add to ymm3/m256/m32bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 B8 /r VFMADD231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, add to ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W0 98 /r VFMADD132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, add to zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 A8 /r VFMADD213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, add to zmm3/m512/m32bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 B8 /r VFMADD231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, add to zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W1 99 /r VFMADD132SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, add to xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 A9 /r VFMADD213SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, add to xmm3/m64 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 B9 /r VFMADD231SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, add to xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 99 /r VFMADD132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, add to xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 A9 /r VFMADD213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, add to xmm3/m64 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 B9 /r VFMADD231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, add to xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W0 99 /r VFMADD132SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, add to xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 A9 /r VFMADD213SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, add to xmm3/m32 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 B9 /r VFMADD231SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, add to xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 99 /r VFMADD132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, add to xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 A9 /r VFMADD213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, add to xmm3/m32 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 B9 /r VFMADD231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, add to xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 98 /r VFMADD132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, add to xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 A8 /r VFMADD213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, add to xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 B8 /r VFMADD231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, add to xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 98 /r VFMADD132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, add to ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 A8 /r VFMADD213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, add to ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 B8 /r VFMADD231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, add to ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W1 98 /r VFMADD132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, add to xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 A8 /r VFMADD213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, add to xmm3/m128/m64bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 B8 /r VFMADD231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, add to xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W1 98 /r VFMADD132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, add to ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 A8 /r VFMADD213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, add to ymm3/m256/m64bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 B8 /r VFMADD231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, add to ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W1 98 /r VFMADD132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, add to zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 A8 /r VFMADD213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm2, add to zmm3/m512/m64bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 B8 /r VFMADD231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, add to zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 98 /r VFMADD132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, add to xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 A8 /r VFMADD213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, add to xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 B8 /r VFMADD231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, add to xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 98 /r VFMADD132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, add to ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 A8 /r VFMADD213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, add to ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.0 B8 /r VFMADD231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, add to ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 98 /r VFMADD132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, add to xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 A8 /r VFMADD213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, add to xmm3/m128/m32bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 B8 /r VFMADD231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, add to xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W0 98 /r VFMADD132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, add to ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 A8 /r VFMADD213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, add to ymm3/m256/m32bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 B8 /r VFMADD231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, add to ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W0 98 /r VFMADD132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, add to zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 A8 /r VFMADD213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, add to zmm3/m512/m32bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 B8 /r VFMADD231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, add to zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W1 99 /r VFMADD132SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, add to xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 A9 /r VFMADD213SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, add to xmm3/m64 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 B9 /r VFMADD231SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, add to xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 99 /r VFMADD132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, add to xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 A9 /r VFMADD213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, add to xmm3/m64 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 B9 /r VFMADD231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, add to xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W0 99 /r VFMADD132SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, add to xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 A9 /r VFMADD213SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, add to xmm3/m32 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 B9 /r VFMADD231SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, add to xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 99 /r VFMADD132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, add to xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 A9 /r VFMADD213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, add to xmm3/m32 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 B9 /r VFMADD231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, add to xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 96 /r VFMADDSUB132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, add/subtract elements in xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 A6 /r VFMADDSUB213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, add/subtract elements in xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 B6 /r VFMADDSUB231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, add/subtract elements in xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 96 /r VFMADDSUB132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, add/subtract elements in ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 A6 /r VFMADDSUB213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, add/subtract elements in ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 B6 /r VFMADDSUB231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, add/subtract elements in ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W1 A6 /r VFMADDSUB213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, add/subtract elements in xmm3/m128/m64bcst and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 B6 /r VFMADDSUB231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, add/subtract elements in xmm1 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 96 /r VFMADDSUB132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, add/subtract elements in xmm2 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A6 /r VFMADDSUB213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, add/subtract elements in ymm3/m256/m64bcst and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 B6 /r VFMADDSUB231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, add/subtract elements in ymm1 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 96 /r VFMADDSUB132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, add/subtract elements in ymm2 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A6 /r VFMADDSUB213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1and zmm2, add/subtract elements in zmm3/m512/m64bcst and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 B6 /r VFMADDSUB231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, add/subtract elements in zmm1 and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 96 /r VFMADDSUB132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, add/subtract elements in zmm2 and put result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 96 /r VFMADDSUB132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, add/subtract elements in xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 A6 /r VFMADDSUB213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, add/subtract elements in xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 B6 /r VFMADDSUB231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, add/subtract elements in xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 96 /r VFMADDSUB132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, add/subtract elements in ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 A6 /r VFMADDSUB213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, add/subtract elements in ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 B6 /r VFMADDSUB231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, add/subtract elements in ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 A6 /r VFMADDSUB213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, add/subtract elements in xmm3/m128/m32bcst and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 B6 /r VFMADDSUB231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, add/subtract elements in xmm1 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 96 /r VFMADDSUB132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, add/subtract elements in zmm2 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A6 /r VFMADDSUB213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, add/subtract elements in ymm3/m256/m32bcst and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 B6 /r VFMADDSUB231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, add/subtract elements in ymm1 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 96 /r VFMADDSUB132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, add/subtract elements in ymm2 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A6 /r VFMADDSUB213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, add/subtract elements in zmm3/m512/m32bcst and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 B6 /r VFMADDSUB231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, add/subtract elements in zmm1 and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 96 /r VFMADDSUB132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, add/subtract elements in zmm2 and put result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 96 /r VFMADDSUB132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, add/subtract elements in xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 A6 /r VFMADDSUB213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, add/subtract elements in xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 B6 /r VFMADDSUB231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, add/subtract elements in xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 96 /r VFMADDSUB132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, add/subtract elements in ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 A6 /r VFMADDSUB213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, add/subtract elements in ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 B6 /r VFMADDSUB231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, add/subtract elements in ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W1 A6 /r VFMADDSUB213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, add/subtract elements in xmm3/m128/m64bcst and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 B6 /r VFMADDSUB231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, add/subtract elements in xmm1 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 96 /r VFMADDSUB132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, add/subtract elements in xmm2 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A6 /r VFMADDSUB213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, add/subtract elements in ymm3/m256/m64bcst and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 B6 /r VFMADDSUB231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, add/subtract elements in ymm1 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 96 /r VFMADDSUB132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, add/subtract elements in ymm2 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A6 /r VFMADDSUB213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1and zmm2, add/subtract elements in zmm3/m512/m64bcst and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 B6 /r VFMADDSUB231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, add/subtract elements in zmm1 and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 96 /r VFMADDSUB132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, add/subtract elements in zmm2 and put result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 96 /r VFMADDSUB132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, add/subtract elements in xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 A6 /r VFMADDSUB213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, add/subtract elements in xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 B6 /r VFMADDSUB231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, add/subtract elements in xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 96 /r VFMADDSUB132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, add/subtract elements in ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 A6 /r VFMADDSUB213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, add/subtract elements in ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 B6 /r VFMADDSUB231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, add/subtract elements in ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 A6 /r VFMADDSUB213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, add/subtract elements in xmm3/m128/m32bcst and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 B6 /r VFMADDSUB231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, add/subtract elements in xmm1 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 96 /r VFMADDSUB132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, add/subtract elements in zmm2 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A6 /r VFMADDSUB213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, add/subtract elements in ymm3/m256/m32bcst and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 B6 /r VFMADDSUB231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, add/subtract elements in ymm1 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 96 /r VFMADDSUB132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, add/subtract elements in ymm2 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A6 /r VFMADDSUB213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, add/subtract elements in zmm3/m512/m32bcst and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 B6 /r VFMADDSUB231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, add/subtract elements in zmm1 and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 96 /r VFMADDSUB132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, add/subtract elements in zmm2 and put result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 96 /r VFMADDSUB132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, add/subtract elements in xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 A6 /r VFMADDSUB213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, add/subtract elements in xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 B6 /r VFMADDSUB231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, add/subtract elements in xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 96 /r VFMADDSUB132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, add/subtract elements in ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 A6 /r VFMADDSUB213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, add/subtract elements in ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 B6 /r VFMADDSUB231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, add/subtract elements in ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W1 A6 /r VFMADDSUB213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, add/subtract elements in xmm3/m128/m64bcst and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 B6 /r VFMADDSUB231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, add/subtract elements in xmm1 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 96 /r VFMADDSUB132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, add/subtract elements in xmm2 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A6 /r VFMADDSUB213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, add/subtract elements in ymm3/m256/m64bcst and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 B6 /r VFMADDSUB231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, add/subtract elements in ymm1 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 96 /r VFMADDSUB132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, add/subtract elements in ymm2 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A6 /r VFMADDSUB213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1and zmm2, add/subtract elements in zmm3/m512/m64bcst and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 B6 /r VFMADDSUB231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, add/subtract elements in zmm1 and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 96 /r VFMADDSUB132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, add/subtract elements in zmm2 and put result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 96 /r VFMADDSUB132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, add/subtract elements in xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 A6 /r VFMADDSUB213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, add/subtract elements in xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 B6 /r VFMADDSUB231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, add/subtract elements in xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 96 /r VFMADDSUB132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, add/subtract elements in ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 A6 /r VFMADDSUB213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, add/subtract elements in ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 B6 /r VFMADDSUB231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, add/subtract elements in ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 A6 /r VFMADDSUB213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, add/subtract elements in xmm3/m128/m32bcst and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 B6 /r VFMADDSUB231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, add/subtract elements in xmm1 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 96 /r VFMADDSUB132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, add/subtract elements in zmm2 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A6 /r VFMADDSUB213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, add/subtract elements in ymm3/m256/m32bcst and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 B6 /r VFMADDSUB231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, add/subtract elements in ymm1 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 96 /r VFMADDSUB132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, add/subtract elements in ymm2 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A6 /r VFMADDSUB213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, add/subtract elements in zmm3/m512/m32bcst and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 B6 /r VFMADDSUB231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, add/subtract elements in zmm1 and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 96 /r VFMADDSUB132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, add/subtract elements in zmm2 and put result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 9A /r VFMSUB132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, subtract xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 AA /r VFMSUB213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, subtract xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 BA /r VFMSUB231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, subtract xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 9A /r VFMSUB132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, subtract ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 AA /r VFMSUB213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, subtract ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 BA /r VFMSUB231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, subtract ymm1 and put result in ymm1.S</td>, <td>EVEX.128.66.0F38.W1 9A /r VFMSUB132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, subtract xmm2 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 AA /r VFMSUB213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, subtract xmm3/m128/m64bcst and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 BA /r VFMSUB231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, subtract xmm1 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 9A /r VFMSUB132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, subtract ymm2 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 AA /r VFMSUB213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, subtract ymm3/m256/m64bcst and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 BA /r VFMSUB231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, subtract ymm1 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 9A /r VFMSUB132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, subtract zmm2 and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 AA /r VFMSUB213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm2, subtract zmm3/m512/m64bcst and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 BA /r VFMSUB231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, subtract zmm1 and put result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 9A /r VFMSUB132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, subtract xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 AA /r VFMSUB213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, subtract xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 BA /r VFMSUB231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, subtract xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 9A /r VFMSUB132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, subtract ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 AA /r VFMSUB213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, subtract ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.0 BA /r VFMSUB231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, subtract ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 9A /r VFMSUB132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, subtract xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 AA /r VFMSUB213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, subtract xmm3/m128/m32bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 BA /r VFMSUB231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, subtract xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W0 9A /r VFMSUB132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, subtract ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 AA /r VFMSUB213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, subtract ymm3/m256/m32bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 BA /r VFMSUB231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, subtract ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W0 9A /r VFMSUB132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, subtract zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 AA /r VFMSUB213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, subtract zmm3/m512/m32bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 BA /r VFMSUB231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, subtract zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W1 9B /r VFMSUB132SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, subtract xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 AB /r VFMSUB213SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, subtract xmm3/m64 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 BB /r VFMSUB231SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, subtract xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 9B /r VFMSUB132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, subtract xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 AB /r VFMSUB213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, subtract xmm3/m64 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 BB /r VFMSUB231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, subtract xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W0 9B /r VFMSUB132SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, subtract xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 AB /r VFMSUB213SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, subtract xmm3/m32 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 BB /r VFMSUB231SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, subtract xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 9B /r VFMSUB132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, subtract xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 AB /r VFMSUB213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, subtract xmm3/m32 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 BB /r VFMSUB231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, subtract xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 9A /r VFMSUB132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, subtract xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 AA /r VFMSUB213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, subtract xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 BA /r VFMSUB231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, subtract xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 9A /r VFMSUB132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, subtract ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 AA /r VFMSUB213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, subtract ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 BA /r VFMSUB231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, subtract ymm1 and put result in ymm1.S</td>, <td>EVEX.128.66.0F38.W1 9A /r VFMSUB132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, subtract xmm2 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 AA /r VFMSUB213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, subtract xmm3/m128/m64bcst and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 BA /r VFMSUB231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, subtract xmm1 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 9A /r VFMSUB132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, subtract ymm2 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 AA /r VFMSUB213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, subtract ymm3/m256/m64bcst and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 BA /r VFMSUB231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, subtract ymm1 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 9A /r VFMSUB132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, subtract zmm2 and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 AA /r VFMSUB213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm2, subtract zmm3/m512/m64bcst and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 BA /r VFMSUB231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, subtract zmm1 and put result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 9A /r VFMSUB132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, subtract xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 AA /r VFMSUB213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, subtract xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 BA /r VFMSUB231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, subtract xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 9A /r VFMSUB132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, subtract ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 AA /r VFMSUB213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, subtract ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.0 BA /r VFMSUB231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, subtract ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 9A /r VFMSUB132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, subtract xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 AA /r VFMSUB213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, subtract xmm3/m128/m32bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 BA /r VFMSUB231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, subtract xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W0 9A /r VFMSUB132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, subtract ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 AA /r VFMSUB213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, subtract ymm3/m256/m32bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 BA /r VFMSUB231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, subtract ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W0 9A /r VFMSUB132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, subtract zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 AA /r VFMSUB213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, subtract zmm3/m512/m32bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 BA /r VFMSUB231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, subtract zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W1 9B /r VFMSUB132SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, subtract xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 AB /r VFMSUB213SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, subtract xmm3/m64 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 BB /r VFMSUB231SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, subtract xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 9B /r VFMSUB132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, subtract xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 AB /r VFMSUB213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, subtract xmm3/m64 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 BB /r VFMSUB231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, subtract xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W0 9B /r VFMSUB132SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, subtract xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 AB /r VFMSUB213SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, subtract xmm3/m32 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 BB /r VFMSUB231SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, subtract xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 9B /r VFMSUB132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, subtract xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 AB /r VFMSUB213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, subtract xmm3/m32 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 BB /r VFMSUB231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, subtract xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 9A /r VFMSUB132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, subtract xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 AA /r VFMSUB213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, subtract xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 BA /r VFMSUB231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, subtract xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 9A /r VFMSUB132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, subtract ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 AA /r VFMSUB213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, subtract ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 BA /r VFMSUB231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, subtract ymm1 and put result in ymm1.S</td>, <td>EVEX.128.66.0F38.W1 9A /r VFMSUB132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, subtract xmm2 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 AA /r VFMSUB213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, subtract xmm3/m128/m64bcst and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 BA /r VFMSUB231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, subtract xmm1 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 9A /r VFMSUB132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, subtract ymm2 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 AA /r VFMSUB213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, subtract ymm3/m256/m64bcst and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 BA /r VFMSUB231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, subtract ymm1 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 9A /r VFMSUB132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, subtract zmm2 and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 AA /r VFMSUB213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm2, subtract zmm3/m512/m64bcst and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 BA /r VFMSUB231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, subtract zmm1 and put result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 9A /r VFMSUB132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, subtract xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 AA /r VFMSUB213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, subtract xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 BA /r VFMSUB231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, subtract xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 9A /r VFMSUB132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, subtract ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 AA /r VFMSUB213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, subtract ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.0 BA /r VFMSUB231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, subtract ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 9A /r VFMSUB132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, subtract xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 AA /r VFMSUB213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, subtract xmm3/m128/m32bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 BA /r VFMSUB231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, subtract xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W0 9A /r VFMSUB132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, subtract ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 AA /r VFMSUB213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, subtract ymm3/m256/m32bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 BA /r VFMSUB231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, subtract ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W0 9A /r VFMSUB132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, subtract zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 AA /r VFMSUB213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, subtract zmm3/m512/m32bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 BA /r VFMSUB231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, subtract zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W1 9B /r VFMSUB132SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, subtract xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 AB /r VFMSUB213SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, subtract xmm3/m64 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 BB /r VFMSUB231SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, subtract xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 9B /r VFMSUB132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, subtract xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 AB /r VFMSUB213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, subtract xmm3/m64 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 BB /r VFMSUB231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, subtract xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W0 9B /r VFMSUB132SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, subtract xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 AB /r VFMSUB213SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, subtract xmm3/m32 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 BB /r VFMSUB231SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, subtract xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 9B /r VFMSUB132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, subtract xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 AB /r VFMSUB213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, subtract xmm3/m32 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 BB /r VFMSUB231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, subtract xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 97 /r VFMSUBADD132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, subtract/add elements in xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 A7 /r VFMSUBADD213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, subtract/add elements in xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 B7 /r VFMSUBADD231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, subtract/add elements in xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 97 /r VFMSUBADD132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, subtract/add elements in ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 A7 /r VFMSUBADD213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, subtract/add elements in ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 B7 /r VFMSUBADD231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, subtract/add elements in ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W1 97 /r VFMSUBADD132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, subtract/add elements in xmm2 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A7 /r VFMSUBADD213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, subtract/add elements in xmm3/m128/m64bcst and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 B7 /r VFMSUBADD231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, subtract/add elements in xmm1 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 97 /r VFMSUBADD132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, subtract/add elements in ymm2 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A7 /r VFMSUBADD213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, subtract/add elements in ymm3/m256/m64bcst and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 B7 /r VFMSUBADD231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, subtract/add elements in ymm1 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 97 /r VFMSUBADD132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, subtract/add elements in zmm2 and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A7 /r VFMSUBADD213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm2, subtract/add elements in zmm3/m512/m64bcst and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 B7 /r VFMSUBADD231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, subtract/add elements in zmm1 and put result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 97 /r VFMSUBADD132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, subtract/add elements in xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 A7 /r VFMSUBADD213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, subtract/add elements in xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 B7 /r VFMSUBADD231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, subtract/add elements in xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 97 /r VFMSUBADD132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, subtract/add elements in ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 A7 /r VFMSUBADD213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, subtract/add elements in ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 B7 /r VFMSUBADD231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, subtract/add elements in ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 97 /r VFMSUBADD132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, subtract/add elements in xmm2 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 A7 /r VFMSUBADD213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, subtract/add elements in xmm3/m128/m32bcst and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 B7 /r VFMSUBADD231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, subtract/add elements in xmm1 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 97 /r VFMSUBADD132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, subtract/add elements in ymm2 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A7 /r VFMSUBADD213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, subtract/add elements in ymm3/m256/m32bcst and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 B7 /r VFMSUBADD231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, subtract/add elements in ymm1 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 97 /r VFMSUBADD132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, subtract/add elements in zmm2 and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A7 /r VFMSUBADD213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, subtract/add elements in zmm3/m512/m32bcst and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 B7 /r VFMSUBADD231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, subtract/add elements in zmm1 and put result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 97 /r VFMSUBADD132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, subtract/add elements in xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 A7 /r VFMSUBADD213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, subtract/add elements in xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 B7 /r VFMSUBADD231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, subtract/add elements in xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 97 /r VFMSUBADD132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, subtract/add elements in ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 A7 /r VFMSUBADD213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, subtract/add elements in ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 B7 /r VFMSUBADD231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, subtract/add elements in ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W1 97 /r VFMSUBADD132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, subtract/add elements in xmm2 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A7 /r VFMSUBADD213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, subtract/add elements in xmm3/m128/m64bcst and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 B7 /r VFMSUBADD231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, subtract/add elements in xmm1 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 97 /r VFMSUBADD132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, subtract/add elements in ymm2 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A7 /r VFMSUBADD213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, subtract/add elements in ymm3/m256/m64bcst and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 B7 /r VFMSUBADD231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, subtract/add elements in ymm1 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 97 /r VFMSUBADD132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, subtract/add elements in zmm2 and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A7 /r VFMSUBADD213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm2, subtract/add elements in zmm3/m512/m64bcst and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 B7 /r VFMSUBADD231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, subtract/add elements in zmm1 and put result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 97 /r VFMSUBADD132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, subtract/add elements in xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 A7 /r VFMSUBADD213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, subtract/add elements in xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 B7 /r VFMSUBADD231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, subtract/add elements in xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 97 /r VFMSUBADD132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, subtract/add elements in ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 A7 /r VFMSUBADD213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, subtract/add elements in ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 B7 /r VFMSUBADD231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, subtract/add elements in ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 97 /r VFMSUBADD132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, subtract/add elements in xmm2 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 A7 /r VFMSUBADD213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, subtract/add elements in xmm3/m128/m32bcst and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 B7 /r VFMSUBADD231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, subtract/add elements in xmm1 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 97 /r VFMSUBADD132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, subtract/add elements in ymm2 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A7 /r VFMSUBADD213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, subtract/add elements in ymm3/m256/m32bcst and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 B7 /r VFMSUBADD231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, subtract/add elements in ymm1 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 97 /r VFMSUBADD132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, subtract/add elements in zmm2 and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A7 /r VFMSUBADD213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, subtract/add elements in zmm3/m512/m32bcst and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 B7 /r VFMSUBADD231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, subtract/add elements in zmm1 and put result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 97 /r VFMSUBADD132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, subtract/add elements in xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 A7 /r VFMSUBADD213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, subtract/add elements in xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 B7 /r VFMSUBADD231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, subtract/add elements in xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 97 /r VFMSUBADD132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, subtract/add elements in ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 A7 /r VFMSUBADD213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, subtract/add elements in ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 B7 /r VFMSUBADD231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, subtract/add elements in ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W1 97 /r VFMSUBADD132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, subtract/add elements in xmm2 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A7 /r VFMSUBADD213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, subtract/add elements in xmm3/m128/m64bcst and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 B7 /r VFMSUBADD231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, subtract/add elements in xmm1 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 97 /r VFMSUBADD132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, subtract/add elements in ymm2 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A7 /r VFMSUBADD213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, subtract/add elements in ymm3/m256/m64bcst and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 B7 /r VFMSUBADD231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, subtract/add elements in ymm1 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 97 /r VFMSUBADD132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, subtract/add elements in zmm2 and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A7 /r VFMSUBADD213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm2, subtract/add elements in zmm3/m512/m64bcst and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 B7 /r VFMSUBADD231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, subtract/add elements in zmm1 and put result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 97 /r VFMSUBADD132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, subtract/add elements in xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 A7 /r VFMSUBADD213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, subtract/add elements in xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 B7 /r VFMSUBADD231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, subtract/add elements in xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 97 /r VFMSUBADD132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, subtract/add elements in ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 A7 /r VFMSUBADD213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, subtract/add elements in ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 B7 /r VFMSUBADD231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, subtract/add elements in ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 97 /r VFMSUBADD132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, subtract/add elements in xmm2 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 A7 /r VFMSUBADD213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, subtract/add elements in xmm3/m128/m32bcst and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 B7 /r VFMSUBADD231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, subtract/add elements in xmm1 and put result in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 97 /r VFMSUBADD132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, subtract/add elements in ymm2 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A7 /r VFMSUBADD213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, subtract/add elements in ymm3/m256/m32bcst and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 B7 /r VFMSUBADD231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, subtract/add elements in ymm1 and put result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 97 /r VFMSUBADD132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, subtract/add elements in zmm2 and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A7 /r VFMSUBADD213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, subtract/add elements in zmm3/m512/m32bcst and put result in zmm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 B7 /r VFMSUBADD231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, subtract/add elements in zmm1 and put result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 9C /r VFNMADD132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 AC /r VFNMADD213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, negate the multiplication result and add to xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 BC /r VFNMADD231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 9C /r VFNMADD132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, negate the multiplication result and add to ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 AC /r VFNMADD213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, negate the multiplication result and add to ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 BC /r VFNMADD231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, negate the multiplication result and add to ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W1 9C /r VFNMADD132PD xmm0 {k1}{z}, xmm1, xmm2/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 AC /r VFNMADD213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, negate the multiplication result and add to xmm3/m128/m64bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 BC /r VFNMADD231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W1 9C /r VFNMADD132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, negate the multiplication result and add to ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 AC /r VFNMADD213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, negate the multiplication result and add to ymm3/m256/m64bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 BC /r VFNMADD231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, negate the multiplication result and add to ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W1 9C /r VFNMADD132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, negate the multiplication result and add to zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 AC /r VFNMADD213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm2, negate the multiplication result and add to zmm3/m512/m64bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 BC /r VFNMADD231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, negate the multiplication result and add to zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 9C /r VFNMADD132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 AC /r VFNMADD213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, negate the multiplication result and add to xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 BC /r VFNMADD231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 9C /r VFNMADD132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, negate the multiplication result and add to ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 AC /r VFNMADD213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, negate the multiplication result and add to ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.0 BC /r VFNMADD231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, negate the multiplication result and add to ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 9C /r VFNMADD132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 AC /r VFNMADD213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, negate the multiplication result and add to xmm3/m128/m32bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 BC /r VFNMADD231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W0 9C /r VFNMADD132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, negate the multiplication result and add to ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 AC /r VFNMADD213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, negate the multiplication result and add to ymm3/m256/m32bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 BC /r VFNMADD231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, negate the multiplication result and add to ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W0 9C /r VFNMADD132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, negate the multiplication result and add to zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 AC /r VFNMADD213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, negate the multiplication result and add to zmm3/m512/m32bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 BC /r VFNMADD231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, negate the multiplication result and add to zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W1 9D /r VFNMADD132SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/mem, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 AD /r VFNMADD213SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/mem and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 BD /r VFNMADD231SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/mem, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 9D /r VFNMADD132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 AD /r VFNMADD213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/m64 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 BD /r VFNMADD231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W0 9D /r VFNMADD132SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 AD /r VFNMADD213SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/m32 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 BD /r VFNMADD231SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 9D /r VFNMADD132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 AD /r VFNMADD213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/m32 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 BD /r VFNMADD231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 9C /r VFNMADD132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 AC /r VFNMADD213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, negate the multiplication result and add to xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 BC /r VFNMADD231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 9C /r VFNMADD132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, negate the multiplication result and add to ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 AC /r VFNMADD213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, negate the multiplication result and add to ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 BC /r VFNMADD231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, negate the multiplication result and add to ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W1 9C /r VFNMADD132PD xmm0 {k1}{z}, xmm1, xmm2/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 AC /r VFNMADD213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, negate the multiplication result and add to xmm3/m128/m64bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 BC /r VFNMADD231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W1 9C /r VFNMADD132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, negate the multiplication result and add to ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 AC /r VFNMADD213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, negate the multiplication result and add to ymm3/m256/m64bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 BC /r VFNMADD231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, negate the multiplication result and add to ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W1 9C /r VFNMADD132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, negate the multiplication result and add to zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 AC /r VFNMADD213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm2, negate the multiplication result and add to zmm3/m512/m64bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 BC /r VFNMADD231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, negate the multiplication result and add to zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 9C /r VFNMADD132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 AC /r VFNMADD213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, negate the multiplication result and add to xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 BC /r VFNMADD231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 9C /r VFNMADD132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, negate the multiplication result and add to ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 AC /r VFNMADD213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, negate the multiplication result and add to ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.0 BC /r VFNMADD231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, negate the multiplication result and add to ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 9C /r VFNMADD132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 AC /r VFNMADD213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, negate the multiplication result and add to xmm3/m128/m32bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 BC /r VFNMADD231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W0 9C /r VFNMADD132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, negate the multiplication result and add to ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 AC /r VFNMADD213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, negate the multiplication result and add to ymm3/m256/m32bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 BC /r VFNMADD231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, negate the multiplication result and add to ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W0 9C /r VFNMADD132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, negate the multiplication result and add to zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 AC /r VFNMADD213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, negate the multiplication result and add to zmm3/m512/m32bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 BC /r VFNMADD231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, negate the multiplication result and add to zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W1 9D /r VFNMADD132SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/mem, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 AD /r VFNMADD213SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/mem and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 BD /r VFNMADD231SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/mem, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 9D /r VFNMADD132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 AD /r VFNMADD213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/m64 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 BD /r VFNMADD231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W0 9D /r VFNMADD132SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 AD /r VFNMADD213SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/m32 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 BD /r VFNMADD231SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 9D /r VFNMADD132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 AD /r VFNMADD213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/m32 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 BD /r VFNMADD231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 9C /r VFNMADD132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 AC /r VFNMADD213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, negate the multiplication result and add to xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 BC /r VFNMADD231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 9C /r VFNMADD132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, negate the multiplication result and add to ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 AC /r VFNMADD213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, negate the multiplication result and add to ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 BC /r VFNMADD231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, negate the multiplication result and add to ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W1 9C /r VFNMADD132PD xmm0 {k1}{z}, xmm1, xmm2/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 AC /r VFNMADD213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, negate the multiplication result and add to xmm3/m128/m64bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 BC /r VFNMADD231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W1 9C /r VFNMADD132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, negate the multiplication result and add to ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 AC /r VFNMADD213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, negate the multiplication result and add to ymm3/m256/m64bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 BC /r VFNMADD231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, negate the multiplication result and add to ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W1 9C /r VFNMADD132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, negate the multiplication result and add to zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 AC /r VFNMADD213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm2, negate the multiplication result and add to zmm3/m512/m64bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 BC /r VFNMADD231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, negate the multiplication result and add to zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 9C /r VFNMADD132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 AC /r VFNMADD213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, negate the multiplication result and add to xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 BC /r VFNMADD231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 9C /r VFNMADD132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, negate the multiplication result and add to ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 AC /r VFNMADD213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, negate the multiplication result and add to ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.0 BC /r VFNMADD231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, negate the multiplication result and add to ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 9C /r VFNMADD132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 AC /r VFNMADD213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, negate the multiplication result and add to xmm3/m128/m32bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 BC /r VFNMADD231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W0 9C /r VFNMADD132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, negate the multiplication result and add to ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 AC /r VFNMADD213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, negate the multiplication result and add to ymm3/m256/m32bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 BC /r VFNMADD231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, negate the multiplication result and add to ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W0 9C /r VFNMADD132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, negate the multiplication result and add to zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 AC /r VFNMADD213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, negate the multiplication result and add to zmm3/m512/m32bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 BC /r VFNMADD231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, negate the multiplication result and add to zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W1 9D /r VFNMADD132SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/mem, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 AD /r VFNMADD213SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/mem and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 BD /r VFNMADD231SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/mem, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 9D /r VFNMADD132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 AD /r VFNMADD213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/m64 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 BD /r VFNMADD231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W0 9D /r VFNMADD132SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 AD /r VFNMADD213SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/m32 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 BD /r VFNMADD231SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 9D /r VFNMADD132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and add to xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 AD /r VFNMADD213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/m32 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 BD /r VFNMADD231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and add to xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 9E /r VFNMSUB132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 AE /r VFNMSUB213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, negate the multiplication result and subtract xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 BE /r VFNMSUB231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 9E /r VFNMSUB132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, negate the multiplication result and subtract ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 AE /r VFNMSUB213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, negate the multiplication result and subtract ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 BE /r VFNMSUB231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, negate the multiplication result and subtract ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W1 9E /r VFNMSUB132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 AE /r VFNMSUB213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m128/m64bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 BE /r VFNMSUB231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W1 9E /r VFNMSUB132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, negate the multiplication result and subtract ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 AE /r VFNMSUB213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, negate the multiplication result and subtract ymm3/m256/m64bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 BE /r VFNMSUB231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, negate the multiplication result and subtract ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W1 9E /r VFNMSUB132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, negate the multiplication result and subtract zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 AE /r VFNMSUB213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm2, negate the multiplication result and subtract zmm3/m512/m64bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 BE /r VFNMSUB231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, negate the multiplication result and subtract zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 9E /r VFNMSUB132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 AE /r VFNMSUB213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, negate the multiplication result and subtract xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 BE /r VFNMSUB231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 9E /r VFNMSUB132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, negate the multiplication result and subtract ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 AE /r VFNMSUB213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, negate the multiplication result and subtract ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.0 BE /r VFNMSUB231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, negate the multiplication result and subtract ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 9E /r VFNMSUB132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 AE /r VFNMSUB213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m128/m32bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 BE /r VFNMSUB231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, negate the multiplication result subtract add to xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W0 9E /r VFNMSUB132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, negate the multiplication result and subtract ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 AE /r VFNMSUB213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, negate the multiplication result and subtract ymm3/m256/m32bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 BE /r VFNMSUB231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, negate the multiplication result subtract add to ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W0 9E /r VFNMSUB132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, negate the multiplication result and subtract zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 AE /r VFNMSUB213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, negate the multiplication result and subtract zmm3/m512/m32bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 BE /r VFNMSUB231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, negate the multiplication result subtract add to zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W1 9F /r VFNMSUB132SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/mem, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 AF /r VFNMSUB213SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/mem and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 BF /r VFNMSUB231SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/mem, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 9F /r VFNMSUB132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 AF /r VFNMSUB213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m64 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 BF /r VFNMSUB231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W0 9F /r VFNMSUB132SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 AF /r VFNMSUB213SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m32 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 BF /r VFNMSUB231SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 9F /r VFNMSUB132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 AF /r VFNMSUB213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m32 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 BF /r VFNMSUB231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 9E /r VFNMSUB132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 AE /r VFNMSUB213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, negate the multiplication result and subtract xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 BE /r VFNMSUB231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 9E /r VFNMSUB132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, negate the multiplication result and subtract ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 AE /r VFNMSUB213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, negate the multiplication result and subtract ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 BE /r VFNMSUB231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, negate the multiplication result and subtract ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W1 9E /r VFNMSUB132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 AE /r VFNMSUB213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m128/m64bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 BE /r VFNMSUB231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W1 9E /r VFNMSUB132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, negate the multiplication result and subtract ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 AE /r VFNMSUB213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, negate the multiplication result and subtract ymm3/m256/m64bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 BE /r VFNMSUB231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, negate the multiplication result and subtract ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W1 9E /r VFNMSUB132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, negate the multiplication result and subtract zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 AE /r VFNMSUB213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm2, negate the multiplication result and subtract zmm3/m512/m64bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 BE /r VFNMSUB231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, negate the multiplication result and subtract zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 9E /r VFNMSUB132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 AE /r VFNMSUB213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, negate the multiplication result and subtract xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 BE /r VFNMSUB231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 9E /r VFNMSUB132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, negate the multiplication result and subtract ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 AE /r VFNMSUB213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, negate the multiplication result and subtract ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.0 BE /r VFNMSUB231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, negate the multiplication result and subtract ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 9E /r VFNMSUB132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 AE /r VFNMSUB213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m128/m32bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 BE /r VFNMSUB231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, negate the multiplication result subtract add to xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W0 9E /r VFNMSUB132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, negate the multiplication result and subtract ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 AE /r VFNMSUB213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, negate the multiplication result and subtract ymm3/m256/m32bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 BE /r VFNMSUB231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, negate the multiplication result subtract add to ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W0 9E /r VFNMSUB132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, negate the multiplication result and subtract zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 AE /r VFNMSUB213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, negate the multiplication result and subtract zmm3/m512/m32bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 BE /r VFNMSUB231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, negate the multiplication result subtract add to zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W1 9F /r VFNMSUB132SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/mem, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 AF /r VFNMSUB213SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/mem and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 BF /r VFNMSUB231SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/mem, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 9F /r VFNMSUB132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 AF /r VFNMSUB213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m64 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 BF /r VFNMSUB231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W0 9F /r VFNMSUB132SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 AF /r VFNMSUB213SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m32 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 BF /r VFNMSUB231SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 9F /r VFNMSUB132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 AF /r VFNMSUB213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m32 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 BF /r VFNMSUB231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 9E /r VFNMSUB132PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/mem, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 AE /r VFNMSUB213PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, negate the multiplication result and subtract xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W1 BE /r VFNMSUB231PD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/mem, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W1 9E /r VFNMSUB132PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/mem, negate the multiplication result and subtract ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 AE /r VFNMSUB213PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, negate the multiplication result and subtract ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.W1 BE /r VFNMSUB231PD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/mem, negate the multiplication result and subtract ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W1 9E /r VFNMSUB132PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm3/m128/m64bcst, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 AE /r VFNMSUB213PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m128/m64bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W1 BE /r VFNMSUB231PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from xmm2 and xmm3/m128/m64bcst, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W1 9E /r VFNMSUB132PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm3/m256/m64bcst, negate the multiplication result and subtract ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 AE /r VFNMSUB213PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm1 and ymm2, negate the multiplication result and subtract ymm3/m256/m64bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W1 BE /r VFNMSUB231PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed double-precision floating-point values from ymm2 and ymm3/m256/m64bcst, negate the multiplication result and subtract ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W1 9E /r VFNMSUB132PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, negate the multiplication result and subtract zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 AE /r VFNMSUB213PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm1 and zmm2, negate the multiplication result and subtract zmm3/m512/m64bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W1 BE /r VFNMSUB231PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, negate the multiplication result and subtract zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 9E /r VFNMSUB132PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/mem, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 AE /r VFNMSUB213PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, negate the multiplication result and subtract xmm3/mem and put result in xmm1.</td>, <td>VEX.128.66.0F38.W0 BE /r VFNMSUB231PS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/mem, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>VEX.256.66.0F38.W0 9E /r VFNMSUB132PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/mem, negate the multiplication result and subtract ymm2 and put result in ymm1.</td>, <td>VEX.256.66.0F38.W0 AE /r VFNMSUB213PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, negate the multiplication result and subtract ymm3/mem and put result in ymm1.</td>, <td>VEX.256.66.0F38.0 BE /r VFNMSUB231PS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/mem, negate the multiplication result and subtract ymm1 and put result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 9E /r VFNMSUB132PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm3/m128/m32bcst, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 AE /r VFNMSUB213PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m128/m32bcst and put result in xmm1.</td>, <td>EVEX.128.66.0F38.W0 BE /r VFNMSUB231PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from xmm2 and xmm3/m128/m32bcst, negate the multiplication result subtract add to xmm1 and put result in xmm1.</td>, <td>EVEX.256.66.0F38.W0 9E /r VFNMSUB132PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm3/m256/m32bcst, negate the multiplication result and subtract ymm2 and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 AE /r VFNMSUB213PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm1 and ymm2, negate the multiplication result and subtract ymm3/m256/m32bcst and put result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 BE /r VFNMSUB231PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Multiply packed single-precision floating-point values from ymm2 and ymm3/m256/m32bcst, negate the multiplication result subtract add to ymm1 and put result in ymm1.</td>, <td>EVEX.512.66.0F38.W0 9E /r VFNMSUB132PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, negate the multiplication result and subtract zmm2 and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 AE /r VFNMSUB213PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm1 and zmm2, negate the multiplication result and subtract zmm3/m512/m32bcst and put result in zmm1.</td>, <td>EVEX.512.66.0F38.W0 BE /r VFNMSUB231PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, negate the multiplication result subtract add to zmm1 and put result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W1 9F /r VFNMSUB132SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/mem, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 AF /r VFNMSUB213SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/mem and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W1 BF /r VFNMSUB231SD xmm1, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/mem, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 9F /r VFNMSUB132SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 AF /r VFNMSUB213SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m64 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W1 BF /r VFNMSUB231SD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.LIG.66.0F38.W0 9F /r VFNMSUB132SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 AF /r VFNMSUB213SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m32 and put result in xmm1.</td>, <td>VEX.LIG.66.0F38.W0 BF /r VFNMSUB231SS xmm1, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>FMA</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 9F /r VFNMSUB132SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and subtract xmm2 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 AF /r VFNMSUB213SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m32 and put result in xmm1.</td>, <td>EVEX.LIG.66.0F38.W0 BF /r VFNMSUB231SS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and subtract xmm1 and put result in xmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F3A.W1 66 /r ib VFPCLASSPD k2 {k1}, xmm2/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result.</td>, <td>EVEX.256.66.0F3A.W1 66 /r ib VFPCLASSPD k2 {k1}, ymm2/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result.</td>, <td>EVEX.512.66.0F3A.W1 66 /r ib VFPCLASSPD k2 {k1}, zmm2/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td></td>, <td>76543210</td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td></td>, <td>SNaN</td>, <td>Neg. Finite</td>, <td>Denormal</td>, <td>Neg. INF</td>, <td>+INF</td>, <td>Neg. 0</td>, <td>+0</td>, <td>QNaN</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F3A.W0 66 /r ib VFPCLASSPS k2 {k1}, xmm2/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result.</td>, <td>EVEX.256.66.0F3A.W0 66 /r ib VFPCLASSPS k2 {k1}, ymm2/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result.</td>, <td>EVEX.512.66.0F3A.W0 66 /r ib VFPCLASSPS k2 {k1}, zmm2/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.LIG.66.0F3A.W1 67 /r ib VFPCLASSSD k2 {k1}, xmm2/m64, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.LIG.66.0F3A.W0 67 /r VFPCLASSSS k2 {k1}, xmm2/m32, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>VEX.128.66.0F38.W1 92 /r VGATHERDPD <em>xmm1, vm32x, xmm2</em></td>, <td>RMV</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using dword indices specified in <em>vm32x</em>, gather double-precision FP values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.W1 93 /r VGATHERQPD <em>xmm1, vm64x, xmm2</em></td>, <td>RMV</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using qword indices specified in <em>vm64x</em>, gather double-precision FP values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.W1 92 /r VGATHERDPD <em>ymm1, vm32x, ymm2</em></td>, <td>RMV</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using dword indices specified in <em>vm32x</em>, gather double-precision FP values from memory conditioned on mask specified by <em>ymm2</em>. Conditionally gathered elements are merged into <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.W1 93 /r VGATHERQPD <em>ymm1, vm64y, ymm2</em></td>, <td>RMV</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using qword indices specified in <em>vm64y</em>, gather double-precision FP values from memory conditioned on mask specified by <em>ymm2</em>. Conditionally gathered elements are merged into <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMV</td>, <td>ModRM:reg (r,w)</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>VEX.vvvv (r, w)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 92 /vsib VGATHERDPS xmm1 {k1}, vm32x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, gather single-precision floating-point values from memory using k1 as completion mask.</td>, <td>EVEX.256.66.0F38.W0 92 /vsib VGATHERDPS ymm1 {k1}, vm32y</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, gather single-precision floating-point values from memory using k1 as completion mask.</td>, <td>EVEX.512.66.0F38.W0 92 /vsib VGATHERDPS zmm1 {k1}, vm32z</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, gather single-precision floating-point values from memory using k1 as completion mask.</td>, <td>EVEX.128.66.0F38.W1 92 /vsib VGATHERDPD xmm1 {k1}, vm32x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, gather float64 vector into float64 vector xmm1 using k1 as completion mask.</td>, <td>EVEX.256.66.0F38.W1 92 /vsib VGATHERDPD ymm1 {k1}, vm32x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, gather float64 vector into float64 vector ymm1 using k1 as completion mask.</td>, <td>EVEX.512.66.0F38.W1 92 /vsib VGATHERDPD zmm1 {k1}, vm32y</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, gather float64 vector into float64 vector zmm1 using k1 as completion mask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 92 /r VGATHERDPS <em>xmm1, vm32x, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using dword indices specified in <em>vm32x</em>, gather single-precision FP values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.W0 93 /r VGATHERQPS <em>xmm1, vm64x, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using qword indices specified in <em>vm64x</em>, gather single-precision FP values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.W0 92 /r VGATHERDPS <em>ymm1, vm32y, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using dword indices specified in <em>vm32y</em>, gather single-precision FP values from memory conditioned on mask specified by <em>ymm2</em>. Conditionally gathered elements are merged into <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.W0 93 /r VGATHERQPS <em>xmm1, vm64y, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using qword indices specified in <em>vm64y</em>, gather single-precision FP values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>ModRM:reg (r,w)</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>VEX.vvvv (r, w)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 92 /vsib VGATHERDPS xmm1 {k1}, vm32x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, gather single-precision floating-point values from memory using k1 as completion mask.</td>, <td>EVEX.256.66.0F38.W0 92 /vsib VGATHERDPS ymm1 {k1}, vm32y</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, gather single-precision floating-point values from memory using k1 as completion mask.</td>, <td>EVEX.512.66.0F38.W0 92 /vsib VGATHERDPS zmm1 {k1}, vm32z</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, gather single-precision floating-point values from memory using k1 as completion mask.</td>, <td>EVEX.128.66.0F38.W1 92 /vsib VGATHERDPD xmm1 {k1}, vm32x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, gather float64 vector into float64 vector xmm1 using k1 as completion mask.</td>, <td>EVEX.256.66.0F38.W1 92 /vsib VGATHERDPD ymm1 {k1}, vm32x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, gather float64 vector into float64 vector ymm1 using k1 as completion mask.</td>, <td>EVEX.512.66.0F38.W1 92 /vsib VGATHERDPD zmm1 {k1}, vm32y</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, gather float64 vector into float64 vector zmm1 using k1 as completion mask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 92 /r VGATHERDPD <em>xmm1, vm32x, xmm2</em></td>, <td>RMV</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using dword indices specified in <em>vm32x</em>, gather double-precision FP values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.W1 93 /r VGATHERQPD <em>xmm1, vm64x, xmm2</em></td>, <td>RMV</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using qword indices specified in <em>vm64x</em>, gather double-precision FP values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.W1 92 /r VGATHERDPD <em>ymm1, vm32x, ymm2</em></td>, <td>RMV</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using dword indices specified in <em>vm32x</em>, gather double-precision FP values from memory conditioned on mask specified by <em>ymm2</em>. Conditionally gathered elements are merged into <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.W1 93 /r VGATHERQPD <em>ymm1, vm64y, ymm2</em></td>, <td>RMV</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using qword indices specified in <em>vm64y</em>, gather double-precision FP values from memory conditioned on mask specified by <em>ymm2</em>. Conditionally gathered elements are merged into <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMV</td>, <td>ModRM:reg (r,w)</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>VEX.vvvv (r, w)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 93 /vsib VGATHERQPS xmm1 {k1}, vm64x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, gather single-precision floating-point values from memory using k1 as completion mask.</td>, <td>EVEX.256.66.0F38.W0 93 /vsib VGATHERQPS xmm1 {k1}, vm64y</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, gather single-precision floating-point values from memory using k1 as completion mask.</td>, <td>EVEX.512.66.0F38.W0 93 /vsib VGATHERQPS ymm1 {k1}, vm64z</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, gather single-precision floating-point values from memory using k1 as completion mask.</td>, <td>EVEX.128.66.0F38.W1 93 /vsib VGATHERQPD xmm1 {k1}, vm64x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, gather float64 vector into float64 vector xmm1 using k1 as completion mask.</td>, <td>EVEX.256.66.0F38.W1 93 /vsib VGATHERQPD ymm1 {k1}, vm64y</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, gather float64 vector into float64 vector ymm1 using k1 as completion mask.</td>, <td>EVEX.512.66.0F38.W1 93 /vsib VGATHERQPD zmm1 {k1}, vm64z</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, gather float64 vector into float64 vector zmm1 using k1 as completion mask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 92 /r VGATHERDPS <em>xmm1, vm32x, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using dword indices specified in <em>vm32x</em>, gather single-precision FP values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.W0 93 /r VGATHERQPS <em>xmm1, vm64x, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using qword indices specified in <em>vm64x</em>, gather single-precision FP values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.W0 92 /r VGATHERDPS <em>ymm1, vm32y, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using dword indices specified in <em>vm32y</em>, gather single-precision FP values from memory conditioned on mask specified by <em>ymm2</em>. Conditionally gathered elements are merged into <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.W0 93 /r VGATHERQPS <em>xmm1, vm64y, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using qword indices specified in <em>vm64y</em>, gather single-precision FP values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>ModRM:reg (r,w)</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>VEX.vvvv (r, w)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 93 /vsib VGATHERQPS xmm1 {k1}, vm64x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, gather single-precision floating-point values from memory using k1 as completion mask.</td>, <td>EVEX.256.66.0F38.W0 93 /vsib VGATHERQPS xmm1 {k1}, vm64y</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, gather single-precision floating-point values from memory using k1 as completion mask.</td>, <td>EVEX.512.66.0F38.W0 93 /vsib VGATHERQPS ymm1 {k1}, vm64z</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, gather single-precision floating-point values from memory using k1 as completion mask.</td>, <td>EVEX.128.66.0F38.W1 93 /vsib VGATHERQPD xmm1 {k1}, vm64x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, gather float64 vector into float64 vector xmm1 using k1 as completion mask.</td>, <td>EVEX.256.66.0F38.W1 93 /vsib VGATHERQPD ymm1 {k1}, vm64y</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, gather float64 vector into float64 vector ymm1 using k1 as completion mask.</td>, <td>EVEX.512.66.0F38.W1 93 /vsib VGATHERQPD zmm1 {k1}, vm64z</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, gather float64 vector into float64 vector zmm1 using k1 as completion mask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 42 /r VGETEXPPD xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert the exponent of packed double-precision floating-point values in the source operand to DP FP results representing unbiased integer exponents and stores the results in the destination register.</td>, <td>EVEX.256.66.0F38.W1 42 /r VGETEXPPD ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert the exponent of packed double-precision floating-point values in the source operand to DP FP results representing unbiased integer exponents and stores the results in the destination register.</td>, <td>EVEX.512.66.0F38.W1 42 /r VGETEXPPD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert the exponent of packed double-precision floating-point values in the source operand to DP FP results representing unbiased integer exponents and stores the results in the destination under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>src1 = NaN</td>, <td>QNaN(src1)</td>, <td rowspan="4">If (SRC = SNaN) then #IE If (SRC = denormal) then #DE</td>, <td>0 &lt; |src1| &lt; INF</td>, <td>floor(log<sub>2</sub>(|src1|))</td>, <td>| src1| = +INF</td>, <td>+INF</td>, <td>| src1| = 0</td>, <td>-INF</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F38.W0 42 /r VGETEXPPS xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert the exponent of packed single-precision floating-point values in the source operand to SP FP results representing unbiased integer exponents and stores the results in the destination register.</td>, <td>EVEX.256.66.0F38.W0 42 /r VGETEXPPS ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Convert the exponent of packed single-precision floating-point values in the source operand to SP FP results representing unbiased integer exponents and stores the results in the destination register.</td>, <td>EVEX.512.66.0F38.W0 42 /r VGETEXPPS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert the exponent of packed single-precision floating-point values in the source operand to SP FP results representing unbiased integer exponents and stores the results in the destination register.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>src1 = NaN</td>, <td>QNaN(src1)</td>, <td rowspan="4">If (SRC = SNaN) then #IE If (SRC = denormal) then #DE</td>, <td>0 &lt; |src1| &lt; INF</td>, <td>floor(log<sub>2</sub>(|src1|))</td>, <td>| src1| = +INF</td>, <td>+INF</td>, <td>| src1| = 0</td>, <td>-INF</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.LIG.66.0F38.W1 43 /r VGETEXPSD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert the biased exponent (bits 62:52) of the low double-precision floating-point value in xmm3/m64 to a DP FP value representing unbiased integer exponent. Stores the result to the low 64-bit of xmm1 under the writemask k1 and merge with the other elements of xmm2.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.LIG.66.0F38.W0 43 /r VGETEXPSS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Convert the biased exponent (bits 30:23) of the low single-precision floating-point value in xmm3/m32 to a SP FP value representing unbiased integer exponent. Stores the result to xmm1 under the writemask k1 and merge with the other elements of xmm2.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F3A.W1 26 /r ib VGETMANTPD xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Get Normalized Mantissa from float64 vector xmm2/m128/m64bcst and store the result in xmm1, using <em>imm</em>8 for sign control and mantissa interval normalization, under writemask.</td>, <td>EVEX.256.66.0F3A.W1 26 /r ib VGETMANTPD ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Get Normalized Mantissa from float64 vector ymm2/m256/m64bcst and store the result in ymm1, using <em>imm</em>8 for sign control and mantissa interval normalization, under writemask.</td>, <td>EVEX.512.66.0F3A.W1 26 /r ib VGETMANTPD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Get Normalized Mantissa from float64 vector zmm2/m512/m64bcst and store the result in zmm1, using <em>imm</em>8 for sign control and mantissa interval normalization, under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>NaN</td>, <td>QNaN(SRC)</td>, <td>Ignore <em>interv</em> If (SRC = SNaN) then #IE</td>, <td>+∞</td>, <td>1.0</td>, <td>Ignore <em>interv</em></td>, <td>+0</td>, <td>1.0</td>, <td>Ignore <em>interv</em></td>, <td>-0</td>, <td>IF (SC[0]) THEN +1.0 ELSE -1.0</td>, <td>Ignore <em>interv</em></td>, <td>-∞</td>, <td>IF (SC[1]) THEN {QNaN_Indefinite} ELSE { IF (SC[0]) THEN +1.0 ELSE -1.0</td>, <td>Ignore <em>interv</em> If (SC[1]) then #IE</td>, <td>negative</td>, <td>SC[1] ? QNaN_Indefinite : Getmant(SRC)</td>, <td>If (SC[1]) then #IE</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F3A.W0 26 /r ib VGETMANTPS xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Get normalized mantissa from float32 vector xmm2/m128/m32bcst and store the result in xmm1, using imm8 for sign control and mantissa interval normalization, under writemask.</td>, <td>EVEX.256.66.0F3A.W0 26 /r ib VGETMANTPS ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Get normalized mantissa from float32 vector ymm2/m256/m32bcst and store the result in ymm1, using imm8 for sign control and mantissa interval normalization, under writemask.</td>, <td>EVEX.512.66.0F3A.W0 26 /r ib VGETMANTPS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Get normalized mantissa from float32 vector zmm2/m512/m32bcst and store the result in zmm1, using imm8 for sign control and mantissa interval normalization, under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.LIG.66.0F3A.W1 27 /r ib VGETMANTSD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract the normalized mantissa of the low float64 element in xmm3/m64 using <em>imm</em>8 for sign control and mantissa interval normalization. Store the mantissa to xmm1 under the writemask k1 and merge with the other elements of xmm2.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.LIG.66.0F3A.W0 27 /r ib VGETMANTSS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Extract the normalized mantissa from the low float32 element of xmm3/m32 using imm8 for sign control and mantissa interval normalization, store the mantissa to xmm1 under the writemask k1 and merge with the other elements of xmm2.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.256.66.0F3A.W0 18 /r ib VINSERTF128 ymm1, ymm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Insert 128 bits of packed floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1.</td>, <td>EVEX.256.66.0F3A.W0 18 /r ib VINSERTF32X4 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Insert 128 bits of packed single-precision floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 18 /r ib VINSERTF32X4 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 128 bits of packed single-precision floating-point values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 18 /r ib VINSERTF64X2 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Insert 128 bits of packed double-precision floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 18 /r ib VINSERTF64X2 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 128 bits of packed double-precision floating-point values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 1A /r ib VINSERTF32X8 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 256 bits of packed single-precision floating-point values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 1A /r ib VINSERTF64X4 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 256 bits of packed double-precision floating-point values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>#UD</td>, <td>If VEX.L = 0.</td>]

[<td>VEX.256.66.0F3A.W0 18 /r ib VINSERTF128 ymm1, ymm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Insert 128 bits of packed floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1.</td>, <td>EVEX.256.66.0F3A.W0 18 /r ib VINSERTF32X4 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Insert 128 bits of packed single-precision floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 18 /r ib VINSERTF32X4 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 128 bits of packed single-precision floating-point values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 18 /r ib VINSERTF64X2 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Insert 128 bits of packed double-precision floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 18 /r ib VINSERTF64X2 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 128 bits of packed double-precision floating-point values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 1A /r ib VINSERTF32X8 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 256 bits of packed single-precision floating-point values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 1A /r ib VINSERTF64X4 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 256 bits of packed double-precision floating-point values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>#UD</td>, <td>If VEX.L = 0.</td>]

[<td>VEX.256.66.0F3A.W0 18 /r ib VINSERTF128 ymm1, ymm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Insert 128 bits of packed floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1.</td>, <td>EVEX.256.66.0F3A.W0 18 /r ib VINSERTF32X4 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Insert 128 bits of packed single-precision floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 18 /r ib VINSERTF32X4 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 128 bits of packed single-precision floating-point values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 18 /r ib VINSERTF64X2 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Insert 128 bits of packed double-precision floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 18 /r ib VINSERTF64X2 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 128 bits of packed double-precision floating-point values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 1A /r ib VINSERTF32X8 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 256 bits of packed single-precision floating-point values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 1A /r ib VINSERTF64X4 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 256 bits of packed double-precision floating-point values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>#UD</td>, <td>If VEX.L = 0.</td>]

[<td>VEX.256.66.0F3A.W0 18 /r ib VINSERTF128 ymm1, ymm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Insert 128 bits of packed floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1.</td>, <td>EVEX.256.66.0F3A.W0 18 /r ib VINSERTF32X4 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Insert 128 bits of packed single-precision floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 18 /r ib VINSERTF32X4 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 128 bits of packed single-precision floating-point values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 18 /r ib VINSERTF64X2 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Insert 128 bits of packed double-precision floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 18 /r ib VINSERTF64X2 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 128 bits of packed double-precision floating-point values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 1A /r ib VINSERTF32X8 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 256 bits of packed single-precision floating-point values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 1A /r ib VINSERTF64X4 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 256 bits of packed double-precision floating-point values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>#UD</td>, <td>If VEX.L = 0.</td>]

[<td>VEX.256.66.0F3A.W0 18 /r ib VINSERTF128 ymm1, ymm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Insert 128 bits of packed floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1.</td>, <td>EVEX.256.66.0F3A.W0 18 /r ib VINSERTF32X4 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Insert 128 bits of packed single-precision floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 18 /r ib VINSERTF32X4 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 128 bits of packed single-precision floating-point values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 18 /r ib VINSERTF64X2 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Insert 128 bits of packed double-precision floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 18 /r ib VINSERTF64X2 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 128 bits of packed double-precision floating-point values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 1A /r ib VINSERTF32X8 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 256 bits of packed single-precision floating-point values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 1A /r ib VINSERTF64X4 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 256 bits of packed double-precision floating-point values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>#UD</td>, <td>If VEX.L = 0.</td>]

[<td>VEX.256.66.0F3A.W0 38 /r ib VINSERTI128 ymm1, ymm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Insert 128 bits of integer data from xmm3/m128 and the remaining values from ymm2 into ymm1.</td>, <td>EVEX.256.66.0F3A.W0 38 /r ib VINSERTI32X4 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 38 /r ib VINSERTI32X4 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 38 /r ib VINSERTI64X2 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 38 /r ib VINSERTI64X2 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 3A /r ib VINSERTI32X8 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 256 bits of packed doubleword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 3A /r ib VINSERTI64X4 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 256 bits of packed quadword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>#UD</td>, <td>If VEX.L = 0.</td>]

[<td>VEX.256.66.0F3A.W0 38 /r ib VINSERTI128 ymm1, ymm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Insert 128 bits of integer data from xmm3/m128 and the remaining values from ymm2 into ymm1.</td>, <td>EVEX.256.66.0F3A.W0 38 /r ib VINSERTI32X4 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 38 /r ib VINSERTI32X4 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 38 /r ib VINSERTI64X2 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 38 /r ib VINSERTI64X2 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 3A /r ib VINSERTI32X8 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 256 bits of packed doubleword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 3A /r ib VINSERTI64X4 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 256 bits of packed quadword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>#UD</td>, <td>If VEX.L = 0.</td>]

[<td>VEX.256.66.0F3A.W0 38 /r ib VINSERTI128 ymm1, ymm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Insert 128 bits of integer data from xmm3/m128 and the remaining values from ymm2 into ymm1.</td>, <td>EVEX.256.66.0F3A.W0 38 /r ib VINSERTI32X4 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 38 /r ib VINSERTI32X4 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 38 /r ib VINSERTI64X2 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 38 /r ib VINSERTI64X2 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 3A /r ib VINSERTI32X8 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 256 bits of packed doubleword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 3A /r ib VINSERTI64X4 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 256 bits of packed quadword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>#UD</td>, <td>If VEX.L = 0.</td>]

[<td>VEX.256.66.0F3A.W0 38 /r ib VINSERTI128 ymm1, ymm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Insert 128 bits of integer data from xmm3/m128 and the remaining values from ymm2 into ymm1.</td>, <td>EVEX.256.66.0F3A.W0 38 /r ib VINSERTI32X4 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 38 /r ib VINSERTI32X4 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 38 /r ib VINSERTI64X2 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 38 /r ib VINSERTI64X2 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 3A /r ib VINSERTI32X8 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 256 bits of packed doubleword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 3A /r ib VINSERTI64X4 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 256 bits of packed quadword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>#UD</td>, <td>If VEX.L = 0.</td>]

[<td>VEX.256.66.0F3A.W0 38 /r ib VINSERTI128 ymm1, ymm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Insert 128 bits of integer data from xmm3/m128 and the remaining values from ymm2 into ymm1.</td>, <td>EVEX.256.66.0F3A.W0 38 /r ib VINSERTI32X4 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 38 /r ib VINSERTI32X4 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 38 /r ib VINSERTI64X2 ymm1 {k1}{z}, ymm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 38 /r ib VINSERTI64X2 zmm1 {k1}{z}, zmm2, xmm3/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 3A /r ib VINSERTI32X8 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Insert 256 bits of packed doubleword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 3A /r ib VINSERTI64X4 zmm1 {k1}{z}, zmm2, ymm3/m256, imm8</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Insert 256 bits of packed quadword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>B</td>, <td>Tuple2</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>C</td>, <td>Tuple4</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>D</td>, <td>Tuple8</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>#UD</td>, <td>If VEX.L = 0.</td>]

[<td>VEX.128.66.0F38.W0 2C /r VMASKMOVPS <em>xmm1, xmm2, m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Conditionally load packed single-precision values from <em>m128</em> using mask in <em>xmm2</em> and store in <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.W0 2C /r VMASKMOVPS <em>ymm1, ymm2, m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Conditionally load packed single-precision values from <em>m256</em> using mask in <em>ymm2</em> and store in <em>ymm1</em>.</td>, <td>VEX.128.66.0F38.W0 2D /r VMASKMOVPD <em>xmm1, xmm2, m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Conditionally load packed double-precision values from <em>m128</em> using mask in <em>xmm2</em> and store in <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.W0 2D /r VMASKMOVPD <em>ymm1, ymm2, m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX</td>, <td>Conditionally load packed double-precision values from <em>m256</em> using mask in <em>ymm2</em> and store in <em>ymm1</em>.</td>, <td>VEX.128.66.0F38.W0 2E /r VMASKMOVPS <em>m128, xmm1, xmm2</em></td>, <td>MVR</td>, <td>V/V</td>, <td>AVX</td>, <td>Conditionally store packed single-precision values from <em>xmm2</em> using mask in <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.W0 2E /r VMASKMOVPS <em>m256, ymm1, ymm2</em></td>, <td>MVR</td>, <td>V/V</td>, <td>AVX</td>, <td>Conditionally store packed single-precision values from <em>ymm2</em> using mask in <em>ymm1</em>.</td>, <td>VEX.128.66.0F38.W0 2F /r VMASKMOVPD <em>m128, xmm1, xmm2</em></td>, <td>MVR</td>, <td>V/V</td>, <td>AVX</td>, <td>Conditionally store packed double-precision values from <em>xmm2</em> using mask in <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.W0 2F /r VMASKMOVPD <em>m256, ymm1, ymm2</em></td>, <td>MVR</td>, <td>V/V</td>, <td>AVX</td>, <td>Conditionally store packed double-precision values from <em>ymm2</em> using mask in <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>MVR</td>, <td>ModRM:r/m (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.W = 1.</td>]

[<td>66 0F 6F /r MOVDQA xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move aligned packed integer values from xmm2/mem to xmm1.</td>, <td>66 0F 7F /r MOVDQA xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move aligned packed integer values from xmm1 to xmm2/mem.</td>, <td>VEX.128.66.0F.WIG 6F /r VMOVDQA xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed integer values from xmm2/mem to xmm1.</td>, <td>VEX.128.66.0F.WIG 7F /r VMOVDQA xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed integer values from xmm1 to xmm2/mem.</td>, <td>VEX.256.66.0F.WIG 6F /r VMOVDQA ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed integer values from ymm2/mem to ymm1.</td>, <td>VEX.256.66.0F.WIG 7F /r VMOVDQA ymm2/m256, ymm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed integer values from ymm1 to ymm2/mem.</td>, <td>EVEX.128.66.0F.W0 6F /r VMOVDQA32 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W0 6F /r VMOVDQA32 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 6F /r VMOVDQA32 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move aligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.W0 7F /r VMOVDQA32 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.66.0F.W0 7F /r VMOVDQA32 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 7F /r VMOVDQA32 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move aligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.66.0F.W1 6F /r VMOVDQA64 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned quadword integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W1 6F /r VMOVDQA64 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned quadword integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W1 6F /r VMOVDQA64 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move aligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.W1 7F /r VMOVDQA64 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.66.0F.W1 7F /r VMOVDQA64 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.66.0F.W1 7F /r VMOVDQA64 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move aligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B or VEX.vvvv != 1111B.</td>]

[<td>66 0F 6F /r MOVDQA xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move aligned packed integer values from xmm2/mem to xmm1.</td>, <td>66 0F 7F /r MOVDQA xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move aligned packed integer values from xmm1 to xmm2/mem.</td>, <td>VEX.128.66.0F.WIG 6F /r VMOVDQA xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed integer values from xmm2/mem to xmm1.</td>, <td>VEX.128.66.0F.WIG 7F /r VMOVDQA xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed integer values from xmm1 to xmm2/mem.</td>, <td>VEX.256.66.0F.WIG 6F /r VMOVDQA ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed integer values from ymm2/mem to ymm1.</td>, <td>VEX.256.66.0F.WIG 7F /r VMOVDQA ymm2/m256, ymm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move aligned packed integer values from ymm1 to ymm2/mem.</td>, <td>EVEX.128.66.0F.W0 6F /r VMOVDQA32 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W0 6F /r VMOVDQA32 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 6F /r VMOVDQA32 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move aligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.W0 7F /r VMOVDQA32 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.66.0F.W0 7F /r VMOVDQA32 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 7F /r VMOVDQA32 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move aligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.66.0F.W1 6F /r VMOVDQA64 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned quadword integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F.W1 6F /r VMOVDQA64 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned quadword integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W1 6F /r VMOVDQA64 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move aligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F.W1 7F /r VMOVDQA64 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.66.0F.W1 7F /r VMOVDQA64 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move aligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.66.0F.W1 7F /r VMOVDQA64 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move aligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B or VEX.vvvv != 1111B.</td>]

[<td>F3 0F 6F /r MOVDQU xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move unaligned packed integer values from xmm2/m128 to xmm1.</td>, <td>F3 0F 7F /r MOVDQU xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move unaligned packed integer values from xmm1 to xmm2/m128.</td>, <td>VEX.128.F3.0F.WIG 6F /r VMOVDQU xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from xmm2/m128 to xmm1.</td>, <td>VEX.128.F3.0F.WIG 7F /r VMOVDQU xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from xmm1 to xmm2/m128.</td>, <td>VEX.256.F3.0F.WIG 6F /r VMOVDQU ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from ymm2/m256 to ymm1.</td>, <td>VEX.256.F3.0F.WIG 7F /r VMOVDQU ymm2/m256, ymm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from ymm1 to ymm2/m256.</td>, <td>EVEX.128.F2.0F.W0 6F /r VMOVDQU8 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F2.0F.W0 6F /r VMOVDQU8 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F2.0F.W0 6F /r VMOVDQU8 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed byte integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F2.0F.W0 7F /r VMOVDQU8 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F2.0F.W0 7F /r VMOVDQU8 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F2.0F.W0 7F /r VMOVDQU8 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed byte integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.F2.0F.W1 6F /r VMOVDQU16 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F2.0F.W1 6F /r VMOVDQU16 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F2.0F.W1 6F /r VMOVDQU16 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed word integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F2.0F.W1 7F /r VMOVDQU16 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F2.0F.W1 7F /r VMOVDQU16 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F2.0F.W1 7F /r VMOVDQU16 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed word integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.F3.0F.W0 6F /r VMOVDQU32 xmm1 {k1}{z}, xmm2/mm128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F3.0F.W0 6F /r VMOVDQU32 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F3.0F.W0 6F /r VMOVDQU32 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F3.0F.W0 7F /r VMOVDQU32 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F3.0F.W0 7F /r VMOVDQU32 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F3.0F.W0 7F /r VMOVDQU32 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.F3.0F.W1 6F /r VMOVDQU64 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F3.0F.W1 6F /r VMOVDQU64 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F3.0F.W1 6F /r VMOVDQU64 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F3.0F.W1 7F /r VMOVDQU64 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F3.0F.W1 7F /r VMOVDQU64 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F3.0F.W1 7F /r VMOVDQU64 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B or VEX.vvvv != 1111B.</td>]

[<td>F3 0F 6F /r MOVDQU xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move unaligned packed integer values from xmm2/m128 to xmm1.</td>, <td>F3 0F 7F /r MOVDQU xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move unaligned packed integer values from xmm1 to xmm2/m128.</td>, <td>VEX.128.F3.0F.WIG 6F /r VMOVDQU xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from xmm2/m128 to xmm1.</td>, <td>VEX.128.F3.0F.WIG 7F /r VMOVDQU xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from xmm1 to xmm2/m128.</td>, <td>VEX.256.F3.0F.WIG 6F /r VMOVDQU ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from ymm2/m256 to ymm1.</td>, <td>VEX.256.F3.0F.WIG 7F /r VMOVDQU ymm2/m256, ymm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from ymm1 to ymm2/m256.</td>, <td>EVEX.128.F2.0F.W0 6F /r VMOVDQU8 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F2.0F.W0 6F /r VMOVDQU8 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F2.0F.W0 6F /r VMOVDQU8 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed byte integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F2.0F.W0 7F /r VMOVDQU8 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F2.0F.W0 7F /r VMOVDQU8 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F2.0F.W0 7F /r VMOVDQU8 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed byte integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.F2.0F.W1 6F /r VMOVDQU16 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F2.0F.W1 6F /r VMOVDQU16 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F2.0F.W1 6F /r VMOVDQU16 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed word integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F2.0F.W1 7F /r VMOVDQU16 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F2.0F.W1 7F /r VMOVDQU16 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F2.0F.W1 7F /r VMOVDQU16 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed word integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.F3.0F.W0 6F /r VMOVDQU32 xmm1 {k1}{z}, xmm2/mm128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F3.0F.W0 6F /r VMOVDQU32 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F3.0F.W0 6F /r VMOVDQU32 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F3.0F.W0 7F /r VMOVDQU32 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F3.0F.W0 7F /r VMOVDQU32 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F3.0F.W0 7F /r VMOVDQU32 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.F3.0F.W1 6F /r VMOVDQU64 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F3.0F.W1 6F /r VMOVDQU64 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F3.0F.W1 6F /r VMOVDQU64 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F3.0F.W1 7F /r VMOVDQU64 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F3.0F.W1 7F /r VMOVDQU64 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F3.0F.W1 7F /r VMOVDQU64 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B or VEX.vvvv != 1111B.</td>]

[<td>F3 0F 6F /r MOVDQU xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move unaligned packed integer values from xmm2/m128 to xmm1.</td>, <td>F3 0F 7F /r MOVDQU xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move unaligned packed integer values from xmm1 to xmm2/m128.</td>, <td>VEX.128.F3.0F.WIG 6F /r VMOVDQU xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from xmm2/m128 to xmm1.</td>, <td>VEX.128.F3.0F.WIG 7F /r VMOVDQU xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from xmm1 to xmm2/m128.</td>, <td>VEX.256.F3.0F.WIG 6F /r VMOVDQU ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from ymm2/m256 to ymm1.</td>, <td>VEX.256.F3.0F.WIG 7F /r VMOVDQU ymm2/m256, ymm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from ymm1 to ymm2/m256.</td>, <td>EVEX.128.F2.0F.W0 6F /r VMOVDQU8 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F2.0F.W0 6F /r VMOVDQU8 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F2.0F.W0 6F /r VMOVDQU8 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed byte integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F2.0F.W0 7F /r VMOVDQU8 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F2.0F.W0 7F /r VMOVDQU8 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F2.0F.W0 7F /r VMOVDQU8 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed byte integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.F2.0F.W1 6F /r VMOVDQU16 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F2.0F.W1 6F /r VMOVDQU16 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F2.0F.W1 6F /r VMOVDQU16 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed word integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F2.0F.W1 7F /r VMOVDQU16 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F2.0F.W1 7F /r VMOVDQU16 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F2.0F.W1 7F /r VMOVDQU16 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed word integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.F3.0F.W0 6F /r VMOVDQU32 xmm1 {k1}{z}, xmm2/mm128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F3.0F.W0 6F /r VMOVDQU32 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F3.0F.W0 6F /r VMOVDQU32 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F3.0F.W0 7F /r VMOVDQU32 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F3.0F.W0 7F /r VMOVDQU32 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F3.0F.W0 7F /r VMOVDQU32 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.F3.0F.W1 6F /r VMOVDQU64 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F3.0F.W1 6F /r VMOVDQU64 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F3.0F.W1 6F /r VMOVDQU64 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F3.0F.W1 7F /r VMOVDQU64 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F3.0F.W1 7F /r VMOVDQU64 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F3.0F.W1 7F /r VMOVDQU64 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B or VEX.vvvv != 1111B.</td>]

[<td>F3 0F 6F /r MOVDQU xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move unaligned packed integer values from xmm2/m128 to xmm1.</td>, <td>F3 0F 7F /r MOVDQU xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>SSE2</td>, <td>Move unaligned packed integer values from xmm1 to xmm2/m128.</td>, <td>VEX.128.F3.0F.WIG 6F /r VMOVDQU xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from xmm2/m128 to xmm1.</td>, <td>VEX.128.F3.0F.WIG 7F /r VMOVDQU xmm2/m128, xmm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from xmm1 to xmm2/m128.</td>, <td>VEX.256.F3.0F.WIG 6F /r VMOVDQU ymm1, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from ymm2/m256 to ymm1.</td>, <td>VEX.256.F3.0F.WIG 7F /r VMOVDQU ymm2/m256, ymm1</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Move unaligned packed integer values from ymm1 to ymm2/m256.</td>, <td>EVEX.128.F2.0F.W0 6F /r VMOVDQU8 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F2.0F.W0 6F /r VMOVDQU8 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F2.0F.W0 6F /r VMOVDQU8 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed byte integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F2.0F.W0 7F /r VMOVDQU8 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F2.0F.W0 7F /r VMOVDQU8 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed byte integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F2.0F.W0 7F /r VMOVDQU8 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed byte integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.F2.0F.W1 6F /r VMOVDQU16 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F2.0F.W1 6F /r VMOVDQU16 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F2.0F.W1 6F /r VMOVDQU16 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed word integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F2.0F.W1 7F /r VMOVDQU16 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F2.0F.W1 7F /r VMOVDQU16 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Move unaligned packed word integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F2.0F.W1 7F /r VMOVDQU16 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Move unaligned packed word integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.F3.0F.W0 6F /r VMOVDQU32 xmm1 {k1}{z}, xmm2/mm128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F3.0F.W0 6F /r VMOVDQU32 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F3.0F.W0 6F /r VMOVDQU32 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed doubleword integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F3.0F.W0 7F /r VMOVDQU32 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F3.0F.W0 7F /r VMOVDQU32 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed doubleword integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F3.0F.W0 7F /r VMOVDQU32 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>EVEX.128.F3.0F.W1 6F /r VMOVDQU64 xmm1 {k1}{z}, xmm2/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.F3.0F.W1 6F /r VMOVDQU64 ymm1 {k1}{z}, ymm2/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.F3.0F.W1 6F /r VMOVDQU64 zmm1 {k1}{z}, zmm2/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed quadword integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>EVEX.128.F3.0F.W1 7F /r VMOVDQU64 xmm2/m128 {k1}{z}, xmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from xmm1 to xmm2/m128 using writemask k1.</td>, <td>EVEX.256.F3.0F.W1 7F /r VMOVDQU64 ymm2/m256 {k1}{z}, ymm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Move unaligned packed quadword integer values from ymm1 to ymm2/m256 using writemask k1.</td>, <td>EVEX.512.F3.0F.W1 7F /r VMOVDQU64 zmm2/m512 {k1}{z}, zmm1</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Move unaligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Full Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B or VEX.vvvv != 1111B.</td>]

[<td>VEX.128.66.0F3A.W0 02 /r ib VPBLENDD <em>xmm1, xmm2, xmm3/m128, imm8</em></td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX2</td>, <td>Select dwords from <em>xmm2</em> and <em>xmm3/m128</em> from mask specified in <em>imm8</em> and store the values into <em>xmm1</em>.</td>, <td>VEX.256.66.0F3A.W0 02 /r ib VPBLENDD <em>ymm1, ymm2, ymm3/m256, imm8</em></td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX2</td>, <td>Select dwords from <em>ymm2</em> and <em>ymm3/m256</em> from mask specified in <em>imm8</em> and store the values into <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RVMI</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>#UD</td>, <td>If VEX.W = 1.</td>]

[<td>EVEX.128.66.0F38.W0 66 /r VPBLENDMB xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Blend byte integer vector xmm2 and byte vector xmm3/m128 and store the result in xmm1, under control mask.</td>, <td>EVEX.256.66.0F38.W0 66 /r VPBLENDMB ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Blend byte integer vector ymm2 and byte vector ymm3/m256 and store the result in ymm1, under control mask.</td>, <td>EVEX.512.66.0F38.W0 66 /r VPBLENDMB zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Blend byte integer vector zmm2 and byte vector zmm3/m512 and store the result in zmm1, under control mask.</td>, <td>EVEX.128.66.0F38.W1 66 /r VPBLENDMW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Blend word integer vector xmm2 and word vector xmm3/m128 and store the result in xmm1, under control mask.</td>, <td>EVEX.256.66.0F38.W1 66 /r VPBLENDMW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Blend word integer vector ymm2 and word vector ymm3/m256 and store the result in ymm1, under control mask.</td>, <td>EVEX.512.66.0F38.W1 66 /r VPBLENDMW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Blend word integer vector zmm2 and word vector zmm3/m512 and store the result in zmm1, under control mask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 64 /r VPBLENDMD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Blend doubleword integer vector xmm2 and doubleword vector xmm3/m128/m32bcst and store the result in xmm1, under control mask.</td>, <td>EVEX.256.66.0F38.W0 64 /r VPBLENDMD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Blend doubleword integer vector ymm2 and doubleword vector ymm3/m256/m32bcst and store the result in ymm1, under control mask.</td>, <td>EVEX.512.66.0F38.W0 64 /r VPBLENDMD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Blend doubleword integer vector zmm2 and doubleword vector zmm3/m512/m32bcst and store the result in zmm1, under control mask.</td>, <td>EVEX.128.66.0F38.W1 64 /r VPBLENDMQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Blend quadword integer vector xmm2 and quadword vector xmm3/m128/m64bcst and store the result in xmm1, under control mask.</td>, <td>EVEX.256.66.0F38.W1 64 /r VPBLENDMQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Blend quadword integer vector ymm2 and quadword vector ymm3/m256/m64bcst and store the result in ymm1, under control mask.</td>, <td>EVEX.512.66.0F38.W1 64 /r VPBLENDMQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Blend quadword integer vector zmm2 and quadword vector zmm3/m512/m64bcst and store the result in zmm1, under control mask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 64 /r VPBLENDMD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Blend doubleword integer vector xmm2 and doubleword vector xmm3/m128/m32bcst and store the result in xmm1, under control mask.</td>, <td>EVEX.256.66.0F38.W0 64 /r VPBLENDMD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Blend doubleword integer vector ymm2 and doubleword vector ymm3/m256/m32bcst and store the result in ymm1, under control mask.</td>, <td>EVEX.512.66.0F38.W0 64 /r VPBLENDMD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Blend doubleword integer vector zmm2 and doubleword vector zmm3/m512/m32bcst and store the result in zmm1, under control mask.</td>, <td>EVEX.128.66.0F38.W1 64 /r VPBLENDMQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Blend quadword integer vector xmm2 and quadword vector xmm3/m128/m64bcst and store the result in xmm1, under control mask.</td>, <td>EVEX.256.66.0F38.W1 64 /r VPBLENDMQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Blend quadword integer vector ymm2 and quadword vector ymm3/m256/m64bcst and store the result in ymm1, under control mask.</td>, <td>EVEX.512.66.0F38.W1 64 /r VPBLENDMQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Blend quadword integer vector zmm2 and quadword vector zmm3/m512/m64bcst and store the result in zmm1, under control mask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 66 /r VPBLENDMB xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Blend byte integer vector xmm2 and byte vector xmm3/m128 and store the result in xmm1, under control mask.</td>, <td>EVEX.256.66.0F38.W0 66 /r VPBLENDMB ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Blend byte integer vector ymm2 and byte vector ymm3/m256 and store the result in ymm1, under control mask.</td>, <td>EVEX.512.66.0F38.W0 66 /r VPBLENDMB zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Blend byte integer vector zmm2 and byte vector zmm3/m512 and store the result in zmm1, under control mask.</td>, <td>EVEX.128.66.0F38.W1 66 /r VPBLENDMW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Blend word integer vector xmm2 and word vector xmm3/m128 and store the result in xmm1, under control mask.</td>, <td>EVEX.256.66.0F38.W1 66 /r VPBLENDMW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Blend word integer vector ymm2 and word vector ymm3/m256 and store the result in ymm1, under control mask.</td>, <td>EVEX.512.66.0F38.W1 66 /r VPBLENDMW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Blend word integer vector zmm2 and word vector zmm3/m512 and store the result in zmm1, under control mask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 78 /r VPBROADCASTB xmm1, xmm2/m8</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Broadcast a byte integer in the source operand to sixteen locations in xmm1.</td>, <td>VEX.256.66.0F38.W0 78 /r VPBROADCASTB ymm1, xmm2/m8</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Broadcast a byte integer in the source operand to thirty-two locations in ymm1.</td>, <td>EVEX.128.66.0F38.W0 78 /r VPBROADCASTB xmm1{k1}{z}, xmm2/m8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast a byte integer in the source operand to locations in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 78 /r VPBROADCASTB ymm1{k1}{z}, xmm2/m8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast a byte integer in the source operand to locations in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 78 /r VPBROADCASTB zmm1{k1}{z}, xmm2/m8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Broadcast a byte integer in the source operand to 64 locations in zmm1 subject to writemask k1.</td>, <td>VEX.128.66.0F38.W0 79 /r VPBROADCASTW xmm1, xmm2/m16</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Broadcast a word integer in the source operand to eight locations in xmm1.</td>, <td>VEX.256.66.0F38.W0 79 /r VPBROADCASTW ymm1, xmm2/m16</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Broadcast a word integer in the source operand to sixteen locations in ymm1.</td>, <td>EVEX.128.66.0F38.W0 79 /r VPBROADCASTW xmm1{k1}{z}, xmm2/m16</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast a word integer in the source operand to locations in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 79 /r VPBROADCASTW ymm1{k1}{z}, xmm2/m16</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast a word integer in the source operand to locations in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 79 /r VPBROADCASTW zmm1{k1}{z}, xmm2/m16</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Broadcast a word integer in the source operand to 32 locations in zmm1 subject to writemask k1.</td>, <td>VEX.128.66.0F38.W0 58 /r VPBROADCASTD xmm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Broadcast a dword integer in the source operand to four locations in xmm1.</td>, <td>VEX.256.66.0F38.W0 58 /r VPBROADCASTD ymm1, xmm2/m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Broadcast a dword integer in the source operand to eight locations in ymm1.</td>, <td>EVEX.128.66.0F38.W0 58 /r VPBROADCASTD xmm1 {k1}{z}, xmm2/m32</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a dword integer in the source operand to locations in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 58 /r VPBROADCASTD ymm1 {k1}{z}, xmm2/m32</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a dword integer in the source operand to locations in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 58 /r VPBROADCASTD zmm1 {k1}{z}, xmm2/m32</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Broadcast a dword integer in the source operand to locations in zmm1 subject to writemask k1.</td>, <td>VEX.128.66.0F38.W0 59 /r VPBROADCASTQ xmm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Broadcast a qword element in source operand to two locations in xmm1.</td>, <td>VEX.256.66.0F38.W0 59 /r VPBROADCASTQ ymm1, xmm2/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Broadcast a qword element in source operand to four locations in ymm1.</td>, <td>EVEX.128.66.0F38.W1 59 /r VPBROADCASTQ xmm1 {k1}{z}, xmm2/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a qword element in source operand to locations in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 59 /r VPBROADCASTQ ymm1 {k1}{z}, xmm2/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a qword element in source operand to locations in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 59 /r VPBROADCASTQ zmm1 {k1}{z}, xmm2/m64</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Broadcast a qword element in source operand to locations in zmm1 subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 59 /r VBROADCASTI32x2 xmm1 {k1}{z}, xmm2/m64</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Broadcast two dword elements in source operand to locations in xmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 59 /r VBROADCASTI32x2 ymm1 {k1}{z}, xmm2/m64</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Broadcast two dword elements in source operand to locations in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 59 /r VBROADCASTI32x2 zmm1 {k1}{z}, xmm2/m64</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Broadcast two dword elements in source operand to locations in zmm1 subject to writemask k1.</td>, <td>VEX.256.66.0F38.W0 5A /r VBROADCASTI128 ymm1, m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Broadcast 128 bits of integer data in mem to low and high 128-bits in ymm1.</td>, <td>EVEX.256.66.0F38.W0 5A /r VBROADCASTI32X4 ymm1 {k1}{z}, m128</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast 128 bits of 4 doubleword integer data in mem to locations in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 5A /r VBROADCASTI32X4 zmm1 {k1}{z}, m128</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Broadcast 128 bits of 4 doubleword integer data in mem to locations in zmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 5A /r VBROADCASTI64X2 ymm1 {k1}{z}, m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Broadcast 128 bits of 2 quadword integer data in mem to locations in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 5A /r VBROADCASTI64X2 zmm1 {k1}{z}, m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Broadcast 128 bits of 2 quadword integer data in mem to locations in zmm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 5B /r VBROADCASTI32X8 zmm1 {k1}{z}, m256</td>, <td>E</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Broadcast 256 bits of 8 doubleword integer data in mem to locations in zmm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 5B /r VBROADCASTI64X4 zmm1 {k1}{z}, m256</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Broadcast 256 bits of 4 quadword integer data in mem to locations in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Tuple2</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>D</td>, <td>Tuple4</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>E</td>, <td>Tuple8</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#UD</td>, <td>If VEX.L = 0 for VPBROADCASTQ, VPBROADCASTI128.</td>, <td>If EVEX.L’L = 0 for VBROADCASTI32X4/VBROADCASTI64X2.</td>, <td>If EVEX.L’L &lt; 10b for VBROADCASTI32X8/VBROADCASTI64X4.</td>]

[<td>EVEX.128.66.0F38.W0 7A /r VPBROADCASTB xmm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast an 8-bit value from a GPR to all bytes in the 128-bit destination subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7A /r VPBROADCASTB ymm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast an 8-bit value from a GPR to all bytes in the 256-bit destination subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7A /r VPBROADCASTB zmm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Broadcast an 8-bit value from a GPR to all bytes in the 512-bit destination subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7B /r VPBROADCASTW xmm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast a 16-bit value from a GPR to all words in the 128-bit destination subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7B /r VPBROADCASTW ymm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast a 16-bit value from a GPR to all words in the 256-bit destination subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7B /r VPBROADCASTW zmm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Broadcast a 16-bit value from a GPR to all words in the 512-bit destination subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7C /r VPBROADCASTD xmm1 {k1}{z}, r32</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a 32-bit value from a GPR to all double-words in the 128-bit destination subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7C /r VPBROADCASTD ymm1 {k1}{z}, r32</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a 32-bit value from a GPR to all double-words in the 256-bit destination subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7C /r VPBROADCASTD zmm1 {k1}{z}, r32</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Broadcast a 32-bit value from a GPR to all double-words in the 512-bit destination subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 7C /r VPBROADCASTQ xmm1 {k1}{z}, r64</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a 64-bit value from a GPR to all quad-words in the 128-bit destination subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7C /r VPBROADCASTQ ymm1 {k1}{z}, r64</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a 64-bit value from a GPR to all quad-words in the 256-bit destination subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7C /r VPBROADCASTQ zmm1 {k1}{z}, r64</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512F</td>, <td>Broadcast a 64-bit value from a GPR to all quad-words in the 512-bit destination subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F38.W0 7A /r VPBROADCASTB xmm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast an 8-bit value from a GPR to all bytes in the 128-bit destination subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7A /r VPBROADCASTB ymm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast an 8-bit value from a GPR to all bytes in the 256-bit destination subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7A /r VPBROADCASTB zmm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Broadcast an 8-bit value from a GPR to all bytes in the 512-bit destination subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7B /r VPBROADCASTW xmm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast a 16-bit value from a GPR to all words in the 128-bit destination subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7B /r VPBROADCASTW ymm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast a 16-bit value from a GPR to all words in the 256-bit destination subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7B /r VPBROADCASTW zmm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Broadcast a 16-bit value from a GPR to all words in the 512-bit destination subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7C /r VPBROADCASTD xmm1 {k1}{z}, r32</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a 32-bit value from a GPR to all double-words in the 128-bit destination subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7C /r VPBROADCASTD ymm1 {k1}{z}, r32</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a 32-bit value from a GPR to all double-words in the 256-bit destination subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7C /r VPBROADCASTD zmm1 {k1}{z}, r32</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Broadcast a 32-bit value from a GPR to all double-words in the 512-bit destination subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 7C /r VPBROADCASTQ xmm1 {k1}{z}, r64</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a 64-bit value from a GPR to all quad-words in the 128-bit destination subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7C /r VPBROADCASTQ ymm1 {k1}{z}, r64</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a 64-bit value from a GPR to all quad-words in the 256-bit destination subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7C /r VPBROADCASTQ zmm1 {k1}{z}, r64</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512F</td>, <td>Broadcast a 64-bit value from a GPR to all quad-words in the 512-bit destination subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W1 2A /r VPBROADCASTMB2Q xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Broadcast low byte value in k1 to two locations in xmm1.</td>, <td>EVEX.256.F3.0F38.W1 2A /r VPBROADCASTMB2Q ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Broadcast low byte value in k1 to four locations in ymm1.</td>, <td>EVEX.512.F3.0F38.W1 2A /r VPBROADCASTMB2Q zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512CD</td>, <td>Broadcast low byte value in k1 to eight locations in zmm1.</td>, <td>EVEX.128.F3.0F38.W0 3A /r VPBROADCASTMW2D xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Broadcast low word value in k1 to four locations in xmm1.</td>, <td>EVEX.256.F3.0F38.W0 3A /r VPBROADCASTMW2D ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Broadcast low word value in k1 to eight locations in ymm1.</td>, <td>EVEX.512.F3.0F38.W0 3A /r VPBROADCASTMW2D zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512CD</td>, <td>Broadcast low word value in k1 to sixteen locations in zmm1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 7A /r VPBROADCASTB xmm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast an 8-bit value from a GPR to all bytes in the 128-bit destination subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7A /r VPBROADCASTB ymm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast an 8-bit value from a GPR to all bytes in the 256-bit destination subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7A /r VPBROADCASTB zmm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Broadcast an 8-bit value from a GPR to all bytes in the 512-bit destination subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7B /r VPBROADCASTW xmm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast a 16-bit value from a GPR to all words in the 128-bit destination subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7B /r VPBROADCASTW ymm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast a 16-bit value from a GPR to all words in the 256-bit destination subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7B /r VPBROADCASTW zmm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Broadcast a 16-bit value from a GPR to all words in the 512-bit destination subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7C /r VPBROADCASTD xmm1 {k1}{z}, r32</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a 32-bit value from a GPR to all double-words in the 128-bit destination subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7C /r VPBROADCASTD ymm1 {k1}{z}, r32</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a 32-bit value from a GPR to all double-words in the 256-bit destination subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7C /r VPBROADCASTD zmm1 {k1}{z}, r32</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Broadcast a 32-bit value from a GPR to all double-words in the 512-bit destination subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 7C /r VPBROADCASTQ xmm1 {k1}{z}, r64</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a 64-bit value from a GPR to all quad-words in the 128-bit destination subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7C /r VPBROADCASTQ ymm1 {k1}{z}, r64</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a 64-bit value from a GPR to all quad-words in the 256-bit destination subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7C /r VPBROADCASTQ zmm1 {k1}{z}, r64</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512F</td>, <td>Broadcast a 64-bit value from a GPR to all quad-words in the 512-bit destination subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F38.W0 7A /r VPBROADCASTB xmm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast an 8-bit value from a GPR to all bytes in the 128-bit destination subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7A /r VPBROADCASTB ymm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast an 8-bit value from a GPR to all bytes in the 256-bit destination subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7A /r VPBROADCASTB zmm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Broadcast an 8-bit value from a GPR to all bytes in the 512-bit destination subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7B /r VPBROADCASTW xmm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast a 16-bit value from a GPR to all words in the 128-bit destination subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7B /r VPBROADCASTW ymm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Broadcast a 16-bit value from a GPR to all words in the 256-bit destination subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7B /r VPBROADCASTW zmm1 {k1}{z}, reg</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Broadcast a 16-bit value from a GPR to all words in the 512-bit destination subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7C /r VPBROADCASTD xmm1 {k1}{z}, r32</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a 32-bit value from a GPR to all double-words in the 128-bit destination subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7C /r VPBROADCASTD ymm1 {k1}{z}, r32</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a 32-bit value from a GPR to all double-words in the 256-bit destination subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7C /r VPBROADCASTD zmm1 {k1}{z}, r32</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Broadcast a 32-bit value from a GPR to all double-words in the 512-bit destination subject to writemask k1.</td>, <td>EVEX.128.66.0F38.W1 7C /r VPBROADCASTQ xmm1 {k1}{z}, r64</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a 64-bit value from a GPR to all quad-words in the 128-bit destination subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7C /r VPBROADCASTQ ymm1 {k1}{z}, r64</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512VL AVX512F</td>, <td>Broadcast a 64-bit value from a GPR to all quad-words in the 256-bit destination subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7C /r VPBROADCASTQ zmm1 {k1}{z}, r64</td>, <td>A</td>, <td>V/N.E.<sup>1</sup></td>, <td>AVX512F</td>, <td>Broadcast a 64-bit value from a GPR to all quad-words in the 512-bit destination subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F3A.W0 3F /r ib VPCMPB k1 {k2}, xmm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte values in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F3A.W0 3F /r ib VPCMPB k1 {k2}, ymm2, ymm3/m256, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte values in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.512.66.0F3A.W0 3F /r ib VPCMPB k1 {k2}, zmm2, zmm3/m512, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed byte values in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.128.66.0F3A.W0 3E /r ib VPCMPUB k1 {k2}, xmm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned byte values in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F3A.W0 3E /r ib VPCMPUB k1 {k2}, ymm2, ymm3/m256, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned byte values in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.512.66.0F3A.W0 3E /r ib VPCMPUB k1 {k2}, zmm2, zmm3/m512, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed unsigned byte values in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>VPCMPEQ* <em>reg1, reg2, reg3</em></td>, <td>VPCMP* <em>reg1, reg2, reg3, 0</em></td>, <td>VPCMPLT* <em>reg1, reg2, reg3</em></td>, <td>VPCMP*<em>reg1, reg2, reg3, 1</em></td>, <td>VPCMPLE* <em>reg1, reg2, reg3</em></td>, <td>VPCMP* <em>reg1, reg2, reg3, 2</em></td>, <td>VPCMPNEQ* <em>reg1, reg2, reg3</em></td>, <td>VPCMP* <em>reg1, reg2, reg3, 4</em></td>, <td>VPPCMPNLT* <em>reg1, reg2, reg3</em></td>, <td>VPCMP* <em>reg1, reg2, reg3, 5</em></td>, <td>VPCMPNLE* <em>reg1, reg2, reg3</em></td>, <td>VPCMP* <em>reg1, reg2, reg3, 6</em></td>]

[<td>EVEX.128.66.0F3A.W0 1F /r ib VPCMPD k1 {k2}, xmm2, xmm3/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F3A.W0 1F /r ib VPCMPD k1 {k2}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.512.66.0F3A.W0 1F /r ib VPCMPD k1 {k2}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed signed doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.</td>, <td>EVEX.128.66.0F3A.W0 1E /r ib VPCMPUD k1 {k2}, xmm2, xmm3/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F3A.W0 1E /r ib VPCMPUD k1 {k2}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.512.66.0F3A.W0 1E /r ib VPCMPUD k1 {k2}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed unsigned doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>]

[<td>EVEX.128.66.0F3A.W1 1F /r ib VPCMPQ k1 {k2}, xmm2, xmm3/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F3A.W1 1F /r ib VPCMPQ k1 {k2}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.512.66.0F3A.W1 1F /r ib VPCMPQ k1 {k2}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed signed quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.128.66.0F3A.W1 1E /r ib VPCMPUQ k1 {k2}, xmm2, xmm3/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F3A.W1 1E /r ib VPCMPUQ k1 {k2}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.512.66.0F3A.W1 1E /r ib VPCMPUQ k1 {k2}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed unsigned quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>]

[<td>EVEX.128.66.0F3A.W0 3F /r ib VPCMPB k1 {k2}, xmm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte values in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F3A.W0 3F /r ib VPCMPB k1 {k2}, ymm2, ymm3/m256, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed byte values in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.512.66.0F3A.W0 3F /r ib VPCMPB k1 {k2}, zmm2, zmm3/m512, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed byte values in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.128.66.0F3A.W0 3E /r ib VPCMPUB k1 {k2}, xmm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned byte values in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F3A.W0 3E /r ib VPCMPUB k1 {k2}, ymm2, ymm3/m256, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned byte values in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.512.66.0F3A.W0 3E /r ib VPCMPUB k1 {k2}, zmm2, zmm3/m512, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed unsigned byte values in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>VPCMPEQ* <em>reg1, reg2, reg3</em></td>, <td>VPCMP* <em>reg1, reg2, reg3, 0</em></td>, <td>VPCMPLT* <em>reg1, reg2, reg3</em></td>, <td>VPCMP*<em>reg1, reg2, reg3, 1</em></td>, <td>VPCMPLE* <em>reg1, reg2, reg3</em></td>, <td>VPCMP* <em>reg1, reg2, reg3, 2</em></td>, <td>VPCMPNEQ* <em>reg1, reg2, reg3</em></td>, <td>VPCMP* <em>reg1, reg2, reg3, 4</em></td>, <td>VPPCMPNLT* <em>reg1, reg2, reg3</em></td>, <td>VPCMP* <em>reg1, reg2, reg3, 5</em></td>, <td>VPCMPNLE* <em>reg1, reg2, reg3</em></td>, <td>VPCMP* <em>reg1, reg2, reg3, 6</em></td>]

[<td>EVEX.128.66.0F3A.W0 1F /r ib VPCMPD k1 {k2}, xmm2, xmm3/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F3A.W0 1F /r ib VPCMPD k1 {k2}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.512.66.0F3A.W0 1F /r ib VPCMPD k1 {k2}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed signed doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.</td>, <td>EVEX.128.66.0F3A.W0 1E /r ib VPCMPUD k1 {k2}, xmm2, xmm3/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned doubleword integer values in xmm3/m128/m32bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F3A.W0 1E /r ib VPCMPUD k1 {k2}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned doubleword integer values in ymm3/m256/m32bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.512.66.0F3A.W0 1E /r ib VPCMPUD k1 {k2}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed unsigned doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>]

[<td>EVEX.128.66.0F3A.W1 1F /r ib VPCMPQ k1 {k2}, xmm2, xmm3/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F3A.W1 1F /r ib VPCMPQ k1 {k2}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed signed quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.512.66.0F3A.W1 1F /r ib VPCMPQ k1 {k2}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed signed quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.128.66.0F3A.W1 1E /r ib VPCMPUQ k1 {k2}, xmm2, xmm3/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned quadword integer values in xmm3/m128/m64bcst and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F3A.W1 1E /r ib VPCMPUQ k1 {k2}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compare packed unsigned quadword integer values in ymm3/m256/m64bcst and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.512.66.0F3A.W1 1E /r ib VPCMPUQ k1 {k2}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compare packed unsigned quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>]

[<td>EVEX.128.66.0F3A.W1 3F /r ib VPCMPW k1 {k2}, xmm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F3A.W1 3F /r ib VPCMPW k1 {k2}, ymm2, ymm3/m256, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.512.66.0F3A.W1 3F /r ib VPCMPW k1 {k2}, zmm2, zmm3/m512, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed word integers in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.128.66.0F3A.W1 3E /r ib VPCMPUW k1 {k2}, xmm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned word integers in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F3A.W1 3E /r ib VPCMPUW k1 {k2}, ymm2, ymm3/m256, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned word integers in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>VPCMPUW k1 {k2}, zmm2, zmm3/m512, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed unsigned word integers in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F3A.W1 3F /r ib VPCMPW k1 {k2}, xmm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F3A.W1 3F /r ib VPCMPW k1 {k2}, ymm2, ymm3/m256, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed signed word integers in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.512.66.0F3A.W1 3F /r ib VPCMPW k1 {k2}, zmm2, zmm3/m512, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed signed word integers in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.128.66.0F3A.W1 3E /r ib VPCMPUW k1 {k2}, xmm2, xmm3/m128, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned word integers in xmm3/m128 and xmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>EVEX.256.66.0F3A.W1 3E /r ib VPCMPUW k1 {k2}, ymm2, ymm3/m256, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Compare packed unsigned word integers in ymm3/m256 and ymm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>VPCMPUW k1 {k2}, zmm2, zmm3/m512, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Compare packed unsigned word integers in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 8B /r VPCOMPRESSD xmm1/m128 {k1}{z}, xmm2</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compress packed doubleword integer values from xmm2 to xmm1/m128 using controlmask k1.</td>, <td>EVEX.256.66.0F38.W0 8B /r VPCOMPRESSD ymm1/m256 {k1}{z}, ymm2</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compress packed doubleword integer values from ymm2 to ymm1/m256 using controlmask k1.</td>, <td>EVEX.512.66.0F38.W0 8B /r VPCOMPRESSD zmm1/m512 {k1}{z}, zmm2</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compress packed doubleword integer values from zmm2 to zmm1/m512 using controlmask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 8B /r VPCOMPRESSQ xmm1/m128 {k1}{z}, xmm2</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compress packed quadword integer values from xmm2 to xmm1/m128 using controlmask k1.</td>, <td>EVEX.256.66.0F38.W1 8B /r VPCOMPRESSQ ymm1/m256 {k1}{z}, ymm2</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Compress packed quadword integer values from ymm2 to ymm1/m256 using controlmask k1.</td>, <td>EVEX.512.66.0F38.W1 8B /r VPCOMPRESSQ zmm1/m512 {k1}{z}, zmm2</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Compress packed quadword integer values from zmm2 to zmm1/m512 using controlmask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 C4 /r VPCONFLICTD xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Detect duplicate double-word values in xmm2/m128/m32bcst using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 C4 /r VPCONFLICTD ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Detect duplicate double-word values in ymm2/m256/m32bcst using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 C4 /r VPCONFLICTD zmm1 {k1}{z}, zmm2/m512/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512CD</td>, <td>Detect duplicate double-word values in zmm2/m512/m32bcst using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 C4 /r VPCONFLICTQ xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Detect duplicate quad-word values in xmm2/m128/m64bcst using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 C4 /r VPCONFLICTQ ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Detect duplicate quad-word values in ymm2/m256/m64bcst using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 C4 /r VPCONFLICTQ zmm1 {k1}{z}, zmm2/m512/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512CD</td>, <td>Detect duplicate quad-word values in zmm2/m512/m64bcst using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 C4 /r VPCONFLICTD xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Detect duplicate double-word values in xmm2/m128/m32bcst using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 C4 /r VPCONFLICTD ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Detect duplicate double-word values in ymm2/m256/m32bcst using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 C4 /r VPCONFLICTD zmm1 {k1}{z}, zmm2/m512/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512CD</td>, <td>Detect duplicate double-word values in zmm2/m512/m32bcst using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 C4 /r VPCONFLICTQ xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Detect duplicate quad-word values in xmm2/m128/m64bcst using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 C4 /r VPCONFLICTQ ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Detect duplicate quad-word values in ymm2/m256/m64bcst using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 C4 /r VPCONFLICTQ zmm1 {k1}{z}, zmm2/m512/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512CD</td>, <td>Detect duplicate quad-word values in zmm2/m512/m64bcst using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>VEX.256.66.0F3A.W0 06 /r ib VPERM2F128 <em>ymm1, ymm2, ymm3/m256, imm8</em></td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX</td>, <td>Permute 128-bit floating-point fields in <em>ymm2</em> and <em>ymm3/mem</em> using controls from <em>imm8</em> and store result in <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RVMI</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>imm8</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 0</td>, <td>If VEX.W = 1.</td>]

[<td>VEX.256.66.0F3A.W0 46 /r ib VPERM2I128 <em>ymm1, ymm2, ymm3/m256, imm8</em></td>, <td>RVMI</td>, <td>V/V</td>, <td>AVX2</td>, <td>Permute 128-bit integer data in <em>ymm2</em> and <em>ymm3/mem</em> using controls from <em>imm8</em> and store result in <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RVMI</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 0,</td>, <td>If VEX.W = 1.</td>]

[<td>EVEX.128.66.0F38.W0 8D /r VPERMB xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512_VBMI</td>, <td>Permute bytes in xmm3/m128 using byte indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 8D /r VPERMB ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512_VBMI</td>, <td>Permute bytes in ymm3/m256 using byte indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 8D /r VPERMB zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_VBMI</td>, <td>Permute bytes in zmm3/m512 using byte indexes in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.256.66.0F38.W0 36 /r VPERMD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Permute doublewords in ymm3/m256 using indices in ymm2 and store the result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 36 /r VPERMD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute doublewords in ymm3/m256/m32bcst using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 36 /r VPERMD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute doublewords in zmm3/m512/m32bcst using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 8D /r VPERMW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers in xmm3/m128 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 8D /r VPERMW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers in ymm3/m256 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 8D /r VPERMW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Permute word integers in zmm3/m512 using indexes in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 0.</td>, <td>If EVEX.L’L = 0 for VPERMD.</td>]

[<td>EVEX.128.66.0F38.W0 75 /r VPERMI2B xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512_VBMI</td>, <td>Permute bytes in xmm3/m128 and xmm2 using byte indexes in xmm1 and store the byte results in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 75 /r VPERMI2B ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512_VBMI</td>, <td>Permute bytes in ymm3/m256 and ymm2 using byte indexes in ymm1 and store the byte results in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 75 /r VPERMI2B zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_VBMI</td>, <td>Permute bytes in zmm3/m512 and zmm2 using byte indexes in zmm1 and store the byte results in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 75 /r VPERMI2W xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in xmm3/m128 and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 75 /r VPERMI2W ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in ymm3/m256 and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 75 /r VPERMI2W zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Permute word integers from two tables in zmm3/m512 and zmm2 using indexes in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 76 /r VPERMI2D xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 76 /r VPERMI2D ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 76 /r VPERMI2D zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-words from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 76 /r VPERMI2Q xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 76 /r VPERMI2Q ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 76 /r VPERMI2Q zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute quad-words from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 77 /r VPERMI2PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 77 /r VPERMI2PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 77 /r VPERMI2PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 77 /r VPERMI2PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 77 /r VPERMI2PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 77 /r VPERMI2PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (r,w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 75 /r VPERMI2W xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in xmm3/m128 and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 75 /r VPERMI2W ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in ymm3/m256 and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 75 /r VPERMI2W zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Permute word integers from two tables in zmm3/m512 and zmm2 using indexes in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 76 /r VPERMI2D xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 76 /r VPERMI2D ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 76 /r VPERMI2D zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-words from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 76 /r VPERMI2Q xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 76 /r VPERMI2Q ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 76 /r VPERMI2Q zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute quad-words from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 77 /r VPERMI2PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 77 /r VPERMI2PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 77 /r VPERMI2PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 77 /r VPERMI2PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 77 /r VPERMI2PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 77 /r VPERMI2PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (r,w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 75 /r VPERMI2W xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in xmm3/m128 and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 75 /r VPERMI2W ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in ymm3/m256 and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 75 /r VPERMI2W zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Permute word integers from two tables in zmm3/m512 and zmm2 using indexes in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 76 /r VPERMI2D xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 76 /r VPERMI2D ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 76 /r VPERMI2D zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-words from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 76 /r VPERMI2Q xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 76 /r VPERMI2Q ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 76 /r VPERMI2Q zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute quad-words from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 77 /r VPERMI2PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 77 /r VPERMI2PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 77 /r VPERMI2PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 77 /r VPERMI2PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 77 /r VPERMI2PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 77 /r VPERMI2PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (r,w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 75 /r VPERMI2W xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in xmm3/m128 and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 75 /r VPERMI2W ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in ymm3/m256 and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 75 /r VPERMI2W zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Permute word integers from two tables in zmm3/m512 and zmm2 using indexes in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 76 /r VPERMI2D xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 76 /r VPERMI2D ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 76 /r VPERMI2D zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-words from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 76 /r VPERMI2Q xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 76 /r VPERMI2Q ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 76 /r VPERMI2Q zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute quad-words from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 77 /r VPERMI2PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 77 /r VPERMI2PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 77 /r VPERMI2PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 77 /r VPERMI2PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 77 /r VPERMI2PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 77 /r VPERMI2PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (r,w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 75 /r VPERMI2W xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in xmm3/m128 and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 75 /r VPERMI2W ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in ymm3/m256 and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 75 /r VPERMI2W zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Permute word integers from two tables in zmm3/m512 and zmm2 using indexes in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 76 /r VPERMI2D xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 76 /r VPERMI2D ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 76 /r VPERMI2D zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-words from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 76 /r VPERMI2Q xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 76 /r VPERMI2Q ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 76 /r VPERMI2Q zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute quad-words from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 77 /r VPERMI2PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 77 /r VPERMI2PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 77 /r VPERMI2PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 77 /r VPERMI2PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm2 using indexes in xmm1 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 77 /r VPERMI2PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm2 using indexes in ymm1 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 77 /r VPERMI2PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (r,w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 0D /r VPERMILPD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Permute double-precision floating-point values in xmm2 using controls from xmm3/m128 and store result in xmm1.</td>, <td>VEX.256.66.0F38.W0 0D /r VPERMILPD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Permute double-precision floating-point values in ymm2 using controls from ymm3/m256 and store result in ymm1.</td>, <td>EVEX.128.66.0F38.W1 0D /r VPERMILPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision floating-point values in xmm2 using control from xmm3/m128/m64bcst and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 0D /r VPERMILPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision floating-point values in ymm2 using control from ymm3/m256/m64bcst and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 0D /r VPERMILPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-precision floating-point values in zmm2 using control from zmm3/m512/m64bcst and store the result in zmm1 using writemask k1.</td>, <td>VEX.128.66.0F3A.W0 05 /r ib VPERMILPD xmm1, xmm2/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Permute double-precision floating-point values in xmm2/m128 using controls from imm8.</td>, <td>VEX.256.66.0F3A.W0 05 /r ib VPERMILPD ymm1, ymm2/m256, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Permute double-precision floating-point values in ymm2/m256 using controls from imm8.</td>, <td>EVEX.128.66.0F3A.W1 05 /r ib VPERMILPD xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision floating-point values in xmm2/m128/m64bcst using controls from imm8 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 05 /r ib VPERMILPD ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision floating-point values in ymm2/m256/m64bcst using controls from imm8 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 05 /r ib VPERMILPD zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-precision floating-point values in zmm2/m512/m64bcst using controls from imm8 and store the result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.W = 1.</td>, <td>#UD</td>, <td>If either (E)VEX.vvvv != 1111B and with imm8.</td>]

[<td>VEX.128.66.0F38.W0 0C /r VPERMILPS xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Permute single-precision floating-point values in xmm2 using controls from xmm3/m128 and store result in xmm1.</td>, <td>VEX.128.66.0F3A.W0 04 /r ib VPERMILPS xmm1, xmm2/m128, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Permute single-precision floating-point values in xmm2/m128 using controls from imm8 and store result in xmm1.</td>, <td>VEX.256.66.0F38.W0 0C /r VPERMILPS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX</td>, <td>Permute single-precision floating-point values in ymm2 using controls from ymm3/m256 and store result in ymm1.</td>, <td>VEX.256.66.0F3A.W0 04 /r ib VPERMILPS ymm1, ymm2/m256, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Permute single-precision floating-point values in ymm2/m256 using controls from imm8 and store result in ymm1.</td>, <td>EVEX.128.66.0F38.W0 0C /r VPERMILPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision floating-point values xmm2 using control from xmm3/m128/m32bcst and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 0C /r VPERMILPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision floating-point values ymm2 using control from ymm3/m256/m32bcst and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 0C /r VPERMILPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute single-precision floating-point values zmm2 using control from zmm3/m512/m32bcst and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F3A.W0 04 /r ib VPERMILPS xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision floating-point values xmm2/m128/m32bcst using controls from imm8 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F3A.W0 04 /r ib VPERMILPS ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision floating-point values ymm2/m256/m32bcst using controls from imm8 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 04 /r ibVPERMILPS zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>D</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute single-precision floating-point values zmm2/m512/m32bcst using controls from imm8 and store the result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>D</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.W = 1.</td>, <td>#UD</td>, <td>If either (E)VEX.vvvv != 1111B and with imm8.</td>]

[<td>VEX.256.66.0F3A.W1 01 /r ib VPERMPD ymm1, ymm2/m256, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Permute double-precision floating-point elements in ymm2/m256 using indices in imm8 and store the result in ymm1.</td>, <td>EVEX.256.66.0F3A.W1 01 /r ib VPERMPD ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision floating-point elements in ymm2/m256/m64bcst using indexes in imm8 and store the result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 01 /r ib VPERMPD zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-precision floating-point elements in zmm2/m512/m64bcst using indices in imm8 and store the result in zmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F38.W1 16 /r VPERMPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision floating-point elements in ymm3/m256/m64bcst using indexes in ymm2 and store the result in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F38.W1 16 /r VPERMPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-precision floating-point elements in zmm3/m512/m64bcst using indices in zmm2 and store the result in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 0.</td>, <td>If VEX.vvvv != 1111B.</td>, <td rowspan="2">#UD</td>, <td>If encoded with EVEX.128.</td>, <td>If EVEX.vvvv != 1111B and with imm8.</td>]

[<td>VEX.256.66.0F38.W0 16 /r VPERMPS ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Permute single-precision floating-point elements in ymm3/m256 using indices in ymm2 and store the result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 16 /r VPERMPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision floating-point elements in ymm3/m256/m32bcst using indexes in ymm2 and store the result in ymm1 subject to write mask k1.</td>, <td>EVEX.512.66.0F38.W0 16 /r VPERMPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute single-precision floating-point values in zmm3/m512/m32bcst using indices in zmm2 and store the result in zmm1 subject to write mask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If VEX.L = 0.</td>]

[<td>VEX.256.66.0F3A.W1 00 /r ib VPERMQ ymm1, ymm2/m256, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Permute qwords in ymm2/m256 using indices in imm8 and store the result in ymm1.</td>, <td>EVEX.256.66.0F3A.W1 00 /r ib VPERMQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute qwords in ymm2/m256/m64bcst using indexes in imm8 and store the result in ymm1.</td>, <td>EVEX.512.66.0F3A.W1 00 /r ib VPERMQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute qwords in zmm2/m512/m64bcst using indices in imm8 and store the result in zmm1.</td>, <td>EVEX.256.66.0F38.W1 36 /r VPERMQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute qwords in ymm3/m256/m64bcst using indexes in ymm2 and store the result in ymm1.</td>, <td>EVEX.512.66.0F38.W1 36 /r VPERMQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute qwords in zmm3/m512/m64bcst using indices in zmm2 and store the result in zmm1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 0.</td>, <td>If VEX.vvvv != 1111B.</td>, <td rowspan="2">#UD</td>, <td>If encoded with EVEX.128.</td>, <td>If EVEX.vvvv != 1111B and with imm8.</td>]

[<td>EVEX.128.66.0F38.W0 7D /r VPERMT2B xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512_VBMI</td>, <td>Permute bytes in xmm3/m128 and xmm1 using byte indexes in xmm2 and store the byte results in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7D /r VPERMT2B ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512_VBMI</td>, <td>Permute bytes in ymm3/m256 and ymm1 using byte indexes in ymm2 and store the byte results in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7D /r VPERMT2B zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_VBMI</td>, <td>Permute bytes in zmm3/m512 and zmm1 using byte indexes in zmm2 and store the byte results in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 7D /r VPERMT2W xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in xmm3/m128 and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7D /r VPERMT2W ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in ymm3/m256 and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7D /r VPERMT2W zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Permute word integers from two tables in zmm3/m512 and zmm1 using indexes in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7E /r VPERMT2D xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7E /r VPERMT2D ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7E /r VPERMT2D zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-words from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 7E /r VPERMT2Q xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7E /r VPERMT2Q ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7E /r VPERMT2Q zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute quad-words from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7F /r VPERMT2PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7F /r VPERMT2PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7F /r VPERMT2PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 7F /r VPERMT2PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7F /r VPERMT2PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7F /r VPERMT2PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (r,w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 7D /r VPERMT2W xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in xmm3/m128 and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7D /r VPERMT2W ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in ymm3/m256 and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7D /r VPERMT2W zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Permute word integers from two tables in zmm3/m512 and zmm1 using indexes in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7E /r VPERMT2D xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7E /r VPERMT2D ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7E /r VPERMT2D zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-words from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 7E /r VPERMT2Q xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7E /r VPERMT2Q ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7E /r VPERMT2Q zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute quad-words from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7F /r VPERMT2PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7F /r VPERMT2PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7F /r VPERMT2PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 7F /r VPERMT2PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7F /r VPERMT2PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7F /r VPERMT2PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (r,w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 7D /r VPERMT2W xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in xmm3/m128 and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7D /r VPERMT2W ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in ymm3/m256 and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7D /r VPERMT2W zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Permute word integers from two tables in zmm3/m512 and zmm1 using indexes in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7E /r VPERMT2D xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7E /r VPERMT2D ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7E /r VPERMT2D zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-words from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 7E /r VPERMT2Q xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7E /r VPERMT2Q ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7E /r VPERMT2Q zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute quad-words from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7F /r VPERMT2PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7F /r VPERMT2PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7F /r VPERMT2PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 7F /r VPERMT2PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7F /r VPERMT2PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7F /r VPERMT2PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (r,w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 7D /r VPERMT2W xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in xmm3/m128 and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7D /r VPERMT2W ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in ymm3/m256 and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7D /r VPERMT2W zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Permute word integers from two tables in zmm3/m512 and zmm1 using indexes in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7E /r VPERMT2D xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7E /r VPERMT2D ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7E /r VPERMT2D zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-words from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 7E /r VPERMT2Q xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7E /r VPERMT2Q ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7E /r VPERMT2Q zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute quad-words from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7F /r VPERMT2PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7F /r VPERMT2PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7F /r VPERMT2PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 7F /r VPERMT2PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7F /r VPERMT2PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7F /r VPERMT2PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (r,w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 7D /r VPERMT2W xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in xmm3/m128 and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7D /r VPERMT2W ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers from two tables in ymm3/m256 and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7D /r VPERMT2W zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Permute word integers from two tables in zmm3/m512 and zmm1 using indexes in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7E /r VPERMT2D xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7E /r VPERMT2D ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-words from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7E /r VPERMT2D zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-words from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 7E /r VPERMT2Q xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7E /r VPERMT2Q ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute quad-words from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7E /r VPERMT2Q zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute quad-words from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 7F /r VPERMT2PS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in xmm3/m128/m32bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 7F /r VPERMT2PS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute single-precision FP values from two tables in ymm3/m256/m32bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 7F /r VPERMT2PS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 7F /r VPERMT2PD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in xmm3/m128/m64bcst and xmm1 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 7F /r VPERMT2PD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute double-precision FP values from two tables in ymm3/m256/m64bcst and ymm1 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 7F /r VPERMT2PD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (r,w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.256.66.0F38.W0 36 /r VPERMD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Permute doublewords in ymm3/m256 using indices in ymm2 and store the result in ymm1.</td>, <td>EVEX.256.66.0F38.W0 36 /r VPERMD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Permute doublewords in ymm3/m256/m32bcst using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 36 /r VPERMD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Permute doublewords in zmm3/m512/m32bcst using indices in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 8D /r VPERMW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers in xmm3/m128 using indexes in xmm2 and store the result in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 8D /r VPERMW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Permute word integers in ymm3/m256 using indexes in ymm2 and store the result in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 8D /r VPERMW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>C</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Permute word integers in zmm3/m512 using indexes in zmm2 and store the result in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If VEX.L = 0.</td>, <td>If EVEX.L’L = 0 for VPERMD.</td>]

[<td>EVEX.128.66.0F38.W0 89 /r VPEXPANDD xmm1 {k1}{z}, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Expand packed double-word integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 89 /r VPEXPANDD ymm1 {k1}{z}, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Expand packed double-word integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 89 /r VPEXPANDD zmm1 {k1}{z}, zmm2/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Expand packed double-word integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F38.W1 89 /r VPEXPANDQ xmm1 {k1}{z}, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Expand packed quad-word integer values from xmm2/m128 to xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 89 /r VPEXPANDQ ymm1 {k1}{z}, ymm2/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Expand packed quad-word integer values from ymm2/m256 to ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 89 /r VPEXPANDQ zmm1 {k1}{z}, zmm2/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Expand packed quad-word integer values from zmm2/m512 to zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>VEX.128.66.0F38.W0 90 /r VPGATHERDD <em>xmm1, vm32x, xmm2</em></td>, <td>RMV</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using dword indices specified in <em>vm32x</em>, gather dword values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.W0 91 /r VPGATHERQD <em>xmm1, vm64x, xmm2</em></td>, <td>RMV</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using qword indices specified in <em>vm64x</em>, gather dword values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.W0 90 /r VPGATHERDD <em>ymm1, vm32y, ymm2</em></td>, <td>RMV</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using dword indices specified in <em>vm32y</em>, gather dword from memory conditioned on mask specified by <em>ymm2</em>. Conditionally gathered elements are merged into <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.W0 91 /r VPGATHERQD <em>xmm1, vm64y, xmm2</em></td>, <td>RMV</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using qword indices specified in <em>vm64y</em>, gather dword values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMV</td>, <td>ModRM:reg (r,w)</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>VEX.vvvv (r, w)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 90 /vsib VPGATHERDD xmm1 {k1}, vm32x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, gather dword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.256.66.0F38.W0 90 /vsib VPGATHERDD ymm1 {k1}, vm32y</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, gather dword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.512.66.0F38.W0 90 /vsib VPGATHERDD zmm1 {k1}, vm32z</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, gather dword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.128.66.0F38.W1 90 /vsib VPGATHERDQ xmm1 {k1}, vm32x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, gather quadword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.256.66.0F38.W1 90 /vsib VPGATHERDQ ymm1 {k1}, vm32x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, gather quadword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.512.66.0F38.W1 90 /vsib VPGATHERDQ zmm1 {k1}, vm32y</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, gather quadword values from memory using writemask k1 for merging-masking.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 90 /vsib VPGATHERDD xmm1 {k1}, vm32x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, gather dword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.256.66.0F38.W0 90 /vsib VPGATHERDD ymm1 {k1}, vm32y</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, gather dword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.512.66.0F38.W0 90 /vsib VPGATHERDD zmm1 {k1}, vm32z</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, gather dword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.128.66.0F38.W1 90 /vsib VPGATHERDQ xmm1 {k1}, vm32x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, gather quadword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.256.66.0F38.W1 90 /vsib VPGATHERDQ ymm1 {k1}, vm32x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, gather quadword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.512.66.0F38.W1 90 /vsib VPGATHERDQ zmm1 {k1}, vm32y</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, gather quadword values from memory using writemask k1 for merging-masking.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 90 /r VPGATHERDQ <em>xmm1, vm32x, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using dword indices specified in <em>vm32x</em>, gather qword values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.W1 91 /r VPGATHERQQ <em>xmm1, vm64x, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using qword indices specified in <em>vm64x</em>, gather qword values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.W1 90 /r VPGATHERDQ <em>ymm1, vm32x, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using dword indices specified in <em>vm32x</em>, gather qword values from memory conditioned on mask specified by <em>ymm2</em>. Conditionally gathered elements are merged into <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.W1 91 /r VPGATHERQQ <em>ymm1, vm64y, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using qword indices specified in <em>vm64y</em>, gather qword values from memory conditioned on mask specified by <em>ymm2</em>. Conditionally gathered elements are merged into <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>ModRM:reg (r,w)</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>VEX.vvvv (r, w)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 90 /r VPGATHERDD <em>xmm1, vm32x, xmm2</em></td>, <td>RMV</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using dword indices specified in <em>vm32x</em>, gather dword values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.W0 91 /r VPGATHERQD <em>xmm1, vm64x, xmm2</em></td>, <td>RMV</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using qword indices specified in <em>vm64x</em>, gather dword values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.W0 90 /r VPGATHERDD <em>ymm1, vm32y, ymm2</em></td>, <td>RMV</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using dword indices specified in <em>vm32y</em>, gather dword from memory conditioned on mask specified by <em>ymm2</em>. Conditionally gathered elements are merged into <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.W0 91 /r VPGATHERQD <em>xmm1, vm64y, xmm2</em></td>, <td>RMV</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using qword indices specified in <em>vm64y</em>, gather dword values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RMV</td>, <td>ModRM:reg (r,w)</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>VEX.vvvv (r, w)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 91 /vsib VPGATHERQD xmm1 {k1}, vm64x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, gather dword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.256.66.0F38.W0 91 /vsib VPGATHERQD xmm1 {k1}, vm64y</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, gather dword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.512.66.0F38.W0 91 /vsib VPGATHERQD ymm1 {k1}, vm64z</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, gather dword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.128.66.0F38.W1 91 /vsib VPGATHERQQ xmm1 {k1}, vm64x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, gather quadword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.256.66.0F38.W1 91 /vsib VPGATHERQQ ymm1 {k1}, vm64y</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, gather quadword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.512.66.0F38.W1 91 /vsib VPGATHERQQ zmm1 {k1}, vm64z</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, gather quadword values from memory using writemask k1 for merging-masking.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W1 90 /r VPGATHERDQ <em>xmm1, vm32x, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using dword indices specified in <em>vm32x</em>, gather qword values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>VEX.128.66.0F38.W1 91 /r VPGATHERQQ <em>xmm1, vm64x, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using qword indices specified in <em>vm64x</em>, gather qword values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.W1 90 /r VPGATHERDQ <em>ymm1, vm32x, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using dword indices specified in <em>vm32x</em>, gather qword values from memory conditioned on mask specified by <em>ymm2</em>. Conditionally gathered elements are merged into <em>ymm1</em>.</td>, <td>VEX.256.66.0F38.W1 91 /r VPGATHERQQ <em>ymm1, vm64y, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Using qword indices specified in <em>vm64y</em>, gather qword values from memory conditioned on mask specified by <em>ymm2</em>. Conditionally gathered elements are merged into <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>ModRM:reg (r,w)</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>VEX.vvvv (r, w)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 91 /vsib VPGATHERQD xmm1 {k1}, vm64x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, gather dword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.256.66.0F38.W0 91 /vsib VPGATHERQD xmm1 {k1}, vm64y</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, gather dword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.512.66.0F38.W0 91 /vsib VPGATHERQD ymm1 {k1}, vm64z</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, gather dword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.128.66.0F38.W1 91 /vsib VPGATHERQQ xmm1 {k1}, vm64x</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, gather quadword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.256.66.0F38.W1 91 /vsib VPGATHERQQ ymm1 {k1}, vm64y</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, gather quadword values from memory using writemask k1 for merging-masking.</td>, <td>EVEX.512.66.0F38.W1 91 /vsib VPGATHERQQ zmm1 {k1}, vm64z</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, gather quadword values from memory using writemask k1 for merging-masking.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 44 /r VPLZCNTD xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Count the number of leading zero bits in each dword element of xmm2/m128/m32bcst using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 44 /r VPLZCNTD ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Count the number of leading zero bits in each dword element of ymm2/m256/m32bcst using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 44 /r VPLZCNTD zmm1 {k1}{z}, zmm2/m512/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512CD</td>, <td>Count the number of leading zero bits in each dword element of zmm2/m512/m32bcst using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 44 /r VPLZCNTQ xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Count the number of leading zero bits in each qword element of xmm2/m128/m64bcst using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 44 /r VPLZCNTQ ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Count the number of leading zero bits in each qword element of ymm2/m256/m64bcst using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 44 /r VPLZCNTQ zmm1 {k1}{z}, zmm2/m512/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512CD</td>, <td>Count the number of leading zero bits in each qword element of zmm2/m512/m64bcst using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 44 /r VPLZCNTD xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Count the number of leading zero bits in each dword element of xmm2/m128/m32bcst using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 44 /r VPLZCNTD ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Count the number of leading zero bits in each dword element of ymm2/m256/m32bcst using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 44 /r VPLZCNTD zmm1 {k1}{z}, zmm2/m512/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512CD</td>, <td>Count the number of leading zero bits in each dword element of zmm2/m512/m32bcst using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 44 /r VPLZCNTQ xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Count the number of leading zero bits in each qword element of xmm2/m128/m64bcst using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 44 /r VPLZCNTQ ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512CD</td>, <td>Count the number of leading zero bits in each qword element of ymm2/m256/m64bcst using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 44 /r VPLZCNTQ zmm1 {k1}{z}, zmm2/m512/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512CD</td>, <td>Count the number of leading zero bits in each qword element of zmm2/m512/m64bcst using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 B5 /r VPMADD52HUQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_IFMA AVX512VL</td>, <td>Multiply unsigned 52-bit integers in xmm2 and xmm3/m128 and add the high 52 bits of the 104-bit product to the qword unsigned integers in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 B5 /r VPMADD52HUQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_IFMA AVX512VL</td>, <td>Multiply unsigned 52-bit integers in ymm2 and ymm3/m128 and add the high 52 bits of the 104-bit product to the qword unsigned integers in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 B5 /r VPMADD52HUQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_IFMA</td>, <td>Multiply unsigned 52-bit integers in zmm2 and zmm3/m128 and add the high 52 bits of the 104-bit product to the qword unsigned integers in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m(r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 B4 /r VPMADD52LUQ xmm1 {k1}{z}, xmm2,xmm3/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_IFMA AVX512VL</td>, <td>Multiply unsigned 52-bit integers in xmm2 and xmm3/m128 and add the low 52 bits of the 104-bit product to the qword unsigned integers in xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 B4 /r VPMADD52LUQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_IFMA AVX512VL</td>, <td>Multiply unsigned 52-bit integers in ymm2 and ymm3/m128 and add the low 52 bits of the 104-bit product to the qword unsigned integers in ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 B4 /r VPMADD52LUQ zmm1 {k1}{z}, zmm2,zmm3/m512/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_IFMA</td>, <td>Multiply unsigned 52-bit integers in zmm2 and zmm3/m128 and add the low 52 bits of the 104-bit product to the qword unsigned integers in zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m(r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 8C /r VPMASKMOVD <em>xmm1, xmm2, m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Conditionally load dword values from <em>m128</em> using mask in <em>xmm2</em> and store in <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.W0 8C /r VPMASKMOVD <em>ymm1, ymm2, m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Conditionally load dword values from <em>m256</em> using mask in <em>ymm2</em> and store in <em>ymm1</em>.</td>, <td>VEX.128.66.0F38.W1 8C /r VPMASKMOVQ <em>xmm1, xmm2, m128</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Conditionally load qword values from <em>m128</em> using mask in <em>xmm2</em> and store in <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.W1 8C /r VPMASKMOVQ <em>ymm1, ymm2, m256</em></td>, <td>RVM</td>, <td>V/V</td>, <td>AVX2</td>, <td>Conditionally load qword values from <em>m256</em> using mask in <em>ymm2</em> and store in <em>ymm1</em>.</td>, <td>VEX.128.66.0F38.W0 8E /r VPMASKMOVD <em>m128, xmm1, xmm2</em></td>, <td>MVR</td>, <td>V/V</td>, <td>AVX2</td>, <td>Conditionally store dword values from <em>xmm2</em> using mask in <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.W0 8E /r VPMASKMOVD <em>m256, ymm1, ymm2</em></td>, <td>MVR</td>, <td>V/V</td>, <td>AVX2</td>, <td>Conditionally store dword values from <em>ymm2</em> using mask in <em>ymm1</em>.</td>, <td>VEX.128.66.0F38.W1 8E /r VPMASKMOVQ <em>m128, xmm1, xmm2</em></td>, <td>MVR</td>, <td>V/V</td>, <td>AVX2</td>, <td>Conditionally store qword values from <em>xmm2</em> using mask in <em>xmm1</em>.</td>, <td>VEX.256.66.0F38.W1 8E /r VPMASKMOVQ <em>m256, ymm1, ymm2</em></td>, <td>MVR</td>, <td>V/V</td>, <td>AVX2</td>, <td>Conditionally store qword values from <em>ymm2</em> using mask in <em>ymm1</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RVM</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>MVR</td>, <td>ModRM:r/m (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:reg (r)</td>, <td>NA</td>]

[<td>EVEX.128.F3.0F38.W0 29 /r VPMOVB2M k1, xmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in XMM1.</td>, <td>EVEX.256.F3.0F38.W0 29 /r VPMOVB2M k1, ymm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in YMM1.</td>, <td>EVEX.512.F3.0F38.W0 29 /r VPMOVB2M k1, zmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in ZMM1.</td>, <td>EVEX.128.F3.0F38.W1 29 /r VPMOVW2M k1, xmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in XMM1.</td>, <td>EVEX.256.F3.0F38.W1 29 /r VPMOVW2M k1, ymm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in YMM1.</td>, <td>EVEX.512.F3.0F38.W1 29 /r VPMOVW2M k1, zmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in ZMM1.</td>, <td>EVEX.128.F3.0F38.W0 39 /r VPMOVD2M k1, xmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in XMM1.</td>, <td>EVEX.256.F3.0F38.W0 39 /r VPMOVD2M k1, ymm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in YMM1.</td>, <td>EVEX.512.F3.0F38.W0 39 /r VPMOVD2M k1, zmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in ZMM1.</td>, <td>EVEX.128.F3.0F38.W1 39 /r VPMOVQ2M k1, xmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in XMM1.</td>, <td>EVEX.256.F3.0F38.W1 39 /r VPMOVQ2M k1, ymm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in YMM1.</td>, <td>EVEX.512.F3.0F38.W1 39 /r VPMOVQ2M k1, zmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in ZMM1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 29 /r VPMOVB2M k1, xmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in XMM1.</td>, <td>EVEX.256.F3.0F38.W0 29 /r VPMOVB2M k1, ymm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in YMM1.</td>, <td>EVEX.512.F3.0F38.W0 29 /r VPMOVB2M k1, zmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in ZMM1.</td>, <td>EVEX.128.F3.0F38.W1 29 /r VPMOVW2M k1, xmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in XMM1.</td>, <td>EVEX.256.F3.0F38.W1 29 /r VPMOVW2M k1, ymm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in YMM1.</td>, <td>EVEX.512.F3.0F38.W1 29 /r VPMOVW2M k1, zmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in ZMM1.</td>, <td>EVEX.128.F3.0F38.W0 39 /r VPMOVD2M k1, xmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in XMM1.</td>, <td>EVEX.256.F3.0F38.W0 39 /r VPMOVD2M k1, ymm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in YMM1.</td>, <td>EVEX.512.F3.0F38.W0 39 /r VPMOVD2M k1, zmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in ZMM1.</td>, <td>EVEX.128.F3.0F38.W1 39 /r VPMOVQ2M k1, xmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in XMM1.</td>, <td>EVEX.256.F3.0F38.W1 39 /r VPMOVQ2M k1, ymm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in YMM1.</td>, <td>EVEX.512.F3.0F38.W1 39 /r VPMOVQ2M k1, zmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in ZMM1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 31 /<em>r</em> VPMOVDB <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed double-word integers from <em>xmm2</em> into 4 packed byte integers in <em>xmm1/m32</em> with truncation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 21 /<em>r</em> VPMOVSDB <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed signed double-word integers from <em>xmm2</em> into 4 packed signed byte integers in <em>xmm1/m32</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 11 /<em>r</em> VPMOVUSDB <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed unsigned double-word integers from <em>xmm2</em> into 4 packed unsigned byte integers in <em>xmm1/m32</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 31 /<em>r</em> VPMOVDB <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed double-word integers from <em>ymm2</em> into 8 packed byte integers in <em>xmm1/m64</em> with truncation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 21 /<em>r</em> VPMOVSDB <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed signed double-word integers from <em>ymm2</em> into 8 packed signed byte integers in <em>xmm1/m64</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 11 /<em>r</em> VPMOVUSDB <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed unsigned double-word integers from <em>ymm2</em> into 8 packed unsigned byte integers in <em>xmm1/m64</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 31 /<em>r</em> VPMOVDB <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed double-word integers from <em>zmm2</em> into 16 packed byte integers in <em>xmm1/m128</em> with truncation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 21 /<em>r</em> VPMOVSDB <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed signed double-word integers from <em>zmm2</em> into 16 packed signed byte integers in <em>xmm1/m128</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 11 /<em>r</em> VPMOVUSDB <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed unsigned double-word integers from <em>zmm2</em> into 16 packed unsigned byte integers in <em>xmm1/m128</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Quarter Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 33 /<em>r</em> VPMOVDW <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed double-word integers from <em>xmm2</em> into 4 packed word integers in <em>xmm1/m64</em> with truncation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 23 /<em>r</em> VPMOVSDW <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed signed double-word integers from <em>xmm2</em> into 4 packed signed word integers in <em>ymm1/m64</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 13 /<em>r</em> VPMOVUSDW <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed unsigned double-word integers from <em>xmm2</em> into 4 packed unsigned word integers in <em>xmm1/m64</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 33 /<em>r</em> VPMOVDW <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed double-word integers from <em>ymm2</em> into 8 packed word integers in <em>xmm1/m128</em> with truncation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 23 /<em>r</em> VPMOVSDW <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed signed double-word integers from <em>ymm2</em> into 8 packed signed word integers in <em>xmm1/m128</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 13 /<em>r</em> VPMOVUSDW <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed unsigned double-word integers from <em>ymm2</em> into 8 packed unsigned word integers in <em>xmm1/m128</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 33 /<em>r</em> VPMOVDW <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed double-word integers from <em>zmm2</em> into 16 packed word integers in <em>ymm1/m256</em> with truncation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 23 /<em>r</em> VPMOVSDW <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed signed double-word integers from <em>zmm2</em> into 16 packed signed word integers in <em>ymm1/m256</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 13 /<em>r</em> VPMOVUSDW <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed unsigned double-word integers from <em>zmm2</em> into 16 packed unsigned word integers in <em>ymm1/m256</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Half Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 28 /r VPMOVM2B xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each byte in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.256.F3.0F38.W0 28 /r VPMOVM2B ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each byte in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.512.F3.0F38.W0 28 /r VPMOVM2B zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sets each byte in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.128.F3.0F38.W1 28 /r VPMOVM2W xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each word in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.256.F3.0F38.W1 28 /r VPMOVM2W ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each word in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.512.F3.0F38.W1 28 /r VPMOVM2W zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sets each word in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.128.F3.0F38.W0 38 /r VPMOVM2D xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each doubleword in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.256.F3.0F38.W0 38 /r VPMOVM2D ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each doubleword in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.512.F3.0F38.W0 38 /r VPMOVM2D zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Sets each doubleword in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.128.F3.0F38.W1 38 /r VPMOVM2Q xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each quadword in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.256.F3.0F38.W1 38 /r VPMOVM2Q ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each quadword in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.512.F3.0F38.W1 38 /r VPMOVM2Q zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Sets each quadword in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 28 /r VPMOVM2B xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each byte in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.256.F3.0F38.W0 28 /r VPMOVM2B ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each byte in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.512.F3.0F38.W0 28 /r VPMOVM2B zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sets each byte in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.128.F3.0F38.W1 28 /r VPMOVM2W xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each word in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.256.F3.0F38.W1 28 /r VPMOVM2W ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each word in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.512.F3.0F38.W1 28 /r VPMOVM2W zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sets each word in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.128.F3.0F38.W0 38 /r VPMOVM2D xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each doubleword in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.256.F3.0F38.W0 38 /r VPMOVM2D ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each doubleword in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.512.F3.0F38.W0 38 /r VPMOVM2D zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Sets each doubleword in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.128.F3.0F38.W1 38 /r VPMOVM2Q xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each quadword in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.256.F3.0F38.W1 38 /r VPMOVM2Q ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each quadword in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.512.F3.0F38.W1 38 /r VPMOVM2Q zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Sets each quadword in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 28 /r VPMOVM2B xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each byte in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.256.F3.0F38.W0 28 /r VPMOVM2B ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each byte in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.512.F3.0F38.W0 28 /r VPMOVM2B zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sets each byte in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.128.F3.0F38.W1 28 /r VPMOVM2W xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each word in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.256.F3.0F38.W1 28 /r VPMOVM2W ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each word in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.512.F3.0F38.W1 28 /r VPMOVM2W zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sets each word in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.128.F3.0F38.W0 38 /r VPMOVM2D xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each doubleword in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.256.F3.0F38.W0 38 /r VPMOVM2D ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each doubleword in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.512.F3.0F38.W0 38 /r VPMOVM2D zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Sets each doubleword in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.128.F3.0F38.W1 38 /r VPMOVM2Q xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each quadword in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.256.F3.0F38.W1 38 /r VPMOVM2Q ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each quadword in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.512.F3.0F38.W1 38 /r VPMOVM2Q zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Sets each quadword in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 28 /r VPMOVM2B xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each byte in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.256.F3.0F38.W0 28 /r VPMOVM2B ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each byte in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.512.F3.0F38.W0 28 /r VPMOVM2B zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sets each byte in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.128.F3.0F38.W1 28 /r VPMOVM2W xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each word in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.256.F3.0F38.W1 28 /r VPMOVM2W ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each word in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.512.F3.0F38.W1 28 /r VPMOVM2W zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sets each word in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.128.F3.0F38.W0 38 /r VPMOVM2D xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each doubleword in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.256.F3.0F38.W0 38 /r VPMOVM2D ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each doubleword in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.512.F3.0F38.W0 38 /r VPMOVM2D zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Sets each doubleword in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.128.F3.0F38.W1 38 /r VPMOVM2Q xmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each quadword in XMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.256.F3.0F38.W1 38 /r VPMOVM2Q ymm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each quadword in YMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>EVEX.512.F3.0F38.W1 38 /r VPMOVM2Q zmm1, k1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Sets each quadword in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 29 /r VPMOVB2M k1, xmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in XMM1.</td>, <td>EVEX.256.F3.0F38.W0 29 /r VPMOVB2M k1, ymm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in YMM1.</td>, <td>EVEX.512.F3.0F38.W0 29 /r VPMOVB2M k1, zmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in ZMM1.</td>, <td>EVEX.128.F3.0F38.W1 29 /r VPMOVW2M k1, xmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in XMM1.</td>, <td>EVEX.256.F3.0F38.W1 29 /r VPMOVW2M k1, ymm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in YMM1.</td>, <td>EVEX.512.F3.0F38.W1 29 /r VPMOVW2M k1, zmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in ZMM1.</td>, <td>EVEX.128.F3.0F38.W0 39 /r VPMOVD2M k1, xmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in XMM1.</td>, <td>EVEX.256.F3.0F38.W0 39 /r VPMOVD2M k1, ymm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in YMM1.</td>, <td>EVEX.512.F3.0F38.W0 39 /r VPMOVD2M k1, zmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in ZMM1.</td>, <td>EVEX.128.F3.0F38.W1 39 /r VPMOVQ2M k1, xmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in XMM1.</td>, <td>EVEX.256.F3.0F38.W1 39 /r VPMOVQ2M k1, ymm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in YMM1.</td>, <td>EVEX.512.F3.0F38.W1 39 /r VPMOVQ2M k1, zmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in ZMM1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 32 /<em>r</em> VPMOVQB <em>xmm1/m16 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed quad-word integers from <em>xmm2</em> into 2 packed byte integers in <em>xmm1/m16</em> with truncation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 22 /<em>r</em> VPMOVSQB <em>xmm1/m16 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed signed quad-word integers from <em>xmm2</em> into 2 packed signed byte integers in <em>xmm1/m16</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 12 /<em>r</em> VPMOVUSQB <em>xmm1/m16 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed unsigned quad-word integers from <em>xmm2</em> into 2 packed unsigned byte integers in <em>xmm1/m16</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 32 /<em>r</em> VPMOVQB <em>xmm1/m32 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed quad-word integers from <em>ymm2</em> into 4 packed byte integers in <em>xmm1/m32</em> with truncation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 22 /<em>r</em> VPMOVSQB <em>xmm1/m32 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed signed quad-word integers from <em>ymm2</em> into 4 packed signed byte integers in <em>xmm1/m32</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 12 /<em>r</em> VPMOVUSQB <em>xmm1/m32 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed unsigned quad-word integers from <em>ymm2</em> into 4 packed unsigned byte integers in <em>xmm1/m32</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 32 /<em>r</em> VPMOVQB <em>xmm1/m64 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed quad-word integers from <em>zmm2</em> into 8 packed byte integers in <em>xmm1/m64</em> with truncation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 22 /<em>r</em> VPMOVSQB <em>xmm1/m64 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed signed quad-word integers from <em>zmm2</em> into 8 packed signed byte integers in <em>xmm1/m64</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 12 /<em>r</em> VPMOVUSQB <em>xmm1/m64 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed unsigned quad-word integers from <em>zmm2</em> into 8 packed unsigned byte integers in <em>xmm1/m64</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Eighth Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 35 /<em>r</em> VPMOVQD <em>xmm1/m128 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed quad-word integers from <em>xmm2</em> into 2 packed double-word integers in <em>xmm1/m128</em> with truncation subject to writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 25 /<em>r</em> VPMOVSQD <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed signed quad-word integers from <em>xmm2</em> into 2 packed signed double-word integers in <em>xmm1/m64</em> using signed saturation subject to writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 15 /<em>r</em> VPMOVUSQD <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed unsigned quad-word integers from <em>xmm2</em> into 2 packed unsigned double-word integers in <em>xmm1/m64</em> using unsigned saturation subject to writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 35 /<em>r</em> VPMOVQD <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed quad-word integers from <em>ymm2</em> into 4 packed double-word integers in <em>xmm1/m128</em> with truncation subject to writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 25 /<em>r</em> VPMOVSQD <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed signed quad-word integers from <em>ymm2</em> into 4 packed signed double-word integers in <em>xmm1/m128</em> using signed saturation subject to writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 15 /<em>r</em> VPMOVUSQD <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed unsigned quad-word integers from y<em>mm2</em> into 4 packed unsigned double-word integers in <em>xmm1/m128</em> using unsigned saturation subject to writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 35 /<em>r</em> VPMOVQD <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed quad-word integers from <em>zmm2</em> into 8 packed double-word integers in <em>ymm1/m256</em> with truncation subject to writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 25 /<em>r</em> VPMOVSQD <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed signed quad-word integers from <em>zmm2</em> into 8 packed signed double-word integers in <em>ymm1/m256</em> using signed saturation subject to writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 15 /<em>r</em> VPMOVUSQD <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed unsigned quad-word integers from <em>zmm2</em> into 8 packed unsigned double-word integers in <em>ymm1/m256</em> using unsigned saturation subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Half Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 34 /<em>r</em> VPMOVQW <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed quad-word integers from <em>xmm2</em> into 2 packed word integers in <em>xmm1/m32</em> with truncation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 24 /<em>r</em> VPMOVSQW <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed signed quad-word integers from <em>zmm2</em> into 8 packed signed word integers in <em>xmm1/m32</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 14 /<em>r</em> VPMOVUSQW <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed unsigned quad-word integers from <em>xmm2</em> into 2 packed unsigned word integers in <em>xmm1/m32</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 34 /<em>r</em> VPMOVQW <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed quad-word integers from <em>ymm2</em> into 4 packed word integers in <em>xmm1/m64</em> with truncation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 24 /<em>r</em> VPMOVSQW <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed signed quad-word integers from <em>ymm2</em> into 4 packed signed word integers in <em>xmm1/m64</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 14 /<em>r</em> VPMOVUSQW <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed unsigned quad-word integers from <em>ymm2</em> into 4 packed unsigned word integers in <em>xmm1/m64</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 34 /<em>r</em> VPMOVQW <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed quad-word integers from <em>zmm2</em> into 8 packed word integers in <em>xmm1/m128</em> with truncation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 24 /<em>r</em> VPMOVSQW <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed signed quad-word integers from <em>zmm2</em> into 8 packed signed word integers in <em>xmm1/m128</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 14 /<em>r</em> VPMOVUSQW <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed unsigned quad-word integers from <em>zmm2</em> into 8 packed unsigned word integers in <em>xmm1/m128</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Quarter Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 31 /<em>r</em> VPMOVDB <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed double-word integers from <em>xmm2</em> into 4 packed byte integers in <em>xmm1/m32</em> with truncation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 21 /<em>r</em> VPMOVSDB <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed signed double-word integers from <em>xmm2</em> into 4 packed signed byte integers in <em>xmm1/m32</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 11 /<em>r</em> VPMOVUSDB <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed unsigned double-word integers from <em>xmm2</em> into 4 packed unsigned byte integers in <em>xmm1/m32</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 31 /<em>r</em> VPMOVDB <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed double-word integers from <em>ymm2</em> into 8 packed byte integers in <em>xmm1/m64</em> with truncation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 21 /<em>r</em> VPMOVSDB <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed signed double-word integers from <em>ymm2</em> into 8 packed signed byte integers in <em>xmm1/m64</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 11 /<em>r</em> VPMOVUSDB <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed unsigned double-word integers from <em>ymm2</em> into 8 packed unsigned byte integers in <em>xmm1/m64</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 31 /<em>r</em> VPMOVDB <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed double-word integers from <em>zmm2</em> into 16 packed byte integers in <em>xmm1/m128</em> with truncation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 21 /<em>r</em> VPMOVSDB <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed signed double-word integers from <em>zmm2</em> into 16 packed signed byte integers in <em>xmm1/m128</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 11 /<em>r</em> VPMOVUSDB <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed unsigned double-word integers from <em>zmm2</em> into 16 packed unsigned byte integers in <em>xmm1/m128</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Quarter Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 33 /<em>r</em> VPMOVDW <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed double-word integers from <em>xmm2</em> into 4 packed word integers in <em>xmm1/m64</em> with truncation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 23 /<em>r</em> VPMOVSDW <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed signed double-word integers from <em>xmm2</em> into 4 packed signed word integers in <em>ymm1/m64</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 13 /<em>r</em> VPMOVUSDW <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed unsigned double-word integers from <em>xmm2</em> into 4 packed unsigned word integers in <em>xmm1/m64</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 33 /<em>r</em> VPMOVDW <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed double-word integers from <em>ymm2</em> into 8 packed word integers in <em>xmm1/m128</em> with truncation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 23 /<em>r</em> VPMOVSDW <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed signed double-word integers from <em>ymm2</em> into 8 packed signed word integers in <em>xmm1/m128</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 13 /<em>r</em> VPMOVUSDW <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed unsigned double-word integers from <em>ymm2</em> into 8 packed unsigned word integers in <em>xmm1/m128</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 33 /<em>r</em> VPMOVDW <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed double-word integers from <em>zmm2</em> into 16 packed word integers in <em>ymm1/m256</em> with truncation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 23 /<em>r</em> VPMOVSDW <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed signed double-word integers from <em>zmm2</em> into 16 packed signed word integers in <em>ymm1/m256</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 13 /<em>r</em> VPMOVUSDW <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed unsigned double-word integers from <em>zmm2</em> into 16 packed unsigned word integers in <em>ymm1/m256</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Half Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 32 /<em>r</em> VPMOVQB <em>xmm1/m16 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed quad-word integers from <em>xmm2</em> into 2 packed byte integers in <em>xmm1/m16</em> with truncation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 22 /<em>r</em> VPMOVSQB <em>xmm1/m16 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed signed quad-word integers from <em>xmm2</em> into 2 packed signed byte integers in <em>xmm1/m16</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 12 /<em>r</em> VPMOVUSQB <em>xmm1/m16 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed unsigned quad-word integers from <em>xmm2</em> into 2 packed unsigned byte integers in <em>xmm1/m16</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 32 /<em>r</em> VPMOVQB <em>xmm1/m32 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed quad-word integers from <em>ymm2</em> into 4 packed byte integers in <em>xmm1/m32</em> with truncation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 22 /<em>r</em> VPMOVSQB <em>xmm1/m32 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed signed quad-word integers from <em>ymm2</em> into 4 packed signed byte integers in <em>xmm1/m32</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 12 /<em>r</em> VPMOVUSQB <em>xmm1/m32 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed unsigned quad-word integers from <em>ymm2</em> into 4 packed unsigned byte integers in <em>xmm1/m32</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 32 /<em>r</em> VPMOVQB <em>xmm1/m64 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed quad-word integers from <em>zmm2</em> into 8 packed byte integers in <em>xmm1/m64</em> with truncation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 22 /<em>r</em> VPMOVSQB <em>xmm1/m64 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed signed quad-word integers from <em>zmm2</em> into 8 packed signed byte integers in <em>xmm1/m64</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 12 /<em>r</em> VPMOVUSQB <em>xmm1/m64 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed unsigned quad-word integers from <em>zmm2</em> into 8 packed unsigned byte integers in <em>xmm1/m64</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Eighth Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 35 /<em>r</em> VPMOVQD <em>xmm1/m128 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed quad-word integers from <em>xmm2</em> into 2 packed double-word integers in <em>xmm1/m128</em> with truncation subject to writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 25 /<em>r</em> VPMOVSQD <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed signed quad-word integers from <em>xmm2</em> into 2 packed signed double-word integers in <em>xmm1/m64</em> using signed saturation subject to writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 15 /<em>r</em> VPMOVUSQD <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed unsigned quad-word integers from <em>xmm2</em> into 2 packed unsigned double-word integers in <em>xmm1/m64</em> using unsigned saturation subject to writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 35 /<em>r</em> VPMOVQD <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed quad-word integers from <em>ymm2</em> into 4 packed double-word integers in <em>xmm1/m128</em> with truncation subject to writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 25 /<em>r</em> VPMOVSQD <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed signed quad-word integers from <em>ymm2</em> into 4 packed signed double-word integers in <em>xmm1/m128</em> using signed saturation subject to writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 15 /<em>r</em> VPMOVUSQD <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed unsigned quad-word integers from y<em>mm2</em> into 4 packed unsigned double-word integers in <em>xmm1/m128</em> using unsigned saturation subject to writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 35 /<em>r</em> VPMOVQD <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed quad-word integers from <em>zmm2</em> into 8 packed double-word integers in <em>ymm1/m256</em> with truncation subject to writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 25 /<em>r</em> VPMOVSQD <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed signed quad-word integers from <em>zmm2</em> into 8 packed signed double-word integers in <em>ymm1/m256</em> using signed saturation subject to writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 15 /<em>r</em> VPMOVUSQD <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed unsigned quad-word integers from <em>zmm2</em> into 8 packed unsigned double-word integers in <em>ymm1/m256</em> using unsigned saturation subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Half Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 34 /<em>r</em> VPMOVQW <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed quad-word integers from <em>xmm2</em> into 2 packed word integers in <em>xmm1/m32</em> with truncation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 24 /<em>r</em> VPMOVSQW <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed signed quad-word integers from <em>zmm2</em> into 8 packed signed word integers in <em>xmm1/m32</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 14 /<em>r</em> VPMOVUSQW <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed unsigned quad-word integers from <em>xmm2</em> into 2 packed unsigned word integers in <em>xmm1/m32</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 34 /<em>r</em> VPMOVQW <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed quad-word integers from <em>ymm2</em> into 4 packed word integers in <em>xmm1/m64</em> with truncation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 24 /<em>r</em> VPMOVSQW <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed signed quad-word integers from <em>ymm2</em> into 4 packed signed word integers in <em>xmm1/m64</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 14 /<em>r</em> VPMOVUSQW <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed unsigned quad-word integers from <em>ymm2</em> into 4 packed unsigned word integers in <em>xmm1/m64</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 34 /<em>r</em> VPMOVQW <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed quad-word integers from <em>zmm2</em> into 8 packed word integers in <em>xmm1/m128</em> with truncation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 24 /<em>r</em> VPMOVSQW <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed signed quad-word integers from <em>zmm2</em> into 8 packed signed word integers in <em>xmm1/m128</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 14 /<em>r</em> VPMOVUSQW <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed unsigned quad-word integers from <em>zmm2</em> into 8 packed unsigned word integers in <em>xmm1/m128</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Quarter Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 30 /<em>r</em> VPMOVWB <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 8 packed word integers from <em>xmm2</em> into 8 packed bytes in <em>xmm1/m64</em> with truncation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 20 /<em>r</em> VPMOVSWB <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 8 packed signed word integers from <em>xmm2</em> into 8 packed signed bytes in <em>xmm1/m64</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 10 /<em>r</em> VPMOVUSWB <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 8 packed unsigned word integers from <em>xmm2</em> into 8 packed unsigned bytes in <em>8mm1/m64</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 30 /<em>r</em> VPMOVWB <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 16 packed word integers from <em>ymm2</em> into 16 packed bytes in <em>xmm1/m128</em> with truncation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 20 /<em>r</em> VPMOVSWB <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 16 packed signed word integers from <em>ymm2</em> into 16 packed signed bytes in <em>xmm1/m128</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 10 /<em>r</em> VPMOVUSWB <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 16 packed unsigned word integers from <em>ymm2</em> into 16 packed unsigned bytes in <em>xmm1/m128</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 30 /<em>r</em> VPMOVWB <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Converts 32 packed word integers from <em>zmm2</em> into 32 packed bytes in <em>ymm1/m256</em> with truncation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 20 /<em>r</em> VPMOVSWB <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Converts 32 packed signed word integers from <em>zmm2</em> into 32 packed signed bytes in <em>ymm1/m256</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 10 /<em>r</em> VPMOVUSWB <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Converts 32 packed unsigned word integers from <em>zmm2</em> into 32 packed unsigned bytes in <em>ymm1/m256</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Half Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 31 /<em>r</em> VPMOVDB <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed double-word integers from <em>xmm2</em> into 4 packed byte integers in <em>xmm1/m32</em> with truncation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 21 /<em>r</em> VPMOVSDB <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed signed double-word integers from <em>xmm2</em> into 4 packed signed byte integers in <em>xmm1/m32</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 11 /<em>r</em> VPMOVUSDB <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed unsigned double-word integers from <em>xmm2</em> into 4 packed unsigned byte integers in <em>xmm1/m32</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 31 /<em>r</em> VPMOVDB <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed double-word integers from <em>ymm2</em> into 8 packed byte integers in <em>xmm1/m64</em> with truncation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 21 /<em>r</em> VPMOVSDB <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed signed double-word integers from <em>ymm2</em> into 8 packed signed byte integers in <em>xmm1/m64</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 11 /<em>r</em> VPMOVUSDB <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed unsigned double-word integers from <em>ymm2</em> into 8 packed unsigned byte integers in <em>xmm1/m64</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 31 /<em>r</em> VPMOVDB <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed double-word integers from <em>zmm2</em> into 16 packed byte integers in <em>xmm1/m128</em> with truncation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 21 /<em>r</em> VPMOVSDB <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed signed double-word integers from <em>zmm2</em> into 16 packed signed byte integers in <em>xmm1/m128</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 11 /<em>r</em> VPMOVUSDB <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed unsigned double-word integers from <em>zmm2</em> into 16 packed unsigned byte integers in <em>xmm1/m128</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Quarter Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 33 /<em>r</em> VPMOVDW <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed double-word integers from <em>xmm2</em> into 4 packed word integers in <em>xmm1/m64</em> with truncation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 23 /<em>r</em> VPMOVSDW <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed signed double-word integers from <em>xmm2</em> into 4 packed signed word integers in <em>ymm1/m64</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 13 /<em>r</em> VPMOVUSDW <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed unsigned double-word integers from <em>xmm2</em> into 4 packed unsigned word integers in <em>xmm1/m64</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 33 /<em>r</em> VPMOVDW <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed double-word integers from <em>ymm2</em> into 8 packed word integers in <em>xmm1/m128</em> with truncation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 23 /<em>r</em> VPMOVSDW <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed signed double-word integers from <em>ymm2</em> into 8 packed signed word integers in <em>xmm1/m128</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 13 /<em>r</em> VPMOVUSDW <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed unsigned double-word integers from <em>ymm2</em> into 8 packed unsigned word integers in <em>xmm1/m128</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 33 /<em>r</em> VPMOVDW <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed double-word integers from <em>zmm2</em> into 16 packed word integers in <em>ymm1/m256</em> with truncation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 23 /<em>r</em> VPMOVSDW <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed signed double-word integers from <em>zmm2</em> into 16 packed signed word integers in <em>ymm1/m256</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 13 /<em>r</em> VPMOVUSDW <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 16 packed unsigned double-word integers from <em>zmm2</em> into 16 packed unsigned word integers in <em>ymm1/m256</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Half Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 32 /<em>r</em> VPMOVQB <em>xmm1/m16 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed quad-word integers from <em>xmm2</em> into 2 packed byte integers in <em>xmm1/m16</em> with truncation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 22 /<em>r</em> VPMOVSQB <em>xmm1/m16 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed signed quad-word integers from <em>xmm2</em> into 2 packed signed byte integers in <em>xmm1/m16</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 12 /<em>r</em> VPMOVUSQB <em>xmm1/m16 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed unsigned quad-word integers from <em>xmm2</em> into 2 packed unsigned byte integers in <em>xmm1/m16</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 32 /<em>r</em> VPMOVQB <em>xmm1/m32 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed quad-word integers from <em>ymm2</em> into 4 packed byte integers in <em>xmm1/m32</em> with truncation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 22 /<em>r</em> VPMOVSQB <em>xmm1/m32 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed signed quad-word integers from <em>ymm2</em> into 4 packed signed byte integers in <em>xmm1/m32</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 12 /<em>r</em> VPMOVUSQB <em>xmm1/m32 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed unsigned quad-word integers from <em>ymm2</em> into 4 packed unsigned byte integers in <em>xmm1/m32</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 32 /<em>r</em> VPMOVQB <em>xmm1/m64 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed quad-word integers from <em>zmm2</em> into 8 packed byte integers in <em>xmm1/m64</em> with truncation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 22 /<em>r</em> VPMOVSQB <em>xmm1/m64 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed signed quad-word integers from <em>zmm2</em> into 8 packed signed byte integers in <em>xmm1/m64</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 12 /<em>r</em> VPMOVUSQB <em>xmm1/m64 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed unsigned quad-word integers from <em>zmm2</em> into 8 packed unsigned byte integers in <em>xmm1/m64</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Eighth Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 35 /<em>r</em> VPMOVQD <em>xmm1/m128 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed quad-word integers from <em>xmm2</em> into 2 packed double-word integers in <em>xmm1/m128</em> with truncation subject to writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 25 /<em>r</em> VPMOVSQD <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed signed quad-word integers from <em>xmm2</em> into 2 packed signed double-word integers in <em>xmm1/m64</em> using signed saturation subject to writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 15 /<em>r</em> VPMOVUSQD <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed unsigned quad-word integers from <em>xmm2</em> into 2 packed unsigned double-word integers in <em>xmm1/m64</em> using unsigned saturation subject to writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 35 /<em>r</em> VPMOVQD <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed quad-word integers from <em>ymm2</em> into 4 packed double-word integers in <em>xmm1/m128</em> with truncation subject to writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 25 /<em>r</em> VPMOVSQD <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed signed quad-word integers from <em>ymm2</em> into 4 packed signed double-word integers in <em>xmm1/m128</em> using signed saturation subject to writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 15 /<em>r</em> VPMOVUSQD <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed unsigned quad-word integers from y<em>mm2</em> into 4 packed unsigned double-word integers in <em>xmm1/m128</em> using unsigned saturation subject to writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 35 /<em>r</em> VPMOVQD <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed quad-word integers from <em>zmm2</em> into 8 packed double-word integers in <em>ymm1/m256</em> with truncation subject to writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 25 /<em>r</em> VPMOVSQD <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed signed quad-word integers from <em>zmm2</em> into 8 packed signed double-word integers in <em>ymm1/m256</em> using signed saturation subject to writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 15 /<em>r</em> VPMOVUSQD <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed unsigned quad-word integers from <em>zmm2</em> into 8 packed unsigned double-word integers in <em>ymm1/m256</em> using unsigned saturation subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Half Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 34 /<em>r</em> VPMOVQW <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed quad-word integers from <em>xmm2</em> into 2 packed word integers in <em>xmm1/m32</em> with truncation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 24 /<em>r</em> VPMOVSQW <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 8 packed signed quad-word integers from <em>zmm2</em> into 8 packed signed word integers in <em>xmm1/m32</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 14 /<em>r</em> VPMOVUSQW <em>xmm1/m32 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 2 packed unsigned quad-word integers from <em>xmm2</em> into 2 packed unsigned word integers in <em>xmm1/m32</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 34 /<em>r</em> VPMOVQW <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed quad-word integers from <em>ymm2</em> into 4 packed word integers in <em>xmm1/m64</em> with truncation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 24 /<em>r</em> VPMOVSQW <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed signed quad-word integers from <em>ymm2</em> into 4 packed signed word integers in <em>xmm1/m64</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 14 /<em>r</em> VPMOVUSQW <em>xmm1/m64 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Converts 4 packed unsigned quad-word integers from <em>ymm2</em> into 4 packed unsigned word integers in <em>xmm1/m64</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 34 /<em>r</em> VPMOVQW <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed quad-word integers from <em>zmm2</em> into 8 packed word integers in <em>xmm1/m128</em> with truncation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 24 /<em>r</em> VPMOVSQW <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed signed quad-word integers from <em>zmm2</em> into 8 packed signed word integers in <em>xmm1/m128</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 14 /<em>r</em> VPMOVUSQW <em>xmm1/m128 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Converts 8 packed unsigned quad-word integers from <em>zmm2</em> into 8 packed unsigned word integers in <em>xmm1/m128</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Quarter Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 30 /<em>r</em> VPMOVWB <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 8 packed word integers from <em>xmm2</em> into 8 packed bytes in <em>xmm1/m64</em> with truncation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 20 /<em>r</em> VPMOVSWB <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 8 packed signed word integers from <em>xmm2</em> into 8 packed signed bytes in <em>xmm1/m64</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 10 /<em>r</em> VPMOVUSWB <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 8 packed unsigned word integers from <em>xmm2</em> into 8 packed unsigned bytes in <em>8mm1/m64</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 30 /<em>r</em> VPMOVWB <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 16 packed word integers from <em>ymm2</em> into 16 packed bytes in <em>xmm1/m128</em> with truncation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 20 /<em>r</em> VPMOVSWB <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 16 packed signed word integers from <em>ymm2</em> into 16 packed signed bytes in <em>xmm1/m128</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 10 /<em>r</em> VPMOVUSWB <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 16 packed unsigned word integers from <em>ymm2</em> into 16 packed unsigned bytes in <em>xmm1/m128</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 30 /<em>r</em> VPMOVWB <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Converts 32 packed word integers from <em>zmm2</em> into 32 packed bytes in <em>ymm1/m256</em> with truncation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 20 /<em>r</em> VPMOVSWB <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Converts 32 packed signed word integers from <em>zmm2</em> into 32 packed signed bytes in <em>ymm1/m256</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 10 /<em>r</em> VPMOVUSWB <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Converts 32 packed unsigned word integers from <em>zmm2</em> into 32 packed unsigned bytes in <em>ymm1/m256</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Half Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 29 /r VPMOVB2M k1, xmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in XMM1.</td>, <td>EVEX.256.F3.0F38.W0 29 /r VPMOVB2M k1, ymm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in YMM1.</td>, <td>EVEX.512.F3.0F38.W0 29 /r VPMOVB2M k1, zmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in ZMM1.</td>, <td>EVEX.128.F3.0F38.W1 29 /r VPMOVW2M k1, xmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in XMM1.</td>, <td>EVEX.256.F3.0F38.W1 29 /r VPMOVW2M k1, ymm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in YMM1.</td>, <td>EVEX.512.F3.0F38.W1 29 /r VPMOVW2M k1, zmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in ZMM1.</td>, <td>EVEX.128.F3.0F38.W0 39 /r VPMOVD2M k1, xmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in XMM1.</td>, <td>EVEX.256.F3.0F38.W0 39 /r VPMOVD2M k1, ymm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in YMM1.</td>, <td>EVEX.512.F3.0F38.W0 39 /r VPMOVD2M k1, zmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in ZMM1.</td>, <td>EVEX.128.F3.0F38.W1 39 /r VPMOVQ2M k1, xmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in XMM1.</td>, <td>EVEX.256.F3.0F38.W1 39 /r VPMOVQ2M k1, ymm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in YMM1.</td>, <td>EVEX.512.F3.0F38.W1 39 /r VPMOVQ2M k1, zmm1</td>, <td>RM</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in ZMM1.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.F3.0F38.W0 30 /<em>r</em> VPMOVWB <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 8 packed word integers from <em>xmm2</em> into 8 packed bytes in <em>xmm1/m64</em> with truncation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 20 /<em>r</em> VPMOVSWB <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 8 packed signed word integers from <em>xmm2</em> into 8 packed signed bytes in <em>xmm1/m64</em> using signed saturation under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 10 /<em>r</em> VPMOVUSWB <em>xmm1/m64 {k1}{z}, xmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 8 packed unsigned word integers from <em>xmm2</em> into 8 packed unsigned bytes in <em>8mm1/m64</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 30 /<em>r</em> VPMOVWB <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 16 packed word integers from <em>ymm2</em> into 16 packed bytes in <em>xmm1/m128</em> with truncation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 20 /<em>r</em> VPMOVSWB <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 16 packed signed word integers from <em>ymm2</em> into 16 packed signed bytes in <em>xmm1/m128</em> using signed saturation under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 10 /<em>r</em> VPMOVUSWB <em>xmm1/m128 {k1}{z}, ymm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Converts 16 packed unsigned word integers from <em>ymm2</em> into 16 packed unsigned bytes in <em>xmm1/m128</em> using unsigned saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 30 /<em>r</em> VPMOVWB <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Converts 32 packed word integers from <em>zmm2</em> into 32 packed bytes in <em>ymm1/m256</em> with truncation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 20 /<em>r</em> VPMOVSWB <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Converts 32 packed signed word integers from <em>zmm2</em> into 32 packed signed bytes in <em>ymm1/m256</em> using signed saturation under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 10 /<em>r</em> VPMOVUSWB <em>ymm1/m256 {k1}{z}, zmm2</em></td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Converts 32 packed unsigned word integers from <em>zmm2</em> into 32 packed unsigned bytes in <em>ymm1/m256</em> using unsigned saturation under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Half Mem</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F38.W1 83 /r VPMULTISHIFTQB xmm1 {k1}{z}, xmm2,xmm3/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_VBMI AVX512VL</td>, <td>Select unaligned bytes from qwords in xmm3/m128/m64bcst using control bytes in xmm2, write byte results to xmm1 under k1.</td>, <td>EVEX.256.66.0F38.W1 83 /r VPMULTISHIFTQB ymm1 {k1}{z}, ymm2,ymm3/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_VBMI AVX512VL</td>, <td>Select unaligned bytes from qwords in ymm3/m256/m64bcst using control bytes in ymm2, write byte results to ymm1 under k1.</td>, <td>EVEX.512.66.0F38.W1 83 /r VPMULTISHIFTQB zmm1 {k1}{z}, zmm2,zmm3/m512/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_VBMI</td>, <td>Select unaligned bytes from qwords in zmm3/m512/m64bcst using control bytes in zmm2, write byte results to zmm1 under k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 15 /r VPROLVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in xmm2 left by count in the corresponding element of xmm3/m128/m32bcst. Result written to xmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /1 ib VPROLD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in xmm2/m128/m32bcst left by imm8. Result written to xmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 15 /r VPROLVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in xmm2 left by count in the corresponding element of xmm3/m128/m64bcst. Result written to xmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.W1 72 /1 ib VPROLQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in xmm2/m128/m64bcst left by imm8. Result written to xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 15 /r VPROLVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in ymm2 left by count in the corresponding element of ymm3/m256/m32bcst. Result written to ymm1 under writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /1 ib VPROLD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in ymm2/m256/m32bcst left by imm8. Result written to ymm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 15 /r VPROLVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in ymm2 left by count in the corresponding element of ymm3/m256/m64bcst. Result written to ymm1 under writemask k1.</td>, <td>EVEX.256.66.0F.W1 72 /1 ib VPROLQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in ymm2/m256/m64bcst left by imm8. Result written to ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 15 /r VPROLVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate left of doublewords in zmm2 by count in the corresponding element of zmm3/m512/m32bcst. Result written to zmm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /1 ib VPROLD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate left of doublewords in zmm3/m512/m32bcst by imm8. Result written to zmm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 15 /r VPROLVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate quadwords in zmm2 left by count in the corresponding element of zmm3/m512/m64bcst. Result written to zmm1under writemask k1.</td>, <td>EVEX.512.66.0F.W1 72 /1 ib VPROLQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate quadwords in zmm2/m512/m64bcst left by imm8. Result written to zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 15 /r VPROLVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in xmm2 left by count in the corresponding element of xmm3/m128/m32bcst. Result written to xmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /1 ib VPROLD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in xmm2/m128/m32bcst left by imm8. Result written to xmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 15 /r VPROLVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in xmm2 left by count in the corresponding element of xmm3/m128/m64bcst. Result written to xmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.W1 72 /1 ib VPROLQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in xmm2/m128/m64bcst left by imm8. Result written to xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 15 /r VPROLVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in ymm2 left by count in the corresponding element of ymm3/m256/m32bcst. Result written to ymm1 under writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /1 ib VPROLD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in ymm2/m256/m32bcst left by imm8. Result written to ymm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 15 /r VPROLVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in ymm2 left by count in the corresponding element of ymm3/m256/m64bcst. Result written to ymm1 under writemask k1.</td>, <td>EVEX.256.66.0F.W1 72 /1 ib VPROLQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in ymm2/m256/m64bcst left by imm8. Result written to ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 15 /r VPROLVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate left of doublewords in zmm2 by count in the corresponding element of zmm3/m512/m32bcst. Result written to zmm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /1 ib VPROLD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate left of doublewords in zmm3/m512/m32bcst by imm8. Result written to zmm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 15 /r VPROLVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate quadwords in zmm2 left by count in the corresponding element of zmm3/m512/m64bcst. Result written to zmm1under writemask k1.</td>, <td>EVEX.512.66.0F.W1 72 /1 ib VPROLQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate quadwords in zmm2/m512/m64bcst left by imm8. Result written to zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 15 /r VPROLVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in xmm2 left by count in the corresponding element of xmm3/m128/m32bcst. Result written to xmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /1 ib VPROLD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in xmm2/m128/m32bcst left by imm8. Result written to xmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 15 /r VPROLVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in xmm2 left by count in the corresponding element of xmm3/m128/m64bcst. Result written to xmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.W1 72 /1 ib VPROLQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in xmm2/m128/m64bcst left by imm8. Result written to xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 15 /r VPROLVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in ymm2 left by count in the corresponding element of ymm3/m256/m32bcst. Result written to ymm1 under writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /1 ib VPROLD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in ymm2/m256/m32bcst left by imm8. Result written to ymm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 15 /r VPROLVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in ymm2 left by count in the corresponding element of ymm3/m256/m64bcst. Result written to ymm1 under writemask k1.</td>, <td>EVEX.256.66.0F.W1 72 /1 ib VPROLQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in ymm2/m256/m64bcst left by imm8. Result written to ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 15 /r VPROLVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate left of doublewords in zmm2 by count in the corresponding element of zmm3/m512/m32bcst. Result written to zmm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /1 ib VPROLD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate left of doublewords in zmm3/m512/m32bcst by imm8. Result written to zmm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 15 /r VPROLVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate quadwords in zmm2 left by count in the corresponding element of zmm3/m512/m64bcst. Result written to zmm1under writemask k1.</td>, <td>EVEX.512.66.0F.W1 72 /1 ib VPROLQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate quadwords in zmm2/m512/m64bcst left by imm8. Result written to zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 15 /r VPROLVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in xmm2 left by count in the corresponding element of xmm3/m128/m32bcst. Result written to xmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /1 ib VPROLD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in xmm2/m128/m32bcst left by imm8. Result written to xmm1 using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 15 /r VPROLVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in xmm2 left by count in the corresponding element of xmm3/m128/m64bcst. Result written to xmm1 under writemask k1.</td>, <td>EVEX.128.66.0F.W1 72 /1 ib VPROLQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in xmm2/m128/m64bcst left by imm8. Result written to xmm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 15 /r VPROLVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in ymm2 left by count in the corresponding element of ymm3/m256/m32bcst. Result written to ymm1 under writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /1 ib VPROLD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in ymm2/m256/m32bcst left by imm8. Result written to ymm1 using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 15 /r VPROLVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in ymm2 left by count in the corresponding element of ymm3/m256/m64bcst. Result written to ymm1 under writemask k1.</td>, <td>EVEX.256.66.0F.W1 72 /1 ib VPROLQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in ymm2/m256/m64bcst left by imm8. Result written to ymm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 15 /r VPROLVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate left of doublewords in zmm2 by count in the corresponding element of zmm3/m512/m32bcst. Result written to zmm1 using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /1 ib VPROLD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate left of doublewords in zmm3/m512/m32bcst by imm8. Result written to zmm1 using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 15 /r VPROLVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate quadwords in zmm2 left by count in the corresponding element of zmm3/m512/m64bcst. Result written to zmm1under writemask k1.</td>, <td>EVEX.512.66.0F.W1 72 /1 ib VPROLQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate quadwords in zmm2/m512/m64bcst left by imm8. Result written to zmm1 using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 14 /r VPRORVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in xmm2 right by count in the corresponding element of xmm3/m128/m32bcst, store result using writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /0 ib VPRORD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in xmm2/m128/m32bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 14 /r VPRORVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in xmm2 right by count in the corresponding element of xmm3/m128/m64bcst, store result using writemask k1.</td>, <td>EVEX.128.66.0F.W1 72 /0 ib VPRORQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in xmm2/m128/m64bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 14 /r VPRORVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in ymm2 right by count in the corresponding element of ymm3/m256/m32bcst, store using result writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /0 ib VPRORD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in ymm2/m256/m32bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 14 /r VPRORVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in ymm2 right by count in the corresponding element of ymm3/m256/m64bcst, store result using writemask k1.</td>, <td>EVEX.256.66.0F.W1 72 /0 ib VPRORQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in ymm2/m256/m64bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 14 /r VPRORVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate doublewords in zmm2 right by count in the corresponding element of zmm3/m512/m32bcst, store result using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /0 ib VPRORD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate doublewords in zmm2/m512/m32bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 14 /r VPRORVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate quadwords in zmm2 right by count in the corresponding element of zmm3/m512/m64bcst, store result using writemask k1.</td>, <td>EVEX.512.66.0F.W1 72 /0 ib VPRORQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate quadwords in zmm2/m512/m64bcst right by imm8, store result using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 14 /r VPRORVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in xmm2 right by count in the corresponding element of xmm3/m128/m32bcst, store result using writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /0 ib VPRORD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in xmm2/m128/m32bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 14 /r VPRORVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in xmm2 right by count in the corresponding element of xmm3/m128/m64bcst, store result using writemask k1.</td>, <td>EVEX.128.66.0F.W1 72 /0 ib VPRORQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in xmm2/m128/m64bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 14 /r VPRORVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in ymm2 right by count in the corresponding element of ymm3/m256/m32bcst, store using result writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /0 ib VPRORD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in ymm2/m256/m32bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 14 /r VPRORVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in ymm2 right by count in the corresponding element of ymm3/m256/m64bcst, store result using writemask k1.</td>, <td>EVEX.256.66.0F.W1 72 /0 ib VPRORQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in ymm2/m256/m64bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 14 /r VPRORVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate doublewords in zmm2 right by count in the corresponding element of zmm3/m512/m32bcst, store result using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /0 ib VPRORD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate doublewords in zmm2/m512/m32bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 14 /r VPRORVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate quadwords in zmm2 right by count in the corresponding element of zmm3/m512/m64bcst, store result using writemask k1.</td>, <td>EVEX.512.66.0F.W1 72 /0 ib VPRORQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate quadwords in zmm2/m512/m64bcst right by imm8, store result using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 14 /r VPRORVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in xmm2 right by count in the corresponding element of xmm3/m128/m32bcst, store result using writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /0 ib VPRORD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in xmm2/m128/m32bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 14 /r VPRORVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in xmm2 right by count in the corresponding element of xmm3/m128/m64bcst, store result using writemask k1.</td>, <td>EVEX.128.66.0F.W1 72 /0 ib VPRORQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in xmm2/m128/m64bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 14 /r VPRORVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in ymm2 right by count in the corresponding element of ymm3/m256/m32bcst, store using result writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /0 ib VPRORD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in ymm2/m256/m32bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 14 /r VPRORVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in ymm2 right by count in the corresponding element of ymm3/m256/m64bcst, store result using writemask k1.</td>, <td>EVEX.256.66.0F.W1 72 /0 ib VPRORQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in ymm2/m256/m64bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 14 /r VPRORVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate doublewords in zmm2 right by count in the corresponding element of zmm3/m512/m32bcst, store result using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /0 ib VPRORD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate doublewords in zmm2/m512/m32bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 14 /r VPRORVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate quadwords in zmm2 right by count in the corresponding element of zmm3/m512/m64bcst, store result using writemask k1.</td>, <td>EVEX.512.66.0F.W1 72 /0 ib VPRORQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate quadwords in zmm2/m512/m64bcst right by imm8, store result using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 14 /r VPRORVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in xmm2 right by count in the corresponding element of xmm3/m128/m32bcst, store result using writemask k1.</td>, <td>EVEX.128.66.0F.W0 72 /0 ib VPRORD xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in xmm2/m128/m32bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 14 /r VPRORVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in xmm2 right by count in the corresponding element of xmm3/m128/m64bcst, store result using writemask k1.</td>, <td>EVEX.128.66.0F.W1 72 /0 ib VPRORQ xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in xmm2/m128/m64bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 14 /r VPRORVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in ymm2 right by count in the corresponding element of ymm3/m256/m32bcst, store using result writemask k1.</td>, <td>EVEX.256.66.0F.W0 72 /0 ib VPRORD ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate doublewords in ymm2/m256/m32bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 14 /r VPRORVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in ymm2 right by count in the corresponding element of ymm3/m256/m64bcst, store result using writemask k1.</td>, <td>EVEX.256.66.0F.W1 72 /0 ib VPRORQ ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rotate quadwords in ymm2/m256/m64bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 14 /r VPRORVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate doublewords in zmm2 right by count in the corresponding element of zmm3/m512/m32bcst, store result using writemask k1.</td>, <td>EVEX.512.66.0F.W0 72 /0 ib VPRORD zmm1 {k1}{z}, zmm2/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate doublewords in zmm2/m512/m32bcst right by imm8, store result using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 14 /r VPRORVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate quadwords in zmm2 right by count in the corresponding element of zmm3/m512/m64bcst, store result using writemask k1.</td>, <td>EVEX.512.66.0F.W1 72 /0 ib VPRORQ zmm1 {k1}{z}, zmm2/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rotate quadwords in zmm2/m512/m64bcst right by imm8, store result using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>VEX.vvvv (w)</td>, <td>ModRM:r/m (R)</td>, <td>Imm8</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 A0 /vsib VPSCATTERDD vm32x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A0 /vsib VPSCATTERDD vm32y {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A0 /vsib VPSCATTERDD vm32z {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A0 /vsib VPSCATTERDQ vm32x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A0 /vsib VPSCATTERDQ vm32x {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A0 /vsib VPSCATTERDQ vm32y {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 A1 /vsib VPSCATTERQD vm64x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A1 /vsib VPSCATTERQD vm64y {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A1 /vsib VPSCATTERQD vm64z {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A1 /vsib VPSCATTERQQ vm64x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A1 /vsib VPSCATTERQQ vm64y {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A1 /vsib VPSCATTERQQ vm64z {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, scatter qword values to memory using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 A0 /vsib VPSCATTERDD vm32x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A0 /vsib VPSCATTERDD vm32y {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A0 /vsib VPSCATTERDD vm32z {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A0 /vsib VPSCATTERDQ vm32x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A0 /vsib VPSCATTERDQ vm32x {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A0 /vsib VPSCATTERDQ vm32y {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 A1 /vsib VPSCATTERQD vm64x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A1 /vsib VPSCATTERQD vm64y {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A1 /vsib VPSCATTERQD vm64z {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A1 /vsib VPSCATTERQQ vm64x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A1 /vsib VPSCATTERQQ vm64y {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A1 /vsib VPSCATTERQQ vm64z {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, scatter qword values to memory using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 A0 /vsib VPSCATTERDD vm32x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A0 /vsib VPSCATTERDD vm32y {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A0 /vsib VPSCATTERDD vm32z {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A0 /vsib VPSCATTERDQ vm32x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A0 /vsib VPSCATTERDQ vm32x {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A0 /vsib VPSCATTERDQ vm32y {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 A1 /vsib VPSCATTERQD vm64x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A1 /vsib VPSCATTERQD vm64y {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A1 /vsib VPSCATTERQD vm64z {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A1 /vsib VPSCATTERQQ vm64x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A1 /vsib VPSCATTERQQ vm64y {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A1 /vsib VPSCATTERQQ vm64z {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, scatter qword values to memory using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 A0 /vsib VPSCATTERDD vm32x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A0 /vsib VPSCATTERDD vm32y {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A0 /vsib VPSCATTERDD vm32z {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A0 /vsib VPSCATTERDQ vm32x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A0 /vsib VPSCATTERDQ vm32x {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A0 /vsib VPSCATTERDQ vm32y {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 A1 /vsib VPSCATTERQD vm64x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A1 /vsib VPSCATTERQD vm64y {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A1 /vsib VPSCATTERQD vm64z {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, scatter dword values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A1 /vsib VPSCATTERQQ vm64x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A1 /vsib VPSCATTERQQ vm64y {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter qword values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A1 /vsib VPSCATTERQQ vm64z {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, scatter qword values to memory using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 47 /r VPSLLVD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.</td>, <td>VEX.128.66.0F38.W1 47 /r VPSLLVQ xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.</td>, <td>VEX.256.66.0F38.W0 47 /r VPSLLVD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.</td>, <td>VEX.256.66.0F38.W1 47 /r VPSLLVQ ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.</td>, <td>EVEX.128.66.0F38.W1 12 /r VPSLLVW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 12 /r VPSLLVW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 12 /r VPSLLVW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 left by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 47 /r VPSLLVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 47 /r VPSLLVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 47 /r VPSLLVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 47 /r VPSLLVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 47 /r VPSLLVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 47 /r VPSLLVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 47 /r VPSLLVD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.</td>, <td>VEX.128.66.0F38.W1 47 /r VPSLLVQ xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.</td>, <td>VEX.256.66.0F38.W0 47 /r VPSLLVD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.</td>, <td>VEX.256.66.0F38.W1 47 /r VPSLLVQ ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.</td>, <td>EVEX.128.66.0F38.W1 12 /r VPSLLVW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 12 /r VPSLLVW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 12 /r VPSLLVW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 left by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 47 /r VPSLLVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 47 /r VPSLLVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 47 /r VPSLLVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 47 /r VPSLLVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 47 /r VPSLLVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 47 /r VPSLLVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 47 /r VPSLLVD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.</td>, <td>VEX.128.66.0F38.W1 47 /r VPSLLVQ xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.</td>, <td>VEX.256.66.0F38.W0 47 /r VPSLLVD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.</td>, <td>VEX.256.66.0F38.W1 47 /r VPSLLVQ ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.</td>, <td>EVEX.128.66.0F38.W1 12 /r VPSLLVW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 left by amount specified in the corresponding element of xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 12 /r VPSLLVW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 left by amount specified in the corresponding element of ymm3/m256 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 12 /r VPSLLVW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 left by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 47 /r VPSLLVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 47 /r VPSLLVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 47 /r VPSLLVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 47 /r VPSLLVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 left by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 47 /r VPSLLVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 left by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 47 /r VPSLLVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 46 /r VPSRAVD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in sign bits.</td>, <td>VEX.256.66.0F38.W0 46 /r VPSRAVD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in sign bits.</td>, <td>EVEX.128.66.0F38.W1 11 /r VPSRAVW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 11 /r VPSRAVW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 11 /r VPSRAVW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 46 /r VPSRAVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 46 /r VPSRAVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 46 /r VPSRAVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 46 /r VPSRAVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 46 /r VPSRAVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 46 /r VPSRAVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in sign bits using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 46 /r VPSRAVD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in sign bits.</td>, <td>VEX.256.66.0F38.W0 46 /r VPSRAVD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in sign bits.</td>, <td>EVEX.128.66.0F38.W1 11 /r VPSRAVW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 11 /r VPSRAVW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 11 /r VPSRAVW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 46 /r VPSRAVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 46 /r VPSRAVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 46 /r VPSRAVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 46 /r VPSRAVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 46 /r VPSRAVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 46 /r VPSRAVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in sign bits using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 46 /r VPSRAVD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in sign bits.</td>, <td>VEX.256.66.0F38.W0 46 /r VPSRAVD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in sign bits.</td>, <td>EVEX.128.66.0F38.W1 11 /r VPSRAVW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 11 /r VPSRAVW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 11 /r VPSRAVW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 46 /r VPSRAVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 46 /r VPSRAVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 46 /r VPSRAVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in sign bits using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 46 /r VPSRAVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in sign bits using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 46 /r VPSRAVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in sign bits using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 46 /r VPSRAVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in sign bits using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 45 /r VPSRLVD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.</td>, <td>VEX.128.66.0F38.W1 45 /r VPSRLVQ xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.</td>, <td>VEX.256.66.0F38.W0 45 /r VPSRLVD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.</td>, <td>VEX.256.66.0F38.W1 45 /r VPSRLVQ ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.</td>, <td>EVEX.128.66.0F38.W1 10 /r VPSRLVW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 10 /r VPSRLVW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 10 /r VPSRLVW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 45 /r VPSRLVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 45 /r VPSRLVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 45 /r VPSRLVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 45 /r VPSRLVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 45 /r VPSRLVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 45 /r VPSRLVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 45 /r VPSRLVD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.</td>, <td>VEX.128.66.0F38.W1 45 /r VPSRLVQ xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.</td>, <td>VEX.256.66.0F38.W0 45 /r VPSRLVD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.</td>, <td>VEX.256.66.0F38.W1 45 /r VPSRLVQ ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.</td>, <td>EVEX.128.66.0F38.W1 10 /r VPSRLVW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 10 /r VPSRLVW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 10 /r VPSRLVW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 45 /r VPSRLVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 45 /r VPSRLVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 45 /r VPSRLVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 45 /r VPSRLVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 45 /r VPSRLVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 45 /r VPSRLVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>VEX.128.66.0F38.W0 45 /r VPSRLVD xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.</td>, <td>VEX.128.66.0F38.W1 45 /r VPSRLVQ xmm1, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s.</td>, <td>VEX.256.66.0F38.W0 45 /r VPSRLVD ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.</td>, <td>VEX.256.66.0F38.W1 45 /r VPSRLVQ ymm1, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX2</td>, <td>Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s.</td>, <td>EVEX.128.66.0F38.W1 10 /r VPSRLVW xmm1 {k1}{z}, xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in xmm2 right by amount specified in the corresponding element of xmm3/m128 while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 10 /r VPSRLVW ymm1 {k1}{z}, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Shift words in ymm2 right by amount specified in the corresponding element of ymm3/m256 while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 10 /r VPSRLVW zmm1 {k1}{z}, zmm2, zmm3/m512</td>, <td>B</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 45 /r VPSRLVD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 45 /r VPSRLVD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift doublewords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 45 /r VPSRLVD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 45 /r VPSRLVQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in xmm2 right by amount specified in the corresponding element of xmm3/m128/m64bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 45 /r VPSRLVQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shift quadwords in ymm2 right by amount specified in the corresponding element of ymm3/m256/m64bcst while shifting in 0s using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 45 /r VPSRLVQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F3A.W0 25 /r ib VPTERNLOGD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m32bcst as source operands and writing the result to xmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.</td>, <td>EVEX.256.66.0F3A.W0 25 /r ib VPTERNLOGD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m32bcst as source operands and writing the result to ymm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.</td>, <td>EVEX.512.66.0F3A.W0 25 /r ib VPTERNLOGD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m32bcst as source operands and writing the result to zmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.</td>, <td>EVEX.128.66.0F3A.W1 25 /r ib VPTERNLOGQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m64bcst as source operands and writing the result to xmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.</td>, <td>EVEX.256.66.0F3A.W1 25 /r ib VPTERNLOGQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m64bcst as source operands and writing the result to ymm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.</td>, <td>EVEX.512.66.0F3A.W1 25 /r ib VPTERNLOGQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m64bcst as source operands and writing the result to zmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>0</td>, <td>1</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>0</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>]

[<td>EVEX.128.66.0F3A.W0 25 /r ib VPTERNLOGD xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m32bcst as source operands and writing the result to xmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.</td>, <td>EVEX.256.66.0F3A.W0 25 /r ib VPTERNLOGD ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m32bcst as source operands and writing the result to ymm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.</td>, <td>EVEX.512.66.0F3A.W0 25 /r ib VPTERNLOGD zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m32bcst as source operands and writing the result to zmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented.</td>, <td>EVEX.128.66.0F3A.W1 25 /r ib VPTERNLOGQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise ternary logic taking xmm1, xmm2 and xmm3/m128/m64bcst as source operands and writing the result to xmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.</td>, <td>EVEX.256.66.0F3A.W1 25 /r ib VPTERNLOGQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise ternary logic taking ymm1, ymm2 and ymm3/m256/m64bcst as source operands and writing the result to ymm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.</td>, <td>EVEX.512.66.0F3A.W1 25 /r ib VPTERNLOGQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m64bcst as source operands and writing the result to zmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>0</td>, <td>1</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>0</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>0</td>, <td>0</td>, <td>0</td>, <td>1</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>0</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>, <td>1</td>]

[<td>EVEX.128.66.0F38.W0 26 /r VPTESTMB k2 {k1}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise AND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 26 /r VPTESTMB k2 {k1}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise AND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 26 /r VPTESTMB k2 {k1}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.66.0F38.W1 26 /r VPTESTMW k2 {k1}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise AND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 26 /r VPTESTMW k2 {k1}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise AND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 26 /r VPTESTMW k2 {k1}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.66.0F38.W0 27 /r VPTESTMD k2 {k1}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 27 /r VPTESTMD k2 {k1}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 27 /r VPTESTMD k2 {k1}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.66.0F38.W1 27 /r VPTESTMQ k2 {k1}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 27 /r VPTESTMQ k2 {k1}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 27 /r VPTESTMQ k2 {k1}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 26 /r VPTESTMB k2 {k1}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise AND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 26 /r VPTESTMB k2 {k1}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise AND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 26 /r VPTESTMB k2 {k1}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.66.0F38.W1 26 /r VPTESTMW k2 {k1}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise AND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 26 /r VPTESTMW k2 {k1}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise AND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 26 /r VPTESTMW k2 {k1}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.66.0F38.W0 27 /r VPTESTMD k2 {k1}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 27 /r VPTESTMD k2 {k1}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 27 /r VPTESTMD k2 {k1}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.66.0F38.W1 27 /r VPTESTMQ k2 {k1}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 27 /r VPTESTMQ k2 {k1}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 27 /r VPTESTMQ k2 {k1}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 26 /r VPTESTMB k2 {k1}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise AND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 26 /r VPTESTMB k2 {k1}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise AND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 26 /r VPTESTMB k2 {k1}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.66.0F38.W1 26 /r VPTESTMW k2 {k1}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise AND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 26 /r VPTESTMW k2 {k1}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise AND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 26 /r VPTESTMW k2 {k1}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.66.0F38.W0 27 /r VPTESTMD k2 {k1}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 27 /r VPTESTMD k2 {k1}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 27 /r VPTESTMD k2 {k1}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.66.0F38.W1 27 /r VPTESTMQ k2 {k1}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 27 /r VPTESTMQ k2 {k1}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 27 /r VPTESTMQ k2 {k1}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 26 /r VPTESTMB k2 {k1}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise AND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 26 /r VPTESTMB k2 {k1}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise AND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 26 /r VPTESTMB k2 {k1}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.66.0F38.W1 26 /r VPTESTMW k2 {k1}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise AND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 26 /r VPTESTMW k2 {k1}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise AND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 26 /r VPTESTMW k2 {k1}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512BW</td>, <td>Bitwise AND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.66.0F38.W0 27 /r VPTESTMD k2 {k1}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 27 /r VPTESTMD k2 {k1}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 27 /r VPTESTMD k2 {k1}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.66.0F38.W1 27 /r VPTESTMQ k2 {k1}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 27 /r VPTESTMQ k2 {k1}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise AND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 27 /r VPTESTMQ k2 {k1}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.F3.0F38.W0 26 /r VPTESTNMB k2 {k1}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise NAND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 26 /r VPTESTNMB k2 {k1}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise NAND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 26 /r VPTESTNMB k2 {k1}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F AVX512BW</td>, <td>Bitwise NAND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.F3.0F38.W1 26 /r VPTESTNMW k2 {k1}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise NAND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.F3.0F38.W1 26 /r VPTESTNMW k2 {k1}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise NAND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.F3.0F38.W1 26 /r VPTESTNMW k2 {k1}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F AVX512BW</td>, <td>Bitwise NAND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 27 /r VPTESTNMD k2 {k1}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise NAND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 27 /r VPTESTNMD k2 {k1}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise NAND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 27 /r VPTESTNMD k2 {k1}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise NAND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.F3.0F38.W1 27 /r VPTESTNMQ k2 {k1}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise NAND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.F3.0F38.W1 27 /r VPTESTNMQ k2 {k1}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise NAND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.F3.0F38.W1 27 /r VPTESTNMQ k2 {k1}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise NAND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.F3.0F38.W0 26 /r VPTESTNMB k2 {k1}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise NAND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 26 /r VPTESTNMB k2 {k1}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise NAND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 26 /r VPTESTNMB k2 {k1}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F AVX512BW</td>, <td>Bitwise NAND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.F3.0F38.W1 26 /r VPTESTNMW k2 {k1}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise NAND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.F3.0F38.W1 26 /r VPTESTNMW k2 {k1}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise NAND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.F3.0F38.W1 26 /r VPTESTNMW k2 {k1}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F AVX512BW</td>, <td>Bitwise NAND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 27 /r VPTESTNMD k2 {k1}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise NAND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 27 /r VPTESTNMD k2 {k1}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise NAND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 27 /r VPTESTNMD k2 {k1}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise NAND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.F3.0F38.W1 27 /r VPTESTNMQ k2 {k1}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise NAND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.F3.0F38.W1 27 /r VPTESTNMQ k2 {k1}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise NAND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.F3.0F38.W1 27 /r VPTESTNMQ k2 {k1}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise NAND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.F3.0F38.W0 26 /r VPTESTNMB k2 {k1}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise NAND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 26 /r VPTESTNMB k2 {k1}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise NAND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 26 /r VPTESTNMB k2 {k1}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F AVX512BW</td>, <td>Bitwise NAND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.F3.0F38.W1 26 /r VPTESTNMW k2 {k1}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise NAND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.F3.0F38.W1 26 /r VPTESTNMW k2 {k1}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise NAND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.F3.0F38.W1 26 /r VPTESTNMW k2 {k1}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F AVX512BW</td>, <td>Bitwise NAND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 27 /r VPTESTNMD k2 {k1}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise NAND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 27 /r VPTESTNMD k2 {k1}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise NAND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 27 /r VPTESTNMD k2 {k1}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise NAND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.F3.0F38.W1 27 /r VPTESTNMQ k2 {k1}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise NAND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.F3.0F38.W1 27 /r VPTESTNMQ k2 {k1}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise NAND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.F3.0F38.W1 27 /r VPTESTNMQ k2 {k1}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise NAND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.F3.0F38.W0 26 /r VPTESTNMB k2 {k1}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise NAND of packed byte integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 26 /r VPTESTNMB k2 {k1}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise NAND of packed byte integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 26 /r VPTESTNMB k2 {k1}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F AVX512BW</td>, <td>Bitwise NAND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.F3.0F38.W1 26 /r VPTESTNMW k2 {k1}, xmm2, xmm3/m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise NAND of packed word integers in xmm2 and xmm3/m128 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.F3.0F38.W1 26 /r VPTESTNMW k2 {k1}, ymm2, ymm3/m256</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512BW</td>, <td>Bitwise NAND of packed word integers in ymm2 and ymm3/m256 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.F3.0F38.W1 26 /r VPTESTNMW k2 {k1}, zmm2, zmm3/m512</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F AVX512BW</td>, <td>Bitwise NAND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.F3.0F38.W0 27 /r VPTESTNMD k2 {k1}, xmm2, xmm3/m128/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise NAND of packed doubleword integers in xmm2 and xmm3/m128/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.F3.0F38.W0 27 /r VPTESTNMD k2 {k1}, ymm2, ymm3/m256/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise NAND of packed doubleword integers in ymm2 and ymm3/m256/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.F3.0F38.W0 27 /r VPTESTNMD k2 {k1}, zmm2, zmm3/m512/m32bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise NAND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.128.F3.0F38.W1 27 /r VPTESTNMQ k2 {k1}, xmm2, xmm3/m128/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise NAND of packed quadword integers in xmm2 and xmm3/m128/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.256.F3.0F38.W1 27 /r VPTESTNMQ k2 {k1}, ymm2, ymm3/m256/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Bitwise NAND of packed quadword integers in ymm2 and ymm3/m256/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>EVEX.512.F3.0F38.W1 27 /r VPTESTNMQ k2 {k1}, zmm2, zmm3/m512/m64bcst</td>, <td>B</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Bitwise NAND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full Mem</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>B</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F3A.W1 50 /r ib VRANGEPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Calculate two RANGE operation output value from 2 pairs of double-precision floating-point values in xmm2 and xmm3/m128/m32bcst, store the results to xmm1 under the writemask k1. Imm8 specifies the comparison and sign of the range operation.</td>, <td>EVEX.256.66.0F3A.W1 50 /r ib VRANGEPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Calculate four RANGE operation output value from 4pairs of double-precision floating-point values in ymm2 and ymm3/m256/m32bcst, store the results to ymm1 under the writemask k1. Imm8 specifies the comparison and sign of the range operation.</td>, <td>EVEX.512.66.0F3A.W1 50 /r ib VRANGEPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Calculate eight RANGE operation output value from 8 pairs of double-precision floating-point values in zmm2 and zmm3/m512/m32bcst, store the results to zmm1 under the writemask k1. Imm8 specifies the comparison and sign of the range operation.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>sNaN1</td>, <td>sNaN2</td>, <td>Quiet(sNaN1)</td>, <td>Yes</td>, <td>Ignored</td>, <td>sNaN1</td>, <td>qNaN2</td>, <td>Quiet(sNaN1)</td>, <td>Yes</td>, <td>Ignored</td>, <td>sNaN1</td>, <td>Norm2</td>, <td>Quiet(sNaN1)</td>, <td>Yes</td>, <td>Ignored</td>, <td>qNaN1</td>, <td>sNaN2</td>, <td>Quiet(sNaN2)</td>, <td>Yes</td>, <td>Ignored</td>, <td>qNaN1</td>, <td>qNaN2</td>, <td>qNaN1</td>, <td>No</td>, <td>Applicable</td>, <td>qNaN1</td>, <td>Norm2</td>, <td>Norm2</td>, <td>No</td>, <td>Applicable</td>, <td>Norm1</td>, <td>sNaN2</td>, <td>Quiet(sNaN2)</td>, <td>Yes</td>, <td>Ignored</td>, <td>Norm1</td>, <td>qNaN2</td>, <td>Norm1</td>, <td>No</td>, <td>Applicable</td>, <td>+0</td>, <td>-0</td>, <td>-0</td>, <td>+0</td>, <td>-0</td>, <td>+0</td>, <td>-0</td>, <td>+0</td>, <td>-0</td>, <td>-0</td>, <td>+0</td>, <td>+0</td>, <td>a</td>, <td>b</td>, <td>b</td>, <td>a</td>, <td>b</td>, <td>a</td>, <td>b</td>, <td>a</td>, <td>b</td>, <td>b</td>, <td>a</td>, <td>a</td>]

[<td>EVEX.128.66.0F3A.W0 50 /r ib VRANGEPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Calculate four RANGE operation output value from 4 pairs of single-precision floating-point values in xmm2 and xmm3/m128/m32bcst, store the results to xmm1 under the writemask k1. Imm8 specifies the comparison and sign of the range operation.</td>, <td>EVEX.256.66.0F3A.W0 50 /r ib VRANGEPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Calculate eight RANGE operation output value from 8 pairs of single-precision floating-point values in ymm2 and ymm3/m256/m32bcst, store the results to ymm1 under the writemask k1. Imm8 specifies the comparison and sign of the range operation.</td>, <td>EVEX.512.66.0F3A.W0 50 /r ib VRANGEPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Calculate 16 RANGE operation output value from 16 pairs of single-precision floating-point values in zmm2 and zmm3/m512/m32bcst, store the results to zmm1 under the writemask k1. Imm8 specifies the comparison and sign of the range operation.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>]

[<td>EVEX.LIG.66.0F3A.W1 51 /r VRANGESD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Calculate a RANGE operation output value from 2 double-precision floating-point values in xmm2 and xmm3/m64, store the output to xmm1 under writemask. Imm8 specifies the comparison and sign of the range operation.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>]

[<td>EVEX.LIG.66.0F3A.W0 51 /r VRANGESS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Calculate a RANGE operation output value from 2 single-precision floating-point values in xmm2 and xmm3/m32, store the output to xmm1 under writemask. Imm8 specifies the comparison and sign of the range operation.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 4C /r VRCP14PD xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Computes the approximate reciprocals of the packed double-precision floating-point values in xmm2/m128/m64bcst and stores the results in xmm1. Under writemask.</td>, <td>EVEX.256.66.0F38.W1 4C /r VRCP14PD ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Computes the approximate reciprocals of the packed double-precision floating-point values in ymm2/m256/m64bcst and stores the results in ymm1. Under writemask.</td>, <td>EVEX.512.66.0F38.W1 4C /r VRCP14PD zmm1 {k1}{z}, zmm2/m512/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Computes the approximate reciprocals of the packed double-precision floating-point values in zmm2/m512/m64bcst and stores the results in zmm1. Under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td><sub>0 ≤ X ≤ 2</sub><sup>-1024</sup></td>, <td>INF</td>, <td>Very small denormal</td>, <td>-2<sup>-1024</sup> ≤ X ≤ -0</td>, <td>-INF</td>, <td>Very small denormal</td>, <td><sub>X &gt; 2</sub>1022</td>, <td>Underflow</td>, <td>Up to 18 bits of fractions are returned*</td>, <td><sub>X &lt; -2</sub><sup>1022</sup></td>, <td>-Underflow</td>, <td>Up to 18 bits of fractions are returned*</td>, <td><sub>X = 2</sub>-n</td>, <td><sub>2</sub><sup>n</sup></td>, <td></td>, <td>X = -2<sup>-n</sup></td>, <td>-2<sup>n</sup></td>, <td></td>]

[<td>EVEX.128.66.0F38.W0 4C /r VRCP14PS xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Computes the approximate reciprocals of the packed single-precision floating-point values in xmm2/m128/m32bcst and stores the results in xmm1. Under writemask.</td>, <td>EVEX.256.66.0F38.W0 4C /r VRCP14PS ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Computes the approximate reciprocals of the packed single-precision floating-point values in ymm2/m256/m32bcst and stores the results in ymm1. Under writemask.</td>, <td>EVEX.512.66.0F38.W0 4C /r VRCP14PS zmm1 {k1}{z}, zmm2/m512/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Computes the approximate reciprocals of the packed single-precision floating-point values in zmm2/m512/m32bcst and stores the results in zmm1. Under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td><sub>0 ≤ X ≤ 2</sub><sup>-128</sup></td>, <td>INF</td>, <td>Very small denormal</td>, <td>-2<sup>-128</sup> ≤ X ≤ -0</td>, <td>-INF</td>, <td>Very small denormal</td>, <td>X &gt; 2<sup>126</sup></td>, <td>Underflow</td>, <td>Up to 18 bits of fractions are returned*</td>, <td>X &lt; -2<sup>126</sup></td>, <td>-Underflow</td>, <td>Up to 18 bits of fractions are returned*</td>, <td><sub>X = 2</sub>-n</td>, <td><sub>2</sub><sup>n</sup></td>, <td></td>, <td>X = -2<sup>-n</sup></td>, <td>-2<sup>n</sup></td>, <td></td>]

[<td>EVEX.LIG.66.0F38.W1 4D /r VRCP14SD xmm1 {k1}{z}, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Computes the approximate reciprocal of the scalar double-precision floating-point value in xmm3/m64 and stores the result in xmm1 using writemask k1. Also, upper double-precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64].</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.LIG.66.0F38.W0 4D /r VRCP14SS xmm1 {k1}{z}, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Computes the approximate reciprocal of the scalar single-precision floating-point value in xmm3/m32 and stores the results in xmm1 using writemask k1. Also, upper double-precision floating-point value (bits[127:32]) from xmm2 is copied to xmm1[127:32].</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F3A.W1 56 /r ib VREDUCEPD xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Perform reduction transformation on packed double-precision floating point values in xmm2/m128/m32bcst by subtracting a number of fraction bits specified by the imm8 field. Stores the result in xmm1 register under writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 56 /r ib VREDUCEPD ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Perform reduction transformation on packed double-precision floating point values in ymm2/m256/m32bcst by subtracting a number of fraction bits specified by the imm8 field. Stores the result in ymm1 register under writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 56 /r ib VREDUCEPD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Perform reduction transformation on double-precision floating point values in zmm2/m512/m32bcst by subtracting a number of fraction bits specified by the imm8 field. Stores the result in zmm1 register under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>|Src1| &lt; 2<sup>-M-1</sup></td>, <td>RNE</td>, <td>Src1</td>, <td rowspan="4">|Src1| &lt; 2<sup>-M</sup></td>, <td>RPI, Src1 &gt; 0</td>, <td>Round (Src1-2<sup>-M</sup>) *</td>, <td>RPI, Src1 ≤ 0</td>, <td>Src1</td>, <td>RNI, Src1 ≥ 0</td>, <td>Src1</td>, <td>RNI, Src1 &lt; 0</td>, <td>Round (Src1+2<sup>-M</sup>) *</td>, <td rowspan="2">Src1 = ±0, or Dest = ±0 (Src1!=INF)</td>, <td>NOT RNI</td>, <td>+0.0</td>, <td>RNI</td>, <td>-0.0</td>, <td>Src1 = ±INF</td>, <td>any</td>, <td>+0.0</td>, <td>Src1= ±NAN</td>, <td>n/a</td>, <td>QNaN(Src1)</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.128.66.0F3A.W0 56 /r ib VREDUCEPS xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Perform reduction transformation on packed single-precision floating point values in xmm2/m128/m32bcst by subtracting a number of fraction bits specified by the imm8 field. Stores the result in xmm1 register under writemask k1.</td>, <td>EVEX.256.66.0F3A.W0 56 /r ib VREDUCEPS ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Perform reduction transformation on packed single-precision floating point values in ymm2/m256/m32bcst by subtracting a number of fraction bits specified by the imm8 field. Stores the result in ymm1 register under writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 56 /r ib VREDUCEPS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Perform reduction transformation on packed single-precision floating point values in zmm2/m512/m32bcst by subtracting a number of fraction bits specified by the imm8 field. Stores the result in zmm1 register under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.vvvv != 1111B.</td>]

[<td>EVEX.LIG.66.0F3A.W1 57 VREDUCESD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}, imm8/r</td>, <td>A</td>, <td>V/V</td>, <td>AVX512D Q</td>, <td>Perform a reduction transformation on a scalar double-precision floating point value in xmm3/m64 by subtracting a number of fraction bits specified by the imm8 field. Also, upper double precision floating-point value (bits[127:64]) from xmm2 are copied to xmm1[127:64]. Stores the result in xmm1 register.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.LIG.66.0F3A.W0 57 /r /ib VREDUCESS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Perform a reduction transformation on a scalar single-precision floating point value in xmm3/m32 by subtracting a number of fraction bits specified by the imm8 field. Also, upper single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32]. Stores the result in xmm1 register.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F3A.W1 09 /r ib VRNDSCALEPD xmm1 {k1}{z}, xmm2/m128/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rounds packed double-precision floating point values in xmm2/m128/m64bcst to a number of fraction bits specified by the imm8 field. Stores the result in xmm1 register. Under writemask.</td>, <td>EVEX.256.66.0F3A.W1 09 /r ib VRNDSCALEPD ymm1 {k1}{z}, ymm2/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rounds packed double-precision floating point values in ymm2/m256/m64bcst to a number of fraction bits specified by the imm8 field. Stores the result in ymm1 register. Under writemask.</td>, <td>EVEX.512.66.0F3A.W1 09 /r ib VRNDSCALEPD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rounds packed double-precision floating-point values in zmm2/m512/m64bcst to a number of fraction bits specified by the imm8 field. Stores the result in zmm1 register using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>, <td><strong>Src1=±inf</strong></td>, <td>Src1</td>, <td><strong>Src1=±NAN</strong></td>, <td>Src1 converted to QNAN</td>, <td><strong>Src1=±0</strong></td>, <td>Src1</td>]

[<td>EVEX.128.66.0F3A.W0 08 /r ib VRNDSCALEPS xmm1 {k1}{z}, xmm2/m128/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rounds packed single-precision floating point values in xmm2/m128/m32bcst to a number of fraction bits specified by the imm8 field. Stores the result in xmm1 register. Under writemask.</td>, <td>EVEX.256.66.0F3A.W0 08 /r ib VRNDSCALEPS ymm1 {k1}{z}, ymm2/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Rounds packed single-precision floating point values in ymm2/m256/m32bcst to a number of fraction bits specified by the imm8 field. Stores the result in ymm1 register. Under writemask.</td>, <td>EVEX.512.66.0F3A.W0 08 /r ib VRNDSCALEPS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rounds packed single-precision floating-point values in zmm2/m512/m32bcst to a number of fraction bits specified by the imm8 field. Stores the result in zmm1 register using writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>, <td>NA</td>]

[<td>EVEX.LIG.66.0F3A.W1 0B /r ib VRNDSCALESD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rounds scalar double-precision floating-point value in xmm3/m64 to a number of fraction bits specified by the imm8 field. Stores the result in xmm1 register.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>Imm8</td>]

[<td>EVEX.LIG.66.0F3A.W0 0A /r ib VRNDSCALESS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Rounds scalar single-precision floating-point value in xmm3/m32 to a number of fraction bits specified by the imm8 field. Stores the result in xmm1 register under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W1 4E /r VRSQRT14PD xmm1 {k1}{z}, xmm2/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Computes the approximate reciprocal square roots of the packed double-precision floating-point values in xmm2/m128/m64bcst and stores the results in xmm1. Under writemask.</td>, <td>EVEX.256.66.0F38.W1 4E /r VRSQRT14PD ymm1 {k1}{z}, ymm2/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Computes the approximate reciprocal square roots of the packed double-precision floating-point values in ymm2/m256/m64bcst and stores the results in ymm1. Under writemask.</td>, <td>EVEX.512.66.0F38.W1 4E /r VRSQRT14PD zmm1 {k1}{z}, zmm2/m512/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Computes the approximate reciprocal square roots of the packed double-precision floating-point values in zmm2/m512/m64bcst and stores the results in zmm1 under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>Any denormal</td>, <td>Normal</td>, <td>Cannot generate overflow</td>, <td>X = 2<sup>-2n</sup></td>, <td><sub>2</sub><sup>n</sup></td>, <td></td>, <td>X&lt;0</td>, <td>QNaN_Indefinite</td>, <td>Including -INF</td>, <td>X = -0</td>, <td>-INF</td>, <td></td>, <td>X = +0</td>, <td>+INF</td>, <td></td>, <td>X = +INF</td>, <td>+0</td>, <td></td>]

[<td>EVEX.128.66.0F38.W0 4E /r VRSQRT14PS xmm1 {k1}{z}, xmm2/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Computes the approximate reciprocal square roots of the packed single-precision floating-point values in xmm2/m128/m32bcst and stores the results in xmm1. Under writemask.</td>, <td>EVEX.256.66.0F38.W0 4E /r VRSQRT14PS ymm1 {k1}{z}, ymm2/m256/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Computes the approximate reciprocal square roots of the packed single-precision floating-point values in ymm2/m256/m32bcst and stores the results in ymm1. Under writemask.</td>, <td>EVEX.512.66.0F38.W0 4E /r VRSQRT14PS zmm1 {k1}{z}, zmm2/m512/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Computes the approximate reciprocal square roots of the packed single-precision floating-point values in zmm2/m512/m32bcst and stores the results in zmm1. Under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>Any denormal</td>, <td>Normal</td>, <td>Cannot generate overflow</td>, <td>X = 2<sup>-2n</sup></td>, <td><sub>2</sub><sup>n</sup></td>, <td></td>, <td>X&lt;0</td>, <td>QNaN_Indefinite</td>, <td>Including -INF</td>, <td>X = -0</td>, <td>-INF</td>, <td></td>, <td>X = +0</td>, <td>+INF</td>, <td></td>, <td>X = +INF</td>, <td>+0</td>, <td></td>]

[<td>EVEX.LIG.66.0F38.W1 4F /r VRSQRT14SD xmm1 {k1}{z}, xmm2, xmm3/m64</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Computes the approximate reciprocal square root of the scalar double-precision floating-point value in xmm3/m64 and stores the result in the low quadword element of xmm1 using writemask k1. Bits[127:64] of xmm2 is copied to xmm1[127:64].</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>Any denormal</td>, <td>Normal</td>, <td>Cannot generate overflow</td>, <td>X = 2<sup>-2n</sup></td>, <td><sub>2</sub><sup>n</sup></td>, <td></td>, <td>X&lt;0</td>, <td>QNaN_Indefinite</td>, <td>Including -INF</td>, <td>X = -0</td>, <td>-INF</td>, <td></td>, <td>X = +0</td>, <td>+INF</td>, <td></td>, <td>X = +INF</td>, <td>+0</td>, <td></td>]

[<td>EVEX.LIG.66.0F38.W0 4F /r VRSQRT14SS xmm1 {k1}{z}, xmm2, xmm3/m32</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Computes the approximate reciprocal square root of the scalar single-precision floating-point value in xmm3/m32 and stores the result in the low doubleword element of xmm1 using writemask k1. Bits[127:32] of xmm2 is copied to xmm1[127:32].</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>Any denormal</td>, <td>Normal</td>, <td>Cannot generate overflow</td>, <td>X = 2<sup>-2n</sup></td>, <td><sub>2</sub><sup>n</sup></td>, <td></td>, <td>X&lt;0</td>, <td>QNaN_Indefinite</td>, <td>Including -INF</td>, <td>X = -0</td>, <td>-INF</td>, <td></td>, <td>X = +0</td>, <td>+INF</td>, <td></td>, <td>X = +INF</td>, <td>+0</td>, <td></td>]

[<td>EVEX.128.66.0F38.W1 2C /r VSCALEFPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Scale the packed double-precision floating-point values in xmm2 using values from xmm3/m128/m64bcst. Under writemask k1.</td>, <td>EVEX.256.66.0F38.W1 2C /r VSCALEFPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Scale the packed double-precision floating-point values in ymm2 using values from ymm3/m256/m64bcst. Under writemask k1.</td>, <td>EVEX.512.66.0F38.W1 2C /r VSCALEFPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Scale the packed double-precision floating-point values in zmm2 using values from zmm3/m512/m64bcst. Under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td><strong>Src1</strong></td>, <td>±QNaN</td>, <td>QNaN(Src1)</td>, <td>+INF</td>, <td>+0</td>, <td>QNaN(Src1)</td>, <td>IF either source is SNAN</td>, <td></td>, <td>±SNaN</td>, <td>QNaN(Src1)</td>, <td>QNaN(Src1)</td>, <td>QNaN(Src1)</td>, <td>QNaN(Src1)</td>, <td>YES</td>, <td></td>, <td>±Inf</td>, <td>QNaN(Src2)</td>, <td>Src1</td>, <td>QNaN_Indefinite</td>, <td>Src1</td>, <td>IF Src2 is SNAN or -INF</td>, <td></td>, <td>±0</td>, <td>QNaN(Src2)</td>, <td>QNaN_Indefinite</td>, <td>Src1</td>, <td>Src1</td>, <td>IF Src2 is SNAN or +INF</td>, <td></td>, <td>Denorm/Norm</td>, <td>QNaN(Src2)</td>, <td>±INF (Src1 sign)</td>, <td>±0 (Src1 sign)</td>, <td>Compute Result</td>, <td>IF Src2 is SNAN</td>, <td>|result| &lt; 2<sup>-1074</sup></td>, <td>±0 or ±Min-Denormal (Src1 sign)</td>, <td>Underflow</td>, <td>|result| ≥ 2<sup>1024</sup></td>, <td>±INF (Src1 sign) or ±Max-normal (Src1 sign)</td>, <td>Overflow</td>]

[<td>EVEX.128.66.0F38.W0 2C /r VSCALEFPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Scale the packed single-precision floating-point values in xmm2 using values from xmm3/m128/m32bcst. Under writemask k1.</td>, <td>EVEX.256.66.0F38.W0 2C /r VSCALEFPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Scale the packed single-precision values in ymm2 using floating point values from ymm3/m256/m32bcst. Under writemask k1.</td>, <td>EVEX.512.66.0F38.W0 2C /r VSCALEFPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Scale the packed single-precision floating-point values in zmm2 using floating-point values from zmm3/m512/m32bcst. Under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>|result| &lt; 2<sup>-149</sup></td>, <td>±0 or ±Min-Denormal (Src1 sign)</td>, <td>Underflow</td>, <td>|result| ≥ 2<sup>128</sup></td>, <td>±INF (Src1 sign) or ±Max-normal (Src1 sign)</td>, <td>Overflow</td>]

[<td>EVEX.LIG.66.0F38.W1 2D /r VSCALEFSD xmm1 {k1}{z}, xmm2, xmm3/m64{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Scale the scalar double-precision floating-point values in xmm2 using the value from xmm3/m64. Under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.LIG.66.0F38.W0 2D /r VSCALEFSS xmm1 {k1}{z}, xmm2, xmm3/m32{er}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Scale the scalar single-precision floating-point value in xmm2 using floating-point value from xmm3/m32. Under writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 A2 /vsib VSCATTERDPS vm32x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A2 /vsib VSCATTERDPS vm32y {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A2 /vsib VSCATTERDPS vm32z {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A2 /vsib VSCATTERDPD vm32x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A2 /vsib VSCATTERDPD vm32x {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A2 /vsib VSCATTERDPD vm32y {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 A3 /vsib VSCATTERQPS vm64x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A3 /vsib VSCATTERQPS vm64y {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A3 /vsib VSCATTERQPS vm64z {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A3 /vsib VSCATTERQPD vm64x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A3 /vsib VSCATTERQPD vm64y {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A3 /vsib VSCATTERQPD vm64z {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 A2 /vsib VSCATTERDPS vm32x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A2 /vsib VSCATTERDPS vm32y {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A2 /vsib VSCATTERDPS vm32z {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A2 /vsib VSCATTERDPD vm32x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A2 /vsib VSCATTERDPD vm32x {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A2 /vsib VSCATTERDPD vm32y {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 A3 /vsib VSCATTERQPS vm64x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A3 /vsib VSCATTERQPS vm64y {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A3 /vsib VSCATTERQPS vm64z {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A3 /vsib VSCATTERQPD vm64x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A3 /vsib VSCATTERQPD vm64y {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A3 /vsib VSCATTERQPD vm64z {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 A2 /vsib VSCATTERDPS vm32x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A2 /vsib VSCATTERDPS vm32y {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A2 /vsib VSCATTERDPS vm32z {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A2 /vsib VSCATTERDPD vm32x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A2 /vsib VSCATTERDPD vm32x {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A2 /vsib VSCATTERDPD vm32y {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 A3 /vsib VSCATTERQPS vm64x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A3 /vsib VSCATTERQPS vm64y {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A3 /vsib VSCATTERQPS vm64z {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A3 /vsib VSCATTERQPD vm64x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A3 /vsib VSCATTERQPD vm64y {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A3 /vsib VSCATTERQPD vm64z {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.128.66.0F38.W0 A2 /vsib VSCATTERDPS vm32x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A2 /vsib VSCATTERDPS vm32y {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A2 /vsib VSCATTERDPS vm32z {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A2 /vsib VSCATTERDPD vm32x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A2 /vsib VSCATTERDPD vm32x {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed dword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A2 /vsib VSCATTERDPD vm32y {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed dword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W0 A3 /vsib VSCATTERQPS vm64x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W0 A3 /vsib VSCATTERQPS vm64y {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W0 A3 /vsib VSCATTERQPS vm64z {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, scatter single-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.128.66.0F38.W1 A3 /vsib VSCATTERQPD vm64x {k1}, xmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.256.66.0F38.W1 A3 /vsib VSCATTERQPD vm64y {k1}, ymm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Using signed qword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>EVEX.512.66.0F38.W1 A3 /vsib VSCATTERQPD vm64z {k1}, zmm1</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Using signed qword indices, scatter double-precision floating-point values to memory using writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.256.66.0F3A.W0 23 /r ib VSHUFF32X4 ymm1{k1}{z}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle 128-bit packed single-precision floating-point values selected by imm8 from ymm2 and ymm3/m256/m32bcst and place results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 23 /r ib VSHUFF32x4 zmm1{k1}{z}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle 128-bit packed single-precision floating-point values selected by imm8 from zmm2 and zmm3/m512/m32bcst and place results in zmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 23 /r ib VSHUFF64X2 ymm1{k1}{z}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle 128-bit packed double-precision floating-point values selected by imm8 from ymm2 and ymm3/m256/m64bcst and place results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 23 /r ib VSHUFF64x2 zmm1{k1}{z}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle 128-bit packed double-precision floating-point values selected by imm8 from zmm2 and zmm3/m512/m64bcst and place results in zmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W0 43 /r ib VSHUFI32X4 ymm1{k1}{z}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle 128-bit packed double-word values selected by imm8 from ymm2 and ymm3/m256/m32bcst and place results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 43 /r ib VSHUFI32x4 zmm1{k1}{z}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle 128-bit packed double-word values selected by imm8 from zmm2 and zmm3/m512/m32bcst and place results in zmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 43 /r ib VSHUFI64X2 ymm1{k1}{z}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle 128-bit packed quad-word values selected by imm8 from ymm2 and ymm3/m256/m64bcst and place results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 43 /r ib VSHUFI64x2 zmm1{k1}{z}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle 128-bit packed quad-word values selected by imm8 from zmm2 and zmm3/m512/m64bcst and place results in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.L’L = 0 for VSHUFF32x4/VSHUFF64x2.</td>]

[<td>EVEX.256.66.0F3A.W0 23 /r ib VSHUFF32X4 ymm1{k1}{z}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle 128-bit packed single-precision floating-point values selected by imm8 from ymm2 and ymm3/m256/m32bcst and place results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 23 /r ib VSHUFF32x4 zmm1{k1}{z}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle 128-bit packed single-precision floating-point values selected by imm8 from zmm2 and zmm3/m512/m32bcst and place results in zmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 23 /r ib VSHUFF64X2 ymm1{k1}{z}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle 128-bit packed double-precision floating-point values selected by imm8 from ymm2 and ymm3/m256/m64bcst and place results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 23 /r ib VSHUFF64x2 zmm1{k1}{z}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle 128-bit packed double-precision floating-point values selected by imm8 from zmm2 and zmm3/m512/m64bcst and place results in zmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W0 43 /r ib VSHUFI32X4 ymm1{k1}{z}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle 128-bit packed double-word values selected by imm8 from ymm2 and ymm3/m256/m32bcst and place results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 43 /r ib VSHUFI32x4 zmm1{k1}{z}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle 128-bit packed double-word values selected by imm8 from zmm2 and zmm3/m512/m32bcst and place results in zmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 43 /r ib VSHUFI64X2 ymm1{k1}{z}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle 128-bit packed quad-word values selected by imm8 from ymm2 and ymm3/m256/m64bcst and place results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 43 /r ib VSHUFI64x2 zmm1{k1}{z}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle 128-bit packed quad-word values selected by imm8 from zmm2 and zmm3/m512/m64bcst and place results in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.L’L = 0 for VSHUFF32x4/VSHUFF64x2.</td>]

[<td>EVEX.256.66.0F3A.W0 23 /r ib VSHUFF32X4 ymm1{k1}{z}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle 128-bit packed single-precision floating-point values selected by imm8 from ymm2 and ymm3/m256/m32bcst and place results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 23 /r ib VSHUFF32x4 zmm1{k1}{z}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle 128-bit packed single-precision floating-point values selected by imm8 from zmm2 and zmm3/m512/m32bcst and place results in zmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 23 /r ib VSHUFF64X2 ymm1{k1}{z}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle 128-bit packed double-precision floating-point values selected by imm8 from ymm2 and ymm3/m256/m64bcst and place results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 23 /r ib VSHUFF64x2 zmm1{k1}{z}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle 128-bit packed double-precision floating-point values selected by imm8 from zmm2 and zmm3/m512/m64bcst and place results in zmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W0 43 /r ib VSHUFI32X4 ymm1{k1}{z}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle 128-bit packed double-word values selected by imm8 from ymm2 and ymm3/m256/m32bcst and place results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 43 /r ib VSHUFI32x4 zmm1{k1}{z}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle 128-bit packed double-word values selected by imm8 from zmm2 and zmm3/m512/m32bcst and place results in zmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 43 /r ib VSHUFI64X2 ymm1{k1}{z}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle 128-bit packed quad-word values selected by imm8 from ymm2 and ymm3/m256/m64bcst and place results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 43 /r ib VSHUFI64x2 zmm1{k1}{z}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle 128-bit packed quad-word values selected by imm8 from zmm2 and zmm3/m512/m64bcst and place results in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.L’L = 0 for VSHUFF32x4/VSHUFF64x2.</td>]

[<td>EVEX.256.66.0F3A.W0 23 /r ib VSHUFF32X4 ymm1{k1}{z}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle 128-bit packed single-precision floating-point values selected by imm8 from ymm2 and ymm3/m256/m32bcst and place results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 23 /r ib VSHUFF32x4 zmm1{k1}{z}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle 128-bit packed single-precision floating-point values selected by imm8 from zmm2 and zmm3/m512/m32bcst and place results in zmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 23 /r ib VSHUFF64X2 ymm1{k1}{z}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle 128-bit packed double-precision floating-point values selected by imm8 from ymm2 and ymm3/m256/m64bcst and place results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 23 /r ib VSHUFF64x2 zmm1{k1}{z}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle 128-bit packed double-precision floating-point values selected by imm8 from zmm2 and zmm3/m512/m64bcst and place results in zmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W0 43 /r ib VSHUFI32X4 ymm1{k1}{z}, ymm2, ymm3/m256/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle 128-bit packed double-word values selected by imm8 from ymm2 and ymm3/m256/m32bcst and place results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W0 43 /r ib VSHUFI32x4 zmm1{k1}{z}, zmm2, zmm3/m512/m32bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle 128-bit packed double-word values selected by imm8 from zmm2 and zmm3/m512/m32bcst and place results in zmm1 subject to writemask k1.</td>, <td>EVEX.256.66.0F3A.W1 43 /r ib VSHUFI64X2 ymm1{k1}{z}, ymm2, ymm3/m256/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512VL AVX512F</td>, <td>Shuffle 128-bit packed quad-word values selected by imm8 from ymm2 and ymm3/m256/m64bcst and place results in ymm1 subject to writemask k1.</td>, <td>EVEX.512.66.0F3A.W1 43 /r ib VSHUFI64x2 zmm1{k1}{z}, zmm2, zmm3/m512/m64bcst, imm8</td>, <td>A</td>, <td>V/V</td>, <td>AVX512F</td>, <td>Shuffle 128-bit packed quad-word values selected by imm8 from zmm2 and zmm3/m512/m64bcst and place results in zmm1 subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>#UD</td>, <td>If EVEX.L’L = 0 for VSHUFF32x4/VSHUFF64x2.</td>]

[<td>VEX.128.66.0F38.W0 0E /r VTESTPS <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of packed single-precision floating-point sources.</td>, <td>VEX.256.66.0F38.W0 0E /r VTESTPS <em>ymm1, ymm2/m256</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of packed single-precision floating-point sources.</td>, <td>VEX.128.66.0F38.W0 0F /r VTESTPD <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of packed double-precision floating-point sources.</td>, <td>VEX.256.66.0F38.W0 0F /r VTESTPD <em>ymm1, ymm2/m256</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of packed double-precision floating-point sources.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If VEX.vvvv ≠ 1111B.</td>, <td>If VEX.W = 1 for VTESTPS or VTESTPD.</td>]

[<td>VEX.128.66.0F38.W0 0E /r VTESTPS <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of packed single-precision floating-point sources.</td>, <td>VEX.256.66.0F38.W0 0E /r VTESTPS <em>ymm1, ymm2/m256</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of packed single-precision floating-point sources.</td>, <td>VEX.128.66.0F38.W0 0F /r VTESTPD <em>xmm1, xmm2/m128</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of packed double-precision floating-point sources.</td>, <td>VEX.256.66.0F38.W0 0F /r VTESTPD <em>ymm1, ymm2/m256</em></td>, <td>RM</td>, <td>V/V</td>, <td>AVX</td>, <td>Set ZF and CF depending on sign bit AND and ANDN of packed double-precision floating-point sources.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>If VEX.vvvv ≠ 1111B.</td>, <td>If VEX.W = 1 for VTESTPS or VTESTPD.</td>]

[<td>VEX.256.0F.WIG 77 VZEROALL</td>, <td>ZO</td>, <td>V/V</td>, <td>AVX</td>, <td>Zero all YMM registers.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>VEX.128.0F.WIG 77 VZEROUPPER</td>, <td>ZO</td>, <td>V/V</td>, <td>AVX</td>, <td>Zero upper 128 bits of all YMM registers.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>9B</td>, <td>WAIT</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Check pending unmasked floating-point exceptions.</td>, <td>9B</td>, <td>FWAIT</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Check pending unmasked floating-point exceptions.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#NM</td>, <td>If CR0.MP[bit 1] = 1 and CR0.TS[bit 3] = 1.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>0F 09</td>, <td>WBINVD</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Write back and flush Internal caches; initiate writing-back and flushing of external caches.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>WBINVD cannot be executed at the virtual-8086 mode.</td>]

[<td colspan="2">F3 0F AE /2 WRFSBASE <em>r32</em></td>, <td>M</td>, <td>V/I</td>, <td>FSGSBASE</td>, <td>Load the FS base address with the 32-bit value in the source register.</td>, <td colspan="2">F3 REX.W 0F AE /2 WRFSBASE <em>r64</em></td>, <td>M</td>, <td>V/I</td>, <td>FSGSBASE</td>, <td>Load the FS base address with the 64-bit value in the source register.</td>, <td>F3 0F AE /3 WRGSBASE <em>r32</em></td>, <td></td>, <td>M</td>, <td>V/I</td>, <td>FSGSBASE</td>, <td>Load the GS base address with the 32-bit value in the source register.</td>, <td colspan="2">F3 REX.W 0F AE /3 WRGSBASE <em>r64</em></td>, <td>M</td>, <td>V/I</td>, <td>FSGSBASE</td>, <td>Load the GS base address with the 64-bit value in the source register.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>The WRFSBASE and WRGSBASE instructions are not recognized in protected mode.</td>, <td>#UD</td>, <td>The WRFSBASE and WRGSBASE instructions are not recognized in real-address mode.</td>, <td>#UD</td>, <td>The WRFSBASE and WRGSBASE instructions are not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The WRFSBASE and WRGSBASE instructions are not recognized in compatibility mode.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CR4.FSGSBASE[bit 16] = 0.</td>, <td>If CPUID.07H.0H:EBX.FSGSBASE[bit 0] = 0</td>, <td>#GP(0)</td>, <td>If the source register contains a non-canonical address.</td>]

[<td colspan="2">F3 0F AE /2 WRFSBASE <em>r32</em></td>, <td>M</td>, <td>V/I</td>, <td>FSGSBASE</td>, <td>Load the FS base address with the 32-bit value in the source register.</td>, <td colspan="2">F3 REX.W 0F AE /2 WRFSBASE <em>r64</em></td>, <td>M</td>, <td>V/I</td>, <td>FSGSBASE</td>, <td>Load the FS base address with the 64-bit value in the source register.</td>, <td>F3 0F AE /3 WRGSBASE <em>r32</em></td>, <td></td>, <td>M</td>, <td>V/I</td>, <td>FSGSBASE</td>, <td>Load the GS base address with the 32-bit value in the source register.</td>, <td colspan="2">F3 REX.W 0F AE /3 WRGSBASE <em>r64</em></td>, <td>M</td>, <td>V/I</td>, <td>FSGSBASE</td>, <td>Load the GS base address with the 64-bit value in the source register.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>The WRFSBASE and WRGSBASE instructions are not recognized in protected mode.</td>, <td>#UD</td>, <td>The WRFSBASE and WRGSBASE instructions are not recognized in real-address mode.</td>, <td>#UD</td>, <td>The WRFSBASE and WRGSBASE instructions are not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The WRFSBASE and WRGSBASE instructions are not recognized in compatibility mode.</td>, <td rowspan="3">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CR4.FSGSBASE[bit 16] = 0.</td>, <td>If CPUID.07H.0H:EBX.FSGSBASE[bit 0] = 0</td>, <td>#GP(0)</td>, <td>If the source register contains a non-canonical address.</td>]

[<td>0F 30</td>, <td>WRMSR</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Write the value in EDX:EAX to MSR specified by ECX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="4">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the value in ECX specifies a reserved or unimplemented MSR address.</td>, <td>If the value in EDX:EAX sets bits that are reserved in the MSR specified by ECX.</td>, <td>If the source register contains a non-canonical address and ECX specifies one of the following MSRs: IA32_DS_AREA, IA32_FS_BASE, IA32_GS_BASE, IA32_KERNEL_GS_BASE, IA32_LSTAR, IA32_SYSENTER_EIP, IA32_SYSENTER_ESP.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="3">#GP</td>, <td>If the value in ECX specifies a reserved or unimplemented MSR address.</td>, <td>If the value in EDX:EAX sets bits that are reserved in the MSR specified by ECX.</td>, <td>If the source register contains a non-canonical address and ECX specifies one of the following MSRs: IA32_DS_AREA, IA32_FS_BASE, IA32_GS_BASE, IA32_KERNEL_GS_BASE, IA32_LSTAR, IA32_SYSENTER_EIP, IA32_SYSENTER_ESP.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>The WRMSR instruction is not recognized in virtual-8086 mode.</td>]

[<td>NP 0F 01 EF</td>, <td>WRPKRU</td>, <td>ZO</td>, <td>V/V</td>, <td>OSPKE</td>, <td>Writes EAX into PKRU.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If ECX ≠ 0.</td>, <td>If EDX ≠ 0.</td>, <td rowspan="2">#UD</td>, <td>If the LOCK prefix is used.</td>, <td>If CR4.PKE = 0.</td>]

[<td>C6 F8 ib XABORT imm8</td>, <td>A</td>, <td>V/V</td>, <td>RTM</td>, <td>Causes an RTM abort if in RTM execution</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand2</td>, <td>Operand3</td>, <td>Operand4</td>, <td>A</td>, <td>imm8</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>CPUID.(EAX=7, ECX=0):EBX.RTM[bit 11] = 0.</td>, <td>If LOCK prefix is used.</td>]

[<td>F2 XACQUIRE</td>, <td>V/V</td>, <td>HLE<sup>1</sup></td>, <td>A hint used with an “XACQUIRE-enabled“ instruction to start lock elision on the instruction memory operand address.</td>, <td>F3 XRELEASE</td>, <td>V/V</td>, <td>HLE</td>, <td>A hint used with an “XRELEASE-enabled“ instruction to end lock elision on the instruction memory operand address.</td>, <td>#GP(0)</td>, <td>If the use of prefix causes instruction length to exceed 15 bytes.</td>]

[<td>0F C0 /<em>r</em></td>, <td>XADD <em>r/m8, r8</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Exchange <em>r8</em> and <em>r/m8</em>; load sum into <em>r/m8</em>.</td>, <td>REX + 0F C0 /<em>r</em></td>, <td>XADD <em>r/m8*, r8*</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Exchange <em>r8</em> and <em>r/m8</em>; load sum into <em>r/m8</em>.</td>, <td>0F C1 /<em>r</em></td>, <td>XADD <em>r/m16, r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Exchange <em>r16</em> and <em>r/m16</em>; load sum into <em>r/m16</em>.</td>, <td>0F C1 /<em>r</em></td>, <td>XADD <em>r/m32, r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Exchange <em>r32</em> and <em>r/m32</em>; load sum into <em>r/m32</em>.</td>, <td>REX.W + 0F C1 /<em>r</em></td>, <td>XADD <em>r/m64, r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Exchange <em>r64</em> and <em>r/m64</em>; load sum into <em>r/m64</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>MR</td>, <td>ModRM:r/m (r, w)</td>, <td>ModRM:reg (r, w)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination is located in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>C7 F8 XBEGIN rel16</td>, <td>A</td>, <td>V/V</td>, <td>RTM</td>, <td>Specifies the start of an RTM region. Provides a 16-bit relative offset to compute the address of the fallback instruction address at which execution resumes following an RTM abort.</td>, <td>C7 F8 XBEGIN rel32</td>, <td>A</td>, <td>V/V</td>, <td>RTM</td>, <td>Specifies the start of an RTM region. Provides a 32-bit relative offset to compute the address of the fallback instruction address at which execution resumes following an RTM abort.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand2</td>, <td>Operand3</td>, <td>Operand4</td>, <td>A</td>, <td>Offset</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>CPUID.(EAX=7, ECX=0):EBX.RTM[bit 11]=0.</td>, <td>If LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the fallback address is outside the CS segment.</td>, <td>#GP(0)</td>, <td>If the fallback address is outside the address space 0000H and FFFFH.</td>, <td rowspan="2">#UD</td>, <td>CPUID.(EAX=7, ECX=0):EBX.RTM[bit 11]=0.</td>, <td>If LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the fallback address is outside the address space 0000H and FFFFH.</td>, <td rowspan="2">#UD</td>, <td>CPUID.(EAX=7, ECX=0):EBX.RTM[bit 11]=0.</td>, <td>If LOCK prefix is used.</td>, <td rowspan="2">#UD</td>, <td>CPUID.(EAX=7, ECX=0):EBX.RTM[bit 11] = 0.</td>, <td>If LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If the fallback address is non-canonical.</td>]

[<td>90+<em>rw</em></td>, <td>XCHG AX, <em>r16</em></td>, <td>O</td>, <td>Valid</td>, <td>Valid</td>, <td>Exchange <em>r16</em> with AX.</td>, <td>90+<em>rw</em></td>, <td>XCHG <em>r16</em>, AX</td>, <td>O</td>, <td>Valid</td>, <td>Valid</td>, <td>Exchange AX with <em>r16.</em></td>, <td>90+<em>rd</em></td>, <td>XCHG EAX, <em>r32</em></td>, <td>O</td>, <td>Valid</td>, <td>Valid</td>, <td>Exchange <em>r32</em> with EAX.</td>, <td>REX.W + 90+<em>rd</em></td>, <td>XCHG RAX, <em>r64</em></td>, <td>O</td>, <td>Valid</td>, <td>N.E.</td>, <td>Exchange <em>r64</em> with RAX.</td>, <td>90+<em>rd</em></td>, <td>XCHG <em>r32</em>, EAX</td>, <td>O</td>, <td>Valid</td>, <td>Valid</td>, <td>Exchange EAX with <em>r32.</em></td>, <td>REX.W + 90+<em>rd</em></td>, <td>XCHG <em>r64</em>, RAX</td>, <td>O</td>, <td>Valid</td>, <td>N.E.</td>, <td>Exchange RAX with <em>r64.</em></td>, <td>86 /<em>r</em></td>, <td>XCHG <em>r/m8, r8</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Exchange <em>r8</em> (byte register) with byte from <em>r/m8.</em></td>, <td>REX + 86 /<em>r</em></td>, <td>XCHG <em>r/m8*, r8*</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Exchange <em>r8</em> (byte register) with byte from <em>r/m8.</em></td>, <td>86 /<em>r</em></td>, <td>XCHG <em>r8, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Exchange byte from <em>r/m8</em> with <em>r8</em> (byte register).</td>, <td>REX + 86 /<em>r</em></td>, <td>XCHG <em>r8*, r/m8*</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Exchange byte from <em>r/m8</em> with <em>r8</em> (byte register).</td>, <td>87 /<em>r</em></td>, <td>XCHG <em>r/m16, r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Exchange <em>r16</em> with word from <em>r/m16.</em></td>, <td>87 /<em>r</em></td>, <td>XCHG <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Exchange word from <em>r/m16</em> with <em>r16.</em></td>, <td>87 /<em>r</em></td>, <td>XCHG <em>r/m32, r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td>Exchange <em>r32</em> with doubleword from <em>r/m32.</em></td>, <td>REX.W + 87 /<em>r</em></td>, <td>XCHG <em>r/m64, r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td>Exchange <em>r64</em> with quadword from <em>r/m64.</em></td>, <td>87 /<em>r</em></td>, <td>XCHG <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td>Exchange doubleword from <em>r/m32</em> with <em>r32.</em></td>, <td>REX.W + 87 /<em>r</em></td>, <td>XCHG <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td>Exchange quadword from <em>r/m64</em> with <em>r64.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>O</td>, <td>AX/EAX/RAX (r, w)</td>, <td>opcode + rd (r, w)</td>, <td>NA</td>, <td>NA</td>, <td>O</td>, <td>opcode + rd (r, w)</td>, <td>AX/EAX/RAX (r, w)</td>, <td>NA</td>, <td>NA</td>, <td>MR</td>, <td>ModRM:r/m (r, w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>RM</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If either operand is in a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>NP 0F 01 D5 XEND</td>, <td>A</td>, <td>V/V</td>, <td>RTM</td>, <td>Specifies the end of an RTM code region.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand2</td>, <td>Operand3</td>, <td>Operand4</td>, <td>A</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>CPUID.(EAX=7, ECX=0):EBX.RTM[bit 11] = 0.</td>, <td>If LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If RTM_ACTIVE = 0.</td>]

[<td>NP 0F 01 D0</td>, <td>XGETBV</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Reads an XCR specified by ECX into EDX:EAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If an invalid XCR is specified in ECX (includes ECX = 1 if CPUID.(EAX=0DH,ECX=1):EAX.XG1[bit 2] = 0).</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If an invalid XCR is specified in ECX (includes ECX = 1 if CPUID.(EAX=0DH,ECX=1):EAX.XG1[bit 2] = 0).</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>]

[<td>D7</td>, <td>XLAT <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Set AL to memory byte DS:[(E)BX + unsigned AL].</td>, <td>D7</td>, <td>XLATB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Set AL to memory byte DS:[(E)BX + unsigned AL].</td>, <td>REX.W + D7</td>, <td>XLATB</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set AL to memory byte [RBX + unsigned AL].</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>D7</td>, <td>XLAT <em>m8</em></td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Set AL to memory byte DS:[(E)BX + unsigned AL].</td>, <td>D7</td>, <td>XLATB</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Set AL to memory byte DS:[(E)BX + unsigned AL].</td>, <td>REX.W + D7</td>, <td>XLATB</td>, <td>ZO</td>, <td>Valid</td>, <td>N.E.</td>, <td>Set AL to memory byte [RBX + unsigned AL].</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>34 <em>ib</em></td>, <td>XOR AL, i<em>mm8</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>AL XOR <em>imm8.</em></td>, <td>35 <em>iw</em></td>, <td>XOR AX, i<em>mm16</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>AX XOR <em>imm16.</em></td>, <td>35 <em>id</em></td>, <td>XOR EAX, i<em>mm32</em></td>, <td>I</td>, <td>Valid</td>, <td>Valid</td>, <td>EAX XOR <em>imm32.</em></td>, <td>REX.W + 35 <em>id</em></td>, <td>XOR RAX, i<em>mm32</em></td>, <td>I</td>, <td>Valid</td>, <td>N.E.</td>, <td>RAX XOR <em>imm32 (sign-extended).</em></td>, <td>80 /6 <em>ib</em></td>, <td>XOR <em>r/m8, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m8</em> XOR <em>imm8.</em></td>, <td>REX + 80 /6 <em>ib</em></td>, <td>XOR <em>r/m8*, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r/m8</em> XOR <em>imm8.</em></td>, <td>81 /6 <em>iw</em></td>, <td>XOR <em>r/m16, imm16</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m16</em> XOR <em>imm16.</em></td>, <td>81 /6 <em>id</em></td>, <td>XOR <em>r/m32, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m32</em> XOR <em>imm32.</em></td>, <td>REX.W + 81 /6 <em>id</em></td>, <td>XOR <em>r/m64, imm32</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r/m64</em> XOR <em>imm32 (sign-extended).</em></td>, <td>83 /6 <em>ib</em></td>, <td>XOR <em>r/m16, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m16</em> XOR <em>imm8 (sign-extended).</em></td>, <td>83 /6 <em>ib</em></td>, <td>XOR <em>r/m32, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m32</em> XOR <em>imm8 (sign-extended).</em></td>, <td>REX.W + 83 /6 <em>ib</em></td>, <td>XOR <em>r/m64, imm8</em></td>, <td>MI</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r/m64</em> XOR <em>imm8 (sign-extended).</em></td>, <td>30 /<em>r</em></td>, <td>XOR <em>r/m8, r8</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m8</em> XOR <em>r8.</em></td>, <td>REX + 30 /<em>r</em></td>, <td>XOR <em>r/m8*, r8*</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r/m8</em> XOR <em>r8.</em></td>, <td>31 /<em>r</em></td>, <td>XOR <em>r/m16, r16</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m16</em> XOR <em>r16.</em></td>, <td>31 /<em>r</em></td>, <td>XOR <em>r/m32, r32</em></td>, <td>MR</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r/m32</em> XOR <em>r32.</em></td>, <td>REX.W + 31 /<em>r</em></td>, <td>XOR <em>r/m64, r64</em></td>, <td>MR</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r/m64</em> XOR <em>r64.</em></td>, <td>32 /<em>r</em></td>, <td>XOR <em>r8, r/m8</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r8</em> XOR <em>r/m8.</em></td>, <td>REX + 32 /<em>r</em></td>, <td>XOR <em>r8*, r/m8*</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r8</em> XOR <em>r/m8.</em></td>, <td>33 /<em>r</em></td>, <td>XOR <em>r16, r/m16</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r16</em> XOR <em>r/m16.</em></td>, <td>33 /<em>r</em></td>, <td>XOR <em>r32, r/m32</em></td>, <td>RM</td>, <td>Valid</td>, <td>Valid</td>, <td><em>r32</em> XOR <em>r/m32.</em></td>, <td>REX.W + 33 /<em>r</em></td>, <td>XOR <em>r64, r/m64</em></td>, <td>RM</td>, <td>Valid</td>, <td>N.E.</td>, <td><em>r64</em> XOR <em>r/m64.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>I</td>, <td>AL/AX/EAX/RAX</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td>MI</td>, <td>ModRM:r/m (r, w)</td>, <td>imm8/16/32</td>, <td>NA</td>, <td>NA</td>, <td>MR</td>, <td>ModRM:r/m (r, w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td>RM</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If the destination operand points to a non-writable segment.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains a NULL segment selector.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#AC(0)</td>, <td>If alignment checking is enabled and an unaligned memory reference is made while the current privilege level is 3.</td>, <td>#UD</td>, <td>If the LOCK prefix is used but the destination is not a memory operand.</td>]

[<td>66 0F 57/r XORPD xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE2</td>, <td>Return the bitwise logical XOR of packed double-precision floating-point values in xmm1 and xmm2/mem.</td>, <td>VEX.128.66.0F.WIG 57 /r VXORPD xmm1,xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the bitwise logical XOR of packed double-precision floating-point values in xmm2 and xmm3/mem.</td>, <td>VEX.256.66.0F.WIG 57 /r VXORPD ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the bitwise logical XOR of packed double-precision floating-point values in ymm2 and ymm3/mem.</td>, <td>EVEX.128.66.0F.W1 57 /r VXORPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Return the bitwise logical XOR of packed double-precision floating-point values in xmm2 and xmm3/m128/m64bcst subject to writemask k1.</td>, <td>EVEX.256.66.0F.W1 57 /r VXORPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Return the bitwise logical XOR of packed double-precision floating-point values in ymm2 and ymm3/m256/m64bcst subject to writemask k1.</td>, <td>EVEX.512.66.0F.W1 57 /r VXORPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Return the bitwise logical XOR of packed double-precision floating-point values in zmm2 and zmm3/m512/m64bcst subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>NP 0F 57 /r XORPS xmm1, xmm2/m128</td>, <td>A</td>, <td>V/V</td>, <td>SSE</td>, <td>Return the bitwise logical XOR of packed single-precision floating-point values in xmm1 and xmm2/mem.</td>, <td>VEX.128.0F.WIG 57 /r VXORPS xmm1,xmm2, xmm3/m128</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the bitwise logical XOR of packed single-precision floating-point values in xmm2 and xmm3/mem.</td>, <td>VEX.256.0F.WIG 57 /r VXORPS ymm1, ymm2, ymm3/m256</td>, <td>B</td>, <td>V/V</td>, <td>AVX</td>, <td>Return the bitwise logical XOR of packed single-precision floating-point values in ymm2 and ymm3/mem.</td>, <td>EVEX.128.0F.W0 57 /r VXORPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Return the bitwise logical XOR of packed single-precision floating-point values in xmm2 and xmm3/m128/m32bcst subject to writemask k1.</td>, <td>EVEX.256.0F.W0 57 /r VXORPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512VL AVX512DQ</td>, <td>Return the bitwise logical XOR of packed single-precision floating-point values in ymm2 and ymm3/m256/m32bcst subject to writemask k1.</td>, <td>EVEX.512.0F.W0 57 /r VXORPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst</td>, <td>C</td>, <td>V/V</td>, <td>AVX512DQ</td>, <td>Return the bitwise logical XOR of packed single-precision floating-point values in zmm2 and zmm3/m512/m32bcst subject to writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>NA</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>B</td>, <td>NA</td>, <td>ModRM:reg (w)</td>, <td>VEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>C</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>]

[<td>F2 XACQUIRE</td>, <td>V/V</td>, <td>HLE<sup>1</sup></td>, <td>A hint used with an “XACQUIRE-enabled“ instruction to start lock elision on the instruction memory operand address.</td>, <td>F3 XRELEASE</td>, <td>V/V</td>, <td>HLE</td>, <td>A hint used with an “XRELEASE-enabled“ instruction to end lock elision on the instruction memory operand address.</td>, <td>#GP(0)</td>, <td>If the use of prefix causes instruction length to exceed 15 bytes.</td>]

[<td>NP 0F AE /5 XRSTOR <em>mem</em></td>, <td>M</td>, <td>V/V</td>, <td>XSAVE</td>, <td>Restore state components specified by EDX:EAX from <em>mem</em>.</td>, <td>NP REX.W + 0F AE /5 XRSTOR64 <em>mem</em></td>, <td>M</td>, <td>V/N.E.</td>, <td>XSAVE</td>, <td>Restore state components specified by EDX:EAX from <em>mem</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="9">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>If bit 63 of the XCOMP_BV field of the XSAVE header is 1 and CPUID.(EAX=0DH,ECX=1):EAX.XSAVEC[bit 1] = 0.</td>, <td>If the standard form is executed and a bit in XCR0 is 0 and the corresponding bit in the XSTATE_BV field of the XSAVE header is 1.</td>, <td>If the standard form is executed and bytes 23:8 of the XSAVE header are not all zero.</td>, <td>If the compacted form is executed and a bit in XCR0 is 0 and the corresponding bit in the XCOMP_BV field of the XSAVE header is 1.</td>, <td>If the compacted form is executed and a bit in the XCOMP_BV field in the XSAVE header is 0 and the corresponding bit in the XSTATE_BV field is 1.</td>, <td>If the compacted form is executed and bytes 63:16 of the XSAVE header are not all zero.</td>, <td>If attempting to write any reserved bits of the MXCSR register with 1.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#AC</td>, <td>If this exception is disabled a general protection exception (#GP) is signaled if the memory operand is not aligned on a 64-byte boundary, as described above. If the alignment check exception (#AC) is enabled (and the CPL is 3), signaling of #AC is not guaranteed and may vary with implementation, as follows. In all implementations where #AC is not signaled, a general protection exception is signaled in its place. In addition, the width of the alignment check may also vary with implementation. For instance, for a given implementation, an alignment check exception might be signaled for a 2-byte misalignment, whereas a general protection exception might be signaled for all other misalignments (4-, 8-, or 16-byte misalignments).</td>, <td rowspan="6">#GP</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td>If bit 63 of the XCOMP_BV field of the XSAVE header is 1 and CPUID.(EAX=0DH,ECX=1):EAX.XSAVEC[bit 1] = 0.</td>, <td>If the standard form is executed and a bit in XCR0 is 0 and the corresponding bit in the XSTATE_BV field of the XSAVE header is 1.</td>, <td>If the standard form is executed and bytes 23:8 of the XSAVE header are not all zero.</td>, <td>If the compacted form is executed and a bit in XCR0 is 0 and the corresponding bit in the XCOMP_BV field of the XSAVE header is 1. If the compacted form is executed and a bit in the XCOMP_BV field in the XSAVE header is 0 and the corresponding bit in the XSTATE_BV field is 1. If the compacted form is executed and bytes 63:16 of the XSAVE header are not all zero. If attempting to write any reserved bits of the MXCSR register with 1.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="9">#GP(0)</td>, <td>If a memory address is in a non-canonical form.</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>If bit 63 of the XCOMP_BV field of the XSAVE header is 1 and CPUID.(EAX=0DH,ECX=1):EAX.XSAVEC[bit 1] = 0.</td>, <td>If the standard form is executed and a bit in XCR0 is 0 and the corresponding bit in the XSTATE_BV field of the XSAVE header is 1.</td>, <td>If the standard form is executed and bytes 23:8 of the XSAVE header are not all zero.</td>, <td>If the compacted form is executed and a bit in XCR0 is 0 and the corresponding bit in the XCOMP_BV field of the XSAVE header is 1.</td>, <td>If the compacted form is executed and a bit in the XCOMP_BV field in the XSAVE header is 0 and the corresponding bit in the XSTATE_BV field is 1.</td>, <td>If the compacted form is executed and bytes 63:16 of the XSAVE header are not all zero.</td>, <td>If attempting to write any reserved bits of the MXCSR register with 1.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#AC</td>, <td>If this exception is disabled a general protection exception (#GP) is signaled if the memory operand is not aligned on a 64-byte boundary, as described above. If the alignment check exception (#AC) is enabled (and the CPL is 3), signaling of #AC is not guaranteed and may vary with implementation, as follows. In all implementations where #AC is not signaled, a general protection exception is signaled in its place. In addition, the width of the alignment check may also vary with implementation. For instance, for a given implementation, an alignment check exception might be signaled for a 2-byte misalignment, whereas a general protection exception might be signaled for all other misalignments (4-, 8-, or 16-byte misalignments).</td>]

[<td>NP 0F C7 /3 XRSTORS <em>mem</em></td>, <td>M</td>, <td>V/V</td>, <td>XSS</td>, <td>Restore state components specified by EDX:EAX from <em>mem</em>.</td>, <td>NP REX.W + 0F C7 /3 XRSTORS64 <em>mem</em></td>, <td>M</td>, <td>V/N.E.</td>, <td>XSS</td>, <td>Restore state components specified by EDX:EAX from <em>mem</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="8">#GP(0)</td>, <td>If CPL &gt; 0.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>If bit 63 of the XCOMP_BV field of the XSAVE header is 0.</td>, <td>If a bit in XCR0 is 0 and the corresponding bit in the XCOMP_BV field of the XSAVE header is 1.</td>, <td>If a bit in the XCOMP_BV field in the XSAVE header is 0 and the corresponding bit in the XSTATE_BV field is 1.</td>, <td>If bytes 63:16 of the XSAVE header are not all zero.</td>, <td>If attempting to write any reserved bits of the MXCSR register with 1.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0 or CPUID.(EAX=0DH,ECX=1):EAX.XSS[bit 3] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="7">#GP</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td>If bit 63 of the XCOMP_BV field of the XSAVE header is 0.</td>, <td>If a bit in XCR0 is 0 and the corresponding bit in the XCOMP_BV field of the XSAVE header is 1.</td>, <td>If a bit in the XCOMP_BV field in the XSAVE header is 0 and the corresponding bit in the XSTATE_BV field is 1.</td>, <td>If bytes 63:16 of the XSAVE header are not all zero.</td>, <td>If attempting to write any reserved bits of the MXCSR register with 1.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0 or CPUID.(EAX=0DH,ECX=1):EAX.XSS[bit 3] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="8">#GP(0)</td>, <td>If CPL &gt; 0.</td>, <td>If a memory address is in a non-canonical form.</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>If bit 63 of the XCOMP_BV field of the XSAVE header is 0.</td>, <td>If a bit in XCR0 is 0 and the corresponding bit in the XCOMP_BV field of the XSAVE header is 1.</td>, <td>If a bit in the XCOMP_BV field in the XSAVE header is 0 and the corresponding bit in the XSTATE_BV field is 1.</td>, <td>If bytes 63:16 of the XSAVE header are not all zero.</td>, <td>If attempting to write any reserved bits of the MXCSR register with 1.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0 or CPUID.(EAX=0DH,ECX=1):EAX.XSS[bit 3] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>]

[<td>NP 0F AE /4 XSAVE <em>mem</em></td>, <td>M</td>, <td>V/V</td>, <td>XSAVE</td>, <td>Save state components specified by EDX:EAX to <em>mem</em>.</td>, <td>NP REX.W + 0F AE /4 XSAVE64 <em>mem</em></td>, <td>M</td>, <td>V/N.E.</td>, <td>XSAVE</td>, <td>Save state components specified by EDX:EAX to <em>mem</em>.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#AC</td>, <td>If this exception is disabled a general protection exception (#GP) is signaled if the memory operand is not aligned on a 64-byte boundary, as described above. If the alignment check exception (#AC) is enabled (and the CPL is 3), signaling of #AC is not guaranteed and may vary with implementation, as follows. In all implementations where #AC is not signaled, a general protection exception is signaled in its place. In addition, the width of the alignment check may also vary with implementation. For instance, for a given implementation, an alignment check exception might be signaled for a 2-byte misalignment, whereas a general protection exception might be signaled for all other misalignments (4-, 8-, or 16-byte misalignments).</td>, <td rowspan="2">#GP</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#AC</td>, <td>If this exception is disabled a general protection exception (#GP) is signaled if the memory operand is not aligned on a 64-byte boundary, as described above. If the alignment check exception (#AC) is enabled (and the CPL is 3), signaling of #AC is not guaranteed and may vary with implementation, as follows. In all implementations where #AC is not signaled, a general protection exception is signaled in its place. In addition, the width of the alignment check may also vary with implementation. For instance, for a given implementation, an alignment check exception might be signaled for a 2-byte misalignment, whereas a general protection exception might be signaled for all other misalignments (4-, 8-, or 16-byte misalignments).</td>]

[<td>NP 0F C7 /4 XSAVEC <em>mem</em></td>, <td>M</td>, <td>V/V</td>, <td>XSAVEC</td>, <td>Save state components specified by EDX:EAX to <em>mem</em> with compaction.</td>, <td>NP REX.W + 0F C7 /4 XSAVEC64 <em>mem</em></td>, <td>M</td>, <td>V/N.E.</td>, <td>XSAVEC</td>, <td>Save state components specified by EDX:EAX to <em>mem</em> with compaction.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0 or CPUID.(EAX=0DH,ECX=1):EAX.XSAVEC[bit 1] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#AC</td>, <td>If this exception is disabled a general protection exception (#GP) is signaled if the memory operand is not aligned on a 64-byte boundary, as described above. If the alignment check exception (#AC) is enabled (and the CPL is 3), signaling of #AC is not guaranteed and may vary with implementation, as follows. In all implementations where #AC is not signaled, a general protection exception is signaled in its place. In addition, the width of the alignment check may also vary with implementation. For instance, for a given implementation, an alignment check exception might be signaled for a 2-byte misalignment, whereas a general protection exception might be signaled for all other misalignments (4-, 8-, or 16-byte misalignments).</td>, <td rowspan="2">#GP</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0 or CPUID.(EAX=0DH,ECX=1):EAX.XSAVEC[bit 1] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0 or CPUID.(EAX=0DH,ECX=1):EAX.XSAVEC[bit 1] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#AC</td>, <td>If this exception is disabled a general protection exception (#GP) is signaled if the memory operand is not aligned on a 64-byte boundary, as described above. If the alignment check exception (#AC) is enabled (and the CPL is 3), signaling of #AC is not guaranteed and may vary with implementation, as follows. In all implementations where #AC is not signaled, a general protection exception is signaled in its place. In addition, the width of the alignment check may also vary with implementation. For instance, for a given implementation, an alignment check exception might be signaled for a 2-byte misalignment, whereas a general protection exception might be signaled for all other misalignments (4-, 8-, or 16-byte misalignments).</td>]

[<td>NP 0F AE /6 XSAVEOPT <em>mem</em></td>, <td>M</td>, <td>V/V</td>, <td>XSAVEOPT</td>, <td>Save state components specified by EDX:EAX to <em>mem</em>, optimizing if possible.</td>, <td>NP REX.W + 0F AE /6 XSAVEOPT64 <em>mem</em></td>, <td>M</td>, <td>V/V</td>, <td>XSAVEOPT</td>, <td>Save state components specified by EDX:EAX to <em>mem</em>, optimizing if possible.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0 or CPUID.(EAX=0DH,ECX=1):EAX.XSAVEOPT[bit 0] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#AC</td>, <td>If this exception is disabled a general protection exception (#GP) is signaled if the memory operand is not aligned on a 64-byte boundary, as described above. If the alignment check exception (#AC) is enabled (and the CPL is 3), signaling of #AC is not guaranteed and may vary with implementation, as follows. In all implementations where #AC is not signaled, a general protection exception is signaled in its place. In addition, the width of the alignment check may also vary with implementation. For instance, for a given implementation, an alignment check exception might be signaled for a 2-byte misalignment, whereas a general protection exception might be signaled for all other misalignments (4-, 8-, or 16-byte misalignments).</td>, <td rowspan="2">#GP</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0 or CPUID.(EAX=0DH,ECX=1):EAX.XSAVEOPT[bit 0] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td rowspan="2">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0 or CPUID.(EAX=0DH,ECX=1):EAX.XSAVEOPT[bit 0] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#AC</td>, <td>If operand is not aligned on a 64-byte boundary, as described above. If the alignment check exception (#AC) is enabled (and the CPL is 3), signaling of #AC is not guaranteed and may vary with implementation, as follows. In all implementations where #AC is not signaled, a general protection exception is signaled in its place. In addition, the width of the alignment check may also vary with implementation. For instance, for a given implementation, an alignment check exception might be signaled for a 2-byte misalignment, whereas a general protection exception might be signaled for all other misalignments (4-, 8-, or 16-byte misalignments).</td>]

[<td>NP 0F C7 /5 XSAVES <em>mem</em></td>, <td>M</td>, <td>V/V</td>, <td>XSS</td>, <td>Save state components specified by EDX:EAX to <em>mem</em> with compaction, optimizing if possible.</td>, <td>NP REX.W + 0F C7 /5 XSAVES64 <em>mem</em></td>, <td>M</td>, <td>V/N.E.</td>, <td>XSS</td>, <td>Save state components specified by EDX:EAX to <em>mem</em> with compaction, optimizing if possible.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="3">#GP(0)</td>, <td>If CPL &gt; 0.</td>, <td>If a memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>#SS(0)</td>, <td>If a memory operand effective address is outside the SS segment limit.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0 or CPUID.(EAX=0DH,ECX=1):EAX.XSS[bit 3] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="2">#GP</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>If any part of the operand lies outside the effective address space from 0 to FFFFH.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0 or CPUID.(EAX=0DH,ECX=1):EAX.XSS[bit 3] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="3">#GP(0)</td>, <td>If CPL &gt; 0.</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If a memory operand is not aligned on a 64-byte boundary, regardless of segment.</td>, <td>#SS(0)</td>, <td>If a memory address referencing the SS segment is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs.</td>, <td>#NM</td>, <td>If CR0.TS[bit 3] = 1.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0 or CPUID.(EAX=0DH,ECX=1):EAX.XSS[bit 3] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>]

[<td>NP 0F 01 D1</td>, <td>XSETBV</td>, <td>ZO</td>, <td>Valid</td>, <td>Valid</td>, <td>Write the value in EDX:EAX to the XCR specified by ECX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="5">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If an invalid XCR is specified in ECX.</td>, <td>If the value in EDX:EAX sets bits that are reserved in the XCR specified by ECX.</td>, <td>If an attempt is made to clear bit 0 of XCR0.</td>, <td>If an attempt is made to set XCR0[2:1] to 10b.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td rowspan="4">#GP</td>, <td>If an invalid XCR is specified in ECX.</td>, <td>If the value in EDX:EAX sets bits that are reserved in the XCR specified by ECX.</td>, <td>If an attempt is made to clear bit 0 of XCR0.</td>, <td>If an attempt is made to set XCR0[2:1] to 10b.</td>, <td rowspan="3">#UD</td>, <td>If CPUID.01H:ECX.XSAVE[bit 26] = 0.</td>, <td>If CR4.OSXSAVE[bit 18] = 0.</td>, <td>If the LOCK prefix is used.</td>, <td>#GP(0)</td>, <td>The XSETBV instruction is not recognized in virtual-8086 mode.</td>]

[<td>NP 0F 01 D6 XTEST</td>, <td>A</td>, <td>V/V</td>, <td>HLE or RTM</td>, <td>Test if executing in a transactional region</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand2</td>, <td>Operand3</td>, <td>Operand4</td>, <td>A</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="2">#UD</td>, <td>CPUID.(EAX=7, ECX=0):EBX.HLE[bit 4] = 0 and CPUID.(EAX=7, ECX=0):EBX.RTM[bit 11] = 0.</td>, <td>If LOCK prefix is used.</td>]

[<td>NP 0F 01 CF ENCLS</td>, <td>NP</td>, <td>V/V</td>, <td>NA</td>, <td>This instruction is used to execute privileged Intel SGX leaf functions that are used for managing and debugging the enclaves.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Implicit Register Operands</td>, <td>NP</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>See Section 40.3</td>, <td rowspan="4">#UD</td>, <td>If any of the LOCK/OSIZE/REP/VEX prefix is used.</td>, <td>If current privilege level is not 0.</td>, <td>If CPUID.(EAX=12H,ECX=0):EAX.SGX1 [bit 0] = 0.</td>, <td>If logical processor is in SMM.</td>, <td rowspan="5">#GP(0)</td>, <td>If IA32_FEATURE_CONTROL.LOCK = 0.</td>, <td>If IA32_FEATURE_CONTROL.SGX_ENABLE = 0.</td>, <td>If input value in EAX encodes an unsupported leaf.</td>, <td>If data segment expand down.</td>, <td>If CR0.PG=0.</td>, <td>#UD</td>, <td>ENCLS is not recognized in real mode.</td>, <td>#UD</td>, <td>ENCLS is not recognized in virtual-8086 mode.</td>, <td rowspan="4">#UD</td>, <td>If any of the LOCK/OSIZE/REP/VEX prefix is used.</td>, <td>If current privilege level is not 0.</td>, <td>If CPUID.(EAX=12H,ECX=0):EAX.SGX1 [bit 0] = 0.</td>, <td>If logical processor is in SMM.</td>, <td rowspan="3">#GP(0)</td>, <td>If IA32_FEATURE_CONTROL.LOCK = 0.</td>, <td>If IA32_FEATURE_CONTROL.SGX_ENABLE = 0.</td>, <td>If input value in EAX encodes an unsupported leaf.</td>]

[<td>EAX = 01H ENCLS[EADD]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function adds a page to an uninitialized enclave.</td>, <td>Op/En</td>, <td>EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>IR</td>, <td>EADD (In)</td>, <td>Address of a PAGEINFO (In)</td>, <td>Address of the destination EPC page (In)</td>, <td>PAGEINFO</td>, <td>PAGEINFO.SECS</td>, <td>PAGEINFO.SRCPGE</td>, <td>PAGEINFO.SECINFO</td>, <td>EPCPAGE</td>, <td>Read access permitted by Non Enclave</td>, <td>Read/Write access permitted by Enclave</td>, <td>Read access permitted by Non Enclave</td>, <td>Read access permitted by Non Enclave</td>, <td>Write access permitted by Enclave</td>, <td>The operands are not properly aligned.</td>, <td>Unsupported security attributes are set.</td>, <td>Refers to an invalid SECS.</td>, <td>Reference is made to an SECS that is locked by another thread.</td>, <td>The EPC page is locked by another thread.</td>, <td>RCX does not contain an effective address of an EPC page.</td>, <td>The EPC page is already valid.</td>, <td>If security attributes specifies a TCS and the source page specifies unsupported TCS values or fields.</td>, <td>The SECS has been initialized.</td>, <td>The specified enclave offset is outside of the enclave address space.</td>, <td rowspan="2">EADD</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>#GP</td>, <td>EPC_PAGE_CONFLICT_EXCEPTION</td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td rowspan="2">EADD</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Concurrent</td>, <td></td>, <td>Exclusive</td>, <td>#GP</td>, <td>Concurrent</td>, <td></td>, <td>TMP_SRCPGE</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Effective address of the source page.</td>, <td>TMP_SECS</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Effective address of the SECS destination page.</td>, <td>TMP_SECINFO</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Effective address of an SECINFO structure which contains security attributes of the page to be added.</td>, <td>SCRATCH_SECINFO</td>, <td>SECINFO</td>, <td>512</td>, <td>Scratch storage for holding the contents of DS:TMP_SECINFO.</td>, <td>TMP_LINADDR</td>, <td>Unsigned Integer</td>, <td>64</td>, <td>Holds the linear address to be stored in the EPCM and used to calculate TMP_ENCLAVEOFFSET.</td>, <td>TMP_ENCLAVEOFFSET</td>, <td>Enclave Offset</td>, <td>64</td>, <td>The page displacement from the enclave base address.</td>, <td>TMPUPDATEFIELD</td>, <td>SHA256 Buffer</td>, <td>512</td>, <td>Buffer used to hold data being added to TMP_SECS.MRENCLAVE.</td>, <td rowspan="8">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If an enclave memory operand is outside of the EPC.</td>, <td>If an enclave memory operand is the wrong type.</td>, <td>If a memory operand is locked.</td>, <td>If the enclave is initialized.</td>, <td>If the enclave's MRENCLAVE is locked.</td>, <td>If the TCS page reserved bits are set.</td>, <td rowspan="2">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If the EPC page is valid.</td>, <td rowspan="8">#GP(0)</td>, <td>If a memory operand is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If an enclave memory operand is outside of the EPC.</td>, <td>If an enclave memory operand is the wrong type.</td>, <td>If a memory operand is locked.</td>, <td>If the enclave is initialized.</td>, <td>If the enclave's MRENCLAVE is locked.</td>, <td>If the TCS page reserved bits are set.</td>, <td rowspan="2">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If the EPC page is valid.</td>]

[<td>EAX = 0DH ENCLS[EAUG]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX2</td>, <td>This leaf function adds a page to an initialized enclave.</td>, <td>Op/En</td>, <td>EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>IR</td>, <td>EAUG (In)</td>, <td>Address of a SECINFO (In)</td>, <td>Address of the destination EPC page (In)</td>, <td>PAGEINFO</td>, <td>PAGEINFO.SECS</td>, <td>PAGEINFO.SRCPGE</td>, <td>PAGEINFO.SECINFO</td>, <td>EPCPAGE</td>, <td>Read access permitted by Non Enclave</td>, <td>Read/Write access permitted by Enclave</td>, <td>Must be zero</td>, <td>Read access permitted by Non Enclave</td>, <td>Write access permitted by Enclave</td>, <td>The operands are not properly aligned.</td>, <td>Unsupported security attributes are set.</td>, <td>Refers to an invalid SECS.</td>, <td>Reference is made to an SECS that is locked by another thread.</td>, <td>The EPC page is locked by another thread.</td>, <td>RCX does not contain an effective address of an EPC page.</td>, <td>The EPC page is already valid.</td>, <td>The specified enclave offset is outside of the enclave address space.</td>, <td>The SECS has been initialized.</td>, <td></td>, <td rowspan="2">EAUG</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>#GP</td>, <td>EPC_PAGE_CONFLICT_EXCEPTION</td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td rowspan="2">EAUG</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_SECS</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Effective address of the SECS destination page.</td>, <td>TMP_SECINFO</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Effective address of an SECINFO structure which contains security attributes of the page to be added.</td>, <td>SCRATCH_SECINFO</td>, <td>SECINFO</td>, <td>512</td>, <td>Scratch storage for holding the contents of DS:TMP_SECINFO.</td>, <td>TMP_LINADDR</td>, <td>Unsigned Integer</td>, <td>64</td>, <td>Holds the linear address to be stored in the EPCM and used to calculate TMP_ENCLAVEOFFSET.</td>, <td rowspan="4">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If a memory operand is locked.</td>, <td>If the enclave is not initialized.</td>, <td>#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td rowspan="4">#GP(0)</td>, <td>If a memory operand is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If a memory operand is locked.</td>, <td>If the enclave is not initialized.</td>, <td>#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>]

[<td>EAX = 09H ENCLS[EBLOCK]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function marks a page in the EPC as blocked.</td>, <td>Op/En</td>, <td colspan="2">EAX</td>, <td>RCX</td>, <td>IR</td>, <td>EBLOCK (In)</td>, <td>Return error code (Out)</td>, <td>Effective address of the EPC page (In)</td>, <td>EPCPAGE</td>, <td>Read/Write access permitted by Enclave</td>, <td>No Error</td>, <td>EBLOCK successful.</td>, <td>SGX_BLKSTATE</td>, <td>Page already blocked. This value is used to indicate to a VMM that the page was already in BLOCKED state as a result of EBLOCK and thus will need to be restored to this state when it is eventually reloaded (using ELDB).</td>, <td>SGX_ENTRYEPOCH_LOCKED</td>, <td>SECS locked for Entry Epoch update. This value indicates that an ETRACK is currently executing on the SECS. The EBLOCK should be reattempted.</td>, <td>SGX_NOTBLOCKABLE</td>, <td>Page type is not one which can be blocked.</td>, <td>SGX_PG_INVLD</td>, <td>Page is not valid and cannot be blocked.</td>, <td>SGX_EPC_PAGE_CONFLICT</td>, <td>Page is being written by EADD, EAUG, ECREATE, ELDU/B, EMODT, or EWB.</td>, <td>EBLOCK</td>, <td>Target [DS:RCX]</td>, <td>Shared</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td></td>, <td>EBLOCK</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Name</td>, <td>Type</td>, <td>Size (Bits)</td>, <td>Description</td>, <td>TMP_BLKSTATE</td>, <td>Integer</td>, <td>64</td>, <td>Page is already blocked.</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If the specified EPC resource is in use.</td>, <td rowspan="2">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand is not an EPC page.</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory operand is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If the specified EPC resource is in use.</td>, <td rowspan="2">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand is not an EPC page.</td>]

[<td>EAX = 00H ENCLS[ECREATE]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function begins an enclave build by creating an SECS page in EPC.</td>, <td>Op/En</td>, <td>EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>IR</td>, <td>ECREATE (In)</td>, <td>Address of a PAGEINFO (In)</td>, <td>Address of the destination SECS page (In)</td>, <td>PAGEINFO</td>, <td>PAGEINFO.SRCPGE</td>, <td>PAGEINFO.SECINFO</td>, <td>EPCPAGE</td>, <td>Read access permitted by Non Enclave</td>, <td>Read access permitted by Non Enclave</td>, <td>Read access permitted by Non Enclave</td>, <td>Write access permitted by Enclave</td>, <td>ECREATE</td>, <td>SECS [DS:RCX]</td>, <td>Exclusive</td>, <td>#GP</td>, <td>EPC_PAGE_CONFLICT_EXCEPTION</td>, <td>ECREATE</td>, <td>SECS [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_SRCPGE</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Effective address of the SECS source page.</td>, <td>TMP_SECS</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Effective address of the SECS destination page.</td>, <td>TMP_SECINFO</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Effective address of an SECINFO structure which contains security attributes of the SECS page to be added.</td>, <td>TMP_XSIZE</td>, <td>SSA Size</td>, <td>64</td>, <td>The size calculation of SSA frame.</td>, <td>TMP_MISC_SIZE</td>, <td>MISC Field Size</td>, <td>64</td>, <td>Size of the selected MISC field components.</td>, <td>TMPUPDATEFIELD</td>, <td>SHA256 Buffer</td>, <td>512</td>, <td>Buffer used to hold data being added to TMP_SECS.MRENCLAVE.</td>, <td rowspan="7">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If the reserved fields are not zero.</td>, <td>If PAGEINFO.SECS is not zero.</td>, <td>If PAGEINFO.LINADDR is not zero.</td>, <td>If the SECS destination is locked.</td>, <td>If SECS.SSAFRAMESIZE is insufficient.</td>, <td rowspan="2">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If the SECS destination is outside the EPC.</td>, <td rowspan="7">#GP(0)</td>, <td>If a memory address is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If the reserved fields are not zero.</td>, <td>If PAGEINFO.SECS is not zero.</td>, <td>If PAGEINFO.LINADDR is not zero.</td>, <td>If the SECS destination is locked.</td>, <td>If SECS.SSAFRAMESIZE is insufficient.</td>, <td rowspan="2">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If the SECS destination is outside the EPC.</td>]

[<td>EAX = 04H ENCLS[EDBGRD]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function reads a dword/quadword from a debug enclave.</td>, <td>Op/En</td>, <td>EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>IR</td>, <td>EDBGRD (In)</td>, <td>Data read from a debug enclave (Out)</td>, <td>Address of source memory in the EPC (In)</td>, <td>EPCQW</td>, <td>Read access permitted by Enclave</td>, <td>No Error</td>, <td>EDBGRD successful.</td>, <td>SGX_PAGE_NOT_DEBUGGABLE</td>, <td>The EPC page cannot be accessed because it is in the PENDING or MODIFIED state.</td>, <td>RCX points into a page that is an SECS. RCX does not resolve to a naturally aligned linear address. RCX points to a page that does not belong to an RCX points to a location inside a TCS that is beyond the architectural size of the enclave that is in debug mode. TCS (SGX_TCS_LIMIT). An operand causing any segment violation. May page fault. CPL &gt; 0.</td>, <td>EDBGRD</td>, <td>Target [DS:RCX]</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td>EDBGRD</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_MODE64</td>, <td>Binary</td>, <td>1</td>, <td>((IA32_EFER.LMA = 1) &amp;&amp; (CS.L = 1))</td>, <td>TMP_SECS</td>, <td></td>, <td>64</td>, <td>Physical address of SECS of the enclave to which source operand belongs.</td>, <td rowspan="6">#GP(0)</td>, <td>If the address in RCS violates DS limit or access rights.</td>, <td>If DS segment is unusable.</td>, <td>If RCX points to a memory location not 4Byte-aligned.</td>, <td>If the address in RCX points to a page belonging to a non-debug enclave.</td>, <td>If the address in RCX points to a page which is not PT_TCS, PT_REG or PT_VA.</td>, <td>If the address in RCX points to a location inside TCS that is beyond SGX_TCS_LIMIT.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If the address in RCX points to a non-EPC page.</td>, <td>If the address in RCX points to an invalid EPC page.</td>, <td rowspan="5">#GP(0)</td>, <td>If RCX is non-canonical form.</td>, <td>If RCX points to a memory location not 8Byte-aligned.</td>, <td>If the address in RCX points to a page belonging to a non-debug enclave.</td>, <td>If the address in RCX points to a page which is not PT_TCS, PT_REG or PT_VA.</td>, <td>If the address in RCX points to a location inside TCS that is beyond SGX_TCS_LIMIT.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If the address in RCX points to a non-EPC page.</td>, <td>If the address in RCX points to an invalid EPC page.</td>]

[<td>EAX = 05H ENCLS[EDBGWR]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function writes a dword/quadword to a debug enclave.</td>, <td>Op/En</td>, <td>EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>IR</td>, <td>EDBGWR (In)</td>, <td>Data to be written to a debug enclave (In)</td>, <td>Address of Target memory in the EPC (In)</td>, <td>EPCQW</td>, <td>Write access permitted by Enclave</td>, <td>RCX points into a page that is an SECS.</td>, <td>RCX does not resolve to a naturally aligned linear address.</td>, <td>RCX points to a page that does not belong to an enclave that is in debug mode.</td>, <td>RCX points to a location inside a TCS that is not the FLAGS word.</td>, <td>An operand causing any segment violation.</td>, <td>May page fault.</td>, <td>CPL &gt; 0.</td>, <td></td>, <td>No Error</td>, <td>EDBGWR successful.</td>, <td>SGX_PAGE_NOT_DEBUGGABLE</td>, <td>The EPC page cannot be accessed because it is in the PENDING or MODIFIED state.</td>, <td>EDBGWR</td>, <td>Target [DS:RCX]</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td>EDBGWR</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_MODE64</td>, <td>Binary</td>, <td>1</td>, <td>((IA32_EFER.LMA = 1) &amp;&amp; (CS.L = 1)).</td>, <td>TMP_SECS</td>, <td></td>, <td>64</td>, <td>Physical address of SECS of the enclave to which source operand belongs.</td>, <td rowspan="6">#GP(0)</td>, <td>If the address in RCS violates DS limit or access rights.</td>, <td>If DS segment is unusable.</td>, <td>If RCX points to a memory location not 4Byte-aligned.</td>, <td>If the address in RCX points to a page belonging to a non-debug enclave.</td>, <td>If the address in RCX points to a page which is not PT_TCS or PT_REG.</td>, <td>If the address in RCX points to a location inside TCS that is not the FLAGS word.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If the address in RCX points to a non-EPC page.</td>, <td>If the address in RCX points to an invalid EPC page.</td>, <td rowspan="5">#GP(0)</td>, <td>If RCX is non-canonical form.</td>, <td>If RCX points to a memory location not 8Byte-aligned.</td>, <td>If the address in RCX points to a page belonging to a non-debug enclave.</td>, <td>If the address in RCX points to a page which is not PT_TCS or PT_REG.</td>, <td>If the address in RCX points to a location inside TCS that is not the FLAGS word.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If the address in RCX points to a non-EPC page.</td>, <td>If the address in RCX points to an invalid EPC page.</td>]

[<td>EAX = 06H ENCLS[EEXTEND]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function measures 256 bytes of an uninitialized enclave page.</td>, <td>Op/En</td>, <td>EAX</td>, <td>EBX</td>, <td>RCX</td>, <td>IR</td>, <td>EEXTEND (In)</td>, <td>Effective address of the SECS of the data chunk (In)</td>, <td>Effective address of a 256-byte chunk in the EPC (In)</td>, <td>EPC[RCX]</td>, <td>Read access by Enclave</td>, <td>RBX points to an address not 4KBytes aligned.</td>, <td>RBX does not resolve to an SECS.</td>, <td>RBX does not point to an SECS page.</td>, <td>RBX does not point to the SECS page of the data chunk.</td>, <td>RCX points to an address not 256B aligned.</td>, <td>RCX points to an unused page or a SECS.</td>, <td>RCX does not resolve in an EPC page.</td>, <td>If SECS is locked.</td>, <td>If the SECS is already initialized.</td>, <td>May page fault.</td>, <td>CPL &gt; 0.</td>, <td></td>, <td rowspan="2">EEXTEND</td>, <td>Target [DS:RCX]</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td>SECS [DS:RBX]</td>, <td>Concurrent</td>, <td></td>, <td></td>, <td rowspan="2">EEXTEND</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECS [DS:RBX]</td>, <td>Concurrent</td>, <td></td>, <td>Exclusive</td>, <td>#GP</td>, <td>Concurrent</td>, <td></td>, <td>TMP_SECS</td>, <td></td>, <td>64</td>, <td>Physical address of SECS of the enclave to which source operand belongs.</td>, <td>TMP_ENCLAVEOFFS ET</td>, <td>Enclave Offset</td>, <td>64</td>, <td>The page displacement from the enclave base address.</td>, <td>TMPUPDATEFIELD</td>, <td>SHA256 Buffer</td>, <td>512</td>, <td>Buffer used to hold data being added to TMP_SECS.MRENCLAVE.</td>, <td rowspan="7">#GP(0)</td>, <td>If the address in RBX is outside the DS segment limit.</td>, <td>If RBX points to an SECS page which is not the SECS of the data chunk.</td>, <td>If the address in RCX is outside the DS segment limit.</td>, <td>If RCX points to a memory location not 256Byte-aligned.</td>, <td>If another instruction is accessing MRENCLAVE.</td>, <td>If another instruction is checking or updating the SECS.</td>, <td>If the enclave is already initialized.</td>, <td rowspan="5">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If the address in RBX points to a non-EPC page.</td>, <td>If the address in RCX points to a page which is not PT_TCS or PT_REG.</td>, <td>If the address in RCX points to a non-EPC page.</td>, <td>If the address in RCX points to an invalid EPC page.</td>, <td rowspan="7">#GP(0)</td>, <td>If RBX is non-canonical form.</td>, <td>If RBX points to an SECS page which is not the SECS of the data chunk.</td>, <td>If RCX is non-canonical form.</td>, <td>If RCX points to a memory location not 256 Byte-aligned.</td>, <td>If another instruction is accessing MRENCLAVE.</td>, <td>If another instruction is checking or updating the SECS.</td>, <td>If the enclave is already initialized.</td>, <td rowspan="5">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If the address in RBX points to a non-EPC page.</td>, <td>If the address in RCX points to a page which is not PT_TCS or PT_REG.</td>, <td>If the address in RCX points to a non-EPC page.</td>, <td>If the address in RCX points to an invalid EPC page.</td>]

[<td>EAX = 02H ENCLS[EINIT]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function initializes the enclave and makes it ready to execute enclave code.</td>, <td>Op/En</td>, <td colspan="2">EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>RDX</td>, <td>IR</td>, <td>EINIT (In)</td>, <td>Error code (Out)</td>, <td>Address of SIGSTRUCT (In)</td>, <td>Address of SECS (In)</td>, <td>Address of EINITTOKEN (In)</td>, <td>SECS</td>, <td>EINITTOKEN</td>, <td>Read/Write access by Enclave</td>, <td>Access by non-Enclave</td>, <td>No Error</td>, <td>EINIT successful.</td>, <td>SGX_INVALID_SIG_STRUCT</td>, <td>If SIGSTRUCT contained an invalid value.</td>, <td>SGX_INVALID_ATTRIBUTE</td>, <td>If SIGSTRUCT contains an unauthorized attributes mask.</td>, <td>SGX_INVALID_MEASUREMENT</td>, <td>If SIGSTRUCT contains an incorrect measurement. If EINITTOKEN contains an incorrect measurement.</td>, <td>SGX_INVALID_SIGNATURE</td>, <td>If signature does not validate with enclosed public key.</td>, <td>SGX_INVALID_LICENSE</td>, <td>If license is invalid.</td>, <td>SGX_INVALID_CPUSVN</td>, <td>If license SVN is unsupported.</td>, <td>SGX_UNMASKED_EVENT</td>, <td>If an unmasked event is received before the instruction completes its operation.</td>, <td>EINIT</td>, <td>SECS [DS:RCX]</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td>EINIT</td>, <td>SECS [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Exclusive</td>, <td>#GP</td>, <td>Concurrent</td>, <td></td>, <td>TMP_SIG</td>, <td>SIGSTRUCT</td>, <td>1808Bytes</td>, <td>Temp space for SIGSTRUCT.</td>, <td>TMP_TOKEN</td>, <td>EINITTOKEN</td>, <td>304Bytes</td>, <td>Temp space for EINITTOKEN.</td>, <td>TMP_MRENCLAVE</td>, <td></td>, <td>32Bytes</td>, <td>Temp space for calculating MRENCLAVE.</td>, <td>TMP_MRSIGNER</td>, <td></td>, <td>32Bytes</td>, <td>Temp space for calculating MRSIGNER.</td>, <td>CONTROLLED_ATTRIBU TES</td>, <td>ATTRIBUTES</td>, <td>16Bytes</td>, <td>Constant mask of all ATTRIBUTE bits that can only be set for authorized enclaves.</td>, <td>TMP_KEYDEPENDENCIE S</td>, <td>Buffer</td>, <td>224Bytes</td>, <td>Temp space for key derivation.</td>, <td>TMP_EINITTOKENKEY</td>, <td></td>, <td>16Bytes</td>, <td>Temp space for the derived EINITTOKEN Key.</td>, <td>TMP_SIG_PADDING</td>, <td>PKCS Padding Buffer</td>, <td>352Bytes</td>, <td>The value of the top 352 bytes from the computation of Signature<sup>3</sup> modulo MRSIGNER.</td>, <td rowspan="4">#GP(0)</td>, <td>If a memory operand is not properly aligned.</td>, <td>If another instruction is modifying the SECS.</td>, <td>If the enclave is already initialized.</td>, <td>If the SECS.MRENCLAVE is in use.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If RCX does not resolve in an EPC page.</td>, <td>If the memory address is not a valid, uninitialized SECS.</td>, <td rowspan="4">#GP(0)</td>, <td>If a memory operand is not properly aligned.</td>, <td>If another instruction is modifying the SECS.</td>, <td>If the enclave is already initialized.</td>, <td>If the SECS.MRENCLAVE is in use.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If RCX does not resolve in an EPC page.</td>, <td>If the memory address is not a valid, uninitialized SECS.</td>]

[<td>EAX = 07H ENCLS[ELDB]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function loads, verifies an EPC page and marks the page as blocked.</td>, <td>EAX = 08H ENCLS[ELDU]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function loads, verifies an EPC page and marks the page as unblocked.</td>, <td>EAX = 12H ENCLS[ELDBC]</td>, <td>IR</td>, <td>V/V</td>, <td>EAX[5]</td>, <td>This leaf function behaves lie ELDB but with improved conflict handling for oversubscription.</td>, <td>EAX = 13H ENCLS[ELDBC]</td>, <td>IR</td>, <td>V/V</td>, <td>EAX[5]</td>, <td>This leaf function behaves like ELDU but with improved conflict handling for oversubscription.</td>, <td>Op/En</td>, <td colspan="2">EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>RDX</td>, <td>IR</td>, <td>ELDB/ELDU (In)</td>, <td>Return error code (Out)</td>, <td>Address of the PAGEINFO (In)</td>, <td>Address of the EPC page (In)</td>, <td>Address of the version-array slot (In)</td>, <td>PAGEINFO</td>, <td>PAGEINFO.SRCPGE</td>, <td>PAGEINFO.PCMD</td>, <td>PAGEINFO.SECS</td>, <td>EPCPAGE</td>, <td>Version-Array Slot</td>, <td>Non-enclave read access</td>, <td>Non-enclave read access</td>, <td>Non-enclave read access</td>, <td>Enclave read/write access</td>, <td>Read/Write access permitted by Enclave</td>, <td>Read/Write access permitted by Enclave</td>, <td>No Error</td>, <td>ELDB/ELDU successful.</td>, <td>SGX_MAC_COMPARE_FAIL</td>, <td>If the MAC check fails.</td>, <td rowspan="3">ELDB/ELDU/</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>#GP</td>, <td>EPC_PAGE_CONFLICT_EXCEPTION</td>, <td>VA [DS:RDX]</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td rowspan="3">ELDBC/ELBUC</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td>EPC_PAGE_CONFLICT_ERROR</td>, <td>VA [DS:RDX]</td>, <td>Shared</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Shared</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td></td>, <td rowspan="3">ELDB/ELDU/</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>VA [DS:RDX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td rowspan="3">ELDBC/ELBUC</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>VA [DS:RDX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_SRCPGE</td>, <td>Memory page</td>, <td>4KBytes</td>, <td></td>, <td>TMP_SECS</td>, <td>Memory page</td>, <td>4KBytes</td>, <td></td>, <td>TMP_PCMD</td>, <td>PCMD</td>, <td>128 Bytes</td>, <td></td>, <td>TMP_HEADER</td>, <td>MACHEADER</td>, <td>128 Bytes</td>, <td></td>, <td>TMP_VER</td>, <td>UINT64</td>, <td>64</td>, <td></td>, <td>TMP_MAC</td>, <td>UINT128</td>, <td>128</td>, <td></td>, <td>TMP_PK</td>, <td>UINT128</td>, <td>128</td>, <td>Page encryption/MAC key.</td>, <td>SCRATCH_PCMD</td>, <td>PCMD</td>, <td>128 Bytes</td>, <td></td>, <td rowspan="6">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If the instruction’s EPC resource is in use by others.</td>, <td>If the instruction fails to verify MAC.</td>, <td>If the version-array slot is in use.</td>, <td>If the parameters fail consistency checks.</td>, <td rowspan="4">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand expected to be in EPC does not resolve to an EPC page.</td>, <td>If one of the EPC memory operands has incorrect page type.</td>, <td>If the destination EPC page is already valid.</td>, <td rowspan="6">#GP(0)</td>, <td>If a memory operand is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If the instruction’s EPC resource is in use by others.</td>, <td>If the instruction fails to verify MAC.</td>, <td>If the version-array slot is in use.</td>, <td>If the parameters fail consistency checks.</td>, <td rowspan="4">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand expected to be in EPC does not resolve to an EPC page.</td>, <td>If one of the EPC memory operands has incorrect page type.</td>, <td>If the destination EPC page is already valid.</td>]

[<td>EAX = 07H ENCLS[ELDB]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function loads, verifies an EPC page and marks the page as blocked.</td>, <td>EAX = 08H ENCLS[ELDU]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function loads, verifies an EPC page and marks the page as unblocked.</td>, <td>EAX = 12H ENCLS[ELDBC]</td>, <td>IR</td>, <td>V/V</td>, <td>EAX[5]</td>, <td>This leaf function behaves lie ELDB but with improved conflict handling for oversubscription.</td>, <td>EAX = 13H ENCLS[ELDBC]</td>, <td>IR</td>, <td>V/V</td>, <td>EAX[5]</td>, <td>This leaf function behaves like ELDU but with improved conflict handling for oversubscription.</td>, <td>Op/En</td>, <td colspan="2">EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>RDX</td>, <td>IR</td>, <td>ELDB/ELDU (In)</td>, <td>Return error code (Out)</td>, <td>Address of the PAGEINFO (In)</td>, <td>Address of the EPC page (In)</td>, <td>Address of the version-array slot (In)</td>, <td>PAGEINFO</td>, <td>PAGEINFO.SRCPGE</td>, <td>PAGEINFO.PCMD</td>, <td>PAGEINFO.SECS</td>, <td>EPCPAGE</td>, <td>Version-Array Slot</td>, <td>Non-enclave read access</td>, <td>Non-enclave read access</td>, <td>Non-enclave read access</td>, <td>Enclave read/write access</td>, <td>Read/Write access permitted by Enclave</td>, <td>Read/Write access permitted by Enclave</td>, <td>No Error</td>, <td>ELDB/ELDU successful.</td>, <td>SGX_MAC_COMPARE_FAIL</td>, <td>If the MAC check fails.</td>, <td rowspan="3">ELDB/ELDU/</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>#GP</td>, <td>EPC_PAGE_CONFLICT_EXCEPTION</td>, <td>VA [DS:RDX]</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td rowspan="3">ELDBC/ELBUC</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td>EPC_PAGE_CONFLICT_ERROR</td>, <td>VA [DS:RDX]</td>, <td>Shared</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Shared</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td></td>, <td rowspan="3">ELDB/ELDU/</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>VA [DS:RDX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td rowspan="3">ELDBC/ELBUC</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>VA [DS:RDX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_SRCPGE</td>, <td>Memory page</td>, <td>4KBytes</td>, <td></td>, <td>TMP_SECS</td>, <td>Memory page</td>, <td>4KBytes</td>, <td></td>, <td>TMP_PCMD</td>, <td>PCMD</td>, <td>128 Bytes</td>, <td></td>, <td>TMP_HEADER</td>, <td>MACHEADER</td>, <td>128 Bytes</td>, <td></td>, <td>TMP_VER</td>, <td>UINT64</td>, <td>64</td>, <td></td>, <td>TMP_MAC</td>, <td>UINT128</td>, <td>128</td>, <td></td>, <td>TMP_PK</td>, <td>UINT128</td>, <td>128</td>, <td>Page encryption/MAC key.</td>, <td>SCRATCH_PCMD</td>, <td>PCMD</td>, <td>128 Bytes</td>, <td></td>, <td rowspan="6">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If the instruction’s EPC resource is in use by others.</td>, <td>If the instruction fails to verify MAC.</td>, <td>If the version-array slot is in use.</td>, <td>If the parameters fail consistency checks.</td>, <td rowspan="4">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand expected to be in EPC does not resolve to an EPC page.</td>, <td>If one of the EPC memory operands has incorrect page type.</td>, <td>If the destination EPC page is already valid.</td>, <td rowspan="6">#GP(0)</td>, <td>If a memory operand is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If the instruction’s EPC resource is in use by others.</td>, <td>If the instruction fails to verify MAC.</td>, <td>If the version-array slot is in use.</td>, <td>If the parameters fail consistency checks.</td>, <td rowspan="4">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand expected to be in EPC does not resolve to an EPC page.</td>, <td>If one of the EPC memory operands has incorrect page type.</td>, <td>If the destination EPC page is already valid.</td>]

[<td>EAX = 07H ENCLS[ELDB]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function loads, verifies an EPC page and marks the page as blocked.</td>, <td>EAX = 08H ENCLS[ELDU]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function loads, verifies an EPC page and marks the page as unblocked.</td>, <td>EAX = 12H ENCLS[ELDBC]</td>, <td>IR</td>, <td>V/V</td>, <td>EAX[5]</td>, <td>This leaf function behaves lie ELDB but with improved conflict handling for oversubscription.</td>, <td>EAX = 13H ENCLS[ELDBC]</td>, <td>IR</td>, <td>V/V</td>, <td>EAX[5]</td>, <td>This leaf function behaves like ELDU but with improved conflict handling for oversubscription.</td>, <td>Op/En</td>, <td colspan="2">EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>RDX</td>, <td>IR</td>, <td>ELDB/ELDU (In)</td>, <td>Return error code (Out)</td>, <td>Address of the PAGEINFO (In)</td>, <td>Address of the EPC page (In)</td>, <td>Address of the version-array slot (In)</td>, <td>PAGEINFO</td>, <td>PAGEINFO.SRCPGE</td>, <td>PAGEINFO.PCMD</td>, <td>PAGEINFO.SECS</td>, <td>EPCPAGE</td>, <td>Version-Array Slot</td>, <td>Non-enclave read access</td>, <td>Non-enclave read access</td>, <td>Non-enclave read access</td>, <td>Enclave read/write access</td>, <td>Read/Write access permitted by Enclave</td>, <td>Read/Write access permitted by Enclave</td>, <td>No Error</td>, <td>ELDB/ELDU successful.</td>, <td>SGX_MAC_COMPARE_FAIL</td>, <td>If the MAC check fails.</td>, <td rowspan="3">ELDB/ELDU/</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>#GP</td>, <td>EPC_PAGE_CONFLICT_EXCEPTION</td>, <td>VA [DS:RDX]</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td rowspan="3">ELDBC/ELBUC</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td>EPC_PAGE_CONFLICT_ERROR</td>, <td>VA [DS:RDX]</td>, <td>Shared</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Shared</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td></td>, <td rowspan="3">ELDB/ELDU/</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>VA [DS:RDX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td rowspan="3">ELDBC/ELBUC</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>VA [DS:RDX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_SRCPGE</td>, <td>Memory page</td>, <td>4KBytes</td>, <td></td>, <td>TMP_SECS</td>, <td>Memory page</td>, <td>4KBytes</td>, <td></td>, <td>TMP_PCMD</td>, <td>PCMD</td>, <td>128 Bytes</td>, <td></td>, <td>TMP_HEADER</td>, <td>MACHEADER</td>, <td>128 Bytes</td>, <td></td>, <td>TMP_VER</td>, <td>UINT64</td>, <td>64</td>, <td></td>, <td>TMP_MAC</td>, <td>UINT128</td>, <td>128</td>, <td></td>, <td>TMP_PK</td>, <td>UINT128</td>, <td>128</td>, <td>Page encryption/MAC key.</td>, <td>SCRATCH_PCMD</td>, <td>PCMD</td>, <td>128 Bytes</td>, <td></td>, <td rowspan="6">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If the instruction’s EPC resource is in use by others.</td>, <td>If the instruction fails to verify MAC.</td>, <td>If the version-array slot is in use.</td>, <td>If the parameters fail consistency checks.</td>, <td rowspan="4">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand expected to be in EPC does not resolve to an EPC page.</td>, <td>If one of the EPC memory operands has incorrect page type.</td>, <td>If the destination EPC page is already valid.</td>, <td rowspan="6">#GP(0)</td>, <td>If a memory operand is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If the instruction’s EPC resource is in use by others.</td>, <td>If the instruction fails to verify MAC.</td>, <td>If the version-array slot is in use.</td>, <td>If the parameters fail consistency checks.</td>, <td rowspan="4">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand expected to be in EPC does not resolve to an EPC page.</td>, <td>If one of the EPC memory operands has incorrect page type.</td>, <td>If the destination EPC page is already valid.</td>]

[<td>EAX = 07H ENCLS[ELDB]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function loads, verifies an EPC page and marks the page as blocked.</td>, <td>EAX = 08H ENCLS[ELDU]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function loads, verifies an EPC page and marks the page as unblocked.</td>, <td>EAX = 12H ENCLS[ELDBC]</td>, <td>IR</td>, <td>V/V</td>, <td>EAX[5]</td>, <td>This leaf function behaves lie ELDB but with improved conflict handling for oversubscription.</td>, <td>EAX = 13H ENCLS[ELDBC]</td>, <td>IR</td>, <td>V/V</td>, <td>EAX[5]</td>, <td>This leaf function behaves like ELDU but with improved conflict handling for oversubscription.</td>, <td>Op/En</td>, <td colspan="2">EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>RDX</td>, <td>IR</td>, <td>ELDB/ELDU (In)</td>, <td>Return error code (Out)</td>, <td>Address of the PAGEINFO (In)</td>, <td>Address of the EPC page (In)</td>, <td>Address of the version-array slot (In)</td>, <td>PAGEINFO</td>, <td>PAGEINFO.SRCPGE</td>, <td>PAGEINFO.PCMD</td>, <td>PAGEINFO.SECS</td>, <td>EPCPAGE</td>, <td>Version-Array Slot</td>, <td>Non-enclave read access</td>, <td>Non-enclave read access</td>, <td>Non-enclave read access</td>, <td>Enclave read/write access</td>, <td>Read/Write access permitted by Enclave</td>, <td>Read/Write access permitted by Enclave</td>, <td>No Error</td>, <td>ELDB/ELDU successful.</td>, <td>SGX_MAC_COMPARE_FAIL</td>, <td>If the MAC check fails.</td>, <td rowspan="3">ELDB/ELDU/</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>#GP</td>, <td>EPC_PAGE_CONFLICT_EXCEPTION</td>, <td>VA [DS:RDX]</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td rowspan="3">ELDBC/ELBUC</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td>EPC_PAGE_CONFLICT_ERROR</td>, <td>VA [DS:RDX]</td>, <td>Shared</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Shared</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td></td>, <td rowspan="3">ELDB/ELDU/</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>VA [DS:RDX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td rowspan="3">ELDBC/ELBUC</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>VA [DS:RDX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECS [DS:RBX]PAGEINFO.SECS</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_SRCPGE</td>, <td>Memory page</td>, <td>4KBytes</td>, <td></td>, <td>TMP_SECS</td>, <td>Memory page</td>, <td>4KBytes</td>, <td></td>, <td>TMP_PCMD</td>, <td>PCMD</td>, <td>128 Bytes</td>, <td></td>, <td>TMP_HEADER</td>, <td>MACHEADER</td>, <td>128 Bytes</td>, <td></td>, <td>TMP_VER</td>, <td>UINT64</td>, <td>64</td>, <td></td>, <td>TMP_MAC</td>, <td>UINT128</td>, <td>128</td>, <td></td>, <td>TMP_PK</td>, <td>UINT128</td>, <td>128</td>, <td>Page encryption/MAC key.</td>, <td>SCRATCH_PCMD</td>, <td>PCMD</td>, <td>128 Bytes</td>, <td></td>, <td rowspan="6">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If the instruction’s EPC resource is in use by others.</td>, <td>If the instruction fails to verify MAC.</td>, <td>If the version-array slot is in use.</td>, <td>If the parameters fail consistency checks.</td>, <td rowspan="4">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand expected to be in EPC does not resolve to an EPC page.</td>, <td>If one of the EPC memory operands has incorrect page type.</td>, <td>If the destination EPC page is already valid.</td>, <td rowspan="6">#GP(0)</td>, <td>If a memory operand is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If the instruction’s EPC resource is in use by others.</td>, <td>If the instruction fails to verify MAC.</td>, <td>If the version-array slot is in use.</td>, <td>If the parameters fail consistency checks.</td>, <td rowspan="4">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand expected to be in EPC does not resolve to an EPC page.</td>, <td>If one of the EPC memory operands has incorrect page type.</td>, <td>If the destination EPC page is already valid.</td>]

[<td>EAX = 0EH ENCLS[EMODPR]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX2</td>, <td>This leaf function restricts the access rights associated with a EPC page in an initialized enclave.</td>, <td>Op/En</td>, <td colspan="2">EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>IR</td>, <td>EMODPR (In)</td>, <td>Return Error Code (Out)</td>, <td>Address of a SECINFO (In)</td>, <td>Address of the destination EPC page (In)</td>, <td>SECINFO</td>, <td>EPCPAGE</td>, <td>Read access permitted by Non Enclave</td>, <td>Read/Write access permitted by Enclave</td>, <td>The operands are not properly aligned.</td>, <td>If unsupported security attributes are set.</td>, <td>The Enclave is not initialized.</td>, <td>SECS is locked by another thread.</td>, <td>The EPC page is locked by another thread.</td>, <td>RCX does not contain an effective address of an EPC page in the running enclave.</td>, <td>The EPC page is not valid.</td>, <td></td>, <td>No Error</td>, <td>EMODPR successful.</td>, <td>SGX_PAGE_NOT_MODIFIABLE</td>, <td>The EPC page cannot be modified because it is in the PENDING or MODIFIED state.</td>, <td>SGX_EPC_PAGE_CONFLICT</td>, <td>Page is being written by EADD, EAUG, ECREATE, ELDU/B, EMODT, or EWB.</td>, <td>EMODPR</td>, <td>Target [DS:RCX]</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td>EMODPR</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>SGX_EPC_PAGE _CONFLICT</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_SECS</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Physical address of SECS to which EPC operand belongs.</td>, <td>SCRATCH_SECINFO</td>, <td>SECINFO</td>, <td>512</td>, <td>Scratch storage for holding the contents of DS:RBX.</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If a memory operand is locked.</td>, <td rowspan="2">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand is not an EPC page.</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory operand is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If a memory operand is locked.</td>, <td rowspan="2">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand is not an EPC page.</td>]

[<td>EAX = 0FH ENCLS[EMODT]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX2</td>, <td>This leaf function changes the type of an existing EPC page.</td>, <td>Op/En</td>, <td colspan="2">EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>IR</td>, <td>EMODT (In)</td>, <td>Return Error Code (Out)</td>, <td>Address of a SECINFO (In)</td>, <td>Address of the destination EPC page (In)</td>, <td>SECINFO</td>, <td>EPCPAGE</td>, <td>Read access permitted by Non Enclave</td>, <td>Read/Write access permitted by Enclave</td>, <td>The operands are not properly aligned.</td>, <td>If unsupported security attributes are set.</td>, <td>The Enclave is not initialized.</td>, <td>SECS is locked by another thread.</td>, <td>The EPC page is locked by another thread.</td>, <td>RCX does not contain an effective address of an EPC page in the running enclave.</td>, <td>The EPC page is not valid.</td>, <td></td>, <td>No Error</td>, <td>EMODT successful.</td>, <td>SGX_PAGE_NOT_MODIFIABLE</td>, <td>The EPC page cannot be modified because it is in the PENDING or MODIFIED state.</td>, <td>SGX_EPC_PAGE_CONFLICT</td>, <td>Page is being written by EADD, EAUG, ECREATE, ELDU/B, EMODPR, or EWB.</td>, <td>EMODT</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td>EPC_PAGE_CONFLICT_ERROR</td>, <td>EMODT</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>SGX_EPC_PAGE _CONFLICT</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_SECS</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Physical address of SECS to which EPC operand belongs.</td>, <td>SCRATCH_SECINFO</td>, <td>SECINFO</td>, <td>512</td>, <td>Scratch storage for holding the contents of DS:RBX.</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If a memory operand is locked.</td>, <td rowspan="2">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand is not an EPC page.</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory operand is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If a memory operand is locked.</td>, <td rowspan="2">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand is not an EPC page.</td>]

[<td>EAX = 0AH ENCLS[EPA]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function adds a Version Array to the EPC.</td>, <td>Op/En</td>, <td>EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>IR</td>, <td>EPA (In)</td>, <td>PT_VA (In, Constant)</td>, <td>Effective address of the EPC page (In)</td>, <td>EPCPAGE</td>, <td>Write access permitted by Enclave</td>, <td>EPA</td>, <td>VA [DS:RCX]</td>, <td>Exclusive</td>, <td>#GP</td>, <td>EPC_PAGE_CONFLICT_EXCEPTION</td>, <td>EPA</td>, <td>VA [DS:RCX]</td>, <td>Concurrent</td>, <td>L</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td rowspan="4">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If another Intel SGX instruction is accessing the EPC page.</td>, <td>If RBX is not set to PT_VA.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand is not an EPC page.</td>, <td>If the EPC page is valid.</td>, <td rowspan="4">#GP(0)</td>, <td>If a memory operand is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If another Intel SGX instruction is accessing the EPC page.</td>, <td>If RBX is not set to PT_VA.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand is not an EPC page.</td>, <td>If the EPC page is valid.</td>]

[<td>EAX = 10H ENCLS[ERDINFO]</td>, <td>IR</td>, <td>V/V</td>, <td>EAX[6]</td>, <td>This leaf function returns type and status information about an EPC page.</td>, <td>Op/En</td>, <td>EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>IR</td>, <td>ERDINFO (In)</td>, <td>Address of a RDINFO structure (In)</td>, <td>Address of the destination EPC page (In)</td>, <td>RDINFO</td>, <td>EPCPAGE</td>, <td>Read/Write access permitted by Non Enclave</td>, <td>Read access permitted by Enclave</td>, <td>A memory operand effective address is outside the DS segment limit (32b mode).</td>, <td>A memory operand is not properly aligned.</td>, <td>DS segment is unusable (32b mode).</td>, <td>A page fault occurs in accessing memory operands.</td>, <td>A memory address is in a non-canonical form (64b mode).</td>, <td></td>, <td>No Error</td>, <td>0</td>, <td>ERDINFO successful.</td>, <td>SGX_EPC_PAGE_CONFLICT</td>, <td></td>, <td>Failure due to concurrent operation of another SGX instruction.</td>, <td>SGX_PG_INVLD</td>, <td></td>, <td>Target page is not a valid EPC page.</td>, <td>SGX_PG_NONEPC</td>, <td></td>, <td>Page is not an EPC page.</td>, <td>ERDINFO</td>, <td>Target [DS:RCX]</td>, <td>Shared</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td></td>, <td>ERDINFO</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_SECS Physical Address 64 Physical address of the SECS of the page being modified.</td>, <td>TMP_RDINFO Linear Address 64 Address of the RDINFO structure.</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If DS segment is unusable.</td>, <td>If a memory operand is not properly aligned.</td>, <td>#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td rowspan="2">#GP(0)</td>, <td>If the memory address is in a non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>]

[<td>EAX = 03H ENCLS[EREMOVE]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function removes a page from the EPC.</td>, <td>Op/En</td>, <td>EAX</td>, <td>RCX</td>, <td>IR</td>, <td>EREMOVE (In)</td>, <td>Effective address of the EPC page (In)</td>, <td>EPCPAGE</td>, <td>Write access permitted by Enclave</td>, <td>The memory operand is not properly aligned.</td>, <td>The memory operand does not resolve in an EPC page.</td>, <td>Refers to an invalid SECS.</td>, <td>Refers to an EPC page that is locked by another thread.</td>, <td>Another Intel SGX instruction is accessing the EPC page.</td>, <td>RCX does not contain an effective address of an EPC page.</td>, <td>the EPC page refers to an SECS with associations.</td>, <td></td>, <td>No Error</td>, <td>EREMOVE successful.</td>, <td>SGX_CHILD_PRESENT</td>, <td>If the SECS still have enclave pages loaded into EPC.</td>, <td>SGX_ENCLAVE_ACT</td>, <td>If there are still logical processors executing inside the enclave.</td>, <td>EREMOVE</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>#GP</td>, <td>EPC_PAGE_CONFLICT_EXCEPTION</td>, <td>EREMOVE</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_SECS</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Effective address of the SECS destination page.</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If another Intel SGX instruction is accessing the page.</td>, <td rowspan="2">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If the memory operand is not an EPC page.</td>, <td rowspan="3">#GP(0)</td>, <td>If the memory operand is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If another Intel SGX instruction is accessing the page.</td>, <td rowspan="2">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If the memory operand is not an EPC page.</td>]

[<td>EAX = 11H ENCLS[ETRACKC]</td>, <td>IR</td>, <td>V/V</td>, <td>EAX[6]</td>, <td>This leaf function activates EBLOCK checks.</td>, <td>Op/En</td>, <td colspan="2">EAX</td>, <td colspan="2">RCX</td>, <td>IR</td>, <td>ETRACK (In)</td>, <td>Return error code (Out)</td>, <td>Address of the destination EPC page (In, EA)</td>, <td>Address of the SECS page (In, EA)</td>, <td>EPCPAGE</td>, <td>Read/Write access permitted by Enclave</td>, <td>No Error</td>, <td>0</td>, <td>ETRACKC successful.</td>, <td>SGX_EPC_PAGE_CONFLICT</td>, <td>7</td>, <td>Failure due to concurrent operation of another SGX instruction.</td>, <td>SGX_PG_INVLD</td>, <td>6</td>, <td>Target page is not a VALID EPC page.</td>, <td>SGX_PREV_TRK_INCMPL</td>, <td>17</td>, <td>All processors did not complete the previous tracking sequence.</td>, <td>SGX_TRACK_NOT_REQUIRED</td>, <td>27</td>, <td>Target page type does not require tracking.</td>, <td rowspan="2">ETRACKC</td>, <td>Target [DS:RCX]</td>, <td>Shared</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td></td>, <td>SECS implicit</td>, <td>Concurrent</td>, <td></td>, <td></td>, <td rowspan="2">ETRACKC</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECS implicit</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Exclusive</td>, <td>SGX_EPC_PAGE _CONFLICT</td>, <td>TMP_SECS</td>, <td>Physical Address</td>, <td>64</td>, <td>Physical address of the SECS of the page being modified.</td>, <td rowspan="3">#GP(0)</td>, <td>If the memory operand violates access-control policies of DS segment.</td>, <td>If DS segment is unusable.</td>, <td>If the memory operand is not properly aligned.</td>, <td rowspan="2">#PF(error</td>, <td>code) If the memory operand expected to be in EPC does not resolve to an EPC page.</td>, <td>If a page fault occurs in access memory operand.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory address is in a non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td rowspan="2">#PF(error</td>, <td>code) If the memory operand expected to be in EPC does not resolve to an EPC page.</td>, <td>If a page fault occurs in access memory operand.</td>]

[<td>EAX = 0CH ENCLS[ETRACK]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function activates EBLOCK checks.</td>, <td>Op/En</td>, <td colspan="2">EAX</td>, <td>RCX</td>, <td>IR</td>, <td>ETRACK (In)</td>, <td>Return error code (Out)</td>, <td>Pointer to the SECS of the EPC page (In)</td>, <td>EPCPAGE</td>, <td>Read/Write access permitted by Enclave</td>, <td>No Error</td>, <td>ETRACK successful.</td>, <td>SGX_PREV_TRK_INCMPL</td>, <td>All processors did not complete the previous shoot-down sequence.</td>, <td>ETRACK</td>, <td>SECS [DS:RCX]</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td>ETRACK</td>, <td>SECS [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Exclusive</td>, <td>SGX_EPC_PAGE _CONFLICT</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If another thread is concurrently using the tracking facility on this SECS.</td>, <td rowspan="2">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand is not an EPC page.</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory operand is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If the specified EPC resource is in use.</td>, <td rowspan="2">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand is not an EPC page.</td>]

[<td>EAX = 0BH ENCLS[EWB]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function invalidates an EPC page and writes it out to main memory.</td>, <td>Op/En</td>, <td colspan="2">EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>RDX</td>, <td>IR</td>, <td>EWB (In)</td>, <td>Error code (Out)</td>, <td>Address of an PAGEINFO (In)</td>, <td>Address of the EPC page (In)</td>, <td>Address of a VA slot (In)</td>, <td>PAGEINFO</td>, <td>PAGEINFO.SRCPGE</td>, <td>PAGEINFO.PCMD</td>, <td>EPCPAGE</td>, <td>VASLOT</td>, <td>Non-EPC R/W access</td>, <td>Non-EPC R/W access</td>, <td>Non-EPC R/W access</td>, <td>EPC R/W access</td>, <td>EPC R/W access</td>, <td>No Error</td>, <td>EWB successful.</td>, <td>SGX_PAGE_NOT_BLOCKED</td>, <td>If page is not marked as blocked.</td>, <td>SGX_NOT_TRACKED</td>, <td>If EWB is racing with ETRACK instruction.</td>, <td>SGX_VA_SLOT_OCCUPIED</td>, <td>Version array slot contained valid entry.</td>, <td>SGX_CHILD_PRESENT</td>, <td>Child page present while attempting to page out enclave.</td>, <td rowspan="2">EWB</td>, <td>Source [DS:RCX]</td>, <td>Exclusive</td>, <td>#GP</td>, <td>EPC_PAGE_CONFLICT_EXCEPTION</td>, <td>VA [DS:RDX]</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td rowspan="2">EWB</td>, <td>Source [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>VA [DS:RDX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Exclusive</td>, <td></td>, <td>TMP_SRCPGE</td>, <td>Memory page</td>, <td>4096</td>, <td></td>, <td>TMP_PCMD</td>, <td>PCMD</td>, <td>128</td>, <td></td>, <td>TMP_SECS</td>, <td>SECS</td>, <td>4096</td>, <td></td>, <td>TMP_BPEPOCH</td>, <td>UINT64</td>, <td>8</td>, <td></td>, <td>TMP_BPREFCOUNT</td>, <td>UINT64</td>, <td>8</td>, <td></td>, <td>TMP_HEADER</td>, <td>MAC Header</td>, <td>128</td>, <td></td>, <td>TMP_PCMD_ENCLAVEID</td>, <td>UINT64</td>, <td>8</td>, <td></td>, <td>TMP_VER</td>, <td>UINT64</td>, <td>8</td>, <td></td>, <td>TMP_PK</td>, <td>UINT128</td>, <td>16</td>, <td></td>, <td rowspan="7">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If the EPC page and VASLOT resolve to the same EPC page.</td>, <td>If another Intel SGX instruction is concurrently accessing either the target EPC, VA, or SECS pages.</td>, <td>If the tracking resource is in use.</td>, <td>If the EPC page or the version array page is invalid.</td>, <td>If the parameters fail consistency checks.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand is not an EPC page.</td>, <td>If one of the EPC memory operands has incorrect page type.</td>, <td rowspan="7">#GP(0)</td>, <td>If a memory operand is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If the EPC page and VASLOT resolve to the same EPC page.</td>, <td>If another Intel SGX instruction is concurrently accessing either the target EPC, VA, or SECS pages.</td>, <td>If the tracking resource is in use.</td>, <td>If the EPC page or the version array page in invalid.</td>, <td>If the parameters fail consistency checks.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand is not an EPC page.</td>, <td>If one of the EPC memory operands has incorrect page type.</td>]

[<td>NP 0F 01 D7 ENCLU</td>, <td>NP</td>, <td>V/V</td>, <td>NA</td>, <td>This instruction is used to execute non-privileged Intel SGX leaf functions.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Implicit Register Operands</td>, <td>NP</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>See Section 40.4</td>, <td rowspan="4">#UD</td>, <td>If any of the LOCK/OSIZE/REP/VEX prefix is used.</td>, <td>If current privilege level is not 3.</td>, <td>If CPUID.(EAX=12H,ECX=0):EAX.SGX1 [bit 0] = 0.</td>, <td>If logical processor is in SMM.</td>, <td rowspan="8">#GP(0)</td>, <td>If IA32_FEATURE_CONTROL.LOCK = 0.</td>, <td>If IA32_FEATURE_CONTROL.SGX_ENABLE = 0.</td>, <td>If input value in EAX encodes an unsupported leaf.</td>, <td>If input value in EAX encodes EENTER/ERESUME and ENCLAVE_MODE = 1.</td>, <td>If input value in EAX encodes EGETKEY/EREPORT/EEXIT/EACCEPT/EACCEPTCOPY/EMODPE and ENCLAVE_MODE = 0.</td>, <td>If operating in 16-bit mode.</td>, <td>If data segment is in 16-bit mode.</td>, <td>If CR0.PG = 0 or CR0.NE= 0.</td>, <td>#NM</td>, <td>If CR0.TS = 1.</td>, <td>#UD</td>, <td>ENCLS is not recognized in real mode.</td>, <td>#UD</td>, <td>ENCLS is not recognized in virtual-8086 mode.</td>, <td rowspan="4">#UD</td>, <td>If any of the LOCK/OSIZE/REP/VEX prefix is used.</td>, <td>If current privilege level is not 3.</td>, <td>If CPUID.(EAX=12H,ECX=0):EAX.SGX1 [bit 0] = 0.</td>, <td>If logical processor is in SMM.</td>, <td rowspan="6">#GP(0)</td>, <td>If IA32_FEATURE_CONTROL.LOCK = 0.</td>, <td>If IA32_FEATURE_CONTROL.SGX_ENABLE = 0.</td>, <td>If input value in EAX encodes an unsupported leaf.</td>, <td>If input value in EAX encodes EENTER/ERESUME and ENCLAVE_MODE = 1.</td>, <td>If input value in EAX encodes EGETKEY/EREPORT/EEXIT/EACCEPT/EACCEPTCOPY/EMODPE and ENCLAVE_MODE = 0.</td>, <td>If CR0.NE= 0.</td>, <td>#NM</td>, <td>If CR0.TS = 1.</td>]

[<td>EAX = 07H ENCLU[EACCEPTCOPY]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX2</td>, <td>This leaf function initializes a dynamically allocated EPC page from another page in the EPC.</td>, <td>Op/En</td>, <td colspan="2">EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>RDX</td>, <td>IR</td>, <td>EACCEPTCOPY (In)</td>, <td>Return Error Code (Out)</td>, <td>Address of a SECINFO (In)</td>, <td>Address of the destination EPC page (In)</td>, <td>Address of the source EPC page (In)</td>, <td>SECINFO</td>, <td>EPCPAGE (Destination)</td>, <td>EPCPAGE (Source)</td>, <td>Read access permitted by Non Enclave</td>, <td>Read/Write access permitted by Enclave</td>, <td>Read access permitted by Enclave</td>, <td>The operands are not properly aligned.</td>, <td>If security attributes of the SECINFO page make the page inaccessible.</td>, <td>The EPC page is locked by another thread.</td>, <td>If security attributes of the source EPC page make the page inaccessible.</td>, <td>The EPC page is not valid.</td>, <td>RBX does not contain an effective address in an EPC page in the running enclave.</td>, <td>SECINFO contains an invalid request.</td>, <td>RCX/RDX does not contain an effective address of an EPC page in the running enclave.</td>, <td>No Error</td>, <td>EACCEPTCOPY successful.</td>, <td>SGX_PAGE_ATTRIBUTES_MISMATCH</td>, <td>The attributes of the target EPC page do not match the expected values.</td>, <td rowspan="3">EACCEPTCOPY</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td></td>, <td>Source [DS:RDX]</td>, <td>Concurrent</td>, <td></td>, <td></td>, <td>SECINFO [DS:RBX]</td>, <td>Concurrent</td>, <td></td>, <td></td>, <td rowspan="3">EACCEPTCOPY</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>#GP</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Source [DS:RDX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECINFO [DS:RBX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SCRATCH_SECINFO</td>, <td>SECINFO</td>, <td>512</td>, <td>Scratch storage for holding the contents of DS:RBX.</td>, <td rowspan="4">#GP(0)</td>, <td>If executed outside an enclave.</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If a memory operand is locked.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand is not an EPC page.</td>, <td>If EPC page has incorrect page type or security attributes.</td>, <td rowspan="4">#GP(0)</td>, <td>If executed outside an enclave.</td>, <td>If a memory operand is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If a memory operand is locked.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand is not an EPC page.</td>, <td>If EPC page has incorrect page type or security attributes.</td>]

[<td>EAX = 05H ENCLU[EACCEPT]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX2</td>, <td>This leaf function accepts changes made by system software to an EPC page in the running enclave.</td>, <td>Op/En</td>, <td colspan="2">EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>IR</td>, <td>EACCEPT (In)</td>, <td>Return Error Code (Out)</td>, <td>Address of a SECINFO (In)</td>, <td>Address of the destination EPC page (In)</td>, <td>SECINFO</td>, <td>EPCPAGE (Destination)</td>, <td>Read access permitted by Non Enclave</td>, <td>Read access permitted by Enclave</td>, <td>The operands are not properly aligned.</td>, <td>RBX does not contain an effective address in an EPC page in the running enclave.</td>, <td>The EPC page is locked by another thread.</td>, <td>RCX does not contain an effective address of an EPC page in the running enclave.</td>, <td>The EPC page is not valid.</td>, <td>Page type is PT_REG and MODIFIED bit is 0.</td>, <td>SECINFO contains an invalid request.</td>, <td>Page type is PT_TCS or PT_TRIM and PENDING bit is 0 and MODIFIED bit is 1.</td>, <td>If security attributes of the SECINFO page make the page inaccessible.</td>, <td></td>, <td>No Error</td>, <td>EACCEPT successful.</td>, <td>SGX_PAGE_ATTRIBUTES_MISMATCH</td>, <td>The attributes of the target EPC page do not match the expected values.</td>, <td>SGX_NOT_TRACKED</td>, <td>The OS did not complete an ETRACK on the target page.</td>, <td rowspan="2">EACCEPT</td>, <td>Target [DS:RCX]</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td>SECINFO [DS:RBX]</td>, <td>Concurrent</td>, <td></td>, <td></td>, <td rowspan="2">EACCEPT</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>#GP</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECINFO [DS:RBX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_SECS</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Physical address of SECS to which EPC operands belongs.</td>, <td>SCRATCH_SECINFO</td>, <td>SECINFO</td>, <td>512</td>, <td>Scratch storage for holding the contents of DS:RBX.</td>, <td rowspan="4">#GP(0)</td>, <td>If executed outside an enclave.</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If a memory operand is locked.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand is not an EPC page.</td>, <td>If EPC page has incorrect page type or security attributes.</td>, <td rowspan="4">#GP(0)</td>, <td>If executed outside an enclave.</td>, <td>If a memory operand is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If a memory operand is locked.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If a memory operand is not an EPC page.</td>, <td>If EPC page has incorrect page type or security attributes.</td>]

[<td>EAX = 02H ENCLU[EENTER]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function is used to enter an enclave.</td>, <td>Op/En</td>, <td colspan="2">EAX</td>, <td>RBX</td>, <td colspan="2">RCX</td>, <td>IR</td>, <td>EENTER (In)</td>, <td>Content of RBX.CSSA (Out)</td>, <td>Address of a TCS (In)</td>, <td>Address of AEP (In)</td>, <td>Address of IP following EENTER (Out)</td>, <td>TCS</td>, <td>Enclave access</td>, <td>Address in RBX is not properly aligned.</td>, <td>Any TCS.FLAGS’s must-be-zero bit is not zero.</td>, <td>TCS pointed to by RBX is not valid or available or locked.</td>, <td>Current 32/64 mode does not match the enclave mode in SECS.ATTRIBUTES.MODE64.</td>, <td>The SECS is in use.</td>, <td>Either of TCS-specified FS and GS segment is not a subsets of the current DS segment.</td>, <td>Any one of DS, ES, CS, SS is not zero.</td>, <td>If XSAVE available, CR4.OSXSAVE = 0, but SECS.ATTRIBUTES.XFRM ≠ 3.</td>, <td>CR4.OSFXSR ≠ 1.</td>, <td>If CR4.OSXSAVE = 1, SECS.ATTRIBUTES.XFRM is not a subset of XCR0.</td>, <td>EENTER</td>, <td>TCS [DS:RBX]</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td>EENTER</td>, <td>TCS [DS:RBX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_FSBASE</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Proposed base address for FS segment.</td>, <td>TMP_GSBASE</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Proposed base address for FS segment.</td>, <td>TMP_FSLIMIT</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Highest legal address in proposed FS segment.</td>, <td>TMP_GSLIMIT</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Highest legal address in proposed GS segment.</td>, <td>TMP_XSIZE</td>, <td>integer</td>, <td>64</td>, <td>Size of XSAVE area based on SECS.ATTRIBUTES.XFRM.</td>, <td>TMP_SSA_PAGE</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Pointer used to iterate over the SSA pages in the current frame.</td>, <td>TMP_GPR</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Address of the GPR area within the current SSA frame.</td>, <td rowspan="11">#GP(0)</td>, <td>If DS:RBX is not page aligned.</td>, <td>If the enclave is not initialized.</td>, <td>If part or all of the FS or GS segment specified by TCS is outside the DS segment or not properly aligned.</td>, <td>If the thread is not in the INACTIVE state.</td>, <td>If CS, DS, ES or SS bases are not all zero.</td>, <td>If executed in enclave mode.</td>, <td>If any reserved field in the TCS FLAG is set.</td>, <td>If the target address is not within the CS segment.</td>, <td>If CR4.OSFXSR = 0.</td>, <td>If CR4.OSXSAVE = 0 and SECS.ATTRIBUTES.XFRM ≠ 3.</td>, <td>If CR4.OSXSAVE = 1and SECS.ATTRIBUTES.XFRM is not a subset of XCR0.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory.</td>, <td>If DS:RBX does not point to a valid TCS.</td>, <td>If one or more pages of the current SSA frame are not readable/writable, or do not resolve to a valid PT_REG EPC page.</td>, <td rowspan="10">#GP(0)</td>, <td>If DS:RBX is not page aligned.</td>, <td>If the enclave is not initialized.</td>, <td>If the thread is not in the INACTIVE state.</td>, <td>If CS, DS, ES or SS bases are not all zero.</td>, <td>If executed in enclave mode.</td>, <td>If part or all of the FS or GS segment specified by TCS is outside the DS segment or not properly aligned.</td>, <td>If the target address is not canonical.</td>, <td>If CR4.OSFXSR = 0.</td>, <td>If CR4.OSXSAVE = 0 and SECS.ATTRIBUTES.XFRM ≠ 3.</td>, <td>If CR4.OSXSAVE = 1and SECS.ATTRIBUTES.XFRM is not a subset of XCR0.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If DS:RBX does not point to a valid TCS.</td>, <td>If one or more pages of the current SSA frame are not readable/writable, or do not resolve to a valid PT_REG EPC page.</td>]

[<td><strong>Opcode/Op/En 64/32 CPUID Description Instruction bit Mode Feature Support Flag</strong> EAX = 04H IR V/V SGX1 This leaf function is used to exit an enclave. ENCLU[EEXIT]</td>, <td>Op/En</td>, <td>EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>IR</td>, <td>EEXIT (In)</td>, <td>Target address outside the enclave (In)</td>, <td>Address of the current AEP (In)</td>, <td>Target Address</td>, <td>Non-Enclave read and execute access</td>, <td>EEXIT</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td></td>, <td>EEXIT</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_RIP</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Saved copy of CRIP for use when creating LBR.</td>, <td rowspan="2">#GP(0)</td>, <td>If executed outside an enclave.</td>, <td>If RBX is outside the CS segment.</td>, <td>#PF(error</td>, <td>code) If a page fault occurs in accessing memory.</td>, <td rowspan="2">#GP(0)</td>, <td>If executed outside an enclave.</td>, <td>If RBX is not canonical.</td>, <td>#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>]

[<td>EAX = 01H ENCLU[EGETKEY]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function retrieves a cryptographic key.</td>, <td>Op/En</td>, <td>EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>IR</td>, <td>EGETKEY (In)</td>, <td>Address to a KEYREQUEST (In)</td>, <td>Address of the OUTPUTDATA (In)</td>, <td>KEYREQUEST</td>, <td>OUTPUTDATA</td>, <td>Enclave read access</td>, <td>Enclave write access</td>, <td rowspan="2"><strong>Source</strong></td>, <td rowspan="2">Key Dependent Constant</td>, <td>Y← SECS.ATTRIBUTES and SECS.MISCSELECT;</td>, <td rowspan="2">CR_SGX OWNER EPOCH</td>, <td>Y← CPUSVN Register;</td>, <td rowspan="2">R← Req.ISV SVN;</td>, <td rowspan="2">SECS. ISVID</td>, <td rowspan="2">SECS.IS VEXTPR ODID</td>, <td rowspan="2">SECS.IS VFAMIL YID</td>, <td rowspan="2">SECS. MRENCLAVE</td>, <td rowspan="2">SECS. MRSIGNER</td>, <td rowspan="2">SECS.CO NFIGID</td>, <td rowspan="2">SECS.CO NFIGSVN</td>, <td rowspan="2">Req. KEYID</td>, <td>R←AttribMask &amp; SECS.ATTRIBUTES and SECS.MISCSELECT;</td>, <td>R← Req.CPU SVN;</td>, <td>EINITTOKEN</td>, <td>Yes</td>, <td>Request</td>, <td>Yes</td>, <td>Request</td>, <td>Request</td>, <td>Yes</td>, <td>No</td>, <td>No</td>, <td>No</td>, <td>Yes</td>, <td>No</td>, <td>No</td>, <td>Request</td>, <td>Report</td>, <td>Yes</td>, <td>Yes</td>, <td>Yes</td>, <td>Yes</td>, <td>No</td>, <td>No</td>, <td>No</td>, <td>No</td>, <td>Yes</td>, <td>No</td>, <td>Yes</td>, <td>Yes</td>, <td>Request</td>, <td>Seal</td>, <td>Yes</td>, <td>Request</td>, <td>Yes</td>, <td>Request</td>, <td>Request</td>, <td>Request</td>, <td>Request</td>, <td>Request</td>, <td>Request</td>, <td>Request</td>, <td>Request</td>, <td>Request</td>, <td>Request</td>, <td>Provisioning</td>, <td>Yes</td>, <td>Request</td>, <td>No</td>, <td>Request</td>, <td>Request</td>, <td>Yes</td>, <td>No</td>, <td>No</td>, <td>No</td>, <td>Yes</td>, <td>No</td>, <td>No</td>, <td>Yes</td>, <td>Provisioning Seal</td>, <td>Yes</td>, <td>Request</td>, <td>No</td>, <td>Request</td>, <td>Request</td>, <td>Request</td>, <td>Request</td>, <td>Request</td>, <td>No</td>, <td>Yes</td>, <td>Request</td>, <td>Request</td>, <td>Yes</td>, <td>No Error</td>, <td>0</td>, <td>EGETKEY successful.</td>, <td>SGX_INVALID_ATTRIBUTE</td>, <td></td>, <td>The KEYREQUEST contains a KEYNAME for which the enclave is not authorized.</td>, <td>SGX_INVALID_CPUSVN</td>, <td></td>, <td>If KEYREQUEST.CPUSVN is an unsupported platforms CPUSVN value.</td>, <td>SGX_INVALID_ISVSVN</td>, <td></td>, <td>If KEYREQUEST software SVN (ISVSVN or CONFIGSVN) is greater than the enclave's corresponding SVN.</td>, <td>SGX_INVALID_KEYNAME</td>, <td></td>, <td>If KEYREQUEST.KEYNAME is an unsupported value.</td>, <td rowspan="2">EGETKEY</td>, <td>KEYREQUEST [DS:RBX]</td>, <td>Concurrent</td>, <td></td>, <td></td>, <td>OUTPUTDATA [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td></td>, <td rowspan="2">EGETKEY</td>, <td>KEYREQUEST [DS:RBX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>OUTPUTDATA [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_CURRENTSECS</td>, <td></td>, <td></td>, <td>Address of the SECS for the currently executing enclave.</td>, <td>TMP_KEYDEPENDENCIES</td>, <td></td>, <td></td>, <td>Temp space for key derivation.</td>, <td>TMP_ATTRIBUTES</td>, <td></td>, <td>128</td>, <td>Temp Space for the calculation of the sealable Attributes.</td>, <td>TMP_ISVEXTPRODID</td>, <td></td>, <td>16 bytes</td>, <td>Temp Space for ISVEXTPRODID.</td>, <td>TMP_ISVPRODID</td>, <td></td>, <td>2 bytes</td>, <td>Temp Space for ISVPRODID.</td>, <td>TMP_ISVFAMILYID</td>, <td></td>, <td>16 bytes</td>, <td>Temp Space for ISVFAMILYID.</td>, <td>TMP_CONFIGID</td>, <td></td>, <td>64 bytes</td>, <td>Temp Space for CONFIGID.</td>, <td>TMP_CONFIGSVN</td>, <td></td>, <td>2 bytes</td>, <td>Temp Space for CONFIGSVN.</td>, <td>TMP_OUTPUTKEY</td>, <td></td>, <td>128</td>, <td>Temp Space for the calculation of the key.</td>, <td rowspan="5">#GP(0)</td>, <td>If executed outside an enclave.</td>, <td>If a memory operand effective address is outside the current enclave.</td>, <td>If an effective address is not properly aligned.</td>, <td>If an effective address is outside the DS segment limit.</td>, <td>If KEYREQUEST format is invalid.</td>, <td>#PF(error</td>, <td>code) If a page fault occurs in accessing memory.</td>, <td rowspan="5">#GP(0)</td>, <td>If executed outside an enclave.</td>, <td>If a memory operand effective address is outside the current enclave.</td>, <td>If an effective address is not properly aligned.</td>, <td>If an effective address is not canonical.</td>, <td>If KEYREQUEST format is invalid.</td>, <td>#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>]

[<td>EAX = 06H ENCLU[EMODPE]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX2</td>, <td>This leaf function extends the access rights of an existing EPC page.</td>, <td>Op/En</td>, <td>EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>IR</td>, <td>EMODPE (In)</td>, <td>Address of a SECINFO (In)</td>, <td>Address of the destination EPC page (In)</td>, <td>SECINFO</td>, <td>EPCPAGE</td>, <td>Read access permitted by Non Enclave</td>, <td>Read access permitted by Enclave</td>, <td>The operands are not properly aligned.</td>, <td>If security attributes of the SECINFO page make the page inaccessible.</td>, <td>The EPC page is locked by another thread.</td>, <td>RBX does not contain an effective address in an EPC page in the running enclave.</td>, <td>The EPC page is not valid.</td>, <td>RCX does not contain an effective address of an EPC page in the running enclave.</td>, <td>SECINFO contains an invalid request.</td>, <td></td>, <td rowspan="2">EMODPE</td>, <td>Target [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td></td>, <td>SECINFO [DS:RBX]</td>, <td>Concurrent</td>, <td></td>, <td></td>, <td rowspan="2">EMODPE</td>, <td>Target [DS:RCX]</td>, <td>Exclusive</td>, <td>#GP</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECINFO [DS:RBX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SCRATCH_SECINFO</td>, <td>SECINFO</td>, <td>512</td>, <td>Scratch storage for holding the contents of DS:RBX.</td>, <td rowspan="4">#GP(0)</td>, <td>If executed outside an enclave.</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If a memory operand is locked.</td>, <td>#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td rowspan="4">#GP(0)</td>, <td>If executed outside an enclave.</td>, <td>If a memory operand is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If a memory operand is locked.</td>, <td>#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>]

[<td>EAX = 00H ENCLU[EREPORT]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function creates a cryptographic report of the enclave.</td>, <td>Op/En</td>, <td>EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>RDX</td>, <td>IR</td>, <td>EREPORT (In)</td>, <td>Address of TARGETINFO (In)</td>, <td>Address of REPORTDATA (In)</td>, <td>Address where the REPORT is written to in an OUTPUTDATA (In)</td>, <td>TARGETINFO</td>, <td>REPORTDATA</td>, <td>OUTPUTDATA</td>, <td>Read access by Enclave</td>, <td>Read access by Enclave</td>, <td>Read/Write access by Enclave</td>, <td>An effective address not properly aligned.</td>, <td>An memory address does not resolve in an EPC page.</td>, <td>If accessing an invalid EPC page.</td>, <td>If the EPC page is blocked.</td>, <td>May page fault.</td>, <td></td>, <td rowspan="3">EREPORT</td>, <td>TARGETINFO [DS:RBX]</td>, <td>Concurrent</td>, <td></td>, <td></td>, <td>REPORTDATA [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td></td>, <td>OUTPUTDATA [DS:RDX]</td>, <td>Concurrent</td>, <td></td>, <td></td>, <td rowspan="3">EREPORT</td>, <td>TARGETINFO [DS:RBX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>REPORTDATA [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>OUTPUTDATA [DS:RDX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_ATTRIBUTES</td>, <td></td>, <td>32</td>, <td>Physical address of SECS of the enclave to which source operand belongs.</td>, <td>TMP_CURRENTSECS</td>, <td></td>, <td></td>, <td>Address of the SECS for the currently executing enclave.</td>, <td>TMP_KEYDEPENDENCIES</td>, <td></td>, <td></td>, <td>Temp space for key derivation.</td>, <td>TMP_REPORTKEY</td>, <td></td>, <td>128</td>, <td>REPORTKEY generated by the instruction.</td>, <td>TMP_REPORT</td>, <td></td>, <td>3712</td>, <td></td>, <td rowspan="4">#GP(0)</td>, <td>If executed outside an enclave.</td>, <td>If the address in RCS is outside the DS segment limit.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If a memory operand is not in the current enclave.</td>, <td>#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td rowspan="4">#GP(0)</td>, <td>If executed outside an enclave.</td>, <td>If RCX is non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>If a memory operand is not in the current enclave.</td>, <td>#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>]

[<td>EAX = 03H ENCLU[ERESUME]</td>, <td>IR</td>, <td>V/V</td>, <td>SGX1</td>, <td>This leaf function is used to re-enter an enclave after an interrupt.</td>, <td>Op/En</td>, <td>RAX</td>, <td>RBX</td>, <td>RCX</td>, <td>IR</td>, <td>ERESUME (In)</td>, <td>Address of a TCS (In)</td>, <td>Address of AEP (In)</td>, <td>TCS</td>, <td>Enclave read/write access</td>, <td>Address in RBX is not properly aligned.</td>, <td>Any TCS.FLAGS’s must-be-zero bit is not zero.</td>, <td>TCS pointed to by RBX is not valid or available or locked.</td>, <td>Current 32/64 mode does not match the enclave mode in SECS.ATTRIBUTES.MODE64.</td>, <td>The SECS is in use by another enclave.</td>, <td>Either of TCS-specified FS and GS segment is not a subset of the current DS segment.</td>, <td>Any one of DS, ES, CS, SS is not zero.</td>, <td>If XSAVE available, CR4.OSXSAVE = 0, but SECS.ATTRIBUTES.XFRM ≠ 3.</td>, <td>CR4.OSFXSR ≠ 1.</td>, <td>If CR4.OSXSAVE = 1, SECS.ATTRIBUTES.XFRM is not a subset of XCR0.</td>, <td>Offsets 520-535 of the XSAVE area not 0.</td>, <td>The bit vector stored at offset 512 of the XSAVE area must be a subset of SECS.ATTRIBUTES.XFRM.</td>, <td>The SSA frame is not valid or in use.</td>, <td></td>, <td>ERESUME</td>, <td>TCS [DS:RBX]</td>, <td>Shared</td>, <td>#GP</td>, <td></td>, <td>ERESUME</td>, <td>TCS [DS:RBX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_FSBASE</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Proposed base address for FS segment.</td>, <td>TMP_GSBASE</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Proposed base address for FS segment.</td>, <td>TMP_FSLIMIT</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Highest legal address in proposed FS segment.</td>, <td>TMP_GSLIMIT</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Highest legal address in proposed GS segment.</td>, <td>TMP_TARGET</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Address of first instruction inside enclave at which execution is to resume.</td>, <td>TMP_SECS</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Physical address of SECS for this enclave.</td>, <td>TMP_SSA</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Address of current SSA frame.</td>, <td>TMP_XSIZE</td>, <td>integer</td>, <td>64</td>, <td>Size of XSAVE area based on SECS.ATTRIBUTES.XFRM.</td>, <td>TMP_SSA_PAGE</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Pointer used to iterate over the SSA pages in the current frame.</td>, <td>TMP_GPR</td>, <td>Effective Address</td>, <td>32/64</td>, <td>Address of the GPR area within the current SSA frame.</td>, <td>TMP_BRANCH_RECORD</td>, <td>LBR Record</td>, <td></td>, <td>From/to addresses to be pushed onto the LBR stack.</td>, <td rowspan="11">#GP(0)</td>, <td>If DS:RBX is not page aligned.</td>, <td>If the enclave is not initialized.</td>, <td>If the thread is not in the INACTIVE state.</td>, <td>If CS, DS, ES or SS bases are not all zero.</td>, <td>If executed in enclave mode.</td>, <td>If part or all of the FS or GS segment specified by TCS is outside the DS segment.</td>, <td>If any reserved field in the TCS FLAG is set.</td>, <td>If the target address is not within the CS segment.</td>, <td>If CR4.OSFXSR = 0.</td>, <td>If CR4.OSXSAVE = 0 and SECS.ATTRIBUTES.XFRM ≠ 3.</td>, <td>If CR4.OSXSAVE = 1and SECS.ATTRIBUTES.XFRM is not a subset of XCR0.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory.</td>, <td>If DS:RBX does not point to a valid TCS.</td>, <td>If one or more pages of the current SSA frame are not readable/writable, or do not resolve to a valid PT_REG EPC page.</td>, <td rowspan="11">#GP(0)</td>, <td>If DS:RBX is not page aligned.</td>, <td>If the enclave is not initialized.</td>, <td>If the thread is not in the INACTIVE state.</td>, <td>If CS, DS, ES or SS bases are not all zero.</td>, <td>If executed in enclave mode.</td>, <td>If part or all of the FS or GS segment specified by TCS is outside the DS segment.</td>, <td>If any reserved field in the TCS FLAG is set.</td>, <td>If the target address is not canonical.</td>, <td>If CR4.OSFXSR = 0.</td>, <td>If CR4.OSXSAVE = 0 and SECS.ATTRIBUTES.XFRM ≠ 3.</td>, <td>If CR4.OSXSAVE = 1and SECS.ATTRIBUTES.XFRM is not a subset of XCR0.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If DS:RBX does not point to a valid TCS.</td>, <td>If one or more pages of the current SSA frame are not readable/writable, or do not resolve to a valid PT_REG EPC page.</td>]

[<td>NP 0F 01 C0 ENCLV</td>, <td>NP</td>, <td>V/V</td>, <td>NA</td>, <td>This instruction is used to execute privileged SGX leaf functions that are reserved for VMM use. They are used for managing the enclaves.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Implicit Register Operands</td>, <td>NP</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>See Section 40.3</td>, <td rowspan="4">#UD</td>, <td>If any of the LOCK/OSIZE/REP/VEX prefix is used.</td>, <td>If current privilege level is not 0.</td>, <td>If CPUID.(EAX=12H,ECX=0):EAX.OSS [bit 5] = 0.</td>, <td>If logical processor is in SMM.</td>, <td rowspan="5">#GP(0)</td>, <td>If IA32_FEATURE_CONTROL.LOCK = 0.</td>, <td>If IA32_FEATURE_CONTROL.SGX_ENABLE = 0.</td>, <td>If input value in EAX encodes an unsupported leaf.</td>, <td>If data segment expand down.</td>, <td>If CR0.PG=0.</td>, <td>#UD</td>, <td>ENCLV is not recognized in real mode.</td>, <td>#UD</td>, <td>ENCLV is not recognized in virtual-8086 mode.</td>, <td rowspan="4">#UD</td>, <td>If any of the LOCK/OSIZE/REP/VEX prefix is used.</td>, <td>If current privilege level is not 0.</td>, <td>If CPUID.(EAX=12H,ECX=0):EAX.OSS [bit 5] = 0.</td>, <td>If logical processor is in SMM.</td>, <td rowspan="3">#GP(0)</td>, <td>If IA32_FEATURE_CONTROL.LOCK = 0.</td>, <td>If IA32_FEATURE_CONTROL.SGX_ENABLE = 0.</td>, <td>If input value in EAX encodes an unsupported leaf.</td>]

[<td>EAX = 00H ENCLV[EDECVIRTCHILD]</td>, <td>IR</td>, <td>V/V</td>, <td>EAX[5]</td>, <td>This leaf function decrements the SECS VIRTCHILDCNT field.</td>, <td>Op/En</td>, <td>EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>IR</td>, <td>EDECVIRTCHILD (In)</td>, <td>Address of an enclave page (In)</td>, <td>Address of an SECS page (In)</td>, <td>EPCPAGE</td>, <td>SECS</td>, <td>Read/Write access permitted by Non Enclave</td>, <td>Read access permitted by Enclave</td>, <td>A memory operand effective address is outside the DS segment limit (32b mode).</td>, <td>A page fault occurs in accessing memory operands.</td>, <td>DS segment is unusable (32b mode).</td>, <td>RBX does not refer to an enclave page (REG, TCS, TRIM, SECS).</td>, <td>A memory address is in a non-canonical form (64b mode).</td>, <td>RCX does not refer to an SECS page.</td>, <td>A memory operand is not properly aligned.</td>, <td>RBX does not refer to an enclave page associated with SECS referenced in RCX.</td>, <td rowspan="2">EDECVIRTCHILD</td>, <td>Target [DS:RBX]</td>, <td>Shared</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td></td>, <td>SECS [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td></td>, <td rowspan="2">EDECVIRTCHILD</td>, <td>Target [DS:RBX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECS [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_SECS</td>, <td>Physical Address</td>, <td>64</td>, <td>Physical address of the SECS of the page being modified.</td>, <td>TMP_VIRTCHILDCNT</td>, <td>Integer</td>, <td>64</td>, <td>Number of virtual child pages.</td>, <td>No Error</td>, <td>0</td>, <td>EDECVIRTCHILD Successful.</td>, <td>SGX_EPC_PAGE_CONFLICT</td>, <td></td>, <td>Failure due to concurrent operation of another SGX instruction.</td>, <td>SGX_INVALID_COUNTER</td>, <td></td>, <td>Attempt to decrement counter that is already zero.</td>, <td rowspan="4">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If DS segment is unusable.</td>, <td>If a memory operand is not properly aligned.</td>, <td>RBX does not refer to an enclave page associated with SECS referenced in RCX.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If RBX does not refer to an enclave page (REG, TCS, TRIM, SECS).</td>, <td>If RCX does not refer to an SECS page.</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory address is in a non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>RBX does not refer to an enclave page associated with SECS referenced in RCX.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If RBX does not refer to an enclave page (REG, TCS, TRIM, SECS).</td>, <td>If RCX does not refer to an SECS page.</td>]

[<td>EAX = 01H ENCLV[EINCVIRTCHILD]</td>, <td>IR</td>, <td>V/V</td>, <td>EAX[5]</td>, <td>This leaf function increments the SECS VIRTCHILDCNT field.</td>, <td>Op/En</td>, <td>EAX</td>, <td>RBX</td>, <td>RCX</td>, <td>IR</td>, <td>EINCVIRTCHILD (In)</td>, <td>Address of an enclave page (In)</td>, <td>Address of an SECS page (In)</td>, <td>EPCPAGE</td>, <td>SECS</td>, <td>Read/Write access permitted by Non Enclave</td>, <td>Read access permitted by Enclave</td>, <td>A memory operand effective address is outside the DS segment limit (32b mode).</td>, <td>A page fault occurs in accessing memory operands.</td>, <td>DS segment is unusable (32b mode).</td>, <td>RBX does not refer to an enclave page (REG, TCS, TRIM, SECS).</td>, <td>A memory address is in a non-canonical form (64b mode).</td>, <td>RCX does not refer to an SECS page.</td>, <td>A memory operand is not properly aligned.</td>, <td>RBX does not refer to an enclave page associated with SECS referenced in RCX.</td>, <td rowspan="2">EINCVIRTCHILD</td>, <td>Target [DS:RBX]</td>, <td>Shared</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td></td>, <td>SECS [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td></td>, <td rowspan="2">EINCVIRTCHILD</td>, <td>Target [DS:RBX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>SECS [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_SECS</td>, <td>Physical Address</td>, <td>64</td>, <td>Physical address of the SECS of the page being modified.</td>, <td>No Error</td>, <td>0</td>, <td>EINCVIRTCHILD Successful.</td>, <td>SGX_EPC_PAGE_CONFLICT</td>, <td></td>, <td>Failure due to concurrent operation of another SGX instruction.</td>, <td rowspan="4">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If DS segment is unusable.</td>, <td>If a memory operand is not properly aligned.</td>, <td>RBX does not refer to an enclave page associated with SECS referenced in RCX.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If RBX does not refer to an enclave page (REG, TCS, TRIM, SECS).</td>, <td>If RCX does not refer to an SECS page.</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory address is in a non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>RBX does not refer to an enclave page associated with SECS referenced in RCX.</td>, <td rowspan="3">#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td>If RBX does not refer to an enclave page (REG, TCS, TRIM, SECS).</td>, <td>If RCX does not refer to an SECS page.</td>]

[<td>EAX = 02H ENCLV[ESETCONTEXT]</td>, <td>IR</td>, <td>V/V</td>, <td>EAX[5]</td>, <td>This leaf function sets the ENCLAVECONTEXT field in SECS.</td>, <td>Op/En</td>, <td>EAX</td>, <td>RCX</td>, <td>RDX</td>, <td>IR</td>, <td>ESETCONTEXT (In)</td>, <td>Address of the destination EPC page (In, EA)</td>, <td>Context Value (In, EA)</td>, <td>EPCPAGE</td>, <td>CONTEXT</td>, <td>Read access permitted by Enclave</td>, <td>Read/Write access permitted by Non Enclave</td>, <td>A memory operand effective address is outside the DS segment limit (32b mode).</td>, <td>A memory operand is not properly aligned.</td>, <td>DS segment is unusable (32b mode).</td>, <td>A page fault occurs in accessing memory operands.</td>, <td>A memory address is in a non-canonical form (64b mode).</td>, <td></td>, <td>ESETCONTEXT</td>, <td>SECS [DS:RCX]</td>, <td>Shared</td>, <td>SGX_EPC_PAGE_ CONFLICT</td>, <td></td>, <td>ESETCONTEXT</td>, <td>SECS [DS:RCX]</td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>Concurrent</td>, <td></td>, <td>TMP_SECS</td>, <td>Physical Address</td>, <td>64</td>, <td>Physical address of the SECS of the page being modified.</td>, <td>TMP_CONTEXT</td>, <td>CONTEXT</td>, <td>64</td>, <td>Data Value of CONTEXT.</td>, <td>No Error</td>, <td>0</td>, <td>ESETCONTEXT Successful.</td>, <td>SGX_EPC_PAGE_CONFLICT</td>, <td></td>, <td>Failure due to concurrent operation of another SGX instruction.</td>, <td rowspan="3">#GP(0)</td>, <td>If a memory operand effective address is outside the DS segment limit.</td>, <td>If DS segment is unusable.</td>, <td>If a memory operand is not properly aligned.</td>, <td>#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>, <td rowspan="2">#GP(0)</td>, <td>If a memory address is in a non-canonical form.</td>, <td>If a memory operand is not properly aligned.</td>, <td>#PF(error</td>, <td>code) If a page fault occurs in accessing memory operands.</td>]

[<td>NP 0F 37 (EAX = 0)</td>, <td>GETSEC[CAPABILITIES]</td>, <td>Report the SMX capabilities. The capabilities index is input in EBX with the result returned in EAX.</td>, <td>Chipset Present</td>, <td>0</td>, <td>Intel® TXT-capable chipset is present.</td>, <td>Undefined</td>, <td>1</td>, <td>Reserved</td>, <td>ENTERACCS</td>, <td>2</td>, <td>GETSEC[ENTERACCS] is available.</td>, <td>EXITAC</td>, <td>3</td>, <td>GETSEC[EXITAC] is available.</td>, <td>SENTER</td>, <td>4</td>, <td>GETSEC[SENTER] is available.</td>, <td>SEXIT</td>, <td>5</td>, <td>GETSEC[SEXIT] is available.</td>, <td>PARAMETERS</td>, <td>6</td>, <td>GETSEC[PARAMETERS] is available.</td>, <td>SMCTRL</td>, <td>7</td>, <td>GETSEC[SMCTRL] is available.</td>, <td>WAKEUP</td>, <td>8</td>, <td>GETSEC[WAKEUP] is available.</td>, <td>Undefined</td>, <td>30:9</td>, <td>Reserved</td>, <td>Extended Leafs</td>, <td>31</td>, <td>Reserved for extended information reporting of GETSEC capabilities.</td>, <td>#UD</td>, <td>IF CR4.SMXE = 0.</td>, <td>#UD</td>, <td>IF CR4.SMXE = 0.</td>, <td>#UD</td>, <td>IF CR4.SMXE = 0.</td>, <td>#UD</td>, <td>IF CR4.SMXE = 0.</td>, <td>#UD</td>, <td>IF CR4.SMXE = 0.</td>]

[<td>NP 0F 37 (EAX = 2)</td>, <td>GETSEC[ENTERACCS]</td>, <td>Enter authenticated code execution mode. EBX holds the authenticated code module physical base address. ECX holds the authenticated code module size (bytes).</td>, <td>CR0</td>, <td>PG←0, AM←0, WP←0: Others unchanged</td>, <td>Paging, Alignment Check, Write-protection are disabled.</td>, <td>CR4</td>, <td>MCE←0: Others unchanged</td>, <td>Machine Check Exceptions disabled.</td>, <td>EFLAGS</td>, <td>00000002H</td>, <td></td>, <td>IA32_EFER</td>, <td>0H</td>, <td>IA-32e mode disabled.</td>, <td>EIP</td>, <td>AC.base + EntryPoint</td>, <td>AC.base is in EBX as input to GETSEC[ENTERACCS].</td>, <td>[E|R]BX</td>, <td>Pre-ENTERACCS state: Next [E|R]IP prior to GETSEC[ENTERACCS]</td>, <td>Carry forward 64-bit processor state across GETSEC[ENTERACCS].</td>, <td>ECX</td>, <td>Pre-ENTERACCS state: [31:16]=GDTR.limit; [15:0]=CS.sel</td>, <td>Carry forward processor state across GETSEC[ENTERACCS].</td>, <td>[E|R]DX</td>, <td>Pre-ENTERACCS state: GDTR base</td>, <td>Carry forward 64-bit processor state across GETSEC[ENTERACCS].</td>, <td>EBP</td>, <td>AC.base</td>, <td></td>, <td>CS</td>, <td>Sel=[SegSel], base=0, limit=FFFFFh, G=1, D=1, AR=9BH</td>, <td></td>, <td>DS</td>, <td>Sel=[SegSel] +8, base=0, limit=FFFFFh, G=1, D=1, AR=93H</td>, <td></td>, <td>GDTR</td>, <td>Base= AC.base (EBX) + [GDTBasePtr], Limit=[GDTLimit]</td>, <td></td>, <td>DR7</td>, <td>00000400H</td>, <td></td>, <td>IA32_DEBUGCTL</td>, <td>0H</td>, <td></td>, <td>IA32_MISC_ENABLE</td>, <td>See <span class="not-imported">Table 6-5</span> for example.</td>, <td>The number of initialized fields may change due to processor implementation.</td>, <td>Fast strings enable</td>, <td>0</td>, <td>Clear to 0.</td>, <td>FOPCODE compatibility mode enable</td>, <td>2</td>, <td>Clear to 0.</td>, <td>Thermal monitor enable</td>, <td>3</td>, <td>Set to 1 if other thermal monitor capability is not enabled.<sup>2</sup></td>, <td>Split-lock disable</td>, <td>4</td>, <td>Clear to 0.</td>, <td>Bus lock on cache line splits disable</td>, <td>8</td>, <td>Clear to 0.</td>, <td>Hardware prefetch disable</td>, <td>9</td>, <td>Clear to 0.</td>, <td>GV1/2 legacy enable</td>, <td>15</td>, <td>Clear to 0.</td>, <td>MONITOR/MWAIT s/m enable</td>, <td>18</td>, <td>Clear to 0.</td>, <td>Adjacent sector prefetch disable</td>, <td>19</td>, <td>Clear to 0.</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[ENTERACCS] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td rowspan="12">#GP(0)</td>, <td>IfCR0.CD=1orCR0.NW=1orCR0.NE=0orCR0.PE=0orCPL&gt;0orEFLAGS.VM=1.</td>, <td>If a Intel® TXT-capable chipset is not present.</td>, <td>If in VMX root operation.</td>, <td>If the initiating processor is not designated as the bootstrap processor via the MSR bit IA32_APIC_BASE.BSP.</td>, <td>If the processor is already in authenticated code execution mode.</td>, <td>If the processor is in SMM.</td>, <td>If a valid uncorrectable machine check error is logged in IA32_MC[I]_STATUS.</td>, <td>If the authenticated code base is not on a 4096 byte boundary.</td>, <td>If the authenticated code size &gt; processor internal authenticated code area capacity.</td>, <td>If the authenticated code size is not modulo 64.</td>, <td>If other enabled logical processor(s) of the same package CR0.CD = 1.</td>, <td>If other enabled logical processor(s) of the same package are not in the wait-for-SIPI or SENTER sleep state.</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[ENTERACCS] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td>#GP(0)</td>, <td>GETSEC[ENTERACCS] is not recognized in real-address mode.</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[ENTERACCS] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td>#GP(0)</td>, <td>GETSEC[ENTERACCS] is not recognized in virtual-8086 mode.</td>, <td>#GP</td>, <td>IF AC code module does not reside in physical address below 2^32 -1.</td>, <td>#GP</td>, <td>IF AC code module does not reside in physical address below 2^32 -1.</td>]

[<td>NP 0F 37 (EAX=3)</td>, <td>GETSEC[EXITAC]</td>, <td>Exit authenticated code execution mode. RBX holds the Near Absolute Indirect jump target and EDX hold the exit parameter flags.</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[EXITAC] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td rowspan="5">#GP(0)</td>, <td>If CR0.PE = 0 or CPL&gt;0 or EFLAGS.VM =1.</td>, <td>If in VMX root operation.</td>, <td>If the processor is not currently in authenticated code execution mode.</td>, <td>If the processor is in SMM.</td>, <td>If any reserved bit position is set in the EDX parameter register.</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[EXITAC] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td>#GP(0)</td>, <td>GETSEC[EXITAC] is not recognized in real-address mode.</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[EXITAC] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td>#GP(0)</td>, <td>GETSEC[EXITAC] is not recognized in virtual-8086 mode.</td>, <td>#GP(0)</td>, <td>If the target address in RBX is not in a canonical form.</td>]

[<td>NP 0F 37 (EAX=6)</td>, <td>GETSEC[PARAMETERS]</td>, <td>Report the SMX parameters. The parameters index is input in EBX with the result returned in EAX, EBX, and ECX.</td>, <td>0</td>, <td>NULL</td>, <td>Reserved (0 returned)</td>, <td>Reserved (unmodified)</td>, <td>Reserved (unmodified)</td>, <td>1</td>, <td>Supported AC module versions</td>, <td>Reserved (0 returned)</td>, <td>Version comparison mask</td>, <td>Version numbers supported</td>, <td>2</td>, <td>Max size of authenticated code execution area</td>, <td>Multiply by 32 for size in bytes</td>, <td>Reserved (unmodified)</td>, <td>Reserved (unmodified)</td>, <td>3</td>, <td>External memory types supported during AC mode</td>, <td>Memory type bit mask</td>, <td>Reserved (unmodified)</td>, <td>Reserved (unmodified)</td>, <td>4</td>, <td>Selective SENTER functionality control</td>, <td>EAX[14:8] correspond to available SENTER function disable controls</td>, <td>Reserved (unmodified)</td>, <td>Reserved (unmodified)</td>, <td>5</td>, <td>TXT extensions support</td>, <td>TXT Feature Extensions Flags (see <span class="not-imported">Table 6-8</span>)</td>, <td>Reserved</td>, <td>Reserved</td>, <td>6-31</td>, <td>Undefined</td>, <td>Reserved (unmodified)</td>, <td>Reserved (unmodified)</td>, <td>Reserved (unmodified)</td>, <td>5</td>, <td>Processor based S-CRTM support</td>, <td>Returns 1 if this processor implements a processor-rooted S-CRTM capability and 0 if not (SCRTM is rooted in BIOS). This flag cannot be used to infer whether the chipset supports TXT or whether the processor support SMX.</td>, <td>6</td>, <td>Machine Check Handling</td>, <td>Returns 1 if it machine check status registers can be preserved through ENTERACCS and SENTER. If this bit is 1, the caller of ENTERACCS and SENTER is not required to clear machine check error status bits before invoking these GETSEC leaves. If this bit returns 0, the caller of ENTERACCS and SENTER must clear all machine check error status bits before invoking these GETSEC leaves.</td>, <td>31:7</td>, <td>Reserved</td>, <td>Reserved for future use. Will return 0.</td>, <td>8</td>, <td>Uncacheable (UC)</td>, <td>9</td>, <td>Write Combining (WC)</td>, <td>11:10</td>, <td>Reserved</td>, <td>12</td>, <td>Write-through (WT)</td>, <td>13</td>, <td>Write-protected (WP)</td>, <td>14</td>, <td>Write-back (WB)</td>, <td>31:15</td>, <td>Reserved</td>, <td>1</td>, <td>0.0 only</td>, <td>Supported AC module versions.</td>, <td>2</td>, <td>32 KBytes</td>, <td>Authenticated code execution area size.</td>, <td>3</td>, <td>UC only</td>, <td>External memory types supported during AC execution mode.</td>, <td>4</td>, <td>None</td>, <td>Available SENTER selective disable controls.</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[PARAMETERS] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[PARAMETERS] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[PARAMETERS] is not reported as supported by GETSEC[CAPABILITIES].</td>]

[<td>NP 0F 37 (EAX=4)</td>, <td>GETSEC[SENTER]</td>, <td>Launch a measured environment. EBX holds the SINIT authenticated code module physical base address. ECX holds the SINIT authenticated code module size (bytes). EDX controls the level of functionality supported by the measured environment launch.</td>, <td>CR0</td>, <td>PG←0, AM←0, WP←0; Others unchanged</td>, <td>PG←0, CD←0, NW←0, AM←0, WP←0; PE←1, NE←1</td>, <td>CR4</td>, <td>00004000H</td>, <td>00004000H</td>, <td>EFLAGS</td>, <td>00000002H</td>, <td>00000002H</td>, <td>IA32_EFER</td>, <td>0H</td>, <td>0</td>, <td>EIP</td>, <td>[EntryPoint from MLE header<sup>1</sup>]</td>, <td>[LT.MLE.JOIN + 12]</td>, <td>EBX</td>, <td>Unchanged [SINIT.BASE]</td>, <td>Unchanged</td>, <td>EDX</td>, <td>SENTER control flags</td>, <td>Unchanged</td>, <td>EBP</td>, <td>SINIT.BASE</td>, <td>Unchanged</td>, <td>CS</td>, <td>Sel=[SINIT SegSel], base=0, limit=FFFFFh, G=1, D=1, AR=9BH</td>, <td>Sel = [LT.MLE.JOIN + 8], base = 0, limit = FFFFFH, G = 1, D = 1, AR = 9BH</td>, <td>DS, ES, SS</td>, <td>Sel=[SINIT SegSel] +8, base=0, limit=FFFFFh, G=1, D=1, AR=93H</td>, <td>Sel = [LT.MLE.JOIN + 8] +8, base = 0, limit = FFFFFH, G = 1, D = 1, AR = 93H</td>, <td>GDTR</td>, <td>Base= SINIT.base (EBX) + [SINIT.GDTBasePtr], Limit=[SINIT.GDTLimit]</td>, <td>Base = [LT.MLE.JOIN + 4], Limit = [LT.MLE.JOIN]</td>, <td>DR7</td>, <td>00000400H</td>, <td>00000400H</td>, <td>IA32_DEBUGCTL</td>, <td>0H</td>, <td>0H</td>, <td>Performance counters and counter control registers</td>, <td>0H</td>, <td>0H</td>, <td>IA32_MISC_ENABLE</td>, <td>See <span class="not-imported">Table 6-5</span></td>, <td>See <span class="not-imported">Table 6-5</span></td>, <td>IA32_SMM_MONITOR _CTL</td>, <td>Bit 2←0</td>, <td>Bit 2←0</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[SENTER] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td rowspan="11">#GP(0)</td>, <td>IfCR0.CD=1orCR0.NW=1orCR0.NE=0orCR0.PE=0orCPL&gt;0orEFLAGS.VM=1.</td>, <td>If in VMX root operation.</td>, <td>If the initiating processor is not designated as the bootstrap processor via the MSR bit IA32_APIC_BASE.BSP.</td>, <td>If an Intel® TXT-capable chipset is not present.</td>, <td>If an Intel® TXT-capable chipset interface to TPM is not detected as present.</td>, <td>If a protected partition is already active or the processor is already in authenticated code mode.</td>, <td>If the processor is in SMM.</td>, <td>If a valid uncorrectable machine check error is logged in IA32_MC[I]_STATUS.</td>, <td>If the authenticated code base is not on a 4096 byte boundary.</td>, <td>If the authenticated code size &gt; processor's authenticated code execution area storage capacity.</td>, <td>If the authenticated code size is not modulo 64.</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[SENTER] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td>#GP(0)</td>, <td>GETSEC[SENTER] is not recognized in real-address mode.</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[SENTER] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td>#GP(0)</td>, <td>GETSEC[SENTER] is not recognized in virtual-8086 mode.</td>, <td>#GP</td>, <td>IF AC code module does not reside in physical address below 2^32 -1.</td>, <td>#GP</td>, <td>IF AC code module does not reside in physical address below 2^32 -1.</td>]

[<td>NP 0F 37 (EAX=5)</td>, <td>GETSEC[SEXIT]</td>, <td>Exit measured environment.</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[SEXIT] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td rowspan="6">#GP(0)</td>, <td>IfCR0.PE=0orCPL&gt;0orEFLAGS.VM=1.</td>, <td>If in VMX root operation.</td>, <td>If the initiating processor is not designated via the MSR bit IA32_APIC_BASE.BSP.</td>, <td>If an Intel® TXT-capable chipset is not present.</td>, <td>If a protected partition is not already active or the processor is already in authenticated code mode.</td>, <td>If the processor is in SMM.</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[SEXIT] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td>#GP(0)</td>, <td>GETSEC[SEXIT] is not recognized in real-address mode.</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[SEXIT] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td>#GP(0)</td>, <td>GETSEC[SEXIT] is not recognized in virtual-8086 mode.</td>]

[<td>NP 0F 37 (EAX = 7)</td>, <td>GETSEC[SMCTRL]</td>, <td>Perform specified SMX mode control as selected with the input EBX.</td>, <td>In VMX non-root operation</td>, <td>VM exit</td>, <td>SENTERFLAG = 0</td>, <td>#GP(0), illegal context</td>, <td>In authenticated code execution mode (ACMODEFLAG = 1)</td>, <td>#GP(0), illegal context</td>, <td>SENTERFLAG = 1, not in VMX operation, not in SMM</td>, <td>Unmask SMI</td>, <td>SENTERFLAG = 1, in VMX root operation, not in SMM</td>, <td>Unmask SMI if SMM monitor is not configured, otherwise #GP(0)</td>, <td>SENTERFLAG = 1, In VMX root operation, in SMM</td>, <td>#GP(0), illegal context</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[SMCTRL] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td rowspan="5">#GP(0)</td>, <td>IfCR0.PE=0orCPL&gt;0orEFLAGS.VM=1.</td>, <td>If in VMX root operation.</td>, <td>If a protected partition is not already active or the processor is currently in authenticated code mode.</td>, <td>If the processor is in SMM.</td>, <td>If the SMM monitor is not configured.</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[SMCTRL] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td>#GP(0)</td>, <td>GETSEC[SMCTRL] is not recognized in real-address mode.</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[SMCTRL] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td>#GP(0)</td>, <td>GETSEC[SMCTRL] is not recognized in virtual-8086 mode.</td>]

[<td>NP 0F 37 (EAX=8)</td>, <td>GETSEC[WAKEUP]</td>, <td>Wake up the responding logical processors from the SENTER sleep state.</td>, <td>0</td>, <td>GDT limit</td>, <td>4</td>, <td>GDT base pointer</td>, <td>8</td>, <td>Segment selector initializer</td>, <td>12</td>, <td>EIP</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[WAKEUP] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td rowspan="4">#GP(0)</td>, <td>IfCR0.PE=0orCPL&gt;0orEFLAGS.VM=1.</td>, <td>If in VMX operation.</td>, <td>If a protected partition is not already active or the processor is currently in authenticated code mode.</td>, <td>If the processor is in SMM.</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[WAKEUP] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td>#GP(0)</td>, <td>GETSEC[WAKEUP] is not recognized in real-address mode.</td>, <td rowspan="2">#UD</td>, <td>If CR4.SMXE = 0.</td>, <td>If GETSEC[WAKEUP] is not reported as supported by GETSEC[CAPABILITIES].</td>, <td>#GP(0)</td>, <td>GETSEC[WAKEUP] is not recognized in virtual-8086 mode.</td>]

[<td>66 0F 38 80 INVEPT r64, m128</td>, <td>RM</td>, <td>Invalidates EPT-derived entries in the TLBs and paging-structure caches (in 64-bit mode).</td>, <td>66 0F 38 80 INVEPT r32, m128</td>, <td>RM</td>, <td>Invalidates EPT-derived entries in the TLBs and paging-structure caches (outside 64-bit mode).</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="4">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains an unusable segment.</td>, <td>If the source operand is located in an execute-only code segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing the memory operand.</td>, <td rowspan="2">#SS(0)</td>, <td>If the memory operand effective address is outside the SS segment limit.</td>, <td>If the SS register contains an unusable segment.</td>, <td rowspan="3">#UD</td>, <td>If not in VMX operation.</td>, <td>If the logical processor does not support EPT (IA32_VMX_PROCBASED_CTLS2[33]=0).</td>, <td>If the logical processor supports EPT (IA32_VMX_PROCBASED_CTLS2[33]=1) but does not support the INVEPT instruction (IA32_VMX_EPT_VPID_CAP[20]=0).</td>, <td>#UD</td>, <td>The INVEPT instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>The INVEPT instruction is not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The INVEPT instruction is not recognized in compatibility mode.</td>, <td rowspan="2">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the memory operand is in the CS, DS, ES, FS, or GS segments and the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing the memory operand.</td>, <td>#SS(0)</td>, <td>If the memory operand is in the SS segment and the memory address is in a non-canonical form.</td>, <td rowspan="3">#UD</td>, <td>If not in VMX operation.</td>, <td>If the logical processor does not support EPT (IA32_VMX_PROCBASED_CTLS2[33]=0).</td>, <td>If the logical processor supports EPT (IA32_VMX_PROCBASED_CTLS2[33]=1) but does not support the INVEPT instruction (IA32_VMX_EPT_VPID_CAP[20]=0).</td>]

[<td>66 0F 38 81 INVVPID r64, m128</td>, <td>RM</td>, <td>Invalidates entries in the TLBs and paging-structure caches based on VPID (in 64-bit mode).</td>, <td>66 0F 38 81 INVVPID r32, m128</td>, <td>RM</td>, <td>Invalidates entries in the TLBs and paging-structure caches based on VPID (outside 64-bit mode).</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="4">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains an unusable segment.</td>, <td>If the source operand is located in an execute-only code segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing the memory operand.</td>, <td rowspan="2">#SS(0)</td>, <td>If the memory operand effective address is outside the SS segment limit.</td>, <td>If the SS register contains an unusable segment.</td>, <td rowspan="3">#UD</td>, <td>If not in VMX operation.</td>, <td>If the logical processor does not support VPIDs (IA32_VMX_PROCBASED_CTLS2[37]=0).</td>, <td>If the logical processor supports VPIDs (IA32_VMX_PROCBASED_CTLS2[37]=1) but does not support the INVVPID instruction (IA32_VMX_EPT_VPID_CAP[32]=0).</td>, <td>#UD</td>, <td>The INVVPID instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>The INVVPID instruction is not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The INVVPID instruction is not recognized in compatibility mode.</td>, <td rowspan="2">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the memory operand is in the CS, DS, ES, FS, or GS segments and the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing the memory operand.</td>, <td>#SS(0)</td>, <td>If the memory destination operand is in the SS segment and the memory address is in a non-canonical form.</td>, <td rowspan="3">#UD</td>, <td>If not in VMX operation.</td>, <td>If the logical processor does not support VPIDs (IA32_VMX_PROCBASED_CTLS2[37]=0).</td>, <td>If the logical processor supports VPIDs (IA32_VMX_PROCBASED_CTLS2[37]=1) but does not support the INVVPID instruction (IA32_VMX_EPT_VPID_CAP[32]=0).</td>]

[<td>0F 01 C1 VMCALL</td>, <td>ZO</td>, <td>Call to VM monitor by causing VM exit<em>.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If the current privilege level is not 0 and the logical processor is in VMX root operation.</td>, <td>#UD</td>, <td>If executed outside VMX operation.</td>, <td>#UD</td>, <td>If executed outside VMX operation.</td>, <td>#UD</td>, <td>If executed outside VMX non-root operation.</td>, <td>#UD</td>, <td>If executed outside VMX non-root operation.</td>, <td>#UD</td>, <td>If executed outside VMX operation.</td>]

[<td>66 0F C7 /6 VMCLEAR m64</td>, <td>M</td>, <td>Copy VMCS data to VMCS region in memory<em>.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="4">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the memory operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains an unusable segment.</td>, <td>If the operand is located in an execute-only code segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing the memory operand.</td>, <td rowspan="2">#SS(0)</td>, <td>If the memory operand effective address is outside the SS segment limit.</td>, <td>If the SS register contains an unusable segment.</td>, <td rowspan="2">#UD</td>, <td>If operand is a register.</td>, <td>If not in VMX operation.</td>, <td>#UD</td>, <td>The VMCLEAR instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>The VMCLEAR instruction is not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The VMCLEAR instruction is not recognized in compatibility mode.</td>, <td rowspan="2">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the source operand is in the CS, DS, ES, FS, or GS segments and the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing the memory operand.</td>, <td>#SS(0)</td>, <td>If the source operand is in the SS segment and the memory address is in a non-canonical form.</td>, <td rowspan="2">#UD</td>, <td>If operand is a register.</td>, <td>If not in VMX operation.</td>]

[<td>NP 0F 01 D4 VMFUNC</td>, <td>ZO</td>, <td>Invoke VM function specified in EAX.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>0F 01 C2 VMLAUNCH</td>, <td>ZO</td>, <td>Launch virtual machine managed by current VMCS<em>.</em></td>, <td>0F 01 C3 VMRESUME</td>, <td>ZO</td>, <td>Resume virtual machine managed by current VMCS<em>.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>#UD</td>, <td>If executed outside VMX operation.</td>, <td>#UD</td>, <td>The VMLAUNCH and VMRESUME instructions are not recognized in real-address mode.</td>, <td>#UD</td>, <td>The VMLAUNCH and VMRESUME instructions are not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The VMLAUNCH and VMRESUME instructions are not recognized in compatibility mode.</td>, <td>#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>#UD</td>, <td>If executed outside VMX operation.</td>]

[<td>NP 0F C7 /6 VMPTRLD m64</td>, <td>M</td>, <td>Loads the current VMCS pointer from memory<em>.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="4">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the memory source operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains an unusable segment.</td>, <td>If the source operand is located in an execute-only code segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing the memory source operand.</td>, <td rowspan="2">#SS(0)</td>, <td>If the memory source operand effective address is outside the SS segment limit.</td>, <td>If the SS register contains an unusable segment.</td>, <td rowspan="2">#UD</td>, <td>If operand is a register.</td>, <td>If not in VMX operation.</td>, <td>#UD</td>, <td>The VMPTRLD instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>The VMPTRLD instruction is not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The VMPTRLD instruction is not recognized in compatibility mode.</td>, <td rowspan="2">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the source operand is in the CS, DS, ES, FS, or GS segments and the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing the memory source operand.</td>, <td>#SS(0)</td>, <td>If the source operand is in the SS segment and the memory address is in a non-canonical form.</td>, <td rowspan="2">#UD</td>, <td>If operand is a register.</td>, <td>If not in VMX operation.</td>]

[<td>NP 0F C7 /7 VMPTRST m64</td>, <td>M</td>, <td>Stores the current VMCS pointer into memory<em>.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (w)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="4">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the memory destination operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains an unusable segment.</td>, <td>If the destination operand is located in a read-only data segment or any code segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing the memory destination operand.</td>, <td rowspan="2">#SS(0)</td>, <td>If the memory destination operand effective address is outside the SS segment limit.</td>, <td>If the SS register contains an unusable segment.</td>, <td rowspan="2">#UD</td>, <td>If operand is a register.</td>, <td>If not in VMX operation.</td>, <td>#UD</td>, <td>The VMPTRST instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>The VMPTRST instruction is not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The VMPTRST instruction is not recognized in compatibility mode.</td>, <td rowspan="2">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the destination operand is in the CS, DS, ES, FS, or GS segments and the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing the memory destination operand.</td>, <td>#SS(0)</td>, <td>If the destination operand is in the SS segment and the memory address is in a non-canonical form.</td>, <td rowspan="2">#UD</td>, <td>If operand is a register.</td>, <td>If not in VMX operation.</td>]

[<td>NP 0F 78 VMREAD r/m64, r64</td>, <td>MR</td>, <td>Reads a specified VMCS field (in 64-bit mode)<em>.</em></td>, <td>NP 0F 78 VMREAD r/m32, r32</td>, <td>MR</td>, <td>Reads a specified VMCS field (outside 64-bit mode)<em>.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>MR</td>, <td>ModRM:r/m (w)</td>, <td>ModRM:reg (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="4">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If a memory destination operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains an unusable segment.</td>, <td>If the destination operand is located in a read-only data segment or any code segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing a memory destination operand.</td>, <td rowspan="2">#SS(0)</td>, <td>If a memory destination operand effective address is outside the SS segment limit.</td>, <td>If the SS register contains an unusable segment.</td>, <td>#UD</td>, <td>If not in VMX operation.</td>, <td>#UD</td>, <td>The VMREAD instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>The VMREAD instruction is not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The VMREAD instruction is not recognized in compatibility mode.</td>, <td rowspan="2">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the memory destination operand is in the CS, DS, ES, FS, or GS segments and the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing a memory destination operand.</td>, <td>#SS(0)</td>, <td>If the memory destination operand is in the SS segment and the memory address is in a non-canonical form.</td>, <td>#UD</td>, <td>If not in VMX operation.</td>]

[<td>0F 01 C2 VMLAUNCH</td>, <td>ZO</td>, <td>Launch virtual machine managed by current VMCS<em>.</em></td>, <td>0F 01 C3 VMRESUME</td>, <td>ZO</td>, <td>Resume virtual machine managed by current VMCS<em>.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>#UD</td>, <td>If executed outside VMX operation.</td>, <td>#UD</td>, <td>The VMLAUNCH and VMRESUME instructions are not recognized in real-address mode.</td>, <td>#UD</td>, <td>The VMLAUNCH and VMRESUME instructions are not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The VMLAUNCH and VMRESUME instructions are not recognized in compatibility mode.</td>, <td>#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>#UD</td>, <td>If executed outside VMX operation.</td>]

[]

[<td>NP 0F 79 VMWRITE r64, r/m64</td>, <td>RM</td>, <td>Writes a specified VMCS field (in 64-bit mode).</td>, <td>NP 0F 79 VMWRITE r32, r/m32</td>, <td>RM</td>, <td>Writes a specified VMCS field (outside 64-bit mode).</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>RM</td>, <td>ModRM:reg (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td rowspan="4">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If a memory source operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains an unusable segment.</td>, <td>If the source operand is located in an execute-only code segment.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing a memory source operand.</td>, <td rowspan="2">#SS(0)</td>, <td>If a memory source operand effective address is outside the SS segment limit.</td>, <td>If the SS register contains an unusable segment.</td>, <td>#UD</td>, <td>If not in VMX operation.</td>, <td>#UD</td>, <td>The VMWRITE instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>The VMWRITE instruction is not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The VMWRITE instruction is not recognized in compatibility mode.</td>, <td rowspan="2">#GP(0)</td>, <td>If the current privilege level is not 0.</td>, <td>If the memory source operand is in the CS, DS, ES, FS, or GS segments and the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing a memory source operand.</td>, <td>#SS(0)</td>, <td>If the memory source operand is in the SS segment and the memory address is in a non-canonical form.</td>, <td>#UD</td>, <td>If not in VMX operation.</td>]

[<td>0F 01 C4 VMXOFF</td>, <td>ZO</td>, <td>Leaves VMX operation<em>.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>ZO</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#GP(0)</td>, <td>If executed in VMX root operation with CPL &gt; 0.</td>, <td>#UD</td>, <td>If executed outside VMX operation.</td>, <td>#UD</td>, <td>The VMXOFF instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>The VMXOFF instruction is not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The VMXOFF instruction is not recognized in compatibility mode.</td>, <td>#GP(0)</td>, <td>If executed in VMX root operation with CPL &gt; 0.</td>, <td>#UD</td>, <td>If executed outside VMX operation.</td>]

[<td>F3 0F C7 /6 VMXON m64</td>, <td>M</td>, <td>Enter VMX root operation<em>.</em></td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td rowspan="6">#GP(0)</td>, <td>If executed outside VMX operation with CPL&gt;0 or with invalid CR0 or CR4 fixed bits.</td>, <td>If executed in A20M mode.</td>, <td>If the memory source operand effective address is outside the CS, DS, ES, FS, or GS segment limit.</td>, <td>If the DS, ES, FS, or GS register contains an unusable segment.</td>, <td>If the source operand is located in an execute-only code segment.</td>, <td>If the value of the IA32_FEATURE_CONTROL MSR does not support entry to VMX operation in the current processor mode.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing the memory source operand.</td>, <td rowspan="2">#SS(0)</td>, <td>If the memory source operand effective address is outside the SS segment limit.</td>, <td>If the SS register contains an unusable segment.</td>, <td rowspan="2">#UD</td>, <td>If operand is a register.</td>, <td>If executed with CR4.VMXE = 0.</td>, <td>#UD</td>, <td>The VMXON instruction is not recognized in real-address mode.</td>, <td>#UD</td>, <td>The VMXON instruction is not recognized in virtual-8086 mode.</td>, <td>#UD</td>, <td>The VMXON instruction is not recognized in compatibility mode.</td>, <td rowspan="3">#GP(0)</td>, <td>If executed outside VMX operation with CPL &gt; 0 or with invalid CR0 or CR4 fixed bits.</td>, <td>If executed in A20M mode.</td>, <td>If the source operand is in the CS, DS, ES, FS, or GS segments and the memory address is in a non-canonical form.</td>, <td>#PF(fault-code)</td>, <td>If a page fault occurs in accessing the memory source operand.</td>, <td>#SS(0)</td>, <td>If the source operand is in the SS segment and the memory address is in a non-canonical form.</td>, <td rowspan="2">#UD</td>, <td>If operand is a register.</td>, <td>If executed with CR4.VMXE = 0.</td>]

[<td>0F 0D /2 PREFETCHWT1 m8</td>, <td>M</td>, <td>V/V</td>, <td>PREFETCHWT1</td>, <td>Move data from m8 closer to the processor using T1 hint with intent to write.</td>, <td>Op/En</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>M</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>, <td>#UD</td>, <td>If the LOCK prefix is used.</td>]

[<td>EVEX.512.F2.0F38.W0 9A /r V4FMADDPS zmm1{k1}{z}, zmm2+3, m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_4FMAPS</td>, <td>Multiply packed single-precision floating-point values from source register block indicated by zmm2 by values from m128 and accumulate the result in zmm1.</td>, <td>EVEX.512.F2.0F38.W0 AA /r V4FNMADDPS zmm1{k1}{z}, zmm2+3, m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_4FMAPS</td>, <td>Multiply and negate packed single-precision floating-point values from source register block indicated by zmm2 by values from m128 and accumulate the result in zmm1.</td>, <td>Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4</td>, <td>A Tuple1_4X ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) NA</td>, <td>#UD</td>, <td>If the EVEX broadcast bit is set to 1.</td>, <td>#UD</td>, <td>If the MODRM.mod = 0b11.</td>]

[<td>EVEX.LLIG.F2.0F38.W0 9B /r V4FMADDSS xmm1{k1}{z}, xmm2+3, m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_4FMAPS</td>, <td>Multiply scalar single-precision floating-point values from source register block indicated by xmm2 by values from m128 and accumulate the result in xmm1.</td>, <td>EVEX.LLIG.F2.0F38.W0 AB /r V4FNMADDSS xmm1{k1}{z}, xmm2+3, m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_4FMAPS</td>, <td>Multiply and negate scalar single-precision floating-point values from source register block indicated by xmm2 by values from m128 and accumulate the result in xmm1.</td>, <td>Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4</td>, <td>A Tuple1_4X ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) NA</td>, <td>#UD</td>, <td>If the EVEX broadcast bit is set to 1.</td>, <td>#UD</td>, <td>If the MODRM.mod = 0b11.</td>]

[<td>EVEX.512.F2.0F38.W0 9A /r V4FMADDPS zmm1{k1}{z}, zmm2+3, m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_4FMAPS</td>, <td>Multiply packed single-precision floating-point values from source register block indicated by zmm2 by values from m128 and accumulate the result in zmm1.</td>, <td>EVEX.512.F2.0F38.W0 AA /r V4FNMADDPS zmm1{k1}{z}, zmm2+3, m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_4FMAPS</td>, <td>Multiply and negate packed single-precision floating-point values from source register block indicated by zmm2 by values from m128 and accumulate the result in zmm1.</td>, <td>Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4</td>, <td>A Tuple1_4X ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) NA</td>, <td>#UD</td>, <td>If the EVEX broadcast bit is set to 1.</td>, <td>#UD</td>, <td>If the MODRM.mod = 0b11.</td>]

[<td>EVEX.LLIG.F2.0F38.W0 9B /r V4FMADDSS xmm1{k1}{z}, xmm2+3, m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_4FMAPS</td>, <td>Multiply scalar single-precision floating-point values from source register block indicated by xmm2 by values from m128 and accumulate the result in xmm1.</td>, <td>EVEX.LLIG.F2.0F38.W0 AB /r V4FNMADDSS xmm1{k1}{z}, xmm2+3, m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_4FMAPS</td>, <td>Multiply and negate scalar single-precision floating-point values from source register block indicated by xmm2 by values from m128 and accumulate the result in xmm1.</td>, <td>Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4</td>, <td>A Tuple1_4X ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) NA</td>, <td>#UD</td>, <td>If the EVEX broadcast bit is set to 1.</td>, <td>#UD</td>, <td>If the MODRM.mod = 0b11.</td>]

[<td>EVEX.512.66.0F38.W1 C8 /r VEXP2PD zmm1 {k1}{z}, zmm2/m512/m64bcst {sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512ER</td>, <td>Computes approximations to the exponential 2^x (with less than 2^-23 of maximum relative error) of the packed double-precision floating-point values from zmm2/m512/m64bcst and stores the floating-point result in zmm1with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NaN</td>, <td>QNaN(src)</td>, <td>If (SRC = SNaN) then #I</td>, <td>+∞</td>, <td>+∞</td>, <td></td>, <td>+/-0</td>, <td>1.0f</td>, <td><em>Exact result</em></td>, <td>-∞</td>, <td>+0.0f</td>, <td></td>, <td>Integral value N</td>, <td>2^ (N)</td>, <td><em>Exact result</em></td>]

[<td>EVEX.512.66.0F38.W0 C8 /r VEXP2PS zmm1 {k1}{z}, zmm2/m512/m32bcst {sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512ER</td>, <td>Computes approximations to the exponential 2^x (with less than 2^-23 of maximum relative error) of the packed single-precision floating-point values from zmm2/m512/m32bcst and stores the floating-point result in zmm1with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (r, w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NaN</td>, <td>QNaN(src)</td>, <td>If (SRC = SNaN) then #I</td>, <td>+∞</td>, <td>+∞</td>, <td></td>, <td>+/-0</td>, <td>1.0f</td>, <td><em>Exact result</em></td>, <td>-∞</td>, <td>+0.0f</td>, <td></td>, <td>Integral value N</td>, <td>2^ (N)</td>, <td><em>Exact result</em></td>]

[<td>EVEX.512.66.0F38.W0 C6 /1 /vsib VGATHERPF0DPS vm32z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T0 hint.</td>, <td>EVEX.512.66.0F38.W0 C7 /1 /vsib VGATHERPF0QPS vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T0 hint.</td>, <td>EVEX.512.66.0F38.W1 C6 /1 /vsib VGATHERPF0DPD vm32y {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T0 hint.</td>, <td>EVEX.512.66.0F38.W1 C7 /1 /vsib VGATHERPF0QPD vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T0 hint.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.512.66.0F38.W0 C6 /1 /vsib VGATHERPF0DPS vm32z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T0 hint.</td>, <td>EVEX.512.66.0F38.W0 C7 /1 /vsib VGATHERPF0QPS vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T0 hint.</td>, <td>EVEX.512.66.0F38.W1 C6 /1 /vsib VGATHERPF0DPD vm32y {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T0 hint.</td>, <td>EVEX.512.66.0F38.W1 C7 /1 /vsib VGATHERPF0QPD vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T0 hint.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.512.66.0F38.W0 C6 /1 /vsib VGATHERPF0DPS vm32z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T0 hint.</td>, <td>EVEX.512.66.0F38.W0 C7 /1 /vsib VGATHERPF0QPS vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T0 hint.</td>, <td>EVEX.512.66.0F38.W1 C6 /1 /vsib VGATHERPF0DPD vm32y {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T0 hint.</td>, <td>EVEX.512.66.0F38.W1 C7 /1 /vsib VGATHERPF0QPD vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T0 hint.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.512.66.0F38.W0 C6 /1 /vsib VGATHERPF0DPS vm32z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T0 hint.</td>, <td>EVEX.512.66.0F38.W0 C7 /1 /vsib VGATHERPF0QPS vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T0 hint.</td>, <td>EVEX.512.66.0F38.W1 C6 /1 /vsib VGATHERPF0DPD vm32y {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T0 hint.</td>, <td>EVEX.512.66.0F38.W1 C7 /1 /vsib VGATHERPF0QPD vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T0 hint.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.512.66.0F38.W0 C6 /2 /vsib VGATHERPF1DPS vm32z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T1 hint.</td>, <td>EVEX.512.66.0F38.W0 C7 /2 /vsib VGATHERPF1QPS vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T1 hint.</td>, <td>EVEX.512.66.0F38.W1 C6 /2 /vsib VGATHERPF1DPD vm32y {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T1 hint.</td>, <td>EVEX.512.66.0F38.W1 C7 /2 /vsib VGATHERPF1QPD vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T1 hint.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.512.66.0F38.W0 C6 /2 /vsib VGATHERPF1DPS vm32z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T1 hint.</td>, <td>EVEX.512.66.0F38.W0 C7 /2 /vsib VGATHERPF1QPS vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T1 hint.</td>, <td>EVEX.512.66.0F38.W1 C6 /2 /vsib VGATHERPF1DPD vm32y {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T1 hint.</td>, <td>EVEX.512.66.0F38.W1 C7 /2 /vsib VGATHERPF1QPD vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T1 hint.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.512.66.0F38.W0 C6 /2 /vsib VGATHERPF1DPS vm32z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T1 hint.</td>, <td>EVEX.512.66.0F38.W0 C7 /2 /vsib VGATHERPF1QPS vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T1 hint.</td>, <td>EVEX.512.66.0F38.W1 C6 /2 /vsib VGATHERPF1DPD vm32y {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T1 hint.</td>, <td>EVEX.512.66.0F38.W1 C7 /2 /vsib VGATHERPF1QPD vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T1 hint.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.512.66.0F38.W0 C6 /2 /vsib VGATHERPF1DPS vm32z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T1 hint.</td>, <td>EVEX.512.66.0F38.W0 C7 /2 /vsib VGATHERPF1QPS vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T1 hint.</td>, <td>EVEX.512.66.0F38.W1 C6 /2 /vsib VGATHERPF1DPD vm32y {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T1 hint.</td>, <td>EVEX.512.66.0F38.W1 C7 /2 /vsib VGATHERPF1QPD vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T1 hint.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.512.F2.0F38.W0 52 /r VP4DPWSSD zmm1{k1}{z}, zmm2+3, m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_4VNNIW</td>, <td>Multiply signed words from source register block indicated by zmm2 by signed words from m128 and accumulate resulting signed dwords in zmm1.</td>, <td>Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4</td>, <td>A Tuple1_4X ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) NA</td>, <td>#UD</td>, <td>If the EVEX broadcast bit is set to 1.</td>, <td>#UD</td>, <td>If the MODRM.mod = 0b11.</td>]

[<td>EVEX.512.F2.0F38.W0 53 /r VP4DPWSSDS zmm1{k1}{z}, zmm2+3, m128</td>, <td>A</td>, <td>V/V</td>, <td>AVX512_4VNNIW</td>, <td>Multiply signed words from source register block indicated by zmm2 by signed words from m128 and accumulate the resulting dword results with signed saturation in zmm1.</td>, <td>Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4</td>, <td>A Tuple1_4X ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) NA</td>, <td>#UD</td>, <td>If the EVEX broadcast bit is set to 1.</td>, <td>#UD</td>, <td>If the MODRM.mod = 0b11.</td>]

[<td>EVEX.512.66.0F38.W1 CA /r VRCP28PD zmm1 {k1}{z}, zmm2/m512/m64bcst {sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512ER</td>, <td>Computes the approximate reciprocals ( &lt; 2^-28 relative error) of the packed double-precision floating-point values in zmm2/m512/m64bcst and stores the results in zmm1. Under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NAN</td>, <td>QNAN(input)</td>, <td>If (SRC = SNaN) then #I</td>, <td><sub>0 ≤ X &lt; 2</sub><sup>-1022</sup></td>, <td>INF</td>, <td>Positive input denormal or zero; #Z</td>, <td>-2<sup>-1022</sup> &lt; X ≤ -0</td>, <td>-INF</td>, <td>Negative input denormal or zero; #Z</td>, <td><sub>X &gt; 2</sub>1022</td>, <td>+0.0f</td>, <td></td>, <td><sub>X &lt; -2</sub><sup>1022</sup></td>, <td>-0.0f</td>, <td></td>, <td>X = +∞</td>, <td>+0.0f</td>, <td></td>, <td>X = -∞</td>, <td>-0.0f</td>, <td></td>, <td><sub>X = 2</sub>-n</td>, <td><sub>2</sub><sup>n</sup></td>, <td>Exact result (unless input/output is a denormal)</td>, <td>X = -2<sup>-n</sup></td>, <td>-2<sup>n</sup></td>, <td>Exact result (unless input/output is a denormal)</td>]

[<td>EVEX.512.66.0F38.W0 CA /r VRCP28PS zmm1 {k1}{z}, zmm2/m512/m32bcst {sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512ER</td>, <td>Computes the approximate reciprocals ( &lt; 2^-28 relative error) of the packed single-precision floating-point values in zmm2/m512/m32bcst and stores the results in zmm1. Under writemask.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NAN</td>, <td>QNAN(input)</td>, <td>If (SRC = SNaN) then #I</td>, <td><sub>0 ≤ X &lt; 2</sub><sup>-126</sup></td>, <td>INF</td>, <td>Positive input denormal or zero; #Z</td>, <td>-2<sup>-126</sup> &lt; X ≤ -0</td>, <td>-INF</td>, <td>Negative input denormal or zero; #Z</td>, <td>X &gt; 2<sup>126</sup></td>, <td>+0.0f</td>, <td></td>, <td>X &lt; -2<sup>126</sup></td>, <td>-0.0f</td>, <td></td>, <td>X = +∞</td>, <td>+0.0f</td>, <td></td>, <td>X = -∞</td>, <td>-0.0f</td>, <td></td>, <td><sub>X = 2</sub>-n</td>, <td><sub>2</sub><sup>n</sup></td>, <td>Exact result (unless input/output is a denormal)</td>, <td>X = -2<sup>-n</sup></td>, <td>-2<sup>n</sup></td>, <td>Exact result (unless input/output is a denormal)</td>]

[<td>EVEX.LIG.66.0F38.W1 CB /r VRCP28SD xmm1 {k1}{z}, xmm2, xmm3/m64 {sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512ER</td>, <td>Computes the approximate reciprocal ( &lt; 2^-28 relative error) of the scalar double-precision floating-point value in xmm3/m64 and stores the results in xmm1. Under writemask. Also, upper double-precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64].</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NAN</td>, <td>QNAN(input)</td>, <td>If (SRC = SNaN) then #I</td>, <td><sub>0 ≤ X &lt; 2</sub><sup>-1022</sup></td>, <td>INF</td>, <td>Positive input denormal or zero; #Z</td>, <td>-2<sup>-1022</sup> &lt; X ≤ -0</td>, <td>-INF</td>, <td>Negative input denormal or zero; #Z</td>, <td><sub>X &gt; 2</sub>1022</td>, <td>+0.0f</td>, <td></td>, <td><sub>X &lt; -2</sub><sup>1022</sup></td>, <td>-0.0f</td>, <td></td>, <td>X = +∞</td>, <td>+0.0f</td>, <td></td>, <td>X = -∞</td>, <td>-0.0f</td>, <td></td>, <td><sub>X = 2</sub>-n</td>, <td><sub>2</sub><sup>n</sup></td>, <td>Exact result (unless input/output is a denormal)</td>, <td>X = -2<sup>-n</sup></td>, <td>-2<sup>n</sup></td>, <td>Exact result (unless input/output is a denormal)</td>]

[<td>EVEX.LIG.66.0F38.W0 CB /r VRCP28SS xmm1 {k1}{z}, xmm2, xmm3/m32 {sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512ER</td>, <td>Computes the approximate reciprocal ( &lt; 2^-28 relative error) of the scalar single-precision floating-point value in xmm3/m32 and stores the results in xmm1. Under writemask. Also, upper 3 single-precision floating-point values (bits[127:32]) from xmm2 is copied to xmm1[127:32].</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NAN</td>, <td>QNAN(input)</td>, <td>If (SRC = SNaN) then #I</td>, <td><sub>0 ≤ X &lt; 2</sub><sup>-126</sup></td>, <td>INF</td>, <td>Positive input denormal or zero; #Z</td>, <td>-2<sup>-126</sup> &lt; X ≤ -0</td>, <td>-INF</td>, <td>Negative input denormal or zero; #Z</td>, <td>X &gt; 2<sup>126</sup></td>, <td>+0.0f</td>, <td></td>, <td>X &lt; -2<sup>126</sup></td>, <td>-0.0f</td>, <td></td>, <td>X = +∞</td>, <td>+0.0f</td>, <td></td>, <td>X = -∞</td>, <td>-0.0f</td>, <td></td>, <td><sub>X = 2</sub>-n</td>, <td><sub>2</sub><sup>n</sup></td>, <td>Exact result (unless input/output is a denormal)</td>, <td>X = -2<sup>-n</sup></td>, <td>-2<sup>n</sup></td>, <td>Exact result (unless input/output is a denormal)</td>]

[<td>EVEX.512.66.0F38.W1 CC /r VRSQRT28PD zmm1 {k1}{z}, zmm2/m512/m64bcst {sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512ER</td>, <td>Computes approximations to the Reciprocal square root (&lt;2^-28 relative error) of the packed double-precision floating-point values from zmm2/m512/m64bcst and stores result in zmm1with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NAN</td>, <td>QNAN(input)</td>, <td>If (SRC = SNaN) then #I</td>, <td>X = 2<sup>-2n</sup></td>, <td><sub>2</sub><sup>n</sup></td>, <td></td>, <td>X&lt;0</td>, <td>QNaN_Indefinite</td>, <td>Including -INF</td>, <td>X = -0 or negative denormal</td>, <td>-INF</td>, <td>#Z</td>, <td>X = +0 or positive denormal</td>, <td>+INF</td>, <td>#Z</td>, <td>X = +INF</td>, <td>+0</td>, <td></td>]

[<td>EVEX.512.66.0F38.W0 CC /r VRSQRT28PS zmm1 {k1}{z}, zmm2/m512/m32bcst {sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512ER</td>, <td>Computes approximations to the Reciprocal square root (&lt;2^-28 relative error) of the packed single-precision floating-point values from zmm2/m512/m32bcst and stores result in zmm1with writemask k1.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Full</td>, <td>ModRM:reg (w)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NA</td>, <td>NAN</td>, <td>QNAN(input)</td>, <td>If (SRC = SNaN) then #I</td>, <td>X = 2<sup>-2n</sup></td>, <td><sub>2</sub><sup>n</sup></td>, <td></td>, <td>X&lt;0</td>, <td>QNaN_Indefinite</td>, <td>Including -INF</td>, <td>X = -0 or negative denormal</td>, <td>-INF</td>, <td>#Z</td>, <td>X = +0 or positive denormal</td>, <td>+INF</td>, <td>#Z</td>, <td>X = +INF</td>, <td>+0</td>, <td></td>]

[<td>EVEX.LIG.66.0F38.W1 CD /r VRSQRT28SD xmm1 {k1}{z}, xmm2, xmm3/m64 {sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512ER</td>, <td>Computes approximate reciprocal square root (&lt;2^-28 relative error) of the scalar double-precision floating-point value from xmm3/m64 and stores result in xmm1with writemask k1. Also, upper double-precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64].</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NAN</td>, <td>QNAN(input)</td>, <td>If (SRC = SNaN) then #I</td>, <td>X = 2<sup>-2n</sup></td>, <td><sub>2</sub><sup>n</sup></td>, <td></td>, <td>X&lt;0</td>, <td>QNaN_Indefinite</td>, <td>Including -INF</td>, <td>X = -0 or negative denormal</td>, <td>-INF</td>, <td>#Z</td>, <td>X = +0 or positive denormal</td>, <td>+INF</td>, <td>#Z</td>, <td>X = +INF</td>, <td>+0</td>, <td></td>]

[<td>EVEX.LIG.66.0F38.W0 CD /r VRSQRT28SS xmm1 {k1}{z}, xmm2, xmm3/m32 {sae}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512ER</td>, <td>Computes approximate reciprocal square root (&lt;2^-28 relative error) of the scalar single-precision floating-point value from xmm3/m32 and stores result in xmm1with writemask k1. Also, upper 3 single-precision floating-point value (bits[127:32]) from xmm2 is copied to xmm1[127:32].</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>ModRM:reg (w)</td>, <td>EVEX.vvvv (r)</td>, <td>ModRM:r/m (r)</td>, <td>NA</td>, <td>NAN</td>, <td>QNAN(input)</td>, <td>If (SRC = SNaN) then #I</td>, <td>X = 2<sup>-2n</sup></td>, <td><sub>2</sub><sup>n</sup></td>, <td></td>, <td>X&lt;0</td>, <td>QNaN_Indefinite</td>, <td>Including -INF</td>, <td>X = -0 or negative denormal</td>, <td>-INF</td>, <td>#Z</td>, <td>X = +0 or positive denormal</td>, <td>+INF</td>, <td>#Z</td>, <td>X = +INF</td>, <td>+0</td>, <td></td>]

[<td>EVEX.512.66.0F38.W0 C6 /5 /vsib VSCATTERPF0DPS vm32z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T0 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W0 C7 /5 /vsib VSCATTERPF0QPS vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T0 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W1 C6 /5 /vsib VSCATTERPF0DPD vm32y {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T0 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W1 C7 /5 /vsib VSCATTERPF0QPD vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T0 hint with intent to write.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.512.66.0F38.W0 C6 /5 /vsib VSCATTERPF0DPS vm32z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T0 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W0 C7 /5 /vsib VSCATTERPF0QPS vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T0 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W1 C6 /5 /vsib VSCATTERPF0DPD vm32y {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T0 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W1 C7 /5 /vsib VSCATTERPF0QPD vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T0 hint with intent to write.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.512.66.0F38.W0 C6 /5 /vsib VSCATTERPF0DPS vm32z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T0 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W0 C7 /5 /vsib VSCATTERPF0QPS vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T0 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W1 C6 /5 /vsib VSCATTERPF0DPD vm32y {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T0 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W1 C7 /5 /vsib VSCATTERPF0QPD vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T0 hint with intent to write.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.512.66.0F38.W0 C6 /5 /vsib VSCATTERPF0DPS vm32z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T0 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W0 C7 /5 /vsib VSCATTERPF0QPS vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T0 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W1 C6 /5 /vsib VSCATTERPF0DPD vm32y {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T0 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W1 C7 /5 /vsib VSCATTERPF0QPD vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T0 hint with intent to write.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.512.66.0F38.W0 C6 /6 /vsib VSCATTERPF1DPS vm32z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T1 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W0 C7 /6 /vsib VSCATTERPF1QPS vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T1 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W1 C6 /6 /vsib VSCATTERPF1DPD vm32y {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T1 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W1 C7 /6 /vsib VSCATTERPF1QPD vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T1 hint with intent to write.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.512.66.0F38.W0 C6 /6 /vsib VSCATTERPF1DPS vm32z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T1 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W0 C7 /6 /vsib VSCATTERPF1QPS vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T1 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W1 C6 /6 /vsib VSCATTERPF1DPD vm32y {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T1 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W1 C7 /6 /vsib VSCATTERPF1QPD vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T1 hint with intent to write.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.512.66.0F38.W0 C6 /6 /vsib VSCATTERPF1DPS vm32z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T1 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W0 C7 /6 /vsib VSCATTERPF1QPS vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T1 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W1 C6 /6 /vsib VSCATTERPF1DPD vm32y {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T1 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W1 C7 /6 /vsib VSCATTERPF1QPD vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T1 hint with intent to write.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[<td>EVEX.512.66.0F38.W0 C6 /6 /vsib VSCATTERPF1DPS vm32z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T1 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W0 C7 /6 /vsib VSCATTERPF1QPS vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T1 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W1 C6 /6 /vsib VSCATTERPF1DPD vm32y {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T1 hint with intent to write.</td>, <td>EVEX.512.66.0F38.W1 C7 /6 /vsib VSCATTERPF1QPD vm64z {k1}</td>, <td>A</td>, <td>V/V</td>, <td>AVX512PF</td>, <td>Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T1 hint with intent to write.</td>, <td>Op/En</td>, <td>Tuple Type</td>, <td>Operand 1</td>, <td>Operand 2</td>, <td>Operand 3</td>, <td>Operand 4</td>, <td>A</td>, <td>Tuple1 Scalar</td>, <td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>, <td>NA</td>, <td>NA</td>, <td>NA</td>]

[]
